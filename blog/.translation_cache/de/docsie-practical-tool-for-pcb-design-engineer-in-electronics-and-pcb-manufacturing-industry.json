{
    "__metadata__": {
        "original_categories": [
            "Knowledge Base",
            "SaaS",
            ""
        ],
        "author_name": "S. George",
        "author_email": "stanley@docsie.io",
        "author_info": "Stanley is on a mission to make SaaS products and people BFFs.",
        "author_image": "https://cdn.docsie.io/workspace_PxAvC1Uenuc7ad6H3/doc_itfnAdVnFfpYmEz80/file_oUUh3WJyvJLA5if1O/1732795947959_5612b0f9-ba65-0759-6acf-ccaa5c6303b3.jpg",
        "header_image": "https://cdn.docsie.io/workspace_PxAvC1Uenuc7ad6H3/doc_wn84Jkoc6hIMTO2eE/file_3AvJVPeR6RCB2bG1R/6_07cc3147-db94-88d0-5b0d-1ca79c6443fe.jpg",
        "timestamp": "2024-08-05T16:06:51+00:00",
        "status": 1
    },
    "docsie-practical-tool-for-pcb-design-eng|title": "Leiterplattendesign-Dokumentationstools 2025 | Kollaborativer Leitfaden zur Leiterplattenherstellung | Elektronikingenieure DevOps-Teams | Wissensmanagementlösungen Vorlagen | Leiterplattendesign-Workflow",
    "docsie-practical-tool-for-pcb-design-eng|display_title": "Wie PCB-Ingenieure intelligente Dokumentation für bessere Designs nutzen",
    "docsie-practical-tool-for-pcb-design-eng|summary": "Erforschen Sie, wie Docsie PCB-Design-Ingenieuren in der Elektronik- und Leiterplattenfertigungsbranche mit optimierten Designprozessen und effizienter Zusammenarbeit hilft.",
    "docsie-practical-tool-for-pcb-design-eng|markdown": "# Die Rolle des Leiterplatten-Design-Ingenieurs in der Elektronik- und Leiterplattenfertigungsindustrie\n\nHaben Sie sich schon einmal überlegt, wie Leiterplatten-Design-Ingenieure zur Elektronik- und Fertigungsindustrie beitragen? Ihre Arbeit beim Entwerfen von Leiterplatten (PCBs) ist entscheidend für die Entwicklung elektronischer Geräte. Als Grundlage für die meisten elektronischen Geräte gewährleistet ein durchdachtes Leiterplattendesign, dass ein Produkt effizient und zuverlässig funktioniert. Leiterplatten-Design-Ingenieure verwandeln Ideen in funktionsfähige, herstellbare und zuverlässige Leiterplatten. Dieser Artikel beleuchtet die wichtige Rolle dieser Ingenieure in der Elektronik- und Leiterplattenfertigungsindustrie, die Herausforderungen bei der Dokumentation und wie Docsie effektive Lösungen bietet.\n\n## Rolle eines Leiterplatten-Design-Ingenieurs in der Elektronik- und Leiterplattenfertigungsindustrie\n\nLeiterplatten-Design-Ingenieure übernehmen vielfältige Aufgaben innerhalb der **Elektronik- und Leiterplattenfertigungsindustrie**. Ihre Hauptaufgabe ist das Entwerfen, Entwickeln und Optimieren von Leiterplatten für verschiedene elektronische Geräte – von Smartphones bis hin zu Automobilsystemen. Ihre Arbeit ist wesentlich für die effiziente und sichere Funktion elektronischer Geräte, da die Leiterplatte als elektronisches Fundament dient und verschiedenen Komponenten die Interaktion ermöglicht.\n\n1. **Design und Layout von Leiterplatten:** Leiterplatten-Design-Ingenieure nutzen spezielle Software-Tools (wie Altium Designer, Eagle oder KiCAD), um das Layout einer Leiterplatte zu entwerfen. Sie platzieren Komponenten, verlegen Leiterbahnen und definieren die Schichtstruktur, um spezifische elektrische und mechanische Anforderungen zu erfüllen.\n\n2. **Prototyping und Testen:** Nach dem Entwurf arbeiten die Ingenieure mit Prototyping-Teams zusammen, um eine physische Leiterplatte zu erstellen. Anschließend testen sie diese auf Funktionalität und identifizieren mögliche Designfehler, bevor die Massenproduktion beginnt.\n\n3. **Sicherstellung der Konformität:** Leiterplatten-Design-Ingenieure müssen sicherstellen, dass ihre Entwürfe Industriestandards und Zertifizierungen wie IPC-Standards, UL-Zertifizierungen oder spezifische regulatorische Anforderungen verschiedener Märkte erfüllen. Die Einhaltung dieser Standards gewährleistet Zuverlässigkeit, Sicherheit und Leistung des Endprodukts.\n\n4. **Zusammenarbeit mit funktionsübergreifenden Teams:** Sie arbeiten mit Elektro- und Maschinenbauingenieuren sowie anderen Stakeholdern zusammen, um eine nahtlose Integration des Designs in das Gesamtsystem zu gewährleisten. Zudem kooperieren sie eng mit Fertigungsteams, um die Herstellbarkeit und Kosteneffizienz des Designs sicherzustellen.\n\n5. **Dokumentation und Berichterstattung:** Ein entscheidender, aber oft herausfordernder Aspekt ist die gründliche Dokumentation. Ingenieure sind verantwortlich für die Erstellung und Pflege detaillierter Designdateien, Schaltpläne und Layouts, die als Blaupause für die Fertigung und zukünftige Überarbeitungen dienen.\n\n## Dokumentationsbezogene Herausforderungen für Leiterplatten-Design-Ingenieure\n\nDie Dokumentation ist ein Grundpfeiler des Leiterplatten-Designprozesses. Sie gewährleistet klare Kommunikation zwischen Teams, einen reibungslosen Übergang von der Entwicklung zur Produktion und nahtlose langfristige Unterstützung. Allerdings kann die Erstellung, Organisation und Pflege genauer Dokumentation herausfordernd sein. Hier sind die häufigsten dokumentationsbezogenen Herausforderungen:\n\n1. **Versionskontrolle:** Mit der Weiterentwicklung von Designs kann die Nachverfolgung verschiedener Iterationen und Versionen komplex werden. Ingenieure müssen einen Änderungsverlauf führen und sicherstellen, dass immer auf die aktuellste Version zugegriffen wird, um Fehler durch veraltete Dateien zu vermeiden.\n\n2. **Zusammenarbeit und Wissensaustausch:** Leiterplattendesigns erfordern oft teamübergreifende Zusammenarbeit. Die Koordination von Änderungen, die Zusammenführung von Feedback und der Zugriff aller Beteiligten auf die neuesten Dokumente kann schwierig sein, besonders bei großen Teams an verschiedenen Standorten.\n\n3. **Wiederverwendbarkeit und Standardisierung:** Ingenieure müssen wiederverwendbare Designelemente (wie Standardkomponenten oder Schaltungen) erstellen und Dokumentationspraktiken standardisieren, um zukünftige Projekte zu optimieren. Ohne geeignete Dokumentationsstrukturen ist es schwierig, frühere Arbeiten effizient zu nutzen.\n\n4. **Komplexität technischer Dokumentation:** Die Dokumentation von Leiterplattendesigns erfordert äußerste Detailgenauigkeit bei Komponentenspezifikationen, Verdrahtungsdiagrammen, Montageanweisungen und Simulationsergebnissen. Die Organisation all dieser Informationen kann besonders bei komplexen Designs umständlich sein.\n\n5. **Compliance- und Regulierungsdokumentation:** Viele Leiterplattendesigns müssen spezifische Branchenstandards oder behördliche Anforderungen erfüllen. Die Verwaltung dieser Dokumente – wie Zertifikate, Testergebnisse und Compliance-Formulare – unter Wahrung von Vertraulichkeit und Zugänglichkeit kann eine Herausforderung darstellen.\n\n6. **Dokumentationspflege für langfristigen Support:** Auch nach der Designphase ist eine präzise Dokumentation für Fehlerbehebung, zukünftige Überarbeitungen oder Reparaturen entscheidend. Ingenieure müssen sicherstellen, dass Dokumente regelmäßig aktualisiert werden und für künftige Teams zugänglich bleiben.\n\n## Lösung von Docsie\n\nDocsie bietet eine umfassende Lösung für die Herausforderungen von Leiterplatten-Design-Ingenieuren, besonders bei der Organisation und Pflege technischer Dokumentation. Mit Docsies Plattform können Ingenieure die Erstellung, Verwaltung und Freigabe von PCB-Design-Dokumentation optimieren.\n\n![](https://cdn.docsie.io/workspace_PxAvC1Uenuc7ad6H3/doc_wn84Jkoc6hIMTO2eE/file_gejSDBalG6XIlaugg/image_28affdea-4c17-8b5d-5089-d055c22576a6.jpg)\n\n1. **Zentrales Dokumentations-Hub:** Docsie ermöglicht Ingenieuren, ein zentrales Repository für alle PCB-Design-Dateien einzurichten, einschließlich Schaltpläne, Layouts, Testergebnisse und Compliance-Zertifikate. Dies stellt sicher, dass alle Beteiligten Zugriff auf die aktuellsten Dokumente haben.\n\n2. **Versionskontrolle und Änderungsmanagement:** Docsie unterstützt Versionskontrolle, sodass Ingenieure Änderungen verfolgen, verschiedene Dokumentversionen vergleichen und bei Bedarf zu früheren Versionen zurückkehren können. Dies gewährleistet, dass stets die genauesten und aktuellsten Informationen verfügbar sind.\n\n3. **Zusammenarbeit und Feedback-Integration:** Docsie ermöglicht Echtzeit-Zusammenarbeit, sodass mehrere Teammitglieder Dokumente kommentieren, bearbeiten und teilen können, ohne Kommunikationsprobleme zu riskieren. Dies hilft Ingenieuren, Feedback effizienter zu sammeln und Änderungen umgehend umzusetzen.\n\n4. **Standardisierte Vorlagen und wiederverwendbare Komponenten:** Docsie bietet vorgefertigte Vorlagen und Tools zur Erstellung standardisierter Design-Dokumentation, was Konsistenz gewährleistet und Fehler reduziert. Ingenieure können auch Bibliotheken wiederverwendbarer Komponenten anlegen, um zukünftige Designs zu optimieren.\n\n5. **Compliance-Tracking:** Docsie unterstützt Ingenieure bei der Verwaltung compliance-bezogener Dokumente und stellt sicher, dass alle notwendigen Zertifikate, Testergebnisse und regulatorischen Dokumente gespeichert und leicht zugänglich sind. Dies ist besonders hilfreich bei strengen Branchenstandards und Zertifizierungen.\n\n6. **Cloud-Speicher und Zugänglichkeit:** Mit Docsies cloudbasierter Lösung können Leiterplatten-Design-Ingenieure von überall auf ihre Dokumentation zugreifen und arbeiten stets mit der aktuellsten Version ihrer Designdateien. Dies verbessert die Effizienz, besonders bei der Zusammenarbeit mit entfernten Teams.\n\n7. **Sicherheit und Kontrolle:** Docsie gewährleistet, dass sensible Design-Informationen sicher gespeichert und nur mit autorisierten Personen geteilt werden. Mit anpassbaren Berechtigungseinstellungen behalten Ingenieure die Kontrolle darüber, wer Zugriff auf ihre Designs und Dokumentationen hat.\n\n## Erfolgsgeschichte eines Kunden\n\nEin Docsie-Kunde, ein globales Elektronikunternehmen, stand vor der Herausforderung, die Dokumentation für sein umfangreiches Portfolio an Leiterplattendesigns aktuell zu halten. Mit Teams auf mehreren Kontinenten war die Zusammenarbeit bei Design-Iterationen und der Zugriff aller Beteiligten auf die neueste Dokumentenversion ein zeitaufwändiger und fehleranfälliger Prozess.\n\nDurch die Implementierung von Docsies Dokumentationsmanagement-Plattform konnte das Unternehmen seinen Design-Dokumentationsprozess optimieren. Das Team nutzte Funktionen für Versionskontrolle und Echtzeit-Zusammenarbeit, was den Zeitaufwand für Dokumentenmanagement erheblich reduzierte. Ingenieure konnten nun schnell Änderungen verfolgen, Design-Iterationen vergleichen und mit funktionsübergreifenden Teams zusammenarbeiten, ohne veraltete Dateien zu riskieren.\n\nZusätzlich ermöglichten die standardisierten Vorlagen von Docsie dem Unternehmen, konsistente und wiederverwendbare Design-Dokumentation zu erstellen. Compliance-Tracking-Funktionen stellten sicher, dass regulatorische Dokumente stets organisiert und zugänglich waren, was die Einhaltung von Branchenstandards und Zertifizierungen erleichterte.\n\nDas Ergebnis: Das Unternehmen verbesserte seine Markteinführungszeit für neue Designs, reduzierte durch Kommunikationsprobleme verursachte Fehler und steigerte seine Gesamteffizienz beim Management von Leiterplatten-Design-Projekten.\n\n## Fazit\n\nDie Rolle eines **Leiterplatten-Design-Ingenieurs** ist entscheidend für den Erfolg der Elektronik- und Leiterplattenfertigungsindustrie. Mit zunehmender Komplexität und Innovation in der Branche wird der Bedarf an effizienter, präziser und kollaborativer Dokumentation immer wichtiger. Herausforderungen wie Versionskontrolle, Wissensaustausch und Compliance können den Fortschritt behindern, wenn sie nicht effektiv gemanagt werden.\n\nDocsie bietet eine robuste Lösung für diese Herausforderungen durch eine zentralisierte Dokumentationsplattform, nahtlose Zusammenarbeit und umfassende Versionskontrolle. Mit Docsie können sich Leiterplatten-Design-Ingenieure auf ihre Kernkompetenz konzentrieren – die Erstellung zuverlässiger, funktionaler und innovativer Leiterplatten – während sie gleichzeitig sicherstellen, dass ihre Dokumentation organisiert, präzise und konform ist.",
    "docsie-practical-tool-for-pcb-design-eng|category|0": "Wissensbasis",
    "docsie-practical-tool-for-pcb-design-eng|category|1": "Software als Dienst",
    "docsie-practical-tool-for-pcb-design-eng|learning_objective|0": "Verstehen Sie die Kernverantwortlichkeiten und Arbeitsabläufe von Leiterplattendesigningenieuren in der Elektronikfertigung",
    "docsie-practical-tool-for-pcb-design-eng|learning_objective|1": "Identifizieren Sie gängige Dokumentationsherausforderungen im PCB-Design, einschließlich Versionskontrolle und Zusammenarbeitsprobleme",
    "docsie-practical-tool-for-pcb-design-eng|learning_objective|2": "Lernen Sie, wie Sie effektive Dokumentationsstrategien für Leiterplattendesign-Projekte umsetzen können\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini-api/reference/files-response.md\n# Create a multimodal response\n\nThis tutorial shows how to display an image returned from Gemini in a Python notebook.\n\n## Get started with files\n\nFirst, you need to install the required packages:\n\n```python\n!pip install -q google-generativeai PIL\n```\n\nYou also need to set up your API key:\n\n```python\nimport os\nimport google.generativeai as genai\nimport PIL.Image\n\n# Set up the API key\napi_key = \"YOUR_API_KEY\"\ngenai.configure(api_key=api_key)\n```\n\n## Use model to generate images\n\nLet's use Gemini 1.5 Pro to generate an image of a squirrel holding an acorn:\n\n```python\nmodel = genai.GenerativeModel('gemini-1.5-pro')\nresponse = model.generate_content(\"Create an image of a cute squirrel holding an acorn\")\n```\n\n## Display generated images\n\nNow, let's extract and display the image from the response:\n\n```python\nimage_bytes = response.candidates[0].content.parts[0].file_data.file_bytes\nwith open(\"squirrel.png\", \"wb\") as f:\n    f.write(image_bytes)\n\n# Display the image\nfrom IPython.display import Image, display\ndisplay(Image(\"squirrel.png\"))\n```\n\nThis code:\n1. Extracts the image bytes from the response\n2. Saves the image to a file\n3. Displays the image in the notebook\n\n## Complete example\n\nHere's a complete example that generates and displays an image:\n\n```python\nimport os\nimport google.generativeai as genai\nfrom IPython.display import Image, display\n\n# Set up the API key\napi_key = \"YOUR_API_KEY\"  # Replace with your actual API key\ngenai.configure(api_key=api_key)\n\n# Generate an image\nmodel = genai.GenerativeModel('gemini-1.5-pro')\nresponse = model.generate_content(\"Create an image of a cute squirrel holding an acorn\")\n\n# Save and display the image\nimage_bytes = response.candidates[0].content.parts[0].file_data.file_bytes\nwith open(\"squirrel.png\", \"wb\") as f:\n    f.write(image_bytes)\n\ndisplay(Image(\"squirrel.png\"))\n```\n\nNow you know how to generate and display images from Gemini models in your Python notebooks!\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini-api/docs/models/safety-settings.md\n# Safety settings\n\nThis document explains how to configure safety settings when using Vertex AI Gemini API.\n\nGemini can generate harmful, misleading, or untruthful responses. You should define safeguards appropriate to your use cases. Safety settings help mitigate the risks.\n\n## Safety attribute categories\n\nSafety attribute categories identify different types of harmful content:\n\n| Harm category | Description |\n|---------------|-------------|\n| `HARM_CATEGORY_HATE_SPEECH` | Negative or harmful comments targeting identity and/or protected attributes |\n| `HARM_CATEGORY_DANGEROUS_CONTENT` | Content that promotes, facilitates, or encourages harmful acts |\n| `HARM_CATEGORY_HARASSMENT` | Content that refers to someone other than the user in a harmful way |\n| `HARM_CATEGORY_SEXUALLY_EXPLICIT` | Contains references to sexual acts or other lewd content |\n\n## Threshold settings\n\nFor each harm category, you can set a threshold that determines when content is blocked:\n\n| Threshold | Description |\n|-----------|-------------|\n| `BLOCK_NONE` | Block no content (least restrictive, has highest risk) |\n| `BLOCK_ONLY_HIGH` | Block only content with high severity rating |\n| `BLOCK_MEDIUM_AND_ABOVE` | Block content with medium or high severity rating |\n| `BLOCK_LOW_AND_ABOVE` | Block all content (most restrictive, has lowest risk) |\n\n## Default settings\n\nThese are the default safety settings for all Gemini models:\n\n| Harm category | Default threshold |\n|---------------|-------------------|\n| `HARM_CATEGORY_HATE_SPEECH` | `BLOCK_MEDIUM_AND_ABOVE` |\n| `HARM_CATEGORY_DANGEROUS_CONTENT` | `BLOCK_MEDIUM_AND_ABOVE` |\n| `HARM_CATEGORY_HARASSMENT` | `BLOCK_MEDIUM_AND_ABOVE` |\n| `HARM_CATEGORY_SEXUALLY_EXPLICIT` | `BLOCK_MEDIUM_AND_ABOVE` |\n\n## Setting safety thresholds\n\nSafety settings can be set via both the Vertex AI SDK and REST API:\n\n### Python (SDK)\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold\n\n# Set up your model\nmodel = GenerativeModel(\"gemini-pro\")\n\n# Configure safety settings\nsafety_settings = {\n    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n}\n\n# Generate content with custom safety settings\nresponse = model.generate_content(\n    \"Tell me about the history of the internet\",\n    safety_settings=safety_settings\n)\n```\n\n### REST API\n\n```bash\nPROJECT_ID=your-project-id\nLOCATION=us-central1\nMODEL_ID=gemini-pro\n\ncurl -X POST \\\n    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n    -H \"Content-Type: application/json\" \\\n    https://${LOCATION}-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n    -d '{\n      \"contents\": [\n        {\n          \"role\": \"user\",\n          \"parts\": [\n            {\n              \"text\": \"Tell me about the history of the internet\"\n            }\n          ]\n        }\n      ],\n      \"safety_settings\": [\n        {\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n          \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n        }\n      ]\n    }'\n```\n\n## Safety in responses\n\nIf content is blocked, you'll receive a safety rating and the response will be blocked:\n\n```python\nprint(response.candidates[0].finish_reason)\n# SAFETY\n\nprint(response.candidates[0].safety_ratings)\n# [\n#   {\n#     category: HARM_CATEGORY_DANGEROUS,\n#     probability: MEDIUM,\n#     blocked: true\n#   }\n# ]\n```\n\n## Best practices\n\n1. **Tailor safety settings to your use case**: Adjust thresholds based on your application's audience and context.\n2. **Handle blocked responses gracefully**: Implement appropriate UI messages when content is blocked.\n3. **Test extensively**: Try various inputs to understand how safety settings affect your application.\n4. **Monitor and adapt**: Continuously evaluate safety performance and adjust as needed.\n\n## Next steps\n\n- Review the [safety settings reference](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#safety-settings)\n- Learn more about [responsible AI practices](https://cloud.google.com/responsible-ai)\n\u0005End File\u0006# google/generative-ai-docs\n# samples/gemini/javascript/notebook/embedModel.ipynb\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"4uRhYXSUgMUu\"\n      },\n      \"source\": [\n        \"# Embedding models (embedding-001)\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini/docs/embeddings.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"K_c63BUjgMUx\"\n      },\n      \"source\": [\n        \"## Setup\\n\",\n        \"\\n\",\n        \"### Install dependencies and download UMAP for visualization\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"cR6NVfcugMUx\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"import glob\\n\",\n        \"import numpy as np\\n\",\n        \"import os\\n\",\n        \"import random\\n\",\n        \"import re\\n\",\n        \"import requests\\n\",\n        \"import time\\n\",\n        \"import json\\n\",\n        \"\\n\",\n        \"!pip install -q @google/generative-ai\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"jt6QrH8JgMUy\"\n      },\n      \"source\": [\n        \"### Set API Key\\n\",\n        \"\\n\",\n        \"1. Create a Makersuite API key at https://makersuite.google.com/app/apikey\\n\",\n        \"2. Set the key below\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"hk7hx1kKgMUy\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"const { GoogleGenerativeAI } = require(\\\"@google/generative-ai\\\");\\n\",\n        \"\\n\",\n        \"// Fetch your API_KEY from the environment\\n\",\n        \"const API_KEY = process.env.API_KEY || \\\"YOUR_API_KEY\\\";\\n\",\n        \"if (!API_KEY || API_KEY === \\\"YOUR_API_KEY\\\") {\\n\",\n        \"  throw new Error(\\\"Please set your API key in the API_KEY environment variable.\\\");\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"// Initialize the Google Generative AI library with your API key\\n\",\n        \"const genAI = new GoogleGenerativeAI(API_KEY);\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"O2trsxuMgMUz\"\n      },\n      \"source\": [\n        \"## Getting Started\\n\",\n        \"\\n\",\n        \"[Embeddings](https://developers.generativeai.google/guide/embeddings_guide) convert text (and eventually other types of data) into a numerical vector representation that captures semantic meaning.\\n\",\n        \"\\n\",\n        \"The current approach to using the Google Gemini API is to create embeddings with the `embedding-001` model and feed them to a vector matching solution like [Chroma](https://www.trychroma.com/) or [Weaviate](https://weaviate.io/).\\n\",\n        \"\\n\",\n        \"As a first example, let's take a short text prompt and see how to get an embedding from the Google Gemini API.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"sqSJrNcQgMUz\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"// Get the embedding model\\n\",\n        \"const embeddingModel = genAI.getGenerativeModel({ model: \\\"embedding-001\\\" });\\n\",\n        \"\\n\",\n        \"// Sample text to embed\\n\",\n        \"const text = \\\"The quick brown fox jumps over the lazy dog.\\\";\\n\",\n        \"\\n\",\n        \"// Get the embedding\\n\",\n        \"async function getEmbedding() {\\n\",\n        \"  const result = await embeddingModel.embedContent(text);\\n\",\n        \"  const embedding = result.embedding;\\n\",\n        \"  console.log(\\\"Embedding length:\\\", embedding.values.length);\\n\",\n        \"  console.log(\\\"First 10 values:\\\", embedding.values.slice(0, 10));\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"getEmbedding();\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"0sHXpZkggMUz\"\n      },\n      \"source\": [\n        \"Let's try now with batches\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"1NcWiGrTgMUz\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"// Multiple texts to embed\\n\",\n        \"const texts = [\\n\",\n        \"  \\\"Ancient Rome was a civilization that grew from a small settlement on the Italian Peninsula to one of the largest empires in the ancient world.\\\",\\n\",\n        \"  \\\"The Roman Republic was established in 509 BCE after the overthrow of the Roman Kingdom.\\\",\\n\",\n        \"  \\\"Julius Caesar was a Roman general and statesman who played a critical role in the events that led to the demise of the Roman Republic and the rise of the Roman Empire.\\\",\\n\",\n        \"  \\\"Augustus, born Gaius Octavius, was the first Roman emperor, reigning from 27 BCE until his death in 14 CE.\\\",\\n\",\n        \"  \\\"The Colosseum, also known as the Flavian Amphitheatre, is an oval amphitheatre in the centre of the city of Rome.\\\"\\n\",\n        \"];\\n\",\n        \"\\n\",\n        \"// Get multiple embeddings\\n\",\n        \"async function getBatchEmbeddings() {\\n\",\n        \"  const result = await embeddingModel.batchEmbedContents(texts);\\n\",\n        \"  const embeddings = result.embeddings;\\n\",\n        \"  \\n\",\n        \"  console.log(\\\"Number of embeddings:\\\", embeddings.length);\\n\",\n        \"  for (let i = 0; i < embeddings.length; i++) {\\n\",\n        \"    console.log(`Embedding ${i+1} length:`, embeddings[i].values.length);\\n\",\n        \"  }\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"getBatchEmbeddings();\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"KJGfCKQFgMU0\"\n      },\n      \"source\": [\n        \"## Calculate similarities between embeddings\\n\",\n        \"\\n\",\n        \"Embeddings can be compared to each other using dot product or cosine similarity. Let's explore these methods.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"G83fAHiagMU0\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"// Function to calculate cosine similarity between two vectors\\n\",\n        \"function cosineSimilarity(a, b) {\\n\",\n        \"  // Calculate dot product\\n\",\n        \"  let dotProduct = 0;\\n\",\n        \"  for (let i = 0; i < a.length; i++) {\\n\",\n        \"    dotProduct += a[i] * b[i];\\n\",\n        \"  }\\n\",\n        \"  \\n\",\n        \"  // Calculate magnitudes\\n\",\n        \"  let magA = 0;\\n\",\n        \"  let magB = 0;\\n\",\n        \"  for (let i = 0; i < a.length; i++) {\\n\",\n        \"    magA += a[i] * a[i];\\n\",\n        \"    magB += b[i] * b[i];\\n\",\n        \"  }\\n\",\n        \"  magA = Math.sqrt(magA);\\n\",\n        \"  magB = Math.sqrt(magB);\\n\",\n        \"  \\n\",\n        \"  // Calculate cosine similarity\\n\",\n        \"  return dotProduct / (magA * magB);\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"// Function to calculate dot product between two vectors\\n\",\n        \"function dotProduct(a, b) {\\n\",\n        \"  let product = 0;\\n\",\n        \"  for (let i = 0; i < a.length; i++) {\\n\",\n        \"    product += a[i] * b[i];\\n\",\n        \"  }\\n\",\n        \"  return product;\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"// Example texts to compare\\n\",\n        \"const sentences = [\\n\",\n        \"  \\\"Rome was the capital of the Roman Empire.\\\",\\n\",\n        \"  \\\"The Roman Empire was one of the largest in history.\\\",\\n\",\n        \"  \\\"Paris is the capital of France.\\\",\\n\",\n        \"  \\\"Machine learning is a subset of artificial intelligence.\\\"\\n\",\n        \"];\\n\",\n        \"\\n\",\n        \"// Get embeddings and calculate similarities\\n\",\n        \"async function compareSentences() {\\n\",\n        \"  const result = await embeddingModel.batchEmbedContents(sentences);\\n\",\n        \"  const embeddings = result.embeddings.map(e => e.values);\\n\",\n        \"  \\n\",\n        \"  console.log(\\\"Similarity matrix (cosine similarity):\\\");\\n\",\n        \"  const similarityMatrix = [];\\n\",\n        \"  \\n\",\n        \"  for (let i = 0; i < embeddings.length; i++) {\\n\",\n        \"    const row = [];\\n\",\n        \"    for (let j = 0; j < embeddings.length; j++) {\\n\",\n        \"      const similarity = cosineSimilarity(embeddings[i], embeddings[j]);\\n\",\n        \"      row.push(similarity.toFixed(3));\\n\",\n        \"    }\\n\",\n        \"    similarityMatrix.push(row);\\n\",\n        \"  }\\n\",\n        \"  \\n\",\n        \"  // Print the matrix in a readable format\\n\",\n        \"  console.table(similarityMatrix);\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"compareSentences();\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"B7tPTXZegMU0\"\n      },\n      \"source\": [\n        \"## Graded relevance demo\\n\",\n        \"\\n\",\n        \"This is a simple illustration of using embeddings to find semantically related content.\\n\",\n        \"\\n\",\n        \"We'll compare a query against several documents and see which ones are most relevant.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"wlLj9o5ygMU1\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"// Sample documents\\n\",\n        \"const documents = [\\n\",\n        \"  \\\"The sky is blue and beautiful.\\\",\\n\",\n        \"  \\\"Love this blue and beautiful sky!\\\",\\n\",\n        \"  \\\"The quick brown fox jumps over the lazy dog.\\\",\\n\",\n        \"  \\\"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\\\",\\n\",\n        \"  \\\"I love green eggs, ham, sausages and bacon!\\\",\\n\",\n        \"  \\\"The brown fox is quick and the blue dog is lazy!\\\",\\n\",\n        \"  \\\"The sky is very blue and the sky is very beautiful today\\\",\\n\",\n        \"  \\\"The dog is lazy but the brown fox is quick!\\\"\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"// Sample queries\\n\",\n        \"const queries = [\\n\",\n        \"  \\\"Blue sky\\\",\\n\",\n        \"  \\\"Breakfast\\\",\\n\",\n        \"  \\\"Brown fox\\\",\\n\",\n        \"  \\\"Lazy dog\\\"\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"// Function to find most relevant documents for a query\\n\",\n        \"async function findRelevantDocuments(query, documents) {\\n\",\n        \"  // Get embeddings for query and documents\\n\",\n        \"  const queryEmbeddingResult = await embeddingModel.embedContent(query);\\n\",\n        \"  const queryEmbedding = queryEmbeddingResult.embedding.values;\\n\",\n        \"  \\n\",\n        \"  const documentEmbeddingsResult = await embeddingModel.batchEmbedContents(documents);\\n\",\n        \"  const documentEmbeddings = documentEmbeddingsResult.embeddings.map(e => e.values);\\n\",\n        \"  \\n\",\n        \"  // Calculate similarities\\n\",\n        \"  const similarities = [];\\n\",\n        \"  for (let i = 0; i < documentEmbeddings.length; i++) {\\n\",\n        \"    const similarity = cosineSimilarity(queryEmbedding, documentEmbeddings[i]);\\n\",\n        \"    similarities.push({ index: i, document: documents[i], similarity });\\n\",\n        \"  }\\n\",\n        \"  \\n\",\n        \"  // Sort by similarity (highest first)\\n\",\n        \"  similarities.sort((a, b) => b.similarity - a.similarity);\\n\",\n        \"  \\n\",\n        \"  return similarities;\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"// Test all queries\\n\",\n        \"async function testAllQueries() {\\n\",\n        \"  for (const query of queries) {\\n\",\n        \"    console.log(`\\\\nQuery: \\\"${query}\\\"`)\\n\",\n        \"    const results = await findRelevantDocuments(query, documents);\\n\",\n        \"    \\n\",\n        \"    console.log(\\\"Top 3 relevant documents:\\\")\\n\",\n        \"    for (let i = 0; i < 3; i++) {\\n\",\n        \"      console.log(`${i+1}. ${results[i].document} (${results[i].similarity.toFixed(3)})`);\\n\",\n        \"    }\\n\",\n        \"  }\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"testAllQueries();\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"provenance\": []\n    },\n    \"kernelspec\": {\n      \"display_name\": \"JavaScript (Node.js)\",\n      \"language\": \"javascript\",\n      \"name\": \"javascript\"\n    },\n    \"language_info\": {\n      \"file_extension\": \".js\",\n      \"mimetype\": \"application/javascript\",\n      \"name\": \"javascript\",\n      \"version\": \"18.19.0\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006# google/generative-ai-docs\n# Gemini API docs configuration file\n\ntitle: Gemini API\ndescription: Build with Gemini on Google's multimodal AI platform.\n\n# Root directory of the repository: `/`\n#  |-- site/                    <- \"root directory\" for Docsy site\n#      |-- en/                  <- English source directory\n#          |-- gemini-api/      <- Product directory (one per product)\n#              |-- _includes/   <- Reusable content (partial pages)\n#              |-- docs/        <- Documentation content pages\n#              |-- docs.md      <- Landing page for documentation\n#              |-- index.md     <- Home page\n#  |-- Gemini/                  <- Generated files for review and deployment\n#      |-- gemini-api/          <- Generated for this project\n#\n# When a site is generated, Docsy merges the site content with the theme.\n# - During preview: files are generated in a temporary directory.\n# - During a build: files are generated in the output directory.\n# - During generation: files from the content branch are copied to the\n#   generation directory.\n\nsource_dir: site/en/gemini-api\noutput_dir: Gemini/gemini-api\n\n# When generating the site, delete the output directory first.\n# This ensures that you don't have any stale files.\ndelete_before_generate: true\n\nnav:\n- title: \"Docs\"\n  path: /gemini-api/docs/\n  menu:\n  - include: /gemini-api/_includes/docs-nav.md\n- title: \"Reference\"\n  path: /gemini-api/reference/\n  menu:\n  - include: /gemini-api/_includes/reference-nav.md\n- title: \"Samples\"\n  path: /gemini-api/samples/\n  menu:\n  - include: /gemini-api/_includes/samples-nav.md\n\nfooter:\n- title: \"Documentation\"\n  links:\n  - title: \"Overview\"\n    path: /gemini-api/docs/\n  - title: \"Quick start\"\n    path: /gemini-api/docs/get-started/\n  - title: \"Reference\"\n    path: /gemini-api/reference/\n\n- title: \"Community\"\n  links:\n  - title: \"Discord\"\n    path: https://discord.gg/google-dev-community\n  - title: \"Stack Overflow\"\n    path: https://stackoverflow.com/questions/tagged/google-gemini\n\n- title: \"Resources\"\n  links:\n  - title: \"Get help\"\n    path: /gemini-api/docs/get-help/\n  - title: \"Google for Developers\"\n    path: https://developers.google.com/\n\n- title: \"More from Google\"\n  links:\n  - title: \"Vertex AI\"\n    path: https://cloud.google.com/vertex-ai\n  - title: \"Vertex AI Codey API\"\n    path: https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-models-overview\n  - title: \"Google AI Studio\"\n    path: https://aistudio.google.com/\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini-api/docs/embeddings/semantic-search.md\n# Semantic search\n\nThis guide shows how to use embeddings for semantic search to find information based on meaning, not just exact keyword matches.\n\n## Overview\n\nSemantic search uses embeddings to find content that's conceptually related to a query, even when there's no word overlap. For example, searching for \"transportation vehicle\" could return results about \"cars\" and \"trucks\" because the embeddings capture their semantic similarity.\n\n## Set up your environment\n\nFirst, you'll need to install the required packages:\n\n```python\n!pip install -q google-generativeai langchain langchain-google-genai faiss-cpu\n```\n\nNow import the necessary libraries and configure your API key:\n\n```python\nimport google.generativeai as genai\nimport numpy as np\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain.vectorstores import FAISS\n\n# Set your API key\ngenai.configure(api_key=\"YOUR_API_KEY\")\n```\n\n## Create a sample document collection\n\nFor this example, let's create some sample documents about various topics:\n\n```python\ndocuments = [\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"Machine learning models can recognize patterns in data.\",\n    \"The Eiffel Tower is a landmark in Paris, France.\",\n    \"Neural networks are inspired by the human brain.\",\n    \"Coffee is one of the world's most popular beverages.\",\n    \"Deep learning is a subset of machine learning.\",\n    \"The Great Wall of China is visible from space.\",\n    \"Python is a widely used programming language in AI development.\",\n    \"Rome is known as the Eternal City.\",\n    \"GPUs accelerate training of large AI models.\"\n]\n```\n\n## Generate embeddings\n\nNow, let's use the Gemini embedding model to create vector representations of our documents:\n\n```python\n# Initialize the embeddings model\nembeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n\n# Create a vector store from the documents\nvector_store = FAISS.from_texts(documents, embeddings)\n```\n\n## Perform semantic searches\n\nLet's try some semantic searches to see how the model captures meaning:\n\n```python\ndef semantic_search(query, top_k=3):\n    \"\"\"Search for documents semantically similar to the query.\"\"\"\n    results = vector_store.similarity_search(query, k=top_k)\n    \n    print(f\"Query: '{query}'\")\n    print(\"Relevant documents:\")\n    for i, doc in enumerate(results):\n        print(f\"{i+1}. {doc.page_content}\")\n    print()\n\n# Example searches\nsemantic_search(\"artificial intelligence technologies\")\nsemantic_search(\"famous tourist attractions in the world\")\nsemantic_search(\"popular drinks people enjoy\")\n```\n\n## Example output\n\n```\nQuery: 'artificial intelligence technologies'\nRelevant documents:\n1. Machine learning models can recognize patterns in data.\n2. Neural networks are inspired by the human brain.\n3. Deep learning is a subset of machine learning.\n\nQuery: 'famous tourist attractions in the world'\nRelevant documents:\n1. The Eiffel Tower is a landmark in Paris, France.\n2. The Great Wall of China is visible from space.\n3. Rome is known as the Eternal City.\n\nQuery: 'popular drinks people enjoy'\nRelevant documents:\n1. Coffee is one of the world's most popular beverages.\n2. The quick brown fox jumps over the lazy dog.\n3. The Eiffel Tower is a landmark in Paris, France.\n```\n\nNotice how the system finds semantically relevant documents even when the query doesn't contain the exact words used in the documents.\n\n## Hybrid search\n\nYou can combine semantic search with traditional keyword-based search for even better results:\n\n```python\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.retrievers.document_compressors import DocumentCompressorPipeline\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Create a hybrid retriever\nretriever = vector_store.as_retriever()\n\ndef hybrid_search(query, top_k=3):\n    \"\"\"Combine semantic and keyword search.\"\"\"\n    # Get semantic search results\n    semantic_results = vector_store.similarity_search(query, k=top_k)\n    \n    # Simple keyword matching (for demonstration)\n    keyword_results = []\n    query_terms = set(query.lower().split())\n    for doc in documents:\n        doc_terms = set(doc.lower().split())\n        if query_terms.intersection(doc_terms):\n            keyword_results.append(doc)\n    \n    # Combine and deduplicate results\n    all_results = set([r.page_content for r in semantic_results] + keyword_results[:top_k])\n    \n    print(f\"Query: '{query}'\")\n    print(\"Relevant documents:\")\n    for i, doc in enumerate(list(all_results)[:top_k]):\n        print(f\"{i+1}. {doc}\")\n    print()\n\n# Example hybrid search\nhybrid_search(\"programming for AI\")\n```\n\n## Best practices\n\n1. **Preprocessing**: Clean and normalize your text data before generating embeddings.\n2. **Chunking**: For longer documents, split them into smaller chunks (paragraphs or sections) for more precise retrieval.\n3. **Metadata**: Store metadata along with your embeddings to provide additional context.\n4. **Filtering**: Implement pre- or post-filtering based on metadata to narrow down search results.\n5. **Evaluation**: Regularly evaluate your search quality with test queries.\n\n## Next steps\n\n- [Experiment with different chunking strategies](https://python.langchain.com/docs/modules/data_connection/document_transformers/)\n- [Explore more advanced retrieval techniques](https://python.langchain.com/docs/modules/data_connection/retrievers/)\n- [Build a complete RAG application with Gemini](https://github.com/google/generative-ai-docs/tree/main/gen-app-builder/search-with-gemini)\n\nBy using Gemini's embedding model for semantic search, you can build powerful information retrieval systems that understand the meaning behind user queries.\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini-api/docs/integrations/langchain.md\n# Use Gemini with LangChain\n\nLangChain is a popular framework for developing applications powered by language models. This guide shows how to integrate Gemini with LangChain.\n\n## Overview\n\nLangChain offers both official integrations for Gemini:\n\n1. **LangChain Google SDK**: The Gemini API implementation\n2. **LangChain Google Vertex AI**: The Vertex AI implementation \n\nThis guide focuses on the Gemini API implementation using the LangChain Google SDK.\n\n## Set up your environment\n\nFirst, install the required packages:\n\n```python\n!pip install -q langchain langchain-google-genai google-generativeai\n```\n\n## Basic usage with LLMs\n\nTo use Gemini models for text generation:\n\n```python\nimport os\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# Set your API key\nos.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n\n# Initialize the chat model\nchat_model = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n\n# Generate a response\nresponse = chat_model.invoke(\"Explain quantum computing in simple terms\")\nprint(response.content)\n```\n\n## Working with chat messages\n\nLangChain supports multi-turn conversations with Gemini:\n\n```python\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nchat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n\nmessages = [\n    SystemMessage(content=\"You are a helpful travel assistant.\"),\n    HumanMessage(content=\"I'm planning a trip to Tokyo. What should I see?\")\n]\n\nresponse = chat.invoke(messages)\nprint(response.content)\n\n# Continue the conversation\nmessages.append(response)\nmessages.append(HumanMessage(content=\"What about food recommendations?\"))\nresponse = chat.invoke(messages)\nprint(response.content)\n```\n\n## Using Gemini with multimodal inputs\n\nGemini supports both text and image inputs. Here's how to use it with multimodal content:\n\n```python\nimport os\nfrom langchain_core.messages import HumanMessage\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom IPython.display import Image\nfrom pathlib import Path\n\n# Download a sample image\n!wget -q -O image.jpg \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/landmark.jpg\"\ndisplay(Image(\"image.jpg\"))\n\n# Create a chat model with the multimodal Gemini model\nchat = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n\n# Create a message with text and image\nmessage = HumanMessage(\n    content=[\n        {\"type\": \"text\", \"text\": \"What's in this image?\"},\n        {\"type\": \"image_url\", \"image_url\": Path(\"image.jpg\")}\n    ]\n)\n\n# Get the response\nresponse = chat.invoke([message])\nprint(response.content)\n```\n\n## Using structured outputs with Gemini\n\nFor specific applications, you may want structured outputs rather than free-form text. You can use LangChain's output parsers with Gemini:\n\n```python\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.output_parsers import ResponseSchema, StructuredOutputParser\n\n# Define the output schema\nclass TravelRecommendation(BaseModel):\n    destination: str = Field(description=\"Name of the travel destination\")\n    best_time_to_visit: str = Field(description=\"The ideal season or months to visit\")\n    attractions: list = Field(description=\"List of top attractions to see\")\n    budget_estimate: str = Field(description=\"Estimated budget range for a week trip\")\n\n# Initialize the chat model\nchat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n\n# Create a prompt for structured output\nprompt = \"\"\"\nProvide travel recommendations for {destination}.\n\"\"\"\n\n# Build a parser\nparser = StructuredOutputParser.from_pydantic_object(TravelRecommendation)\nformat_instructions = parser.get_format_instructions()\n\n# Combine the prompt with format instructions\nfull_prompt = f\"{prompt}\\n\\n{format_instructions}\"\n\n# Get a structured response\nresponse = chat.invoke(full_prompt.format(destination=\"Barcelona\"))\nparsed_response = parser.parse(response.content)\n\nprint(f\"Destination: {parsed_response.destination}\")\nprint(f\"Best time to visit: {parsed_response.best_time_to_visit}\")\nprint(f\"Top attractions: {', '.join(parsed_response.attractions)}\")\nprint(f\"Budget estimate: {parsed_response.budget_estimate}\")\n```\n\n## Using embeddings with Gemini\n\nGemini also provides embeddings, which are useful for various applications like semantic search:\n\n```python\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\n\n# Initialize the embeddings model\nembeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n\n# Create some sample text\ntexts = [\n    \"Artificial intelligence is transforming industries worldwide\",\n    \"Machine learning algorithms can recognize patterns in data\",\n    \"Neural networks are inspired by the human brain\",\n    \"Deep learning is a subset of machine learning\",\n    \"Natural language processing helps computers understand human language\"\n]\n\n# Create a vector store\nvector_store = FAISS.from_texts(texts, embeddings)\n\n# Perform a similarity search\nquery = \"AI technology\"\ndocs = vector_store.similarity_search(query)\n\nprint(f\"Query: {query}\")\nprint(\"Similar documents:\")\nfor i, doc in enumerate(docs):\n    print(f\"{i+1}. {doc.page_content}\")\n```\n\n## Building a basic RAG application\n\nLet's combine Gemini with LangChain to build a simple Retrieval-Augmented Generation (RAG) application:\n\n```python\nfrom langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\n\n# Sample data (in a real application, you'd load documents from files)\ndocuments = [\n    \"The Gemini model was released by Google in 2023. It has both multimodal and text-only versions.\",\n    \"Gemini Pro is the text-based model optimized for text-only prompts.\",\n    \"Gemini Pro Vision can handle both text and image inputs.\",\n    \"Gemini API is accessible through REST API and client libraries.\",\n    \"Gemini models show strong performance on various benchmarks.\"\n]\n\n# Split text into chunks\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.create_documents(documents)\n\n# Create embeddings and vector store\nembeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\nvector_store = FAISS.from_documents(texts, embeddings)\n\n# Set up the retriever\nretriever = vector_store.as_retriever()\n\n# Initialize the language model\nllm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n\n# Create a RAG chain\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=retriever\n)\n\n# Query the system\nquery = \"What is Gemini Pro Vision?\"\nresult = qa_chain.invoke({\"query\": query})\nprint(f\"Query: {query}\")\nprint(f\"Answer: {result['result']}\")\n```\n\n## Next steps\n\n- Explore the [LangChain documentation](https://python.langchain.com/docs/get_started/introduction) for more advanced features\n- Check out the [LangChain Google Generative AI integration documentation](https://python.langchain.com/docs/integrations/llms/google_genai)\n- Try building more complex applications combining Gemini with other LangChain components\n- Implement agents using Gemini and LangChain's agent framework\n- Explore function calling with Gemini and LangChain\n\nBy integrating Gemini with LangChain, you can leverage the powerful capabilities of both technologies to build sophisticated AI applications.\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini-api/reference/rest/v1/GenerateContent.md\n# GenerateContent\n\nThe `generateContent` method allows you to generate content from a Gemini model given a user's prompt.\n\n```http\nPOST https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent\n```\n\n## Request body\n\nThe request body contains a `GenerateContentRequest` object.\n\n### GenerateContentRequest\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `contents` | Array of `Content` objects | Required. The content of the current conversation with the model. |\n| `systemInstruction` | `Content` | Optional. The system instructions that will be used for generating the response. |\n| `generationConfig` | `GenerationConfig` | Optional. Configuration options for content generation. |\n| `safetySettings` | Array of `SafetySetting` objects | Optional. Safety settings for content generation. |\n| `tools` | Array of `Tool` objects | Optional. A list of tools the model may use. |\n\n### Content\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `role` | string | Optional. The role of the current message (e.g., \"user\", \"model\"). |\n| `parts` | Array of `Part` objects | Required. The parts that make up the content. |\n\n### Part\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `text` | string | Text content. |\n| `inlineData` | `InlineData` | Inline data for image or binary content. |\n| `fileData` | `FileData` | Reference to a file. |\n| `functionCall` | `FunctionCall` | A function call executed by the model. |\n| `functionResponse` | `FunctionResponse` | A response from a function call. |\n\n### InlineData\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `mimeType` | string | Required. The MIME type of the data (e.g., \"image/jpeg\"). |\n| `data` | string | Required. Base64-encoded data. |\n\n### FileData\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `mimeType` | string | Required. The MIME type of the file. |\n| `fileUri` | string | Required. URI for the file. |\n\n### GenerationConfig\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `temperature` | float | Optional. Controls randomness (0.0 to 1.0). |\n| `topP` | float | Optional. Nucleus sampling (0.0 to 1.0). |\n| `topK` | integer | Optional. Top-K sampling. |\n| `candidateCount` | integer | Optional. Number of response candidates to generate. |\n| `maxOutputTokens` | integer | Optional. Maximum number of tokens to generate. |\n| `stopSequences` | Array of strings | Optional. Custom sequences where generation should stop. |\n| `presencePenalty` | float | Optional. Penalty for new tokens based on their presence. |\n| `frequencyPenalty` | float | Optional. Penalty for new tokens based on their frequency. |\n\n### SafetySetting\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `category` | enum | Required. The safety category to configure. |\n| `threshold` | enum | Required. The threshold at which harm is blocked. |\n\n## Response body\n\nThe response body contains a `GenerateContentResponse` object.\n\n### GenerateContentResponse\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `candidates` | Array of `Candidate` objects | Content candidates returned from the model. |\n| `promptFeedback` | `PromptFeedback` | Feedback for the prompt. |\n| `usageMetadata` | `UsageMetadata` | Information about token usage. |\n\n### Candidate\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `content` | `Content` | The generated content. |\n| `finishReason` | enum | The reason why the model stopped generating tokens. |\n| `safetyRatings` | Array of `SafetyRating` objects | Safety ratings for the content. |\n| `citationMetadata` | `CitationMetadata` | Citation information for sources. |\n| `index` | integer | Index of the candidate. |\n\n### SafetyRating\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `category` | enum | The safety category. |\n| `probability` | enum | The probability of harm. |\n| `blocked` | boolean | Whether the content was blocked. |\n\n### PromptFeedback\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `safetyRatings` | Array of `SafetyRating` objects | Safety ratings for the prompt. |\n| `blockReason` | enum | The reason the prompt was blocked, if it was. |\n\n### UsageMetadata\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `promptTokenCount` | integer | Number of tokens in the prompt. |\n| `candidatesTokenCount` | integer | Number of tokens in the response. |\n| `totalTokenCount` | integer | Total number of tokens used. |\n\n## Example: Text-only request\n\n```json\n{\n  \"contents\": [{\n    \"parts\": [{\n      \"text\": \"Write a story about a magic backpack\"\n    }]\n  }],\n  \"generationConfig\": {\n    \"temperature\": 0.9,\n    \"maxOutputTokens\": 2048\n  }\n}\n```\n\n## Example: Multimodal request with image\n\n```json\n{\n  \"contents\": [{\n    \"parts\": [\n      {\n        \"text\": \"What's in this image?\"\n      },\n      {\n        \"inlineData\": {\n          \"mimeType\": \"image/jpeg\",\n          \"data\": \"BASE64_ENCODED_IMAGE_DATA\"\n        }\n      }\n    ]\n  }]\n}\n```\n\n## Example: Using system instructions\n\n```json\n{\n  \"contents\": [{\n    \"parts\": [{\n      \"text\": \"Write a poem about mountains\"\n    }]\n  }],\n  \"systemInstruction\": {\n    \"parts\": [{\n      \"text\": \"You are a professional poet who specializes in sonnets.\"\n    }]\n  }\n}\n```\n\n## Example: Success response\n\n```json\n{\n  \"candidates\": [{\n    \"content\": {\n      \"parts\": [{\n        \"text\": \"Once upon a time, there was a magical backpack...\"\n      }]\n    },\n    \"finishReason\": \"STOP\",\n    \"safetyRatings\": [\n      {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      }\n    ]\n  }],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 8,\n    \"candidatesTokenCount\": 103,\n    \"totalTokenCount\": 111\n  }\n}\n```\n\n## Example: Safety blocked response\n\n```json\n{\n  \"candidates\": [{\n    \"content\": {\n      \"parts\": []\n    },\n    \"finishReason\": \"SAFETY\",\n    \"safetyRatings\": [\n      {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"probability\": \"HIGH\",\n        \"blocked\": true\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"probability\": \"NEGLIGIBLE\"\n      }\n    ]\n  }],\n  \"promptFeedback\": {\n    \"safetyRatings\": [\n      {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"probability\": \"MEDIUM\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"probability\": \"NEGLIGIBLE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"probability\": \"NEGLIGIBLE\"\n      }\n    ]\n  }\n}\n```\n\n## Notes\n\n- For multimodal requests using Gemini Pro Vision, images must be sent as either base64-encoded data in the `inlineData` field or via a Cloud Storage URI in the `fileData` field.\n- The `generateContent` method supports streaming responses using server-sent events (SSE).\n- The maximum combined token count for input and output is model-dependent.\n- Safety settings are applied to both the user prompt and model responses.\n\u0005End File\u0006# google/generative-ai-docs\n# Gemini API docs configuration file\n\ntitle: Gemini API\ndescription: Build with Gemini on Google's multimodal AI platform.\n\n# Root directory of the repository: `/`\n#  |-- site/                    <- \"root directory\" for Docsy site\n#      |-- en/                  <- English source directory\n#          |-- gemini-api/      <- Product directory (one per product)\n#              |-- _includes/   <- Reusable content (partial pages)\n#              |-- docs/        <- Documentation content pages\n#              |-- docs.md      <- Landing page for documentation\n#              |-- index.md     <- Home page\n#  |-- Gemini/                  <- Generated files for review and deployment\n#      |-- gemini-api/          <- Generated for this project\n#\n# When a site is generated, Docsy merges the site content with the theme.\n# - During preview: files are generated in a temporary directory.\n# - During a build: files are generated in the output directory.\n# - During generation: files from the content branch are copied to the\n#   generation directory.\n\nsource_dir: site/en/gemini-api\noutput_dir: Gemini/gemini-api\n\n# When generating the site, delete the output directory first.\n# This ensures that you don't have any stale files.\ndelete_before_generate: true\n\nnav:\n- title: \"Docs\"\n  path: /gemini-api/docs/\n  menu:\n  - include: /gemini-api/_includes/docs-nav.md\n- title: \"Reference\"\n  path: /gemini-api/reference/\n  menu:\n  - include: /gemini-api/_includes/reference-nav.md\n- title: \"Samples\"\n  path: /gemini-api/samples/\n  menu:\n  - include: /gemini-api/_includes/samples-nav.md\n- title: \"Tutorials\"\n  path: /gemini-api/tutorials/\n  menu:\n  - include: /gemini-api/_includes/tutorials-nav.md\n\nfooter:\n- title: \"Documentation\"\n  links:\n  - title: \"Overview\"\n    path: /gemini-api/docs/\n  - title: \"Quick start\"\n    path: /gemini-api/docs/get-started/quickstart/\n  - title: \"Reference\"\n    path: /gemini-api/reference/\n\n- title: \"Feedback\"\n  links:\n  - title: \"File an issue\"\n    path: https://github.com/google/generative-ai-docs/issues/new/choose\n  - title: \"Feature request\"\n    path: https://github.com/google/generative-ai-docs/issues/new/choose\n\n- title: \"Community\"\n  links:\n  - title: \"Discord\"\n    path: https://discord.gg/google-dev-community\n  - title: \"Stack Overflow\"\n    path: https://stackoverflow.com/questions/tagged/google-gemini\n\n- title: \"Resources\"\n  links:\n  - title: \"Google AI\"\n    path: https://ai.google/\n  - title: \"AI Essentials\"\n    path: https://ai.google/build/essentials/\n  - title: \"Get help\"\n    path: /gemini-api/docs/get-started/get-help/\n  - title: \"Google for Developers\"\n    path: https://developers.google.com/\n\u0005End File\u0006# google/generative-ai-docs\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Gk-LkMCf-MgW\"\n      },\n      \"source\": [\n        \"# Multimodal prompting with gemini-pro-vision\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini/docs/multimodal_prompting.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"GtXJhs2_-MgZ\"\n      },\n      \"source\": [\n        \"Multimodal prompting means creating prompts that combine different types of information: text, images, and video. The `gemini-pro-vision` model can take both images and text as input.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"dZUXTLCt-Mga\"\n      },\n      \"source\": [\n        \"## Setup\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"8KZb_BRv-Mga\"\n      },\n      \"source\": [\n        \"### Install the Vertex AI SDK for Python\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"XYpLs5Ox-Mgb\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install google-generativeai\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"_9yVvo3l-Mgb\"\n      },\n      \"source\": [\n        \"### Import libraries\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"KnDokKTM-Mgb\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"from PIL import Image\\n\",\n        \"import pathlib\\n\",\n        \"import requests\\n\",\n        \"import google.generativeai as genai\\n\",\n        \"\\n\",\n        \"from IPython.display import display\\n\",\n        \"from IPython.display import Markdown\\n\",\n        \"def to_markdown(text):\\n\",\n        \"  text = text.replace('•', '  *')\\n\",\n        \"  return Markdown(text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"4n41B0QZ-Mgc\"\n      },\n      \"source\": [\n        \"### Configure your API key\\n\",\n        \"\\n\",\n        \"To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google/generative-ai-docs/blob/main/site/en/gemini/docs/authentication.ipynb) guide.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"JFgC79RH-Mgc\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"from google.colab import userdata\\n\",\n        \"GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\\n\",\n        \"\\n\",\n        \"genai.configure(api_key=GOOGLE_API_KEY)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Rx3NMHIb-Mgc\"\n      },\n      \"source\": [\n        \"## Image understanding\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"UNRJJOxS-Mgd\"\n      },\n      \"source\": [\n        \"Multimodal models such as Gemini can understand the content of images in a prompt. Let's try a simple example. \"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"JyM-hUEI-Mgd\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a sample image to use\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/scene.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./img.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"nE8lQ6zL-Mgd\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"model = genai.GenerativeModel('gemini-pro-vision')\\n\",\n        \"response = model.generate_content([\\\"What's in this image?\\\", img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"fO4eQO59-Mge\"\n      },\n      \"source\": [\n        \"Let's use a slightly more complex prompt with an image that involves understanding textual elements in the image.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"7tRbNLxO-Mge\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/grocery_receipt.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./receipt.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Xoqzn-6Z-Mge\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Look at this grocery receipt and:\\n\",\n        \"1. Calculate the total spent on fruits and vegetables\\n\",\n        \"2. Suggest a healthy recipe I can make with these ingredients\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"1jCpSxqS-Mgf\"\n      },\n      \"source\": [\n        \"## Multiple images as context\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"lUGGv4ZM-Mgf\"\n      },\n      \"source\": [\n        \"Let's try using multiple images in a single prompt. The vision model can analyze a sequence of images for comparison, classification, or to address a more complex prompt.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"6aXUwxIa-Mgf\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a set of sample images\\n\",\n        \"img1_url = 'https://storage.googleapis.com/generativeai-downloads/data/living_room1.jpg'\\n\",\n        \"img2_url = 'https://storage.googleapis.com/generativeai-downloads/data/living_room2.jpg'\\n\",\n        \"\\n\",\n        \"img1_data = requests.get(img1_url).content\\n\",\n        \"img2_data = requests.get(img2_url).content\\n\",\n        \"\\n\",\n        \"img1_path = pathlib.Path('./living_room1.jpg')\\n\",\n        \"img2_path = pathlib.Path('./living_room2.jpg')\\n\",\n        \"\\n\",\n        \"img1_path.write_bytes(img1_data)\\n\",\n        \"img2_path.write_bytes(img2_data)\\n\",\n        \"\\n\",\n        \"img1 = Image.open(img1_path)\\n\",\n        \"img2 = Image.open(img2_path)\\n\",\n        \"\\n\",\n        \"print(\\\"Image 1:\\\")\\n\",\n        \"display(img1)\\n\",\n        \"print(\\\"\\\\nImage 2:\\\")\\n\",\n        \"display(img2)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"qFRcyzA--Mgf\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Compare these two living room designs:\\n\",\n        \"1. Describe the key style differences\\n\",\n        \"2. Which one appears more cozy for a family?\\n\",\n        \"3. Suggest one improvement for each\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img1, img2])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"6pT4C-RP-Mgg\"\n      },\n      \"source\": [\n        \"## Detailed image analysis\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"y3uI1_GC-Mgg\"\n      },\n      \"source\": [\n        \"Gemini can provide detailed analysis of images, including identifying elements and explaining relationships between objects.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"pLTHXRDh-Mgg\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/diagram.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./diagram.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"IM9yKHjV-Mgg\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Analyze this diagram:\\n\",\n        \"1. What does it represent?\\n\",\n        \"2. Explain each component and its function\\n\",\n        \"3. How do the components interact with each other?\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"cFcpMbUX-Mgh\"\n      },\n      \"source\": [\n        \"## Creative tasks with images\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"d5hwcSiH-Mgh\"\n      },\n      \"source\": [\n        \"Gemini can also use images as inspiration for creative tasks. Let's try using an image as a prompt for a story.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"BPU6TxL3-Mgh\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/mountain_landscape.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./landscape.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"tLfKi-yl-Mgh\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Use this image as inspiration to:\\n\",\n        \"1. Write a short poem (4-6 lines) capturing the mood of this landscape\\n\",\n        \"2. Create a brief story opening (2-3 sentences) that could take place in this setting\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"uCxwRPQl-Mgh\"\n      },\n      \"source\": [\n        \"## Image understanding with complex reasoning\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"GSJX70eK-Mgi\"\n      },\n      \"source\": [\n        \"Gemini can combine image understanding with complex reasoning to solve problems. Let's try a mathematical problem presented in an image.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"cHVWR1aM-Mgi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/math_problem.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./math_problem.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"qGS8PcDr-Mgi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"For the math problem shown in the image:\\n\",\n        \"1. Identify what is being asked\\n\",\n        \"2. Solve it step by step\\n\",\n        \"3. Verify your answer\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"hE6LiZWu-Mgi\"\n      },\n      \"source\": [\n        \"## Combining images with detailed instructions\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Ao-bBfN9-Mgi\"\n      },\n      \"source\": [\n        \"You can provide detailed instructions alongside images to get more specific outputs from Gemini.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"AQk9-ZFU-Mgi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/product.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./product.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"KXPcbEFw-Mgj\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"You are a marketing consultant. I need help creating marketing content for this product. \\n\",\n        \"\\n\",\n        \"Please provide:\\n\",\n        \"1. A catchy product name\\n\",\n        \"2. 5 key selling points based on what you can see\\n\",\n        \"3. A short product description (50-60 words) highlighting its premium features\\n\",\n        \"4. Two different taglines that emphasize its elegance\\n\",\n        \"\\n\",\n        \"The target audience is tech-savvy professionals who value both design and functionality.\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"provenance\": [],\n      \"toc_visible\": true\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3 (ipykernel)\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.11.3\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini-api/tutorials/node-express-webhook-app-tutorial.md\n# Building a Webhook-Enabled Node.js/Express Chatbot with Gemini\n\nIn this tutorial, you'll build a webhook-enabled chatbot using Node.js, Express, and the Gemini API. This setup allows your application to receive notifications from other services and interact with Gemini to generate responses.\n\n## Prerequisites\n\n- Node.js installed on your machine\n- Basic knowledge of JavaScript and Express\n- A Gemini API key (get one from [Google AI Studio](https://aistudio.google.com/))\n- [ngrok](https://ngrok.com/) for exposing your local server to the internet (for testing webhooks)\n\n## Project Setup\n\n1. Create a new directory for your project:\n\n```bash\nmkdir gemini-webhook-chatbot\ncd gemini-webhook-chatbot\n```\n\n2. Initialize a new Node.js project:\n\n```bash\nnpm init -y\n```\n\n3. Install the required dependencies:\n\n```bash\nnpm install express body-parser @google/generativeai dotenv\n```\n\n4. Create a `.env` file to store your API key:\n\n```\nGOOGLE_API_KEY=your_api_key_here\nPORT=3000\n```\n\n## Create the Express Server\n\nCreate a file named `server.js` with the following code:\n\n```javascript\n// server.js\nrequire('dotenv').config();\nconst express = require('express');\nconst bodyParser = require('body-parser');\nconst { GoogleGenerativeAI } = require('@google/generativeai');\n\n// Initialize Express app\nconst app = express();\nconst port = process.env.PORT || 3000;\n\n// Middleware\napp.use(bodyParser.json());\napp.use(express.static('public'));\n\n// Initialize Gemini API\nconst genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY);\nconst model = genAI.getGenerativeModel({ model: \"gemini-pro\" });\n\n// Chat history storage (in a real app, use a database)\nconst chatHistory = {};\n\n// Routes\napp.get('/', (req, res) => {\n  res.sendFile(__dirname + '/public/index.html');\n});\n\n// Webhook endpoint\napp.post('/webhook', async (req, res) => {\n  try {\n    const { userId, message, source } = req.body;\n    \n    if (!userId || !message) {\n      return res.status(400).json({ error: 'Missing required fields' });\n    }\n    \n    console.log(`Received webhook from ${source || 'unknown source'} for user ${userId}`);\n    \n    // Initialize chat history for this user if it doesn't exist\n    if (!chatHistory[userId]) {\n      chatHistory[userId] = [];\n    }\n    \n    // Add user message to history\n    chatHistory[userId].push({\n      role: 'user',\n      parts: [{ text: message }]\n    });\n    \n    // Generate response from Gemini\n    const chat = model.startChat({\n      history: chatHistory[userId],\n      generationConfig: {\n        temperature: 0.8,\n        maxOutputTokens: 1000,\n      },\n    });\n    \n    const result = await chat.sendMessage(message);\n    const response = result.response.text();\n    \n    // Add AI response to history\n    chatHistory[userId].push({\n      role: 'model',\n      parts: [{ text: response }]\n    });\n    \n    // Limit history length to prevent token limits\n    if (chatHistory[userId].length > 10) {\n      chatHistory[userId] = chatHistory[userId].slice(-10);\n    }\n    \n    return res.json({\n      userId,\n      response,\n    });\n  } catch (error) {\n    console.error('Error processing webhook:', error);\n    return res.status(500).json({ error: 'Internal server error' });\n  }\n});\n\n// Direct chat endpoint\napp.post('/chat', async (req, res) => {\n  try {\n    const { userId, message } = req.body;\n    \n    if (!userId || !message) {\n      return res.status(400).json({ error: 'Missing required fields' });\n    }\n    \n    // Initialize chat history for this user if it doesn't exist\n    if (!chatHistory[userId]) {\n      chatHistory[userId] = [];\n    }\n    \n    // Add user message to history\n    chatHistory[userId].push({\n      role: 'user',\n      parts: [{ text: message }]\n    });\n    \n    // Generate response from Gemini\n    const chat = model.startChat({\n      history: chatHistory[userId],\n      generationConfig: {\n        temperature: 0.8,\n        maxOutputTokens: 1000,\n      },\n    });\n    \n    const result = await chat.sendMessage(message);\n    const response = result.response.text();\n    \n    // Add AI response to history\n    chatHistory[userId].push({\n      role: 'model',\n      parts: [{ text: response }]\n    });\n    \n    // Limit history length to prevent token limits\n    if (chatHistory[userId].length > 10) {\n      chatHistory[userId] = chatHistory[userId].slice(-10);\n    }\n    \n    return res.json({\n      userId,\n      response,\n    });\n  } catch (error) {\n    console.error('Error processing chat:', error);\n    return res.status(500).json({ error: 'Internal server error' });\n  }\n});\n\n// Start the server\napp.listen(port, () => {\n  console.log(`Server running at http://localhost:${port}`);\n});\n```\n\n## Create a Simple Frontend\n\nCreate a directory named `public` and inside it, create a file named `index.html`:\n\n```bash\nmkdir public\ntouch public/index.html\n```\n\nAdd the following HTML to `index.html`:\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Gemini Webhook Chatbot</title>\n  <style>\n    body {\n      font-family: Arial, sans-serif;\n      max-width: 800px;\n      margin: 0 auto;\n      padding: 20px;\n    }\n    #chat-container {\n      border: 1px solid #ddd;\n      padding: 20px;\n      height: 400px;\n      overflow-y: auto;\n      margin-bottom: 20px;\n      border-radius: 5px;\n    }\n    .message {\n      margin-bottom: 10px;\n      padding: 10px;\n      border-radius: 5px;\n    }\n    .user-message {\n      background-color: #e3f2fd;\n      text-align: right;\n    }\n    .bot-message {\n      background-color: #f1f1f1;\n    }\n    #message-form {\n      display: flex;\n    }\n    #message-input {\n      flex-grow: 1;\n      padding: 10px;\n      border: 1px solid #ddd;\n      border-radius: 5px;\n    }\n    button {\n      padding: 10px 20px;\n      background-color: #4285f4;\n      color: white;\n      border: none;\n      border-radius: 5px;\n      margin-left: 10px;\n      cursor: pointer;\n    }\n    button:hover {\n      background-color: #3367d6;\n    }\n    h1 {\n      color: #4285f4;\n    }\n    .webhook-info {\n      background-color: #fafafa;\n      padding: 15px;\n      border-radius: 5px;\n      margin-top: 20px;\n      border: 1px solid #eee;\n    }\n  </style>\n</head>\n<body>\n  <h1>Gemini Webhook Chatbot</h1>\n  \n  <div id=\"chat-container\"></div>\n  \n  <form id=\"message-form\">\n    <input type=\"text\" id=\"message-input\" placeholder=\"Type your message here...\" required>\n    <button type=\"submit\">Send</button>\n  </form>\n  \n  <div class=\"webhook-info\">\n    <h3>Webhook Information</h3>\n    <p>To send messages via webhook, make a POST request to:</p>\n    <code id=\"webhook-url\">/webhook</code>\n    <p>with the following JSON body:</p>\n    <pre>{\n  \"userId\": \"user123\",\n  \"message\": \"Your message here\",\n  \"source\": \"optional-source-identifier\"\n}</pre>\n  </div>\n  \n  <script>\n    // Generate a random user ID for this session\n    const userId = 'user_' + Math.random().toString(36).substring(2, 10);\n    const chatContainer = document.getElementById('chat-container');\n    const messageForm = document.getElementById('message-form');\n    const messageInput = document.getElementById('message-input');\n    \n    // Update the webhook URL to include the full domain\n    document.getElementById('webhook-url').textContent = `${window.location.origin}/webhook`;\n    \n    // Add a message to the chat container\n    function addMessage(text, isUser) {\n      const messageElement = document.createElement('div');\n      messageElement.classList.add('message');\n      messageElement.classList.add(isUser ? 'user-message' : 'bot-message');\n      messageElement.textContent = text;\n      chatContainer.appendChild(messageElement);\n      chatContainer.scrollTop = chatContainer.scrollHeight;\n    }\n    \n    // Handle form submission\n    messageForm.addEventListener('submit', async (e) => {\n      e.preventDefault();\n      \n      const message = messageInput.value.trim();\n      if (!message) return;\n      \n      // Add user message to chat\n      addMessage(message, true);\n      messageInput.value = '';\n      \n      try {\n        // Send message to server\n        const response = await fetch('/chat', {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify({\n            userId,\n            message\n          })\n        });\n        \n        const data = await response.json();\n        \n        if (data.error) {\n          addMessage(`Error: ${data.error}`, false);\n        } else {\n          // Add bot response to chat\n          addMessage(data.response, false);\n        }\n      } catch (error) {\n        console.error('Error sending message:', error);\n        addMessage('Sorry, there was an error communicating with the server.', false);\n      }\n    });\n    \n    // Add welcome message\n    addMessage('Welcome! I\\'m a Gemini-powered chatbot. How can I help you today?', false);\n  </script>\n</body>\n</html>\n```\n\n## Run the Application\n\nStart your server:\n\n```bash\nnode server.js\n```\n\nOpen your browser and go to `http://localhost:3000` to interact with your chatbot directly through the web interface.\n\n## Test the Webhook\n\nTo test the webhook functionality, you need to expose your local server to the internet. You can use ngrok for this:\n\n1. Start ngrok on the same port as your Express server:\n\n```bash\nngrok http 3000\n```\n\n2. Ngrok will provide you with a public URL (like `https://abc123.ngrok.io`). Use this URL to send webhook requests to your application.\n\n3. To test the webhook, you can use curl or any API testing tool like Postman:\n\n```bash\ncurl -X POST https://your-ngrok-url/webhook \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"userId\": \"external_user_123\",\n    \"message\": \"Hello from the webhook!\",\n    \"source\": \"external-service\"\n  }'\n```\n\n## Enhancing Your Webhook Chatbot\n\nHere are some ways to enhance your chatbot:\n\n### 1. Add webhook authentication\n\n```javascript\n// Add this middleware before your webhook route\nfunction authenticateWebhook(req, res, next) {\n  const apiKey = req.headers['x-api-key'];\n  \n  if (!apiKey || apiKey !== process.env.WEBHOOK_SECRET) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n  \n  next();\n}\n\n// Use it in your webhook route\napp.post('/webhook', authenticateWebhook, async (req, res) => {\n  // Your existing code\n});\n```\n\n### 2. Add persistent storage\n\nReplace the in-memory chat history with a database solution like MongoDB:\n\n```javascript\n// Example with MongoDB\nconst { MongoClient } = require('mongodb');\nconst uri = process.env.MONGODB_URI;\nconst client = new MongoClient(uri);\n\nasync function storeMessage(userId, message, isUser) {\n  try {\n    await client.connect();\n    const database = client.db('chatbot');\n    const collection = database.collection('messages');\n    \n    await collection.insertOne({\n      userId,\n      content: message,\n      role: isUser ? 'user' : 'model',\n      timestamp: new Date()\n    });\n  } finally {\n    await client.close();\n  }\n}\n\nasync function getConversationHistory(userId, limit = 10) {\n  try {\n    await client.connect();\n    const database = client.db('chatbot');\n    const collection = database.collection('messages');\n    \n    return await collection.find({ userId })\n      .sort({ timestamp: -1 })\n      .limit(limit)\n      .toArray();\n  } finally {\n    await client.close();\n  }\n}\n```\n\n### 3. Add system instructions\n\nCustomize the Gemini model's behavior with system instructions:\n\n```javascript\nconst chat = model.startChat({\n  history: chatHistory[userId],\n  generationConfig: {\n    temperature: 0.8,\n    maxOutputTokens: 1000,\n  },\n  systemInstruction: {\n    role: \"system\",\n    parts: [{\n      text: \"You are a helpful assistant specializing in customer support for a tech company. Be concise, friendly, and always ask if there's anything else you can help with.\"\n    }]\n  }\n});\n```\n\n### 4. Implement webhook callbacks\n\nSend the response back to the original service that triggered the webhook:\n\n```javascript\nasync function sendCallbackResponse(callbackUrl, data) {\n  try {\n    const response = await fetch(callbackUrl, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify(data)\n    });\n    \n    return response.ok;\n  } catch (error) {\n    console.error('Error sending callback:', error);\n    return false;\n  }\n}\n\n// In your webhook route\napp.post('/webhook', async (req, res) => {\n  try {\n    const { userId, message, source, callbackUrl } = req.body;\n    \n    // Process the message with Gemini...\n    \n    // If a callback URL was provided, send the response there\n    if (callbackUrl) {\n      sendCallbackResponse(callbackUrl, {\n        userId,\n        response,\n        source: 'gemini-chatbot'\n      });\n    }\n    \n    return res.json({\n      userId,\n      response,\n    });\n  } catch (error) {\n    // Error handling\n  }\n});\n```\n\n## Conclusion\n\nYou've built a webhook-enabled chatbot using Node.js, Express, and the Gemini API. This chatbot can receive messages through both a web interface and webhook endpoints, making it versatile for various integration scenarios.\n\nThis application demonstrates:\n1. How to integrate the Gemini API into a Node.js application\n2. How to manage conversation history\n3. How to implement webhooks for external integrations\n4. How to build a simple web interface for direct interactions\n\nFrom here, you can expand your chatbot by adding authentication, database storage, more sophisticated conversation management, or integrations with other services like Slack, Discord, or custom business applications.\n\u0005End File\u0006# site/en/gemini-api/docs/get-started/system-instruction.md\n# System instruction\n\nSystem instruction allows you to set high-level behavior for the model. This guide explains how to use system instruction effectively with the Gemini API.\n\n## Overview\n\nA system instruction is a special type of instruction that serves as an overall directive for the model. It defines the general behavior, role, or other characteristics the model should adopt throughout the conversation. Think of it as a \"persona\" or \"operating instructions\" for the model.\n\n## Why use system instruction?\n\nSystem instruction provides several benefits:\n\n1. **Consistent behavior**: Maintains a consistent persona or set of rules throughout a conversation\n2. **More efficient**: Reduces the need to repeat instructions in every prompt\n3. **Cleaner prompts**: Keeps your user prompts focused on the specific task rather than model behavior\n4. **Better control**: Gives you more control over how the model responds\n\n## Basic usage\n\nYou can set system instruction when initializing a chat session:\n\n### Python\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\nmodel = genai.GenerativeModel('gemini-pro')\nchat = model.start_chat(\n    system_instruction=\"You are a helpful assistant who responds in the style of a friendly pirate.\"\n)\n\nresponse = chat.send_message(\"Tell me about the weather today.\")\nprint(response.text)\n```\n\n### REST API\n\n```bash\ncurl -X POST \\\n  'https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent' \\\n  -H 'Content-Type: application/json' \\\n  -H 'x-goog-api-key: YOUR_API_KEY' \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [{\"text\": \"Tell me about the weather today.\"}]\n      }\n    ],\n    \"systemInstruction\": {\n      \"role\": \"system\",\n      \"parts\": [{\"text\": \"You are a helpful assistant who responds in the style of a friendly pirate.\"}]\n    }\n  }'\n```\n\n## Best practices\n\n### Be specific and clear\n\nProvide clear, specific instructions about the model's behavior:\n\n```python\nsystem_instruction = \"\"\"\nYou are a professional technical documentation writer. When responding:\n1. Use clear, concise language\n2. Include relevant code examples where appropriate\n3. Structure your responses with proper headings and lists\n4. Avoid jargon unless necessary for the topic\n5. Always end with a brief summary\n\"\"\"\n```\n\n### Define constraints\n\nSet boundaries for what the model should or shouldn't do:\n\n```python\nsystem_instruction = \"\"\"\nYou are a math tutor for high school students. When helping with problems:\n- Guide students through solutions rather than simply providing answers\n- Use step-by-step explanations\n- Check for common misconceptions\n- Do not solve the entire problem directly\n- Provide hints when students are stuck\n\"\"\"\n```\n\n### Establish a persona\n\nCreate a specific character or role for the model:\n\n```python\nsystem_instruction = \"\"\"\nYou are Chef Olivia, a professional chef with 20 years of experience in Italian cuisine.\nYou specialize in creating recipes that are authentic yet accessible for home cooks.\nWhen discussing food, reference traditional techniques and explain unfamiliar terms.\nYour tone is warm, encouraging, and passionate about good food.\n\"\"\"\n```\n\n### Combine with safety guidelines\n\nInclude safety guidelines in your system instruction:\n\n```python\nsystem_instruction = \"\"\"\nYou are a helpful writing assistant. When helping with writing:\n- Provide constructive feedback on grammar, structure, and style\n- Suggest improvements rather than rewriting entirely\n- Focus on clarity and readability\n- Do not generate content that contains hate speech, discrimination, or harmful language\n- Decline to write academic essays or work that appears to be for academic dishonesty\n\"\"\"\n```\n\n## Examples\n\n### Customer support assistant\n\n```python\nsystem_instruction = \"\"\"\nYou are a customer support specialist for TechGadgets Inc., a consumer electronics company.\nFollow these guidelines:\n1. Be polite, professional, and helpful at all times\n2. Use the customer's name when provided\n3. For product questions, provide accurate information about TechGadgets products only\n4. For technical issues, offer troubleshooting steps before suggesting a return\n5. If you don't know specific product details, acknowledge this and offer to connect them with a specialist\n6. Never share information about unreleased products or internal company policies\n7. End each response by asking if there's anything else you can help with\n\"\"\"\n```\n\n### Language learning tutor\n\n```python\nsystem_instruction = \"\"\"\nYou are a Spanish language tutor for intermediate learners.\n- Respond to simple questions in both Spanish and English\n- For complex questions, use simpler Spanish and provide translations\n- Correct grammatical errors gently with explanations\n- Use common idioms and phrases to enrich vocabulary\n- Avoid advanced tenses until the student demonstrates readiness\n- Incorporate cultural context where relevant\n- Provide encouragement and positive reinforcement\n\"\"\"\n```\n\n### Creative writing coach\n\n```python\nsystem_instruction = \"\"\"\nYou are a creative writing coach who helps aspiring writers improve their craft.\nYour approach is:\n- Analyze writing samples for strengths and areas for improvement\n- Provide specific, actionable feedback rather than general comments\n- Focus on elements like character development, dialogue, pacing, and description\n- Suggest writing exercises tailored to the writer's needs\n- Reference relevant examples from published literature\n- Be encouraging while still providing honest critique\n- Adapt your feedback style based on the writer's experience level\n\"\"\"\n```\n\n## Advanced techniques\n\n### Combining with user input memory\n\nFor complex scenarios, you can combine system instruction with tracked conversation history:\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\nsystem_instruction = \"\"\"\nYou are a personalized fitness coach. Adapt your recommendations based on:\n1. The user's stated fitness goals\n2. Any physical limitations they mention\n3. Their previous exercise experience\n4. Their available equipment\nKeep track of this information throughout the conversation.\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-pro')\nchat = model.start_chat(system_instruction=system_instruction)\n\n# Initial interaction\nresponse = chat.send_message(\"Hi, I want to get more fit but I have a bad knee.\")\nprint(response.text)\n\n# Follow-up interaction (model remembers the knee issue)\nresponse = chat.send_message(\"What cardio exercises would be good for me?\")\nprint(response.text)\n```\n\n### Dynamic system instructions\n\nIn some applications, you might want to modify the system instruction based on user preferences or application state:\n\n```python\ndef get_system_instruction(user_preferences):\n    base_instruction = \"You are a helpful assistant.\"\n    \n    if user_preferences.get(\"expertise_level\") == \"beginner\":\n        base_instruction += \" Explain concepts in simple terms without technical jargon.\"\n    elif user_preferences.get(\"expertise_level\") == \"expert\":\n        base_instruction += \" You can use technical terminology and provide in-depth explanations.\"\n    \n    if user_preferences.get(\"response_style\") == \"concise\":\n        base_instruction += \" Keep your responses brief and to the point.\"\n    elif user_preferences.get(\"response_style\") == \"detailed\":\n        base_instruction += \" Provide comprehensive, detailed responses.\"\n    \n    return base_instruction\n\n# Example usage\nuser_prefs = {\n    \"expertise_level\": \"beginner\",\n    \"response_style\": \"concise\"\n}\n\nsystem_instruction = get_system_instruction(user_prefs)\nchat = model.start_chat(system_instruction=system_instruction)\n```\n\n## Limitations and considerations\n\n- System instruction is applied to the entire chat session\n- Very long system instructions might reduce the token space available for the conversation\n- The model may not perfectly adhere to all aspects of complex system instructions\n- For highly specific behaviors, you might need to reinforce the system instruction with occasional reminders in your prompts\n\n## Next steps\n\n- Experiment with different system instructions to find what works best for your application\n- Combine system instruction with other techniques like few-shot examples for more powerful results\n- Consider developing a library of system instructions for different use cases in your application\n- Explore [prompt design guidelines](https://ai.google.dev/docs/prompt_best_practices) for more tips on effective prompting\n\u0005End File\u0006# google/generative-ai-docs\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"hGvDlxuJKuMO\"\n      },\n      \"source\": [\n        \"# Function calling with gemini-1.5-pro\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini/docs/function_calling.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"gKRKwkcoLN46\"\n      },\n      \"source\": [\n        \"This notebook shows how to use [function calling](https://ai.google.dev/docs/function_calling) with the Gemini API, using the `gemini-1.5-pro` model.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"n0I59msLMDcg\"\n      },\n      \"source\": [\n        \"## Installation and setup\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Lxe6eS4eKqkR\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install -q google-generativeai\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"MH8cAM9fMHSX\"\n      },\n      \"source\": [\n        \"### Configure your API key\\n\",\n        \"\\n\",\n        \"To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google/generative-ai-docs/blob/main/site/en/gemini/docs/authentication.ipynb) guide.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"qf_9xKE3Kxu5\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"import google.generativeai as genai\\n\",\n        \"from google.colab import userdata\\n\",\n        \"import json\\n\",\n        \"\\n\",\n        \"genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"2q6S-Zv-MUyj\"\n      },\n      \"source\": [\n        \"## Function calling\\n\",\n        \"\\n\",\n        \"Let's look at a simple example where we define a function for getting the current weather in a location and use function calling to extract location and weather preferences from a prompt.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"3pVH2JIxMQJv\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define our functions\\n\",\n        \"get_current_weather = {\\n\",\n        \"  \\\"name\\\": \\\"get_current_weather\\\",\\n\",\n        \"  \\\"description\\\": \\\"Get the current weather in a given location\\\",\\n\",\n        \"  \\\"parameters\\\": {\\n\",\n        \"      \\\"type\\\": \\\"object\\\",\\n\",\n        \"      \\\"properties\\\": {\\n\",\n        \"          \\\"location\\\": {\\n\",\n        \"              \\\"type\\\": \\\"string\\\",\\n\",\n        \"              \\\"description\\\": \\\"The city and state, e.g. San Francisco, CA\\\",\\n\",\n        \"          },\\n\",\n        \"          \\\"unit\\\": {\\\"type\\\": \\\"string\\\", \\\"enum\\\": [\\\"celsius\\\", \\\"fahrenheit\\\"]},\\n\",\n        \"      },\\n\",\n        \"      \\\"required\\\": [\\\"location\\\"],\\n\",\n        \"  },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"# Set up the model\\n\",\n        \"model = genai.GenerativeModel('gemini-1.5-pro')\\n\",\n        \"\\n\",\n        \"# Test a simple prompt\\n\",\n        \"prompt = \\\"What's the weather like in Boston?\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content(\\n\",\n        \"    prompt,\\n\",\n        \"    tools=[{\\\"function_declarations\\\": [get_current_weather]}]\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Y30-bDR1k7AH\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Show the function call the model wants to make\\n\",\n        \"print(response.candidates[0].content.parts[0].function_call)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"n2QJfTvwlHCK\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# For a more complex case, let's see how it handles multiple parameters\\n\",\n        \"prompt = \\\"What's the weather like in New Orleans? I prefer celsius.\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content(\\n\",\n        \"    prompt,\\n\",\n        \"    tools=[{\\\"function_declarations\\\": [get_current_weather]}]\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"print(response.candidates[0].content.parts[0].function_call)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"vhWNq8TqlnQp\"\n      },\n      \"source\": [\n        \"Now let's see how function calling works in a full conversation. We'll simulate the full loop of:\\n\",\n        \"1. Getting a function call from the model\\n\",\n        \"2. Calling the function ourselves (simulated)\\n\",\n        \"3. Providing the function response back to the model\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"8O77NP97llIh\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Simulate actual function implementation\\n\",\n        \"def get_current_weather_actual(location, unit=\\\"fahrenheit\\\"):\\n\",\n        \"    \\\"\\\"\\\"Simulated weather data for demonstration\\\"\\\"\\\"\\n\",\n        \"    weather_data = {\\n\",\n        \"        \\\"Boston\\\": {\\\"temperature\\\": 38, \\\"condition\\\": \\\"Partly Cloudy\\\", \\\"humidity\\\": 65, \\\"wind\\\": \\\"10 mph\\\"},\\n\",\n        \"        \\\"San Francisco\\\": {\\\"temperature\\\": 58, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 72, \\\"wind\\\": \\\"8 mph\\\"},\\n\",\n        \"        \\\"New York\\\": {\\\"temperature\\\": 42, \\\"condition\\\": \\\"Rainy\\\", \\\"humidity\\\": 80, \\\"wind\\\": \\\"15 mph\\\"},\\n\",\n        \"        \\\"Los Angeles\\\": {\\\"temperature\\\": 72, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 60, \\\"wind\\\": \\\"5 mph\\\"},\\n\",\n        \"        \\\"Chicago\\\": {\\\"temperature\\\": 35, \\\"condition\\\": \\\"Windy\\\", \\\"humidity\\\": 70, \\\"wind\\\": \\\"25 mph\\\"},\\n\",\n        \"        \\\"New Orleans\\\": {\\\"temperature\\\": 68, \\\"condition\\\": \\\"Humid\\\", \\\"humidity\\\": 90, \\\"wind\\\": \\\"7 mph\\\"},\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    # Extract just the city name from the location if it contains a state\\n\",\n        \"    city = location.split(',')[0].strip()\\n\",\n        \"    \\n\",\n        \"    if city in weather_data:\\n\",\n        \"        result = weather_data[city].copy()\\n\",\n        \"        # Convert temperature if needed\\n\",\n        \"        if unit == \\\"celsius\\\":\\n\",\n        \"            result[\\\"temperature\\\"] = round((result[\\\"temperature\\\"] - 32) * 5/9)\\n\",\n        \"        return result\\n\",\n        \"    else:\\n\",\n        \"        return {\\\"error\\\": f\\\"Weather data not available for {location}\\\"}\\n\",\n        \"\\n\",\n        \"# Let's start a chat session\\n\",\n        \"chat = model.start_chat(tools=[{\\\"function_declarations\\\": [get_current_weather]}])\\n\",\n        \"\\n\",\n        \"# User asks about weather\\n\",\n        \"response = chat.send_message(\\\"What's the weather like in Boston?\\\")\\n\",\n        \"\\n\",\n        \"# Check if model wants to call a function\\n\",\n        \"function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"print(f\\\"Model wants to call: {function_call.name}\\\")\\n\",\n        \"print(f\\\"With arguments: {function_call.args}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"T2wq8tZYqBVP\"\n      },\n      \"source\": [\n        \"Now we can execute the function with the arguments the model extracted, and send the result back:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"ij2b00YcqLsi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Extract the arguments\\n\",\n        \"args = function_call.args\\n\",\n        \"location = args.get(\\\"location\\\")\\n\",\n        \"unit = args.get(\\\"unit\\\", \\\"fahrenheit\\\")\\n\",\n        \"\\n\",\n        \"# Call our function\\n\",\n        \"function_response = get_current_weather_actual(location, unit)\\n\",\n        \"print(f\\\"Function returned: {function_response}\\\")\\n\",\n        \"\\n\",\n        \"# Send the function response back to the model\\n\",\n        \"response = chat.send_message(\\n\",\n        \"    {\\n\",\n        \"        \\\"function_response\\\": {\\n\",\n        \"            \\\"name\\\": function_call.name,\\n\",\n        \"            \\\"response\\\": function_response\\n\",\n        \"        }\\n\",\n        \"    }\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Display the model's response\\n\",\n        \"print(\\\"\\\\nModel response:\\\")\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"0OB8_dEfrNV0\"\n      },\n      \"source\": [\n        \"Let's do one more example to see how the model handles follow-up questions in the context of function calling:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"gP0qZk9TrU3a\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Follow-up question\\n\",\n        \"response = chat.send_message(\\\"And what about New York? Is it warmer there?\\\")\\n\",\n        \"\\n\",\n        \"# Check if model wants to call a function again\\n\",\n        \"function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"print(f\\\"Model wants to call: {function_call.name}\\\")\\n\",\n        \"print(f\\\"With arguments: {function_call.args}\\\")\\n\",\n        \"\\n\",\n        \"# Extract the arguments\\n\",\n        \"args = function_call.args\\n\",\n        \"location = args.get(\\\"location\\\")\\n\",\n        \"unit = args.get(\\\"unit\\\", \\\"fahrenheit\\\")\\n\",\n        \"\\n\",\n        \"# Call our function\\n\",\n        \"function_response = get_current_weather_actual(location, unit)\\n\",\n        \"print(f\\\"Function returned: {function_response}\\\")\\n\",\n        \"\\n\",\n        \"# Send the function response back to the model\\n\",\n        \"response = chat.send_message(\\n\",\n        \"    {\\n\",\n        \"        \\\"function_response\\\": {\\n\",\n        \"            \\\"name\\\": function_call.name,\\n\",\n        \"            \\\"response\\\": function_response\\n\",\n        \"        }\\n\",\n        \"    }\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Display the model's response\\n\",\n        \"print(\\\"\\\\nModel response:\\\")\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"uJ0ioBrhtIQD\"\n      },\n      \"source\": [\n        \"## More complex function calling examples\\n\",\n        \"\\n\",\n        \"Now let's look at more complex examples with multiple functions and more parameters.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"w0WQzqietH2a\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define multiple functions\\n\",\n        \"get_current_weather = {\\n\",\n        \"  \\\"name\\\": \\\"get_current_weather\\\",\\n\",\n        \"  \\\"description\\\": \\\"Get the current weather in a given location\\\",\\n\",\n        \"  \\\"parameters\\\": {\\n\",\n        \"      \\\"type\\\": \\\"object\\\",\\n\",\n        \"      \\\"properties\\\": {\\n\",\n        \"          \\\"location\\\": {\\n\",\n        \"              \\\"type\\\": \\\"string\\\",\\n\",\n        \"              \\\"description\\\": \\\"The city and state, e.g. San Francisco, CA\\\",\\n\",\n        \"          },\\n\",\n        \"          \\\"unit\\\": {\\\"type\\\": \\\"string\\\", \\\"enum\\\": [\\\"celsius\\\", \\\"fahrenheit\\\"]},\\n\",\n        \"      },\\n\",\n        \"      \\\"required\\\": [\\\"location\\\"],\\n\",\n        \"  },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"get_restaurant_recommendation = {\\n\",\n        \"    \\\"name\\\": \\\"get_restaurant_recommendation\\\",\\n\",\n        \"    \\\"description\\\": \\\"Get restaurant recommendations for a location based on various criteria\\\",\\n\",\n        \"    \\\"parameters\\\": {\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"location\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"The city and state, e.g. San Francisco, CA\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"cuisine\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Type of cuisine, e.g. Italian, Chinese, etc.\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"price_level\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"cheap\\\", \\\"moderate\\\", \\\"expensive\\\", \\\"very expensive\\\"],\\n\",\n        \"                \\\"description\\\": \\\"The price level of the restaurant\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"open_now\\\": {\\n\",\n        \"                \\\"type\\\": \\\"boolean\\\",\\n\",\n        \"                \\\"description\\\": \\\"Whether the restaurant should be open now\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"outdoor_seating\\\": {\\n\",\n        \"                \\\"type\\\": \\\"boolean\\\",\\n\",\n        \"                \\\"description\\\": \\\"Whether the restaurant should have outdoor seating\\\",\\n\",\n        \"            },\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"location\\\"],\\n\",\n        \"    },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"# Set up the model with multiple functions\\n\",\n        \"chat = model.start_chat(\\n\",\n        \"    tools=[{\\\"function_declarations\\\": [get_current_weather, get_restaurant_recommendation]}]\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"xKMC1b5nuj8R\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with a weather-related prompt\\n\",\n        \"response = chat.send_message(\\\"What's the weather like in San Francisco today?\\\")\\n\",\n        \"\\n\",\n        \"# Show which function the model chose\\n\",\n        \"function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"print(f\\\"Model chose function: {function_call.name}\\\")\\n\",\n        \"print(f\\\"With arguments: {function_call.args}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"u4B9vwsru52i\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Now test with a restaurant-related prompt\\n\",\n        \"response = chat.send_message(\\\"I'm looking for an Italian restaurant in Chicago with outdoor seating\\\")\\n\",\n        \"\\n\",\n        \"# Show which function the model chose\\n\",\n        \"function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"print(f\\\"Model chose function: {function_call.name}\\\")\\n\",\n        \"print(f\\\"With arguments: {function_call.args}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"B5wxf20vvRsi\"\n      },\n      \"source\": [\n        \"Let's try an ambiguous prompt to see how the model handles it:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"k4U_1hBbvZsa\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with an ambiguous prompt\\n\",\n        \"response = chat.send_message(\\\"I'm planning a day in Los Angeles\\\")\\n\",\n        \"\\n\",\n        \"# Show the model's response\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"PUJm6hMqAKAJ\"\n      },\n      \"source\": [\n        \"## A Complete Example\\n\",\n        \"\\n\",\n        \"Let's build a more realistic example with a full conversation flow. We'll simulate a travel planning assistant that can check weather and find restaurants.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"67oaxPrQAJzp\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Simulate actual function implementations\\n\",\n        \"def get_current_weather_actual(location, unit=\\\"fahrenheit\\\"):\\n\",\n        \"    \\\"\\\"\\\"Simulated weather data for demonstration\\\"\\\"\\\"\\n\",\n        \"    weather_data = {\\n\",\n        \"        \\\"Boston\\\": {\\\"temperature\\\": 38, \\\"condition\\\": \\\"Partly Cloudy\\\", \\\"humidity\\\": 65, \\\"wind\\\": \\\"10 mph\\\"},\\n\",\n        \"        \\\"San Francisco\\\": {\\\"temperature\\\": 58, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 72, \\\"wind\\\": \\\"8 mph\\\"},\\n\",\n        \"        \\\"New York\\\": {\\\"temperature\\\": 42, \\\"condition\\\": \\\"Rainy\\\", \\\"humidity\\\": 80, \\\"wind\\\": \\\"15 mph\\\"},\\n\",\n        \"        \\\"Los Angeles\\\": {\\\"temperature\\\": 72, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 60, \\\"wind\\\": \\\"5 mph\\\"},\\n\",\n        \"        \\\"Chicago\\\": {\\\"temperature\\\": 35, \\\"condition\\\": \\\"Windy\\\", \\\"humidity\\\": 70, \\\"wind\\\": \\\"25 mph\\\"},\\n\",\n        \"        \\\"New Orleans\\\": {\\\"temperature\\\": 68, \\\"condition\\\": \\\"Humid\\\", \\\"humidity\\\": 90, \\\"wind\\\": \\\"7 mph\\\"},\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    # Extract just the city name from the location if it contains a state\\n\",\n        \"    city = location.split(',')[0].strip()\\n\",\n        \"    \\n\",\n        \"    if city in weather_data:\\n\",\n        \"        result = weather_data[city].copy()\\n\",\n        \"        # Convert temperature if needed\\n\",\n        \"        if unit == \\\"celsius\\\":\\n\",\n        \"            result[\\\"temperature\\\"] = round((result[\\\"temperature\\\"] - 32) * 5/9)\\n\",\n        \"        return result\\n\",\n        \"    else:\\n\",\n        \"        return {\\\"error\\\": f\\\"Weather data not available for {location}\\\"}\\n\",\n        \"\\n\",\n        \"def get_restaurant_recommendation_actual(location, cuisine=None, price_level=None, open_now=None, outdoor_seating=None):\\n\",\n        \"    \\\"\\\"\\\"Simulated restaurant recommendation function\\\"\\\"\\\"\\n\",\n        \"    restaurants = {\\n\",\n        \"        \\\"New York\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"Bella Italia\\\", \\\"cuisine\\\": \\\"Italian\\\", \\\"price_level\\\": \\\"expensive\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.7},\\n\",\n        \"            {\\\"name\\\": \\\"Sushi Heaven\\\", \\\"cuisine\\\": \\\"Japanese\\\", \\\"price_level\\\": \\\"expensive\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": False, \\\"rating\\\": 4.9},\\n\",\n        \"            {\\\"name\\\": \\\"Taco Time\\\", \\\"cuisine\\\": \\\"Mexican\\\", \\\"price_level\\\": \\\"moderate\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.3},\\n\",\n        \"            {\\\"name\\\": \\\"Burger Joint\\\", \\\"cuisine\\\": \\\"American\\\", \\\"price_level\\\": \\\"cheap\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.1},\\n\",\n        \"            {\\\"name\\\": \\\"Le Fancy\\\", \\\"cuisine\\\": \\\"French\\\", \\\"price_level\\\": \\\"very expensive\\\", \\\"open_now\\\": False, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.8},\\n\",\n        \"        ],\\n\",\n        \"        \\\"Chicago\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"Deep Dish Haven\\\", \\\"cuisine\\\": \\\"Italian\\\", \\\"price_level\\\": \\\"moderate\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": False, \\\"rating\\\": 4.6},\\n\",\n        \"            {\\\"name\\\": \\\"Windy City Sushi\\\", \\\"cuisine\\\": \\\"Japanese\\\", \\\"price_level\\\": \\\"expensive\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": False, \\\"rating\\\": 4.5},\\n\",\n        \"            {\\\"name\\\": \\\"Taqueria Chicago\\\", \\\"cuisine\\\": \\\"Mexican\\\", \\\"price_level\\\": \\\"cheap\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.2},\\n\",\n        \"            {\\\"name\\\": \\\"Steak & Co\\\", \\\"cuisine\\\": \\\"American\\\", \\\"price_level\\\": \\\"very expensive\\\", \\\"open_now\\\": False, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.9},\\n\",\n        \"            {\\\"name\\\": \\\"Pizza Paradise\\\", \\\"cuisine\\\": \\\"Italian\\\", \\\"price_level\\\": \\\"cheap\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": False, \\\"rating\\\": 4.0},\\n\",\n        \"        ],\\n\",\n        \"        \\\"Los Angeles\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"LA Italian\\\", \\\"cuisine\\\": \\\"Italian\\\", \\\"price_level\\\": \\\"expensive\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.4},\\n\",\n        \"            {\\\"name\\\": \\\"California Rolls\\\", \\\"cuisine\\\": \\\"Japanese\\\", \\\"price_level\\\": \\\"moderate\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.7},\\n\",\n        \"            {\\\"name\\\": \\\"Sunset Tacos\\\", \\\"cuisine\\\": \\\"Mexican\\\", \\\"price_level\\\": \\\"cheap\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.8},\\n\",\n        \"            {\\\"name\\\": \\\"Hollywood Burgers\\\", \\\"cuisine\\\": \\\"American\\\", \\\"price_level\\\": \\\"moderate\\\", \\\"open_now\\\": True, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.3},\\n\",\n        \"            {\\\"name\\\": \\\"Beverly Hills Dining\\\", \\\"cuisine\\\": \\\"French\\\", \\\"price_level\\\": \\\"very expensive\\\", \\\"open_now\\\": False, \\\"outdoor_seating\\\": True, \\\"rating\\\": 4.9},\\n\",\n        \"        ],\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    # Extract just the city name from the location if it contains a state\\n\",\n        \"    city = location.split(',')[0].strip()\\n\",\n        \"    \\n\",\n        \"    if city not in restaurants:\\n\",\n        \"        return {\\\"error\\\": f\\\"No restaurant data available for {location}\\\"}\\n\",\n        \"    \\n\",\n        \"    # Filter restaurants based on criteria\\n\",\n        \"    filtered = restaurants[city]\\n\",\n        \"    \\n\",\n        \"    if cuisine:\\n\",\n        \"        filtered = [r for r in filtered if r[\\\"cuisine\\\"].lower() == cuisine.lower()]\\n\",\n        \"    \\n\",\n        \"    if price_level:\\n\",\n        \"        filtered = [r for r in filtered if r[\\\"price_level\\\"] == price_level]\\n\",\n        \"    \\n\",\n        \"    if open_now is not None:\\n\",\n        \"        filtered = [r for r in filtered if r[\\\"open_now\\\"] == open_now]\\n\",\n        \"    \\n\",\n        \"    if outdoor_seating is not None:\\n\",\n        \"        filtered = [r for r in filtered if r[\\\"outdoor_seating\\\"] == outdoor_seating]\\n\",\n        \"    \\n\",\n        \"    # Sort by rating\\n\",\n        \"    filtered.sort(key=lambda x: x[\\\"rating\\\"], reverse=True)\\n\",\n        \"    \\n\",\n        \"    return {\\\"restaurants\\\": filtered[:3]} if filtered else {\\\"message\\\": \\\"No restaurants found matching your criteria\\\"}\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"3YDgaQeTCMJZ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Initialize chat with system instruction\\n\",\n        \"system_instruction = \\\"\\\"\\\"You are a helpful travel assistant that helps users plan their trips. \\n\",\n        \"You can check the weather and recommend restaurants based on their preferences.\\n\",\n        \"Always provide helpful context based on the information you receive.\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"chat = model.start_chat(\\n\",\n        \"    system_instruction=system_instruction,\\n\",\n        \"    tools=[{\\\"function_declarations\\\": [get_current_weather, get_restaurant_recommendation]}]\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"4OD3oTD0Chby\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define a helper function to handle the conversation flow\\n\",\n        \"def process_turn(user_message):\\n\",\n        \"    print(f\\\"User: {user_message}\\\")\\n\",\n        \"    \\n\",\n        \"    # Send the message to the model\\n\",\n        \"    response = chat.send_message(user_message)\\n\",\n        \"    \\n\",\n        \"    # Check if model wants to call a function\\n\",\n        \"    if hasattr(response.candidates[0].content.parts[0], 'function_call'):\\n\",\n        \"        function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"        print(f\\\"\\\\nModel is calling function: {function_call.name}\\\")\\n\",\n        \"        print(f\\\"With parameters: {function_call.args}\\\")\\n\",\n        \"        \\n\",\n        \"        # Execute the appropriate function\\n\",\n        \"        if function_call.name == \\\"get_current_weather\\\":\\n\",\n        \"            args = function_call.args\\n\",\n        \"            function_response = get_current_weather_actual(\\n\",\n        \"                location=args.get(\\\"location\\\"),\\n\",\n        \"                unit=args.get(\\\"unit\\\", \\\"fahrenheit\\\")\\n\",\n        \"            )\\n\",\n        \"        elif function_call.name == \\\"get_restaurant_recommendation\\\":\\n\",\n        \"            args = function_call.args\\n\",\n        \"            function_response = get_restaurant_recommendation_actual(\\n\",\n        \"                location=args.get(\\\"location\\\"),\\n\",\n        \"                cuisine=args.get(\\\"cuisine\\\"),\\n\",\n        \"                price_level=args.get(\\\"price_level\\\"),\\n\",\n        \"                open_now=args.get(\\\"open_now\\\"),\\n\",\n        \"                outdoor_seating=args.get(\\\"outdoor_seating\\\")\\n\",\n        \"            )\\n\",\n        \"        else:\\n\",\n        \"            function_response = {\\\"error\\\": f\\\"Unknown function: {function_call.name}\\\"}\\n\",\n        \"        \\n\",\n        \"        print(f\\\"Function response: {function_response}\\\")\\n\",\n        \"        \\n\",\n        \"        # Send the function response back to the model\\n\",\n        \"        response = chat.send_message(\\n\",\n        \"            {\\n\",\n        \"                \\\"function_response\\\": {\\n\",\n        \"                    \\\"name\\\": function_call.name,\\n\",\n        \"                    \\\"response\\\": function_response\\n\",\n        \"                }\\n\",\n        \"            }\\n\",\n        \"        )\\n\",\n        \"    \\n\",\n        \"    # Print the model's final response\\n\",\n        \"    print(f\\\"\\\\nAssistant: {response.text}\\\\n\\\")\\n\",\n        \"    print(\\\"-\\\" * 80)\\n\",\n        \"    return response\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"3Q7dVNbdEIgF\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Let's run through a conversation\\n\",\n        \"process_turn(\\\"I'm planning a trip to New York next week. What's the weather like there?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"bjV_vIbDEVjR\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"process_turn(\\\"Sounds like I should bring a raincoat! Can you recommend some good Italian restaurants there?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"1hHwRJAFEn6Y\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"process_turn(\\\"Bella Italia sounds great, but I prefer something cheaper. Any other options?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Q5HRbKkpE4J5\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"process_turn(\\\"Now I'm thinking about changing my plans. How's the weather in Los Angeles?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"r6VYskvSFK1A\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"process_turn(\\\"That sounds much better! Can you recommend Mexican restaurants there with outdoor seating?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"8rYXcuXFFfIb\"\n      },\n      \"source\": [\n        \"## Handling function calls with complex data types\\n\",\n        \"\\n\",\n        \"Let's see how function calling works with more complex parameter types like arrays and nested objects.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"6dNToDKrFqwS\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define a function with complex parameters\\n\",\n        \"book_hotel = {\\n\",\n        \"    \\\"name\\\": \\\"book_hotel\\\",\\n\",\n        \"    \\\"description\\\": \\\"Book a hotel room based on user preferences\\\",\\n\",\n        \"    \\\"parameters\\\": {\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"location\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"City where the hotel is located\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"check_in_date\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Check-in date in YYYY-MM-DD format\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"check_out_date\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Check-out date in YYYY-MM-DD format\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"guests\\\": {\\n\",\n        \"                \\\"type\\\": \\\"object\\\",\\n\",\n        \"                \\\"description\\\": \\\"Information about the guests\\\",\\n\",\n        \"                \\\"properties\\\": {\\n\",\n        \"                    \\\"adults\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Number of adults\\\",\\n\",\n        \"                    },\\n\",\n        \"                    \\\"children\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Number of children\\\",\\n\",\n        \"                    },\\n\",\n        \"                    \\\"pets\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"boolean\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Whether pets are accompanying the guests\\\",\\n\",\n        \"                    }\\n\",\n        \"                },\\n\",\n        \"                \\\"required\\\": [\\\"adults\\\"]\\n\",\n        \"            },\\n\",\n        \"            \\\"room_type\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"standard\\\", \\\"deluxe\\\", \\\"suite\\\", \\\"penthouse\\\"],\\n\",\n        \"                \\\"description\\\": \\\"Type of room to book\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"amenities\\\": {\\n\",\n        \"                \\\"type\\\": \\\"array\\\",\\n\",\n        \"                \\\"items\\\": {\\n\",\n        \"                    \\\"type\\\": \\\"string\\\",\\n\",\n        \"                },\\n\",\n        \"                \\\"description\\\": \\\"List of requested amenities (e.g., pool, gym, spa)\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"budget_per_night\\\": {\\n\",\n        \"                \\\"type\\\": \\\"number\\\",\\n\",\n        \"                \\\"description\\\": \\\"Maximum budget per night in USD\\\",\\n\",\n        \"            },\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"location\\\", \\\"check_in_date\\\", \\\"check_out_date\\\", \\\"guests\\\"],\\n\",\n        \"    },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"# Initialize a new chat\\n\",\n        \"complex_chat = model.start_chat(\\n\",\n        \"    tools=[{\\\"function_declarations\\\": [book_hotel]}]\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Cc71hCT3Gxlq\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with a detailed booking request\\n\",\n        \"response = complex_chat.send_message(\\n\",\n        \"    \\\"I need to book a hotel in Miami for 2 adults and 1 child from June 15 to June 20, 2024. \\\"\\n\",\n        \"    \\\"We'd like a suite with an ocean view. Our budget is $500 per night. \\\"\\n\",\n        \"    \\\"We need a pool, gym, and room service. Also, we'll be bringing our dog.\\\"\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Check the function call\\n\",\n        \"function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"print(f\\\"Function name: {function_call.name}\\\")\\n\",\n        \"print(\\\"Parameters:\\\")\\n\",\n        \"print(json.dumps(function_call.args, indent=2))\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"5wKXjEPRHUiS\"\n      },\n      \"source\": [\n        \"Let's try with a more ambiguous request where the model needs to infer some details:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"FJKa0eU3Hdby\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with a more ambiguous request\\n\",\n        \"response = complex_chat.send_message(\\n\",\n        \"    \\\"I want to stay somewhere nice in Los Angeles next month for about a week. \\\"\\n\",\n        \"    \\\"There's just me and my partner, and we like having a gym.\\\"\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Check if model asks for clarification or makes assumptions\\n\",\n        \"if hasattr(response.candidates[0].content.parts[0], 'text'):\\n\",\n        \"    print(\\\"Model asked for clarification:\\\")\\n\",\n        \"    print(response.text)\\n\",\n        \"else:\\n\",\n        \"    function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"    print(f\\\"Function name: {function_call.name}\\\")\\n\",\n        \"    print(\\\"Parameters:\\\")\\n\",\n        \"    print(json.dumps(function_call.args, indent=2))\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"0rxCsGFBH3zy\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Provide more specific details\\n\",\n        \"response = complex_chat.send_message(\\n\",\n        \"    \\\"We'd like to stay from August 10-17, and our budget is around $300 per night. \\\"\\n\",\n        \"    \\\"A standard room is fine as long as it has a good view.\\\"\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Check the function call\\n\",\n        \"function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"print(f\\\"Function name: {function_call.name}\\\")\\n\",\n        \"print(\\\"Parameters:\\\")\\n\",\n        \"print(json.dumps(function_call.args, indent=2))\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"l9VNRm0XIWaS\"\n      },\n      \"source\": [\n        \"## Handling multiple function calls\\n\",\n        \"\\n\",\n        \"Sometimes a single user request might require multiple function calls to fulfill. Let's implement a helper that can handle this scenario.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"JI3AxOkrIlCK\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define functions for a trip planning scenario\\n\",\n        \"check_flights = {\\n\",\n        \"    \\\"name\\\": \\\"check_flights\\\",\\n\",\n        \"    \\\"description\\\": \\\"Check available flights between two locations on a specific date\\\",\\n\",\n        \"    \\\"parameters\\\": {\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"origin\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Departure city or airport code\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"destination\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Arrival city or airport code\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"date\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Travel date in YYYY-MM-DD format\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"passengers\\\": {\\n\",\n        \"                \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                \\\"description\\\": \\\"Number of passengers\\\",\\n\",\n        \"            },\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"origin\\\", \\\"destination\\\", \\\"date\\\"],\\n\",\n        \"    },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"book_hotel = {\\n\",\n        \"    \\\"name\\\": \\\"book_hotel\\\",\\n\",\n        \"    \\\"description\\\": \\\"Book a hotel room based on user preferences\\\",\\n\",\n        \"    \\\"parameters\\\": {\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"location\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"City where the hotel is located\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"check_in_date\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Check-in date in YYYY-MM-DD format\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"check_out_date\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Check-out date in YYYY-MM-DD format\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"guests\\\": {\\n\",\n        \"                \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                \\\"description\\\": \\\"Number of guests\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"room_type\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"standard\\\", \\\"deluxe\\\", \\\"suite\\\"],\\n\",\n        \"                \\\"description\\\": \\\"Type of room to book\\\",\\n\",\n        \"            },\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"location\\\", \\\"check_in_date\\\", \\\"check_out_date\\\", \\\"guests\\\"],\\n\",\n        \"    },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"get_attractions = {\\n\",\n        \"    \\\"name\\\": \\\"get_attractions\\\",\\n\",\n        \"    \\\"description\\\": \\\"Get tourist attractions in a specified location\\\",\\n\",\n        \"    \\\"parameters\\\": {\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"location\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"City or location to find attractions\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"category\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"museums\\\", \\\"parks\\\", \\\"historical\\\", \\\"entertainment\\\", \\\"shopping\\\"],\\n\",\n        \"                \\\"description\\\": \\\"Category of attractions\\\",\\n\",\n        \"            },\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"location\\\"],\\n\",\n        \"    },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"# Simulated implementations\\n\",\n        \"def check_flights_actual(origin, destination, date, passengers=1):\\n\",\n        \"    flights = [\\n\",\n        \"        {\\\"airline\\\": \\\"SkyHigh Airways\\\", \\\"flight\\\": \\\"SH101\\\", \\\"departure\\\": \\\"08:00\\\", \\\"arrival\\\": \\\"10:30\\\", \\\"price\\\": 320},\\n\",\n        \"        {\\\"airline\\\": \\\"Global Air\\\", \\\"flight\\\": \\\"GA205\\\", \\\"departure\\\": \\\"12:15\\\", \\\"arrival\\\": \\\"14:45\\\", \\\"price\\\": 285},\\n\",\n        \"        {\\\"airline\\\": \\\"Continental Express\\\", \\\"flight\\\": \\\"CE512\\\", \\\"departure\\\": \\\"16:30\\\", \\\"arrival\\\": \\\"19:00\\\", \\\"price\\\": 350},\\n\",\n        \"    ]\\n\",\n        \"    return {\\\"flights\\\": flights, \\\"origin\\\": origin, \\\"destination\\\": destination, \\\"date\\\": date, \\\"passengers\\\": passengers}\\n\",\n        \"\\n\",\n        \"def book_hotel_actual(location, check_in_date, check_out_date, guests, room_type=\\\"standard\\\"):\\n\",\n        \"    hotels = [\\n\",\n        \"        {\\\"name\\\": \\\"Grand Hotel\\\", \\\"room_type\\\": room_type, \\\"price_per_night\\\": 200, \\\"rating\\\": 4.7, \\\"available\\\": True},\\n\",\n        \"        {\\\"name\\\": \\\"City Center Inn\\\", \\\"room_type\\\": room_type, \\\"price_per_night\\\": 150, \\\"rating\\\": 4.2, \\\"available\\\": True},\\n\",\n        \"        {\\\"name\\\": \\\"Luxury Suites\\\", \\\"room_type\\\": room_type, \\\"price_per_night\\\": 300, \\\"rating\\\": 4.9, \\\"available\\\": room_type != \\\"suite\\\"},\\n\",\n        \"    ]\\n\",\n        \"    return {\\\"hotels\\\": hotels, \\\"location\\\": location, \\\"check_in\\\": check_in_date, \\\"check_out\\\": check_out_date, \\\"guests\\\": guests}\\n\",\n        \"\\n\",\n        \"def get_attractions_actual(location, category=None):\\n\",\n        \"    attractions = {\\n\",\n        \"        \\\"museums\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"City History Museum\\\", \\\"rating\\\": 4.6, \\\"price\\\": \\\"$15\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Modern Art Gallery\\\", \\\"rating\\\": 4.4, \\\"price\\\": \\\"$20\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Science Center\\\", \\\"rating\\\": 4.8, \\\"price\\\": \\\"$25\\\"},\\n\",\n        \"        ],\\n\",\n        \"        \\\"parks\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"Central Gardens\\\", \\\"rating\\\": 4.7, \\\"price\\\": \\\"Free\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Riverside Park\\\", \\\"rating\\\": 4.5, \\\"price\\\": \\\"Free\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Botanical Gardens\\\", \\\"rating\\\": 4.9, \\\"price\\\": \\\"$10\\\"},\\n\",\n        \"        ],\\n\",\n        \"        \\\"historical\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"Ancient Cathedral\\\", \\\"rating\\\": 4.8, \\\"price\\\": \\\"$12\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Old Town Square\\\", \\\"rating\\\": 4.6, \\\"price\\\": \\\"Free\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Historic Castle\\\", \\\"rating\\\": 4.9, \\\"price\\\": \\\"$22\\\"},\\n\",\n        \"        ],\\n\",\n        \"        \\\"entertainment\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"City Theater\\\", \\\"rating\\\": 4.5, \\\"price\\\": \\\"$40-100\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Amusement Park\\\", \\\"rating\\\": 4.7, \\\"price\\\": \\\"$50\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Concert Hall\\\", \\\"rating\\\": 4.6, \\\"price\\\": \\\"$30-120\\\"},\\n\",\n        \"        ],\\n\",\n        \"        \\\"shopping\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"Main Street Mall\\\", \\\"rating\\\": 4.4, \\\"price\\\": \\\"Varies\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Artisan Market\\\", \\\"rating\\\": 4.7, \\\"price\\\": \\\"Varies\\\"},\\n\",\n        \"            {\\\"name\\\": \\\"Luxury Shopping Center\\\", \\\"rating\\\": 4.3, \\\"price\\\": \\\"High\\\"},\\n\",\n        \"        ],\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    if category and category in attractions:\\n\",\n        \"        return {\\\"attractions\\\": attractions[category], \\\"location\\\": location, \\\"category\\\": category}\\n\",\n        \"    else:\\n\",\n        \"        # If no category specified, return one item from each category\\n\",\n        \"        mixed = [cat[0] for cat in attractions.values()]\\n\",\n        \"        return {\\\"attractions\\\": mixed, \\\"location\\\": location, \\\"category\\\": \\\"mixed\\\"}\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"0j6Ay8csK8ea\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Initialize a chat with all three functions\\n\",\n        \"multi_chat = model.start_chat(\\n\",\n        \"    system_instruction=\\\"You are a travel planning assistant that helps users book complete trips.\\\",\\n\",\n        \"    tools=[{\\\"function_declarations\\\": [check_flights, book_hotel, get_attractions]}]\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"9tl0uTiQLCsa\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Process a complex request that might require multiple function calls\\n\",\n        \"def process_complex_request(user_message):\\n\",\n        \"    print(f\\\"User: {user_message}\\\\n\\\")\\n\",\n        \"    \\n\",\n        \"    # Send initial message to the model\\n\",\n        \"    response = multi_chat.send_message(user_message)\\n\",\n        \"    \\n\",\n        \"    # Process all function calls until we get a text response\\n\",\n        \"    while hasattr(response.candidates[0].content.parts[0], 'function_call'):\\n\",\n        \"        function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"        print(f\\\"Model is calling function: {function_call.name}\\\")\\n\",\n        \"        print(f\\\"With parameters: {json.dumps(function_call.args, indent=2)}\\\")\\n\",\n        \"        \\n\",\n        \"        # Execute the appropriate function\\n\",\n        \"        if function_call.name == \\\"check_flights\\\":\\n\",\n        \"            args = function_call.args\\n\",\n        \"            function_response = check_flights_actual(\\n\",\n        \"                origin=args.get(\\\"origin\\\"),\\n\",\n        \"                destination=args.get(\\\"destination\\\"),\\n\",\n        \"                date=args.get(\\\"date\\\"),\\n\",\n        \"                passengers=args.get(\\\"passengers\\\", 1)\\n\",\n        \"            )\\n\",\n        \"        elif function_call.name == \\\"book_hotel\\\":\\n\",\n        \"            args = function_call.args\\n\",\n        \"            function_response = book_hotel_actual(\\n\",\n        \"                location=args.get(\\\"location\\\"),\\n\",\n        \"                check_in_date=args.get(\\\"check_in_date\\\"),\\n\",\n        \"                check_out_date=args.get(\\\"check_out_date\\\"),\\n\",\n        \"                guests=args.get(\\\"guests\\\"),\\n\",\n        \"                room_type=args.get(\\\"room_type\\\", \\\"standard\\\")\\n\",\n        \"            )\\n\",\n        \"        elif function_call.name == \\\"get_attractions\\\":\\n\",\n        \"            args = function_call.args\\n\",\n        \"            function_response = get_attractions_actual(\\n\",\n        \"                location=args.get(\\\"location\\\"),\\n\",\n        \"                category=args.get(\\\"category\\\")\\n\",\n        \"            )\\n\",\n        \"        else:\\n\",\n        \"            function_response = {\\\"error\\\": f\\\"Unknown function: {function_call.name}\\\"}\\n\",\n        \"        \\n\",\n        \"        print(f\\\"Function response: {json.dumps(function_response, indent=2)}\\\\n\\\")\\n\",\n        \"        \\n\",\n        \"        # Send the function response back to the model\\n\",\n        \"        response = multi_chat.send_message(\\n\",\n        \"            {\\n\",\n        \"                \\\"function_response\\\": {\\n\",\n        \"                    \\\"name\\\": function_call.name,\\n\",\n        \"                    \\\"response\\\": function_response\\n\",\n        \"                }\\n\",\n        \"            }\\n\",\n        \"        )\\n\",\n        \"    \\n\",\n        \"    # Print the model's final response\\n\",\n        \"    print(f\\\"Assistant: {response.text}\\\\n\\\")\\n\",\n        \"    print(\\\"-\\\" * 80)\\n\",\n        \"    return response\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"d3LLR-UXMQ6p\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with a complex request that might need multiple function calls\\n\",\n        \"process_complex_request(\\n\",\n        \"    \\\"I want to plan a trip from New York to Paris from September 10 to September 15 for 2 people. \\\"\\n\",\n        \"    \\\"I'd like to book a deluxe hotel room and also find out about museums and historical sites to visit.\\\"\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"msFWUwTfQG4K\"\n      },\n      \"source\": [\n        \"## Error handling in function calls\\n\",\n        \"\\n\",\n        \"Let's explore how to handle errors in function calls and how the model responds to them.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"9aL3hc-LQNCa\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Initialize a chat with a simple calculator function\\n\",\n        \"calculate = {\\n\",\n        \"    \\\"name\\\": \\\"calculate\\\",\\n\",\n        \"    \\\"description\\\": \\\"Perform a mathematical calculation\\\",\\n\",\n        \"    \\\"parameters\\\": {\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"operation\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"add\\\", \\\"subtract\\\", \\\"multiply\\\", \\\"divide\\\", \\\"square_root\\\"],\\n\",\n        \"                \\\"description\\\": \\\"The mathematical operation to perform\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"a\\\": {\\n\",\n        \"                \\\"type\\\": \\\"number\\\",\\n\",\n        \"                \\\"description\\\": \\\"The first operand\\\",\\n\",\n        \"            },\\n\",\n        \"            \\\"b\\\": {\\n\",\n        \"                \\\"type\\\": \\\"number\\\",\\n\",\n        \"                \\\"description\\\": \\\"The second operand (not needed for square_root)\\\",\\n\",\n        \"            },\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"operation\\\", \\\"a\\\"],\\n\",\n        \"    },\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"def calculate_actual(operation, a, b=None):\\n\",\n        \"    try:\\n\",\n        \"        if operation == \\\"add\\\":\\n\",\n        \"            if b is None:\\n\",\n        \"                return {\\\"error\\\": \\\"Missing second operand for addition\\\"}\\n\",\n        \"            return {\\\"result\\\": a + b}\\n\",\n        \"        elif operation == \\\"subtract\\\":\\n\",\n        \"            if b is None:\\n\",\n        \"                return {\\\"error\\\": \\\"Missing second operand for subtraction\\\"}\\n\",\n        \"            return {\\\"result\\\": a - b}\\n\",\n        \"        elif operation == \\\"multiply\\\":\\n\",\n        \"            if b is None:\\n\",\n        \"                return {\\\"error\\\": \\\"Missing second operand for multiplication\\\"}\\n\",\n        \"            return {\\\"result\\\": a * b}\\n\",\n        \"        elif operation == \\\"divide\\\":\\n\",\n        \"            if b is None:\\n\",\n        \"                return {\\\"error\\\": \\\"Missing second operand for division\\\"}\\n\",\n        \"            if b == 0:\\n\",\n        \"                return {\\\"error\\\": \\\"Cannot divide by zero\\\"}\\n\",\n        \"            return {\\\"result\\\": a / b}\\n\",\n        \"        elif operation == \\\"square_root\\\":\\n\",\n        \"            if a < 0:\\n\",\n        \"                return {\\\"error\\\": \\\"Cannot calculate square root of negative number\\\"}\\n\",\n        \"            return {\\\"result\\\": a ** 0.5}\\n\",\n        \"        else:\\n\",\n        \"            return {\\\"error\\\": f\\\"Unknown operation: {operation}\\\"}\\n\",\n        \"    except Exception as e:\\n\",\n        \"        return {\\\"error\\\": f\\\"Calculation error: {str(e)}\\\"}\\n\",\n        \"\\n\",\n        \"calc_chat = model.start_chat(\\n\",\n        \"    tools=[{\\\"function_declarations\\\": [calculate]}]\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Dcc6KyxmRVbS\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Helper function to process calculator requests\\n\",\n        \"def process_calculation(user_message):\\n\",\n        \"    print(f\\\"User: {user_message}\\\\n\\\")\\n\",\n        \"    \\n\",\n        \"    # Send message to the model\\n\",\n        \"    response = calc_chat.send_message(user_message)\\n\",\n        \"    \\n\",\n        \"    # Check if model wants to call a function\\n\",\n        \"    if hasattr(response.candidates[0].content.parts[0], 'function_call'):\\n\",\n        \"        function_call = response.candidates[0].content.parts[0].function_call\\n\",\n        \"        print(f\\\"Model is calling function: {function_call.name}\\\")\\n\",\n        \"        print(f\\\"With parameters: {json.dumps(function_call.args, indent=2)}\\\")\\n\",\n        \"        \\n\",\n        \"        # Execute the function\\n\",\n        \"        args = function_call.args\\n\",\n        \"        function_response = calculate_actual(\\n\",\n        \"            operation=args.get(\\\"operation\\\"),\\n\",\n        \"            a=args.get(\\\"a\\\"),\\n\",\n        \"            b=args.get(\\\"b\\\")\\n\",\n        \"        )\\n\",\n        \"        \\n\",\n        \"        print(f\\\"Function response: {json.dumps(function_response, indent=2)}\\\\n\\\")\\n\",\n        \"        \\n\",\n        \"        # Send the function response back to the model\\n\",\n        \"        response = calc_chat.send_message(\\n\",\n        \"            {\\n\",\n        \"                \\\"function_response\\\": {\\n\",\n        \"                    \\\"name\\\": function_call.name,\\n\",\n        \"                    \\\"response\\\": function_response\\n\",\n        \"                }\\n\",\n        \"            }\\n\",\n        \"        )\\n\",\n        \"    \\n\",\n        \"    # Print the model's response\\n\",\n        \"    print(f\\\"Assistant: {response.text}\\\\n\\\")\\n\",\n        \"    print(\\\"-\\\" * 80)\\n\",\n        \"    return response\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"3aNxZOgRR_qp\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with a normal calculation\\n\",\n        \"process_calculation(\\\"What is 42 divided by 6?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"8gDYR4J6SXbK\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with a calculation that will produce an error\\n\",\n        \"process_calculation(\\\"What is 10 divided by 0?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"GKzTEb4ESjap\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with another error case\\n\",\n        \"process_calculation(\\\"What is the square root of -25?\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"hcNuDR-8SxYq\"\n      },\n      \"source\": [\n        \"## Best practices for function calling\\n\",\n        \"\\n\",\n        \"Let's summarize some best practices for using function calling effectively:\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"1MkQT3nETEIp\"\n      },\n      \"source\": [\n        \"1. **Clear function descriptions**: Provide clear, concise descriptions for your functions and parameters\\n\",\n        \"\\n\",\n        \"2. **Use appropriate parameter types**: Choose the most appropriate type for each parameter (string, number, boolean, array, object)\\n\",\n        \"\\n\",\n        \"3. **Mark required parameters**: Identify which parameters are required using the `required` field\\n\",\n        \"\\n\",\n        \"4. **Use enums for fixed choices**: When parameters have a fixed set of valid values, use the `enum` field\\n\",\n        \"\\n\",\n        \"5. **Handle errors gracefully**: Return meaningful error messages when function calls fail\\n\",\n        \"\\n\",\n        \"6. **Process multiple function calls**: Design your application to handle cases where multiple function calls are needed\\n\",\n        \"\\n\",\n        \"7. **Provide feedback to the model**: Always send function responses back to the model\\n\",\n        \"\\n\",\n        \"8. **Use system instructions**: Set appropriate system instructions to guide the model's behavior\\n\",\n        \"\\n\",\n        \"9. **Test edge cases**: Test with a variety of inputs including edge cases and error conditions\\n\",\n        \"\\n\",\n        \"10. **Implement validation**: Validate parameters before executing functions\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"provenance\": []\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3 (ipykernel)\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.11.3\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006# site/en/gemini-api/docs/generative_models/multimodal-prompting.md\n# Multimodal prompting\n\nThis guide shows how to use multimodal prompting with Gemini Pro Vision to create applications that can understand and respond to inputs containing both text and images.\n\n## Overview\n\nMultimodal prompting allows you to combine different types of content—such as text and images—in your prompts. Gemini Pro Vision is designed to understand the context across these different modalities and generate appropriate responses.\n\n## Set up your environment\n\nFirst, install the necessary libraries:\n\n```python\n!pip install -q google-generativeai pillow\n```\n\nNow import the libraries and configure your API key:\n\n```python\nimport google.generativeai as genai\nfrom PIL import Image\nimport requests\nimport io\n\n# Configure the API key\ngenai.configure(api_key=\"YOUR_API_KEY\")\n```\n\n## Create a multimodal model\n\nInitialize the Gemini Pro Vision model:\n\n```python\nmodel = genai.GenerativeModel('gemini-pro-vision')\n```\n\n## Simple image understanding\n\nLet's start with a basic example of image understanding:\n\n```python\n# Load an image from a URL\nimage_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/cat.jpg\"\nimage_data = requests.get(image_url).content\nimage = Image.open(io.BytesIO(image_data))\n\n# Display the image (in a notebook)\ndisplay(image)\n\n# Generate content based on the image\nresponse = model.generate_content([\"What's in this image?\", image])\nprint(response.text)\n```\n\n## Analyzing images with specific instructions\n\nYou can provide specific instructions for analyzing images:\n\n```python\n# Load an image\nimage_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/landmark.jpg\"\nimage_data = requests.get(image_url).content\nimage = Image.open(io.BytesIO(image_data))\n\n# Display the image (in a notebook)\ndisplay(image)\n\n# Ask specific questions about the image\nprompt = \"\"\"\nFor the landmark in this image:\n1. Identify the name and location\n2. Provide three interesting historical facts\n3. When is the best time of year to visit?\n\"\"\"\n\nresponse = model.generate_content([prompt, image])\nprint(response.text)\n```\n\n## Multiple images in a single prompt\n\nYou can include multiple images in a single prompt:\n\n```python\n# Load two images\nimage_url1 = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/palace1.jpg\"\nimage_url2 = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/palace2.jpg\"\n\nimage_data1 = requests.get(image_url1).content\nimage_data2 = requests.get(image_url2).content\n\nimage1 = Image.open(io.BytesIO(image_data1))\nimage2 = Image.open(io.BytesIO(image_data2))\n\n# Display the images (in a notebook)\ndisplay(image1)\ndisplay(image2)\n\n# Compare the two images\nprompt = \"\"\"\nCompare these two buildings:\n1. What architectural styles do they represent?\n2. What are the key differences between them?\n3. What historical periods were they likely built in?\n\"\"\"\n\nresponse = model.generate_content([prompt, image1, image2])\nprint(response.text)\n```\n\n## Reading text from images\n\nGemini Pro Vision can extract and interpret text from images:\n\n```python\n# Load an image containing text\nimage_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/receipt.jpg\"\nimage_data = requests.get(image_url).content\nimage = Image.open(io.BytesIO(image_data))\n\n# Display the image (in a notebook)\ndisplay(image)\n\n# Extract information from the receipt\nprompt = \"\"\"\nLook at this receipt and:\n1. List all the items purchased and their prices\n2. Calculate the total amount spent\n3. What type of establishment is this from?\n\"\"\"\n\nresponse = model.generate_content([prompt, image])\nprint(response.text)\n```\n\n## Explaining diagrams and charts\n\nGemini is particularly useful for understanding diagrams and charts:\n\n```python\n# Load a diagram image\nimage_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/diagram.jpg\"\nimage_data = requests.get(image_url).content\nimage = Image.open(io.BytesIO(image_data))\n\n# Display the image (in a notebook)\ndisplay(image)\n\n# Analyze the diagram\nprompt = \"\"\"\nExplain this diagram in detail:\n1. What process or system does it represent?\n2. Describe each component and its function\n3. How do the components interact with each other?\n\"\"\"\n\nresponse = model.generate_content([prompt, image])\nprint(response.text)\n```\n\n## Creative tasks with images\n\nYou can use images as inspiration for creative content:\n\n```python\n# Load an image\nimage_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/landscape.jpg\"\nimage_data = requests.get(image_url).content\nimage = Image.open(io.BytesIO(image_data))\n\n# Display the image (in a notebook)\ndisplay(image)\n\n# Generate creative content based on the image\nprompt = \"\"\"\nUsing this image as inspiration:\n1. Write a short poem (4-6 lines) capturing the mood of this scene\n2. Create a brief story introduction (2-3 sentences) set in this location\n\"\"\"\n\nresponse = model.generate_content([prompt, image])\nprint(response.text)\n```\n\n## Working with images of handwritten text\n\nGemini can recognize and process handwritten text:\n\n```python\n# Load an image with handwritten text\nimage_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/handwritten.jpg\"\nimage_data = requests.get(image_url).content\nimage = Image.open(io.BytesIO(image_data))\n\n# Display the image (in a notebook)\ndisplay(image)\n\n# Transcribe and interpret the handwritten text\nprompt = \"\"\"\nFor this handwritten note:\n1. Transcribe the text exactly as written\n2. Correct any spelling or grammatical errors\n3. Summarize the main points in a single sentence\n\"\"\"\n\nresponse = model.generate_content([prompt, image])\nprint(response.text)\n```\n\n## Solving problems from images\n\nGemini can solve problems presented in images:\n\n```python\n# Load an image with a math problem\nimage_url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/math_problem.jpg\"\nimage_data = requests.get(image_url).content\nimage = Image.open(io.BytesIO(image_data))\n\n# Display the image (in a notebook)\ndisplay(image)\n\n# Solve the math problem\nprompt = \"\"\"\nFor this math problem:\n1. What is being asked?\n2. Solve it step by step\n3. Verify your answer\n\"\"\"\n\nresponse = model.generate_content([prompt, image])\nprint(response.text)\n```\n\n## Best practices for multimodal prompting\n\n1. **Be specific in your instructions**: Clearly state what you want the model to analyze or explain about the images.\n\n2. **Provide context**: When necessary, include contextual information to help the model understand what's important in the image.\n\n3. **Use numbered lists for multiple questions**: This helps structure the model's response and ensures it addresses all parts of your query.\n\n4. **Experiment with different prompts**: If you don't get the desired results, try rephrasing your prompt or being more specific.\n\n5. **Consider image quality**: Higher quality images generally yield better results. Crop images to focus on the relevant content when possible.\n\n6. **Combine multiple images strategically**: When using multiple images, clearly explain their relationship or what you want the model to compare.\n\n7. **Be aware of model limitations**: Gemini may struggle with very detailed text in images, complex technical diagrams, or images with many small elements.\n\n## Advanced techniques\n\n### Using system instructions with multimodal prompts\n\nYou can set system instructions to guide the model's behavior:\n\n```python\nchat = model.start_chat(\n    system_instruction=\"You are an expert art historian specializing in identifying painting styles and artists. Provide detailed analysis of any artwork shown.\"\n)\n\nresponse = chat.send_message([\n    \"Who might have painted this and what style is it?\", \n    image\n])\nprint(response.text)\n```\n\n### Combining multimodal with function calling\n\nYou can use multimodal inputs with function calling for structured outputs:\n\n```python\n# Define a function for image analysis\nimage_analysis_function = {\n    \"name\": \"analyze_image\",\n    \"description\": \"Analyze the content of an image and provide structured information\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"main_subject\": {\n                \"type\": \"string\",\n                \"description\": \"The main subject or focus of the image\"\n            },\n            \"background_elements\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"string\"\n                },\n                \"description\": \"Elements visible in the background of the image\"\n            },\n            \"colors\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"string\"\n                },\n                \"description\": \"Predominant colors in the image\"\n            },\n            \"mood\": {\n                \"type\": \"string\",\n                \"description\": \"The overall mood or feeling conveyed by the image\"\n            }\n        },\n        \"required\": [\"main_subject\", \"colors\", \"mood\"]\n    }\n}\n\n# Create a model with the function\nmodel_with_function = genai.GenerativeModel(\n    model_name=\"gemini-pro-vision\",\n    tools=[{\"function_declarations\": [image_analysis_function]}]\n)\n\n# Generate structured analysis\nresponse = model_with_function.generate_content(\n    [\"Analyze this image in detail\", image]\n)\n\n# Extract the function call\nfunction_call = response.candidates[0].content.parts[0].function_call\nprint(function_call.name)\nprint(function_call.args)\n```\n\n## Troubleshooting\n\nIf you encounter issues with multimodal prompting:\n\n1. **Image size or format**: Ensure your images are in a supported format (JPEG, PNG, WebP, HEIC) and within size limits.\n\n2. **Prompt clarity**: Make sure your prompts are clear and specific about what you want the model to analyze.\n\n3. **Content policy violations**: If responses are blocked, your images might contain content that violates content policies.\n\n4. **Complex images**: Break down analysis of complex images into multiple, more focused prompts.\n\n5. **API errors**: Check for error messages in the API response for specific issues.\n\n## Next steps\n\n- Explore [image recognition and classification](https://ai.google.dev/tutorials/vision_tutorial) capabilities\n- Learn about [function calling](https://ai.google.dev/docs/function_calling) with multimodal inputs\n- Try [RAG (Retrieval-Augmented Generation)](https://ai.google.dev/docs/rag_overview) with image inputs\n- Build a [multimodal chatbot](https://ai.google.dev/tutorials/chat_apps_tutorial) with both text and image understanding\n\u0005End File\u0006# google/generative-ai-docs\n# Use function calling with Gemini\n\nThis guide explains how to use function calling with the Gemini API to enable structured interactions between your application and Gemini models.\n\n## Overview\n\nFunction calling allows Gemini to:\n1. Recognize when a function should be called based on user input\n2. Generate a JSON object with the necessary parameters for the function\n3. Allow your application to execute the function\n4. Use the function's result to generate a final response\n\nThis capability is useful for:\n- Retrieving real-time information (weather, sports scores, etc.)\n- Performing actions in external systems (booking appointments, ordering products)\n- Accessing databases or private data\n- Generating structured data for your application\n\n## Basic function calling flow\n\nThe basic flow for function calling is:\n\n1. **Define functions**: Specify the function schema with name, description, and parameters\n2. **Send user query**: Send the user's request along with function definitions\n3. **Get function call**: Model identifies a function should be called and returns parameters\n4. **Execute function**: Your application executes the function with the provided parameters\n5. **Return result**: Send the function result back to the model\n6. **Get final response**: Model generates a human-friendly response based on function results\n\n## Setting up your environment\n\nFirst, install the required packages:\n\n```python\n!pip install -q google-generativeai\n```\n\nThen set up your API key:\n\n```python\nimport google.generativeai as genai\nimport json\n\n# Set your API key\ngenai.configure(api_key=\"YOUR_API_KEY\")\n```\n\n## Defining a function\n\nLet's define a simple weather lookup function:\n\n```python\n# Define the function schema\nget_current_weather = {\n  \"name\": \"get_current_weather\",\n  \"description\": \"Get the current weather in a given location\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"location\": {\n        \"type\": \"string\",\n        \"description\": \"The city and state, e.g. San Francisco, CA\"\n      },\n      \"unit\": {\n        \"type\": \"string\",\n        \"enum\": [\"celsius\", \"fahrenheit\"],\n        \"description\": \"The unit of temperature\"\n      }\n    },\n    \"required\": [\"location\"]\n  }\n}\n\n# Set up the model with the function\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-pro\",\n  tools=[{\"function_declarations\": [get_current_weather]}]\n)\n```\n\n## Making a function call\n\nNow let's use the model to process a user query and generate a function call:\n\n```python\n# User query\nuser_query = \"What's the weather like in Boston?\"\n\n# Generate response\nresponse = model.generate_content(user_query)\n\n# Check if model wants to call a function\nfunction_call = response.candidates[0].content.parts[0].function_call\nprint(f\"Function to call: {function_call.name}\")\nprint(f\"Parameters: {function_call.args}\")\n```\n\n## Executing a function and providing the result\n\nIn a real application, you'd execute the actual function. Here we'll simulate it:\n\n```python\n# This would be your actual function implementation\ndef get_weather_data(location, unit=\"fahrenheit\"):\n    \"\"\"Simulate getting weather data\"\"\"\n    # In a real app, you'd call a weather API here\n    weather_data = {\n        \"location\": location,\n        \"temperature\": 72 if unit == \"fahrenheit\" else 22,\n        \"condition\": \"Sunny\",\n        \"humidity\": 45,\n        \"wind_speed\": 10\n    }\n    return weather_data\n\n# Extract parameters from the function call\nlocation = function_call.args[\"location\"]\nunit = function_call.args.get(\"unit\", \"fahrenheit\")\n\n# Execute the function\nfunction_result = get_weather_data(location, unit)\n\n# Create a chat to maintain context\nchat = model.start_chat(\n  tools=[{\"function_declarations\": [get_current_weather]}]\n)\n\n# Send initial user query\nresponse = chat.send_message(user_query)\n\n# Send function result back to the model\nresponse = chat.send_message({\n  \"function_response\": {\n    \"name\": function_call.name,\n    \"response\": function_result\n  }\n})\n\n# Print the model's response\nprint(response.text)\n```\n\n## Multiple functions\n\nYou can define multiple functions for more complex use cases:\n\n```python\n# Define multiple functions\nget_current_weather = {\n  \"name\": \"get_current_weather\",\n  \"description\": \"Get the current weather in a given location\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"location\": {\n        \"type\": \"string\",\n        \"description\": \"The city and state, e.g. San Francisco, CA\"\n      },\n      \"unit\": {\n        \"type\": \"string\",\n        \"enum\": [\"celsius\", \"fahrenheit\"]\n      }\n    },\n    \"required\": [\"location\"]\n  }\n}\n\nget_restaurant_recommendation = {\n  \"name\": \"get_restaurant_recommendation\",\n  \"description\": \"Get restaurant recommendations for a location\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"location\": {\n        \"type\": \"string\",\n        \"description\": \"The city and state, e.g. San Francisco, CA\"\n      },\n      \"cuisine\": {\n        \"type\": \"string\",\n        \"description\": \"Type of cuisine, e.g. Italian, Chinese\"\n      },\n      \"price_level\": {\n        \"type\": \"string\",\n        \"enum\": [\"cheap\", \"moderate\", \"expensive\", \"very expensive\"]\n      },\n      \"outdoor_seating\": {\n        \"type\": \"boolean\",\n        \"description\": \"Whether outdoor seating is required\"\n      }\n    },\n    \"required\": [\"location\"]\n  }\n}\n\n# Set up the model with multiple functions\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-pro\",\n  tools=[{\"function_declarations\": [get_current_weather, get_restaurant_recommendation]}]\n)\n```\n\nNow the model will choose the appropriate function based on the user's query:\n\n```python\n# Test with weather query\nweather_query = \"What's the weather like in Miami?\"\nweather_response = model.generate_content(weather_query)\nweather_function = weather_response.candidates[0].content.parts[0].function_call\nprint(f\"For weather query, model chose: {weather_function.name}\")\n\n# Test with restaurant query\nrestaurant_query = \"Find me Italian restaurants in Chicago with outdoor seating\"\nrestaurant_response = model.generate_content(restaurant_query)\nrestaurant_function = restaurant_response.candidates[0].content.parts[0].function_call\nprint(f\"For restaurant query, model chose: {restaurant_function.name}\")\nprint(f\"Parameters: {restaurant_function.args}\")\n```\n\n## Complex parameter types\n\nFunctions can have complex parameter types like arrays and nested objects:\n\n```python\n# Function with complex parameters\nbook_flight = {\n  \"name\": \"book_flight\",\n  \"description\": \"Book a flight based on user preferences\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"departure\": {\n        \"type\": \"string\",\n        \"description\": \"Departure city or airport code\"\n      },\n      \"destination\": {\n        \"type\": \"string\",\n        \"description\": \"Destination city or airport code\"\n      },\n      \"date\": {\n        \"type\": \"string\",\n        \"description\": \"Departure date in YYYY-MM-DD format\"\n      },\n      \"passengers\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"adults\": {\n            \"type\": \"integer\",\n            \"description\": \"Number of adult passengers\"\n          },\n          \"children\": {\n            \"type\": \"integer\",\n            \"description\": \"Number of child passengers\"\n          }\n        },\n        \"required\": [\"adults\"]\n      },\n      \"preferences\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\",\n          \"enum\": [\"window\", \"aisle\", \"extra_legroom\", \"vegetarian_meal\", \"priority_boarding\"]\n        },\n        \"description\": \"List of passenger preferences\"\n      }\n    },\n    \"required\": [\"departure\", \"destination\", \"date\"]\n  }\n}\n\n# Test with a complex query\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-pro\",\n  tools=[{\"function_declarations\": [book_flight]}]\n)\n\ncomplex_query = \"\"\"\nI need to book a flight from New York to London on October 15, 2024. \nThere will be 2 adults and 1 child. We prefer aisle seats and would like vegetarian meals.\n\"\"\"\n\ncomplex_response = model.generate_content(complex_query)\ncomplex_function = complex_response.candidates[0].content.parts[0].function_call\nprint(f\"Function name: {complex_function.name}\")\nprint(\"Parameters:\")\nprint(json.dumps(complex_function.args, indent=2))\n```\n\n## Handling multi-turn conversations\n\nFunction calling works well in multi-turn conversations:\n\n```python\n# Create a chat with function calling\nchat = model.start_chat(\n  tools=[{\"function_declarations\": [get_current_weather, get_restaurant_recommendation]}]\n)\n\n# Define a helper function to process each turn\ndef process_turn(user_message):\n    # Send the user message\n    response = chat.send_message(user_message)\n    \n    # Check if model wants to call a function\n    if hasattr(response.candidates[0].content.parts[0], 'function_call'):\n        function_call = response.candidates[0].content.parts[0].function_call\n        print(f\"Model wants to call: {function_call.name}\")\n        \n        # Simulate executing the function\n        if function_call.name == \"get_current_weather\":\n            result = {\n                \"location\": function_call.args.get(\"location\"),\n                \"temperature\": 65,\n                \"condition\": \"Partly cloudy\",\n                \"humidity\": 70,\n                \"wind_speed\": 8\n            }\n        elif function_call.name == \"get_restaurant_recommendation\":\n            result = {\n                \"restaurants\": [\n                    {\"name\": \"Pasta Palace\", \"cuisine\": \"Italian\", \"rating\": 4.5},\n                    {\"name\": \"Luigi's Trattoria\", \"cuisine\": \"Italian\", \"rating\": 4.7},\n                    {\"name\": \"Mamma Mia\", \"cuisine\": \"Italian\", \"rating\": 4.2}\n                ]\n            }\n        \n        # Send function result back to model\n        response = chat.send_message({\n            \"function_response\": {\n                \"name\": function_call.name,\n                \"response\": result\n            }\n        })\n    \n    print(f\"Model response: {response.text}\\n\")\n    return response\n\n# Start a conversation\nprint(\"Starting conversation...\\n\")\nprocess_turn(\"What's the weather like in Seattle?\")\nprocess_turn(\"Thanks! Now can you recommend Italian restaurants there?\")\nprocess_turn(\"Which one has the highest rating?\")\n```\n\n## Best practices\n\n1. **Clear function descriptions**: Provide clear, specific descriptions for your functions and parameters.\n\n2. **Appropriate naming**: Use descriptive function and parameter names that indicate their purpose.\n\n3. **Parameter constraints**: Use the `required` field to mark necessary parameters and `enum` for fixed options.\n\n4. **Error handling**: Implement proper error handling for function execution and invalid parameters.\n\n5. **Validation**: Validate parameters before executing functions to ensure they meet your requirements.\n\n6. **Multi-turn design**: Design your conversation flow to handle multiple turns and function calls.\n\n7. **Testing**: Test your functions with various user inputs to ensure they work correctly.\n\n8. **Context preservation**: Use chat sessions to maintain context throughout the conversation.\n\n## Example: Building a trip planning assistant\n\nLet's build a complete example of a trip planning assistant:\n\n```python\n# Define functions for trip planning\nget_flight_info = {\n  \"name\": \"get_flight_info\",\n  \"description\": \"Get flight information between two locations\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"departure\": {\n        \"type\": \"string\",\n        \"description\": \"Departure city or airport\"\n      },\n      \"destination\": {\n        \"type\": \"string\",\n        \"description\": \"Destination city or airport\"\n      },\n      \"date\": {\n        \"type\": \"string\",\n        \"description\": \"Travel date in YYYY-MM-DD format\"\n      }\n    },\n    \"required\": [\"departure\", \"destination\", \"date\"]\n  }\n}\n\nget_hotel_info = {\n  \"name\": \"get_hotel_info\",\n  \"description\": \"Get hotel information in a location\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"location\": {\n        \"type\": \"string\",\n        \"description\": \"City or area to search for hotels\"\n      },\n      \"check_in\": {\n        \"type\": \"string\",\n        \"description\": \"Check-in date in YYYY-MM-DD format\"\n      },\n      \"check_out\": {\n        \"type\": \"string\",\n        \"description\": \"Check-out date in YYYY-MM-DD format\"\n      },\n      \"guests\": {\n        \"type\": \"integer\",\n        \"description\": \"Number of guests\"\n      }\n    },\n    \"required\": [\"location\", \"check_in\", \"check_out\"]\n  }\n}\n\nget_attractions = {\n  \"name\": \"get_attractions\",\n  \"description\": \"Get tourist attractions in a location\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"location\": {\n        \"type\": \"string\",\n        \"description\": \"City or area to search for attractions\"\n      },\n      \"type\": {\n        \"type\": \"string\",\n        \"enum\": [\"museum\", \"park\", \"historical\", \"entertainment\", \"shopping\"],\n        \"description\": \"Type of attraction\"\n      }\n    },\n    \"required\": [\"location\"]\n  }\n}\n\n# Set up the model with all functions\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-pro\",\n  tools=[{\"function_declarations\": [get_flight_info, get_hotel_info, get_attractions]}]\n)\n\n# Create a chat with a system instruction\ntrip_chat = model.start_chat(\n  system_instruction=\"You are a helpful trip planning assistant. Help users plan their trips by getting flight information, hotel recommendations, and suggesting attractions to visit.\",\n  tools=[{\"function_declarations\": [get_flight_info, get_hotel_info, get_attractions]}]\n)\n\n# Simulated function implementations\ndef simulate_get_flight_info(params):\n    return {\n        \"flights\": [\n            {\"airline\": \"SkyWings\", \"departure_time\": \"08:30\", \"arrival_time\": \"11:45\", \"price\": 320},\n            {\"airline\": \"Global Air\", \"departure_time\": \"12:15\", \"arrival_time\": \"15:30\", \"price\": 285},\n            {\"airline\": \"TransContinental\", \"departure_time\": \"16:00\", \"arrival_time\": \"19:15\", \"price\": 310}\n        ]\n    }\n\ndef simulate_get_hotel_info(params):\n    return {\n        \"hotels\": [\n            {\"name\": \"Grand Plaza Hotel\", \"stars\": 4, \"price_per_night\": 180, \"distance_to_center\": \"0.5 miles\"},\n            {\"name\": \"Comfort Inn\", \"stars\": 3, \"price_per_night\": 120, \"distance_to_center\": \"1.2 miles\"},\n            {\"name\": \"Luxury Suites\", \"stars\": 5, \"price_per_night\": 280, \"distance_to_center\": \"0.3 miles\"}\n        ]\n    }\n\ndef simulate_get_attractions(params):\n    attraction_types = {\n        \"museum\": [\n            {\"name\": \"Modern Art Gallery\", \"rating\": 4.6, \"price\": \"$15\"},\n            {\"name\": \"Natural History Museum\", \"rating\": 4.8, \"price\": \"$20\"}\n        ],\n        \"park\": [\n            {\"name\": \"Central Gardens\", \"rating\": 4.7, \"price\": \"Free\"},\n            {\"name\": \"Riverside Park\", \"rating\": 4.5, \"price\": \"Free\"}\n        ],\n        \"historical\": [\n            {\"name\": \"Ancient Cathedral\", \"rating\": 4.9, \"price\": \"$12\"},\n            {\"name\": \"Old Town Square\", \"rating\": 4.6, \"price\": \"Free\"}\n        ]\n    }\n    \n    attraction_type = params.get(\"type\", \"museum\")\n    if attraction_type in attraction_types:\n        return {\"attractions\": attraction_types[attraction_type]}\n    else:\n        # Return a mix of attractions if no specific type requested\n        return {\"attractions\": [item[0] for item in attraction_types.values()]}\n\n# Process a trip planning conversation\ndef plan_trip(user_message):\n    print(f\"User: {user_message}\\n\")\n    \n    # Send the user message\n    response = trip_chat.send_message(user_message)\n    \n    # Check if model wants to call a function\n    if hasattr(response.candidates[0].content.parts[0], 'function_call'):\n        function_call = response.candidates[0].content.parts[0].function_call\n        print(f\"Model is calling function: {function_call.name}\")\n        print(f\"With parameters: {json.dumps(function_call.args, indent=2)}\\n\")\n        \n        # Simulate executing the appropriate function\n        if function_call.name == \"get_flight_info\":\n            function_result = simulate_get_flight_info(function_call.args)\n        elif function_call.name == \"get_hotel_info\":\n            function_result = simulate_get_hotel_info(function_call.args)\n        elif function_call.name == \"get_attractions\":\n            function_result = simulate_get_attractions(function_call.args)\n        else:\n            function_result = {\"error\": \"Unknown function\"}\n        \n        print(f\"Function result: {json.dumps(function_result, indent=2)}\\n\")\n        \n        # Send function result back to model\n        response = trip_chat.send_message({\n            \"function_response\": {\n                \"name\": function_call.name,\n                \"response\": function_result\n            }\n        })\n    \n    print(f\"Assistant: {response.text}\\n\")\n    print(\"-\" * 80)\n    return response\n\n# Run the trip planning conversation\nplan_trip(\"I want to plan a trip from New York to Paris from May 15 to May 22, 2024\")\nplan_trip(\"Can you find me a hotel in Paris for those dates? We are 2 people.\")\nplan_trip(\"What historical attractions should I visit in Paris?\")\n```\n\n## Conclusion\n\nFunction calling in Gemini enables powerful integrations between your application and AI models. By allowing the model to request specific data or trigger actions based on user inputs, you can build more capable and interactive AI applications.\n\n## Next steps\n\n- Try implementing function calling with other use cases such as calendar management, product ordering, or database queries\n- Explore more complex conversational flows that involve multiple function calls\n- Implement error handling and parameter validation for robust function execution\n- Consider combining function calling with other techniques like [RAG](https://ai.google.dev/docs/rag_overview) for even more powerful applications\n\u0005End File\u0006# samples/gemini/python/notebook/multimodalPrompting.ipynb\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Gk-LkMCf-MgW\"\n      },\n      \"source\": [\n        \"# Multimodal prompting with gemini-pro-vision\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini/docs/multimodal_prompting.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"GtXJhs2_-MgZ\"\n      },\n      \"source\": [\n        \"Multimodal prompting means creating prompts that combine different types of information: text, images, and video. The `gemini-pro-vision` model can take both images and text as input.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"dZUXTLCt-Mga\"\n      },\n      \"source\": [\n        \"## Setup\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"8KZb_BRv-Mga\"\n      },\n      \"source\": [\n        \"### Install the Vertex AI SDK for Python\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"XYpLs5Ox-Mgb\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install google-generativeai\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"_9yVvo3l-Mgb\"\n      },\n      \"source\": [\n        \"### Import libraries\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"KnDokKTM-Mgb\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"from PIL import Image\\n\",\n        \"import pathlib\\n\",\n        \"import requests\\n\",\n        \"import google.generativeai as genai\\n\",\n        \"\\n\",\n        \"from IPython.display import display\\n\",\n        \"from IPython.display import Markdown\\n\",\n        \"def to_markdown(text):\\n\",\n        \"  text = text.replace('•', '  *')\\n\",\n        \"  return Markdown(text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"4n41B0QZ-Mgc\"\n      },\n      \"source\": [\n        \"### Configure your API key\\n\",\n        \"\\n\",\n        \"To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google/generative-ai-docs/blob/main/site/en/gemini/docs/authentication.ipynb) guide.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"JFgC79RH-Mgc\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"from google.colab import userdata\\n\",\n        \"GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\\n\",\n        \"\\n\",\n        \"genai.configure(api_key=GOOGLE_API_KEY)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Rx3NMHIb-Mgc\"\n      },\n      \"source\": [\n        \"## Image understanding\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"UNRJJOxS-Mgd\"\n      },\n      \"source\": [\n        \"Multimodal models such as Gemini can understand the content of images in a prompt. Let's try a simple example. \"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"JyM-hUEI-Mgd\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a sample image to use\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/scene.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./img.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"nE8lQ6zL-Mgd\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"model = genai.GenerativeModel('gemini-pro-vision')\\n\",\n        \"response = model.generate_content([\\\"What's in this image?\\\", img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"fO4eQO59-Mge\"\n      },\n      \"source\": [\n        \"Let's use a slightly more complex prompt with an image that involves understanding textual elements in the image.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"7tRbNLxO-Mge\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/grocery_receipt.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./receipt.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Xoqzn-6Z-Mge\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Look at this grocery receipt and:\\n\",\n        \"1. Calculate the total spent on fruits and vegetables\\n\",\n        \"2. Suggest a healthy recipe I can make with these ingredients\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"1jCpSxqS-Mgf\"\n      },\n      \"source\": [\n        \"## Multiple images as context\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"lUGGv4ZM-Mgf\"\n      },\n      \"source\": [\n        \"Let's try using multiple images in a single prompt. The vision model can analyze a sequence of images for comparison, classification, or to address a more complex prompt.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"6aXUwxIa-Mgf\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a set of sample images\\n\",\n        \"img1_url = 'https://storage.googleapis.com/generativeai-downloads/data/living_room1.jpg'\\n\",\n        \"img2_url = 'https://storage.googleapis.com/generativeai-downloads/data/living_room2.jpg'\\n\",\n        \"\\n\",\n        \"img1_data = requests.get(img1_url).content\\n\",\n        \"img2_data = requests.get(img2_url).content\\n\",\n        \"\\n\",\n        \"img1_path = pathlib.Path('./living_room1.jpg')\\n\",\n        \"img2_path = pathlib.Path('./living_room2.jpg')\\n\",\n        \"\\n\",\n        \"img1_path.write_bytes(img1_data)\\n\",\n        \"img2_path.write_bytes(img2_data)\\n\",\n        \"\\n\",\n        \"img1 = Image.open(img1_path)\\n\",\n        \"img2 = Image.open(img2_path)\\n\",\n        \"\\n\",\n        \"print(\\\"Image 1:\\\")\\n\",\n        \"display(img1)\\n\",\n        \"print(\\\"\\\\nImage 2:\\\")\\n\",\n        \"display(img2)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"qFRcyzA--Mgf\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Compare these two living room designs:\\n\",\n        \"1. Describe the key style differences\\n\",\n        \"2. Which one appears more cozy for a family?\\n\",\n        \"3. Suggest one improvement for each\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img1, img2])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"6pT4C-RP-Mgg\"\n      },\n      \"source\": [\n        \"## Detailed image analysis\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"y3uI1_GC-Mgg\"\n      },\n      \"source\": [\n        \"Gemini can provide detailed analysis of images, including identifying elements and explaining relationships between objects.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"pLTHXRDh-Mgg\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/diagram.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./diagram.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"IM9yKHjV-Mgg\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Analyze this diagram:\\n\",\n        \"1. What does it represent?\\n\",\n        \"2. Explain each component and its function\\n\",\n        \"3. How do the components interact with each other?\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"cFcpMbUX-Mgh\"\n      },\n      \"source\": [\n        \"## Creative tasks with images\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"d5hwcSiH-Mgh\"\n      },\n      \"source\": [\n        \"Gemini can also use images as inspiration for creative tasks. Let's try using an image as a prompt for a story.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"BPU6TxL3-Mgh\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/mountain_landscape.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./landscape.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"tLfKi-yl-Mgh\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Use this image as inspiration to:\\n\",\n        \"1. Write a short poem (4-6 lines) capturing the mood of this landscape\\n\",\n        \"2. Create a brief story opening (2-3 sentences) that could take place in this setting\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"uCxwRPQl-Mgh\"\n      },\n      \"source\": [\n        \"## Image understanding with complex reasoning\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"GSJX70eK-Mgi\"\n      },\n      \"source\": [\n        \"Gemini can combine image understanding with complex reasoning to solve problems. Let's try a mathematical problem presented in an image.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"cHVWR1aM-Mgi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/math_problem.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./math_problem.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"qGS8PcDr-Mgi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"For the math problem shown in the image:\\n\",\n        \"1. Identify what is being asked\\n\",\n        \"2. Solve it step by step\\n\",\n        \"3. Verify your answer\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"hE6LiZWu-Mgi\"\n      },\n      \"source\": [\n        \"## Combining images with detailed instructions\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Ao-bBfN9-Mgi\"\n      },\n      \"source\": [\n        \"You can provide detailed instructions alongside images to get more specific outputs from Gemini.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"AQk9-ZFU-Mgi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a new sample image\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/product.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./product.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"KXPcbEFw-Mgj\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"You are a marketing consultant. I need help creating marketing content for this product. \\n\",\n        \"\\n\",\n        \"Please provide:\\n\",\n        \"1. A catchy product name\\n\",\n        \"2. 5 key selling points based on what you can see\\n\",\n        \"3. A short product description (50-60 words) highlighting its premium features\\n\",\n        \"4. Two different taglines that emphasize its elegance\\n\",\n        \"\\n\",\n        \"The target audience is tech-savvy professionals who value both design and functionality.\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"58W-xDO6Bdcj\"\n      },\n      \"source\": [\n        \"## Using Gemini 1.5 Pro for multimodal prompting\\n\",\n        \"\\n\",\n        \"Let's explore Gemini 1.5 Pro's expanded multimodal capabilities. Gemini 1.5 Pro can process higher resolution images and more images in a single request.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"CQEb-l0JBkAp\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Initialize Gemini 1.5 Pro model\\n\",\n        \"model_1_5 = genai.GenerativeModel('gemini-1.5-pro')\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"0XJnZhjqB0hx\"\n      },\n      \"source\": [\n        \"### Processing complex images\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"ZLtUmSgCB3gI\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import a complex image with detailed elements\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/complex_diagram.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./complex_diagram.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"-RLkWP1tCJOA\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Analyze this technical diagram in detail:\\n\",\n        \"1. What system or process does this represent?\\n\",\n        \"2. Explain each component and its function\\n\",\n        \"3. Describe how information or resources flow through this system\\n\",\n        \"4. What industry or field would use this type of system?\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model_1_5.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"SHB-wVZ1CZnI\"\n      },\n      \"source\": [\n        \"### Multiple image analysis with more context\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"HY2LI5VGCeCw\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import multiple related images\\n\",\n        \"image_urls = [\\n\",\n        \"    'https://storage.googleapis.com/generativeai-downloads/data/architecture1.jpg',\\n\",\n        \"    'https://storage.googleapis.com/generativeai-downloads/data/architecture2.jpg',\\n\",\n        \"    'https://storage.googleapis.com/generativeai-downloads/data/architecture3.jpg',\\n\",\n        \"    'https://storage.googleapis.com/generativeai-downloads/data/architecture4.jpg'\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"images = []\\n\",\n        \"for i, url in enumerate(image_urls):\\n\",\n        \"    img_data = requests.get(url).content\\n\",\n        \"    img_path = pathlib.Path(f'./architecture{i+1}.jpg')\\n\",\n        \"    img_path.write_bytes(img_data)\\n\",\n        \"    img = Image.open(img_path)\\n\",\n        \"    images.append(img)\\n\",\n        \"    print(f\\\"Image {i+1}:\\\")\\n\",\n        \"    display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"9qADPEMtDCWg\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Analyze these architectural examples:\\n\",\n        \"1. Identify the architectural style of each building\\n\",\n        \"2. Compare and contrast their design elements\\n\",\n        \"3. Explain how each style reflects the cultural and historical context in which it developed\\n\",\n        \"4. Which of these styles has had the most influence on modern architecture and why?\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"# Create a multimodal prompt with all images\\n\",\n        \"multimodal_prompt = [prompt] + images\\n\",\n        \"\\n\",\n        \"response = model_1_5.generate_content(multimodal_prompt)\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"jgQCVOyMDZwI\"\n      },\n      \"source\": [\n        \"### Image-based problem solving\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"LM4kRF0gDdBw\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import an image of a coding problem\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/code_snippet.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./code_snippet.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"TtA0JXlADqEA\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"For this code snippet:\\n\",\n        \"1. Explain what the code does\\n\",\n        \"2. Identify any bugs or issues in the implementation\\n\",\n        \"3. Suggest optimizations to improve efficiency\\n\",\n        \"4. Provide a corrected and optimized version of the code\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model_1_5.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"FUYiF6QvD_Hg\"\n      },\n      \"source\": [\n        \"### Combining image analysis with multimodal reasoning\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"GZGzlDwfEC9Q\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Import an image of a data visualization\\n\",\n        \"img_url = 'https://storage.googleapis.com/generativeai-downloads/data/data_viz.jpg'\\n\",\n        \"img_data = requests.get(img_url).content\\n\",\n        \"img_path = pathlib.Path('./data_viz.jpg')\\n\",\n        \"img_path.write_bytes(img_data)\\n\",\n        \"img = Image.open(img_path)\\n\",\n        \"display(img)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"32Z0ZHjsESZw\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Analyze this data visualization:\\n\",\n        \"1. What type of visualization is this and what data is being shown?\\n\",\n        \"2. What are the key insights or trends visible in this data?\\n\",\n        \"3. Are there any potential issues with how this data is presented?\\n\",\n        \"4. Suggest 3 follow-up analyses that would complement this visualization\\n\",\n        \"5. If you were presenting this to executives, what would be your main 2-3 talking points?\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model_1_5.generate_content([prompt, img])\\n\",\n        \"to_markdown(response.text)\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"provenance\": [],\n      \"toc_visible\": true\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3 (ipykernel)\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.11.3\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006# google/generative-ai-docs\n# Function calling with Gemini models\n\nGemini models can identify when a function should be called from a user's input and generate a JSON object containing arguments for the function call. This capability allows you to build applications that can take actions beyond text generation, such as retrieving information from APIs, databases, or other systems.\n\n## Overview\n\nThe function calling feature has these key components:\n\n1. **Function definitions**: You define functions with their names, descriptions, and parameter schemas\n2. **Model integration**: The model processes the user's input and determines if a function should be called\n3. **Argument generation**: The model generates structured JSON arguments for the function\n4. **Function execution**: Your application executes the function with the provided arguments\n5. **Response enhancement**: The model incorporates the function's result into its response\n\n## Defining functions\n\nTo use function calling, you first need to define your functions in a structured format. Each function definition includes:\n\n- `name`: The function's name\n- `description`: A description of what the function does\n- `parameters`: A JSON Schema object defining the function's parameters\n\nHere's an example function definition for getting weather information:\n\n```python\n# Define the function schema\nget_current_weather = {\n  \"name\": \"get_current_weather\",\n  \"description\": \"Get the current weather in a given location\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"location\": {\n        \"type\": \"string\",\n        \"description\": \"The city and state, e.g. San Francisco, CA\"\n      },\n      \"unit\": {\n        \"type\": \"string\",\n        \"enum\": [\"celsius\", \"fahrenheit\"],\n        \"description\": \"The unit of temperature\"\n      }\n    },\n    \"required\": [\"location\"]\n  }\n}\n```\n\n## Using function calling in Python\n\nHere's how to use function calling with the Python SDK:\n\n```python\nimport google.generativeai as genai\n\n# Configure the API\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# Define the function (as shown above)\nget_current_weather = {...}\n\n# Create a model with the function\nmodel = genai.GenerativeModel(\n  \"gemini-pro\",\n  tools=[{\"function_declarations\": [get_current_weather]}]\n)\n\n# Get a response with a function call\nresponse = model.generate_content(\n  \"What's the weather like in Boston?\"\n)\n\n# Check if the model wants to call a function\nfunction_call = response.candidates[0].content.parts[0].function_call\nprint(function_call.name)  # 'get_current_weather'\nprint(function_call.args)  # {'location': 'Boston'}\n```\n\n## Providing function results\n\nAfter the model generates a function call, your application should:\n\n1. Execute the actual function with the provided arguments\n2. Return the result to the model\n\nHere's how to do this in a chat session:\n\n```python\n# Start a chat with function capability\nchat = model.start_chat(\n  tools=[{\"function_declarations\": [get_current_weather]}]\n)\n\n# User query\nresponse = chat.send_message(\"What's the weather like in Boston?\")\n\n# Get function call\nfunction_call = response.candidates[0].content.parts[0].function_call\n\n# Execute the function (simulate for this example)\nweather_data = {\n  \"temperature\": 38,\n  \"unit\": \"fahrenheit\",\n  \"description\": \"Partly cloudy\",\n  \"humidity\": 65\n}\n\n# Send function result back to the model\nresponse = chat.send_message({\n  \"function_response\": {\n    \"name\": function_call.name,\n    \"response\": weather_data\n  }\n})\n\n# Get the model's final response\nprint(response.text)\n# It's currently 38°F (partly cloudy) in Boston with 65% humidity.\n```\n\n## REST API example\n\nYou can also use function calling via the REST API:\n\n```json\n// Request\nPOST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\n\n{\n  \"contents\": [{\n    \"parts\": [{\n      \"text\": \"What's the weather like in Boston?\"\n    }]\n  }],\n  \"tools\": [{\n    \"function_declarations\": [{\n      \"name\": \"get_current_weather\",\n      \"description\": \"Get the current weather in a given location\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"string\",\n            \"description\": \"The city and state, e.g. San Francisco, CA\"\n          },\n          \"unit\": {\n            \"type\": \"string\",\n            \"enum\": [\"celsius\", \"fahrenheit\"]\n          }\n        },\n        \"required\": [\"location\"]\n      }\n    }]\n  }]\n}\n\n// Response\n{\n  \"candidates\": [{\n    \"content\": {\n      \"parts\": [{\n        \"functionCall\": {\n          \"name\": \"get_current_weather\",\n          \"args\": {\n            \"location\": \"Boston\"\n          }\n        }\n      }]\n    },\n    \"finishReason\": \"STOP\"\n  }]\n}\n```\n\n## Multiple functions\n\nYou can define multiple functions, and the model will choose the appropriate one based on the user's input:\n\n```python\n# Define multiple functions\nget_current_weather = {...}\nget_restaurant_recommendations = {...}\n\n# Create a model with multiple functions\nmodel = genai.GenerativeModel(\n  \"gemini-pro\",\n  tools=[{\"function_declarations\": [get_current_weather, get_restaurant_recommendations]}]\n)\n\n# Test with different queries\nweather_response = model.generate_content(\"What's the weather like in Miami?\")\nrestaurant_response = model.generate_content(\"Recommend Italian restaurants in Chicago\")\n\n# The model chooses the appropriate function for each query\n```\n\n## Complex parameter types\n\nFunction parameters can include various data types:\n\n```python\n# Function with complex parameters\nbook_flight = {\n  \"name\": \"book_flight\",\n  \"description\": \"Book a flight\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"departure\": {\n        \"type\": \"string\",\n        \"description\": \"Departure city\"\n      },\n      \"destination\": {\n        \"type\": \"string\",\n        \"description\": \"Destination city\"\n      },\n      \"date\": {\n        \"type\": \"string\",\n        \"description\": \"Date in YYYY-MM-DD format\"\n      },\n      \"passengers\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"adults\": {\n            \"type\": \"integer\",\n            \"description\": \"Number of adults\"\n          },\n          \"children\": {\n            \"type\": \"integer\",\n            \"description\": \"Number of children\"\n          }\n        }\n      },\n      \"preferences\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\",\n          \"enum\": [\"window\", \"aisle\", \"vegetarian_meal\"]\n        }\n      }\n    },\n    \"required\": [\"departure\", \"destination\", \"date\"]\n  }\n}\n```\n\n## Best practices\n\n1. **Clear function descriptions**: Provide clear descriptions for functions and parameters to help the model understand when to call them.\n\n2. **Parameter validation**: Always validate parameters before executing functions, even though the model tries to provide correctly formatted arguments.\n\n3. **Error handling**: Implement robust error handling for when function execution fails.\n\n4. **Multiple functions**: Design functions with specific purposes rather than creating a single function that does everything.\n\n5. **Required parameters**: Use the `required` field to specify which parameters are necessary.\n\n6. **Parameter constraints**: Use `enum` to restrict parameter values to a specific set when appropriate.\n\n7. **Testing**: Test your functions with various inputs to ensure they work correctly with the model.\n\n## Limitations\n\n- The model may occasionally generate invalid arguments or call functions when not needed.\n- Function calling is currently supported in Gemini Pro and Gemini Pro Vision models.\n- There's a limit to the complexity of function definitions that can be processed.\n\n## Next steps\n\n- Try implementing function calling with different use cases like calendar management, database queries, or external API calls.\n- Combine function calling with other techniques like RAG (Retrieval-Augmented Generation) for more powerful applications.\n- Experiment with structured outputs by using function calling to generate data in specific formats.\n- Build multi-turn conversations that use function calling to gather information incrementally.\n\u0005End File\u0006# site/en/gemini-api/docs/chat-apps.md\n# Building chat applications with Gemini\n\nThis guide shows you how to build chat applications with Gemini models, covering essential concepts and best practices for creating engaging, contextually-aware conversational experiences.\n\n## Overview\n\nChat applications with Gemini utilize conversation history to provide coherent and contextually relevant responses across multiple turns. The model can:\n\n- Remember previous exchanges\n- Track information provided by the user\n- Maintain consistent persona and style\n- Build on earlier parts of the conversation\n\n## Set up your environment\n\nFirst, install the necessary libraries:\n\n```python\n!pip install -q google-generativeai\n```\n\nNow import the libraries and configure your API key:\n\n```python\nimport google.generativeai as genai\n\n# Configure the API key\ngenai.configure(api_key=\"YOUR_API_KEY\")\n```\n\n## Basic chat session\n\nLet's start with a basic chat session:\n\n```python\n# Initialize the model\nmodel = genai.GenerativeModel('gemini-pro')\n\n# Start a chat session\nchat = model.start_chat(history=[])\n\n# First user message\nresponse = chat.send_message(\"Hi there! Can you help me plan a trip to Japan?\")\nprint(\"AI:\", response.text)\n\n# Second user message\nresponse = chat.send_message(\"I'll have about 10 days and I'm interested in both traditional and modern aspects of Japanese culture.\")\nprint(\"AI:\", response.text)\n\n# Third user message\nresponse = chat.send_message(\"What would be better to visit in April, Tokyo or Kyoto?\")\nprint(\"AI:\", response.text)\n```\n\nThe chat session maintains context automatically, allowing the model to refer back to previous messages.\n\n## Managing conversation history\n\nYou can initialize a chat with existing conversation history:\n\n```python\n# Create predefined history\nhistory = [\n    {\n        \"role\": \"user\",\n        \"parts\": [\"I want to learn how to play the guitar. What should I know as a beginner?\"]\n    },\n    {\n        \"role\": \"model\",\n        \"parts\": [\"Learning guitar as a beginner is an exciting journey! Here are some essential things to know:\\n\\n1. **Start with the right guitar**: For beginners, an acoustic guitar is often recommended because it's simpler (no amplifier needed) and builds finger strength. However, if you're primarily interested in electric guitar music, starting with an electric guitar is fine too.\\n\\n2. **Basic equipment**:\\n   - Guitar picks\\n   - Spare strings\\n   - A tuner (or tuner app)\\n   - A comfortable strap if you plan to play standing\\n\\n3. **Learn to tune your guitar**: This is fundamental. Use a tuner or tuner app to help at first.\\n\\n4. **Understand basic parts** of the guitar: headstock, tuning pegs, neck, frets, body, strings, etc.\\n\\n5. **Start with basic chords**: Learn common open chords like G, C, D, Em, and Am. These will allow you to play many songs.\\n\\n6. **Practice finger placement**: Press the strings firmly just behind the fret to produce clean notes.\\n\\n7. **Develop calluses**: Your fingertips will be sore at first, but they'll toughen up with practice.\\n\\n8. **Practice regularly**: Even 15-20 minutes daily is better than a 3-hour session once a week.\\n\\n9. **Learn basic strumming patterns**: Start with simple downstrokes, then incorporate upstrokes.\\n\\n10. **Start with simple songs**: Find beginner-friendly songs with 2-3 chords to build confidence.\\n\\n11. **Consider learning resources**:\\n    - YouTube tutorials\\n    - Guitar learning apps (like Yousician, Ultimate Guitar, or Justin Guitar)\\n    - Basic beginner books\\n    - Consider a few lessons with a teacher to establish good habits\\n\\n12. **Be patient**: Everyone struggles at first. Your fingers need time to develop the necessary strength and dexterity.\\n\\nDo you have a specific style of music you're interested in playing? Or any questions about getting started?\"]\n    }\n]\n\n# Start a chat with existing history\nchat = model.start_chat(history=history)\n\n# The model will remember the context about learning guitar\nresponse = chat.send_message(\"What are some good beginner-friendly songs I could learn?\")\nprint(\"AI:\", response.text)\n```\n\nYou can also view and manipulate the history:\n\n```python\n# View the full conversation history\nfor message in chat.history:\n    print(f\"{message.role}: {message.parts[0].text[:50]}...\")\n\n# Get just the most recent exchange\nlast_user_message = chat.history[-2]  # Second to last message (user)\nlast_model_response = chat.history[-1]  # Last message (model)\n\nprint(f\"Last user message: {last_user_message.parts[0].text[:50]}...\")\nprint(f\"Last model response: {last_model_response.parts[0].text[:50]}...\")\n```\n\n## Personalized chat with system instructions\n\nYou can personalize your chat application by providing system instructions:\n\n```python\n# Create a chat with system instructions\ntravel_agent_chat = model.start_chat(\n    system_instruction=\"\"\"You are a helpful travel agent with expertise in international destinations.\n    Always provide personalized recommendations based on the traveler's interests, budget, and preferences.\n    Include practical information like best times to visit, local transportation, and cultural etiquette.\n    If there are safety concerns for a destination, mention them tactfully.\n    When suggesting accommodations or activities, provide options for different budget levels.\"\"\"\n)\n\n# Test the travel agent persona\nresponse = travel_agent_chat.send_message(\"I'm planning a trip to Thailand in November with my family. We love nature, food, and cultural experiences.\")\nprint(\"Travel Agent:\", response.text)\n```\n\n## Building a multi-turn conversation interface\n\nHere's how to create a simple interactive chat interface:\n\n```python\ndef interactive_chat(system_instruction=None):\n    \"\"\"Simple interactive chat loop with Gemini.\"\"\"\n    \n    # Initialize the chat\n    chat = model.start_chat(system_instruction=system_instruction)\n    \n    print(\"Chat initialized. Type 'exit' to end the conversation.\")\n    print(\"=\" * 50)\n    \n    if system_instruction:\n        print(f\"System instruction: {system_instruction}\")\n        print(\"-\" * 50)\n    \n    while True:\n        user_input = input(\"You: \")\n        \n        if user_input.lower() in ['exit', 'quit', 'bye']:\n            print(\"Ending chat session. Goodbye!\")\n            break\n        \n        try:\n            response = chat.send_message(user_input)\n            print(\"\\nAI:\", response.text)\n            print(\"-\" * 50)\n        except Exception as e:\n            print(f\"Error: {str(e)}\")\n    \n    return chat  # Return the chat object if you want to examine the history\n\n# Example usage\nsystem_instruction = \"You are a helpful, concise assistant. Provide short, clear answers unless the user asks for elaboration.\"\nchat_session = interactive_chat(system_instruction)\n```\n\n## Handling conversation context efficiently\n\nAs conversations grow longer, you may need to manage context more efficiently:\n\n```python\ndef summarize_conversation(chat_history):\n    \"\"\"Summarize a lengthy conversation history to maintain context while reducing tokens.\"\"\"\n    \n    # Create a prompt for summarization\n    summary_prompt = \"Please summarize the key points of this conversation, including important details, preferences, and any decisions made:\\n\\n\"\n    \n    # Convert history to a readable format\n    for message in chat_history:\n        role = \"User\" if message.role == \"user\" else \"AI\"\n        summary_prompt += f\"{role}: {message.parts[0].text}\\n\\n\"\n    \n    # Generate a summary\n    summary_model = genai.GenerativeModel('gemini-pro')\n    summary_response = summary_model.generate_content(summary_prompt)\n    \n    return summary_response.text\n\n# Example usage\nif len(chat.history) > 10:  # If history is getting long\n    summary = summarize_conversation(chat.history)\n    \n    # Start a new chat with the summary as context\n    new_chat = model.start_chat(\n        history=[\n            {\"role\": \"user\", \"parts\": [\"Here's a summary of our conversation so far: \" + summary]},\n            {\"role\": \"model\", \"parts\": [\"Thank you for the summary. How can I continue to help you?\"]}\n        ]\n    )\n```\n\n## Implementing specialized chat features\n\n### Chat with different temperature settings\n\nAdjust the creativity and determinism of responses:\n\n```python\n# Create a creative chat (higher temperature)\ncreative_chat = model.start_chat(\n    generation_config={\"temperature\": 0.9}\n)\n\n# Create a more deterministic chat (lower temperature)\nprecise_chat = model.start_chat(\n    generation_config={\"temperature\": 0.1}\n)\n\n# Compare responses to the same prompt\ncreative_response = creative_chat.send_message(\"Write a short poem about artificial intelligence\")\nprecise_response = precise_chat.send_message(\"Write a short poem about artificial intelligence\")\n\nprint(\"Creative response:\")\nprint(creative_response.text)\nprint(\"\\nPrecise response:\")\nprint(precise_response.text)\n```\n\n### Chat with safety settings\n\nCustomize safety thresholds:\n\n```python\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold\n\n# Create a chat with custom safety settings\nsafety_settings = {\n    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n}\n\nsafe_chat = model.start_chat(\n    safety_settings=safety_settings\n)\n```\n\n### Multimodal chat with images\n\nUse Gemini Pro Vision to create chats that can process images:\n\n```python\nfrom IPython.display import Image\nimport requests\nfrom PIL import Image as PILImage\nimport io\n\n# Initialize the vision model\nvision_model = genai.GenerativeModel('gemini-pro-vision')\n\n# Start a multimodal chat\nvision_chat = vision_model.start_chat()\n\n# Function to load an image from URL\ndef load_image_from_url(url):\n    response = requests.get(url)\n    return PILImage.open(io.BytesIO(response.content))\n\n# Example usage\nimage_url = \"https://storage.googleapis.com/generativeai-downloads/images/tokyo.jpg\"\nimg = load_image_from_url(image_url)\n\n# Display the image\ndisplay(img)\n\n# Send a message with the image\nresponse = vision_chat.send_message([\n    \"What can you tell me about this location?\",\n    img\n])\nprint(\"AI:\", response.text)\n\n# Continue the conversation about the image\nresponse = vision_chat.send_message(\"What's the best time of year to visit this place?\")\nprint(\"AI:\", response.text)\n```\n\n## Building a complete chat application\n\nHere's an example of a more complete chat application combining multiple features:\n\n```python\nimport google.generativeai as genai\nimport time\nimport json\nfrom datetime import datetime\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold\nfrom PIL import Image\nimport requests\nimport io\n\nclass GeminiChatApp:\n    def __init__(self, api_key, model_name=\"gemini-pro\", vision_model_name=\"gemini-pro-vision\"):\n        # Configure the API\n        genai.configure(api_key=api_key)\n        \n        # Initialize models\n        self.text_model = genai.GenerativeModel(model_name)\n        self.vision_model = genai.GenerativeModel(vision_model_name)\n        \n        # Default settings\n        self.default_temperature = 0.7\n        self.default_safety_settings = {\n            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n        }\n        \n        # Initialize chat sessions dictionary\n        self.chat_sessions = {}\n    \n    def create_chat_session(self, session_id, system_instruction=None, temperature=None, \n                            safety_settings=None, multimodal=False):\n        \"\"\"Create a new chat session with specified settings.\"\"\"\n        # Use default values if not provided\n        temp = temperature if temperature is not None else self.default_temperature\n        safety = safety_settings if safety_settings is not None else self.default_safety_settings\n        \n        # Generation config\n        generation_config = {\n            \"temperature\": temp,\n            \"top_p\": 0.95,\n            \"top_k\": 64,\n            \"max_output_tokens\": 2048,\n        }\n        \n        # Select the appropriate model\n        model = self.vision_model if multimodal else self.text_model\n        \n        # Create the chat\n        chat = model.start_chat(\n            system_instruction=system_instruction,\n            generation_config=generation_config,\n            safety_settings=safety\n        )\n        \n        # Store the session\n        self.chat_sessions[session_id] = {\n            \"chat\": chat,\n            \"created_at\": datetime.now(),\n            \"last_activity\": datetime.now(),\n            \"multimodal\": multimodal,\n            \"message_count\": 0\n        }\n        \n        return session_id\n    \n    def send_message(self, session_id, message, image_url=None):\n        \"\"\"Send a message to the specified chat session.\"\"\"\n        # Check if session exists\n        if session_id not in self.chat_sessions:\n            raise ValueError(f\"Chat session {session_id} does not exist\")\n        \n        session = self.chat_sessions[session_id]\n        chat = session[\"chat\"]\n        is_multimodal = session[\"multimodal\"]\n        \n        # Update activity timestamp\n        session[\"last_activity\"] = datetime.now()\n        \n        try:\n            # Handle multimodal input\n            if image_url and is_multimodal:\n                # Load the image\n                image = self._load_image_from_url(image_url)\n                response = chat.send_message([message, image])\n            else:\n                # Text-only message\n                response = chat.send_message(message)\n            \n            # Update message count\n            session[\"message_count\"] += 1\n            \n            return {\n                \"text\": response.text,\n                \"session_id\": session_id,\n                \"timestamp\": datetime.now().isoformat()\n            }\n            \n        except Exception as e:\n            return {\n                \"error\": str(e),\n                \"session_id\": session_id,\n                \"timestamp\": datetime.now().isoformat()\n            }\n    \n    def get_chat_history(self, session_id):\n        \"\"\"Retrieve the chat history for a session.\"\"\"\n        if session_id not in self.chat_sessions:\n            raise ValueError(f\"Chat session {session_id} does not exist\")\n        \n        history = []\n        chat = self.chat_sessions[session_id][\"chat\"]\n        \n        for message in chat.history:\n            # Handle different types of content\n            if message.role == \"user\" or message.role == \"model\":\n                # For text messages\n                if len(message.parts) == 1 and hasattr(message.parts[0], 'text'):\n                    history.append({\n                        \"role\": message.role,\n                        \"content\": message.parts[0].text,\n                        \"type\": \"text\"\n                    })\n                # For multimodal messages\n                else:\n                    parts_content = []\n                    for part in message.parts:\n                        if hasattr(part, 'text'):\n                            parts_content.append({\"type\": \"text\", \"content\": part.text})\n                        else:\n                            parts_content.append({\"type\": \"image\", \"content\": \"[Image]\"})\n                    \n                    history.append({\n                        \"role\": message.role,\n                        \"content\": parts_content,\n                        \"type\": \"multimodal\"\n                    })\n        \n        return history\n    \n    def end_chat_session(self, session_id):\n        \"\"\"End and remove a chat session.\"\"\"\n        if session_id in self.chat_sessions:\n            # Save chat history if needed before removing\n            history = self.get_chat_history(session_id)\n            \n            # Remove the session\n            del self.chat_sessions[session_id]\n            \n            return {\n                \"status\": \"success\",\n                \"message\": f\"Chat session {session_id} ended\",\n                \"history_length\": len(history)\n            }\n        else:\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Chat session {session_id} does not exist\"\n            }\n    \n    def list_active_sessions(self):\n        \"\"\"List all active chat sessions.\"\"\"\n        return {\n            session_id: {\n                \"created_at\": session[\"created_at\"].isoformat(),\n                \"last_activity\": session[\"last_activity\"].isoformat(),\n                \"multimodal\": session[\"multimodal\"],\n                \"message_count\": session[\"message_count\"]\n            }\n            for session_id, session in self.chat_sessions.items()\n        }\n    \n    def _load_image_from_url(self, url):\n        \"\"\"Helper method to load an image from a URL.\"\"\"\n        response = requests.get(url)\n        return Image.open(io.BytesIO(response.content))\n\n# Example usage\nif __name__ == \"__main__\":\n    # Initialize the app\n    app = GeminiChatApp(api_key=\"YOUR_API_KEY\")\n    \n    # Create a text chat session\n    text_session_id = \"user123_text_\" + str(int(time.time()))\n    app.create_chat_session(\n        text_session_id,\n        system_instruction=\"You are a helpful, friendly assistant named Gemini.\"\n    )\n    \n    # Create a multimodal chat session\n    vision_session_id = \"user123_vision_\" + str(int(time.time()))\n    app.create_chat_session(\n        vision_session_id,\n        system_instruction=\"You are a visual analysis assistant that can describe images in detail.\",\n        multimodal=True\n    )\n    \n    # Test the text chat\n    print(\"Text chat example:\")\n    response = app.send_message(text_session_id, \"Hello! Can you tell me about the stars?\")\n    print(response[\"text\"])\n    \n    # Test the multimodal chat with an image\n    print(\"\\nMultimodal chat example:\")\n    image_url = \"https://storage.googleapis.com/generativeai-downloads/images/mountains.jpg\"\n    response = app.send_message(vision_session_id, \"What do you see in this image?\", image_url)\n    print(response[\"text\"])\n    \n    # Follow-up question\n    response = app.send_message(vision_session_id, \"Is this a good place for hiking?\")\n    print(\"\\nFollow-up response:\")\n    print(response[\"text\"])\n    \n    # Check active sessions\n    print(\"\\nActive sessions:\")\n    print(app.list_active_sessions())\n    \n    # Get chat history\n    print(\"\\nChat history:\")\n    history = app.get_chat_history(text_session_id)\n    for message in history:\n        print(f\"{message['role']}: {message['content']}\")\n    \n    # End sessions\n    app.end_chat_session(text_session_id)\n    app.end_chat_session(vision_session_id)\n```\n\n## Best practices for chat applications\n\n1. **Provide clear system instructions**: Set the tone, persona, and behavior of your chatbot with specific system instructions.\n\n2. **Manage context efficiently**: For long conversations, consider summarizing or pruning history to stay within token limits.\n\n3. **Handle errors gracefully**: Implement error handling for rate limits, timeouts, and other API issues.\n\n4. **Implement user feedback mechanisms**: Allow users to indicate if responses are helpful or need improvement.\n\n5. **Start with sensible defaults**: Choose appropriate temperature and safety settings based on your use case.\n\n6. **Optimize for conversation flow**: Design prompts that encourage natural, flowing conversations.\n\n7. **Provide visual feedback**: In user interfaces, indicate when the AI is \"thinking\" or generating responses.\n\n8. **Consider conversation timeouts**: Implement session timeouts for inactive conversations to manage resources.\n\n9. **Test with diverse inputs**: Test your chat application with a variety of inputs and conversation flows.\n\n10. **Respect privacy**: Be clear about how user data is stored and used, and implement appropriate security measures.\n\n## Next steps\n\n- Implement a web or mobile interface for your chat application\n- Add persistent storage for chat history\n- Integrate with external data sources or APIs\n- Implement specialized chat agents for different domains\n- Add user authentication and personalization features\n- Explore function calling to enhance your chat application with actions\n\nBy following these guidelines and examples, you can build sophisticated chat applications that leverage the full potential of Gemini models.\n\u0005End File\u0006# site/en/gemini-api/docs/generative_models/safety-settings.md\n# Configure safety settings\n\nThis guide explains how to configure safety settings for your Gemini API requests. Safety settings allow you to control how the model handles potentially harmful content.\n\n## Overview\n\nSafety settings help determine what content is blocked based on categories and threshold levels. You can customize these settings to match your application's needs.\n\n## Safety categories\n\nGemini models classify potentially harmful content into four categories:\n\n| Category | Description |\n|----------|-------------|\n| `HARM_CATEGORY_HARASSMENT` | Content that refers to someone other than the user in a harmful way |\n| `HARM_CATEGORY_HATE_SPEECH` | Content that expresses hatred or offensive content toward identity and/or protected attributes |\n| `HARM_CATEGORY_SEXUALLY_EXPLICIT` | Content that contains references to sexual acts or other lewd content |\n| `HARM_CATEGORY_DANGEROUS_CONTENT` | Content that promotes, facilitates, or encourages harmful activities |\n\n## Threshold levels\n\nFor each category, you can set a threshold that determines when content is blocked:\n\n| Threshold | Description |\n|-----------|-------------|\n| `BLOCK_",
    "docsie-practical-tool-for-pcb-design-eng|learning_objective|3": "Beherrschen Sie Kollaborationstechniken für funktionsübergreifende Leiterplattendesign-Teams mithilfe moderner Dokumentationswerkzeuge",
    "docsie-practical-tool-for-pcb-design-eng|learning_objective|4": "Entdecken Sie, wie Dokumentationsplattformen wie Docsie die PCB-Design-Arbeitsabläufe und den Wissensaustausch vereinfachen können"
}
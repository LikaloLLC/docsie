{
    "__metadata__": {
        "original_categories": [
            "Product Documentation",
            "Product Management",
            "Documentation Portals",
            "Best Practices",
            "Product Documentation Tutorials"
        ],
        "author_name": "Tal F.",
        "author_email": "tal@docsie.io",
        "author_info": "VP of Customer Success @ Docsie",
        "author_image": " https://cdn.docsie.io/user_profiles/15/logo_logo_QmXrbijvL0L2hFKNm6Q25DtjahujKdB6nu4pqBlLBgvtT.png",
        "header_image": "https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_QpDdxIGnXpT0d02oQ/file_cUcNP3sxthYruGOPe/boo_XGfvRm3TVTFbV6HET/31d24913-2263-63d5-046f-0805d33f8b2aUntitled_1_min_1_2_3_4_5.jpg",
        "timestamp": "2021-05-04T16:12:56+00:00",
        "status": 1
    },
    "the-ultimate-training-manual-template-gu|title": "Den ultimata handledningsmalguiden för 2023",
    "the-ultimate-training-manual-template-gu|summary": "Hur ledande organisationer får en konkurrensfördel genom att hålla sina utbildningsmanualer enkla, koncisa och mycket framgångsrika.",
    "the-ultimate-training-manual-template-gu|markdown": "# Ansvarar du för utbildningen av kollegor, kunder eller nyanställda? I så fall, fortsätt läsa.\n\nAtt dela kunskap och utbilda andra kan vara utmanande. Särskilt om du saknar en bra mall för utbildningsmaterial att komma igång med. I den här artikeln visar jag hur du kan öka produktiviteten och minska stilleståndstiden genom att använda Docsie för att skapa en enkel mall för utbildningsmaterial och dela den med ditt team.\n\n## Skapa en effektiv mall för utbildningsmaterial: Viktiga steg\n\n1. Identifiera din målgrupp och utbildningsbehov\n2. Skissa upp struktur och innehåll\n3. Utveckla tydligt och koncist utbildningsmaterial\n4. Inkludera visuella hjälpmedel (diagram, skärmbilder, videor)\n5. Skapa interaktiva element (quiz, övningar)\n6. Implementera en användarvänlig design och layout\n7. Granska och testa materialet med potentiella användare\n8. Samla in och integrera feedback\n9. Uppdatera och underhåll innehållet regelbundet\n\n## Fördelar med ett väldesignat utbildningsmaterial:\n\n- Förbättrad introduktion för nyanställda\n- Konsekvent utbildning i hela organisationen\n- Ökad produktivitet och effektivitet\n- Minskade utbildningskostnader\n- Bättre engagemang och bibehållande av personal\n\nEn omfattande mall för utbildningsmaterial fungerar som en värdefull resurs för både utbildare och deltagare, och säkerställer effektiv kunskapsöverföring och kompetensutveckling.\n\n## Steg 1: Skapa ett konto på Docsie (det är gratis).\n\n##\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_wX9JoNbS1HNZqB1vU/boo_WxwzJSt3rqWegFPsx/964e0589-ee96-b0fb-6fdd-d760b5e81f53image.png)\n\nDocsie är ett enkelt verktyg för att utveckla utbildningsmaterial som ger företag återanvändbara mallar för att skapa bättre utbildningshandböcker. Det är helt gratis att komma igång, och du kan bygga ditt första utbildningsmaterial på under 10 minuter. När du har registrerat dig kan vi börja förklara hur du skapar utbildningsmaterial med Docsie.\n\n## Steg 2: Skapa en bok för att göra en bra grundmall för utbildningsmaterial.\n\nDocsie bygger på konceptet med böcker och hyllor, där böcker fungerar som utbildningshandböcker och hyllor som avdelningar och kunskapscentrum.\n\nTänk dig att du är ett upptaget säljteam som behöver ha allt ert utbildningsmaterial för utgående försäljning samlat på ett ställe. Du kan använda Docsie för att organisera och kategorisera ditt utbildningsmaterial med hjälp av uppsättningar. När du är redo kan du bjuda in resten av utbildningsteamet för att samarbeta och bygga bättre utbildningsmaterial tillsammans.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_qd5uDhTnzIv7i7usI/boo_WxwzJSt3rqWegFPsx/eeee9ae3-949a-4a68-ff86-1774bdad3340image.png)\n\n## Steg 3 - Definiera utbildningsinstruktioner\n\nHär identifierar du utbildningskategorier och vägar du behöver skapa för att utbilda din målgrupp.\n\nDenna guide förutsätter att du redan känner till din målgrupp. Syftet är att visa hur du enkelt kan skapa innehåll för ditt utbildningsmaterial.\n\nTänk på ett säljteam. Det har grundläggande och avancerade säljspår för olika positioner som SDR (försäljningsrepresentanter), Account Executives, Customer Success Representatives och så vidare. Positionerna kan ha olika namn och ansvarsområden beroende på ditt företags natur, men alla kräver utbildningsmaterial och ett spårbart sätt att dela information.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_G26esoODDFXA7gBlw/boo_WxwzJSt3rqWegFPsx/0bbdb8bd-8fa4-5057-8bb2-4816e06b647aimage.png)\n\nNär du har identifierat dina utbildningsspår kan du börja intervjua experter i dessa positioner för att fastställa innehållet. Du kan till exempel intervjua en account executive för att förstå hur de arbetar.\n\nNär du känner till deras dagliga rutiner, praxis och skyldigheter kan du skapa ett processdiagram som detaljerar arbetsuppgifterna, vilket ger dig en tydlig bild av ansvarsområdena.\n\nSedan bryter du ner dessa uppgifter i konkreta steg efter nivå/senioritet, vilket gör det enkelt att skapa utbildningsmaterial eftersom du vet vad och hur du ska skriva för ditt specifika team.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_h2VzPUoPrfLAgyWSZ/boo_WxwzJSt3rqWegFPsx/426f2d7b-d360-d8d2-3042-01b6797217c2image.png)\n\nNär du samlat tillräckligt med information kan du använda den för att utveckla ditt utbildningsmaterial med hjälp av en mall.\n\n## Steg 4: Utveckla utbildningsmaterial\n\nMed utgångspunkt i din disposition och färdplan från tidigare steg, och med informationen du samlat från ditt team, börjar du fylla din mall med innehåll, steg för steg, och gradvis utöka varje steg för att hjälpa dina deltagare bygga en solid kunskapsbas.\n\nOlika artiklar kan använda olika steg i Docsie för att illustrera utbildningsmaterial. Det finns många bra verktyg som fungerar tillsammans med Docsie för att hjälpa dig skapa fantastiska manualer.\n\n## Fantastiska verktyg\n\nDet finns många bra verktyg som kan ge dig ett försprång när du skapar ditt utbildningsmaterial och hjälpa dig att utveckla och fylla i din mall.\n\n## Snag-It\n\n> Obs: Om du är Mac-användare kan du kopiera och klistra in bilden i Docsie med Shift, Command och 4.\n\nSnag-it låter dig enkelt ta en bild av sidans innehåll och kommentera den med ett snyggt och enkelt annoteringsverktyg.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_WB2ORmffxUjyz00Yq/boo_WxwzJSt3rqWegFPsx/95d5c0e9-15c6-6429-45c5-88ab34c2d9a6image.png)\n\n## Camtasia\n\nCamtasia hjälper dig att enkelt spela in instruktionsvideos för att förbättra utbildningsupplevelsen och effektiviteten i ditt material.\n\n## Docsie Guides\n\nMed ett enkelt Chrome-tillägg kan du använda Docsie Guides för att automatiskt dokumentera ditt utbildningsmaterial och alla bilder med anmärkningar. Docsie Guides hjälper dig också att skapa guidade turer utan kodning för att visa hur din produkt används för kunder eller nya medarbetare.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_8ae41KnpRQi0C0u7t/boo_WxwzJSt3rqWegFPsx/9fbb3165-564b-a2c7-66db-1076080930a04ddd50e0_12bf_9027_3986_78792c015969Gifs_optimized.gif)\n\n## Steg 5 - Publicera ditt utbildningsmaterial och dela det med ditt team\n\nNär du har utvecklat ditt utbildningsmaterial i Docsie vill du dela det med nya medarbetare och/eller kunder. Det är så enkelt som att klicka på publicera och låta det visas på en Docsie-inbäddad sida på din webbplats.\n\nOm du vill begränsa åtkomsten till ditt utbildningsmaterial kan du enkelt göra det i Docsie. Du kan också tilldela ett unikt lösenord till en specifik deltagare och återkalla åtkomsten när som helst.\n\nMed bara en rad kod kan du också integrera ditt utbildningsmaterial direkt i företagets intranät med Docsie.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_SReYm8UdA6cJ9A6PX/boo_WxwzJSt3rqWegFPsx/0323cf4c-d72e-5b5c-5e0f-fcf03d027ce4image.png)\n\n## Steg 6: Samla in feedback om ditt utbildningsmaterial och uppdatera det i Docsie.\n\nNär du har lanserat din prototyp för utbildningsmaterial är du redo att gå vidare. Du kanske vill förstå hur deltagare och/eller kunder interagerar med ditt material och ge dem möjlighet att ge dig konkret feedback för att förbättra ditt arbete.\n\nHär kan du använda Vocally (ett Docsie-tillägg) för att samla in videoklipp från deltagarnas utbildningsupplevelser för att bättre förstå hur de hanterar ditt material. Du kan också ge dem möjlighet att lämna synpunkter på sin utbildningsupplevelse, som kategoriseras i Vocally manager.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_OqJHxdveDITl5by25/boo_WxwzJSt3rqWegFPsx/0a5ecb60-0b4b-1bf9-f1c6-d9a0a1357ca5image.png)\n\nDu kan sedan använda Vocally Manager, som enkelt integreras med din projekthanteringsprogramvara, för att skapa konkreta uppgifter för att uppdatera och förbättra ditt material baserat på användarfeedback.\n\n![](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_ULxUK3nJlSUujhpeo/file_TCiT6UQygjeRreFqY/boo_WxwzJSt3rqWegFPsx/b0696bf6-153e-b42a-4933-97fd097dd59eimage.png)\n\n## Steg 7: Underhåll och översätt innehållet i ditt utbildningsmaterial.\n\nDu kan nu översätta dina utbildningsmallar till flera språk direkt i Docsie, och du kan till och med kommunicera med erfarna innehållsöversättare som kan hjälpa dig att uppdatera ditt innehåll till rabatterat pris.\n\nNär ditt utbildningsmaterial växer är det dessutom lika enkelt som att klicka på en knapp för att skapa nya versioner i Docsie. På så sätt förlorar du inga värdefulla kopior och har alltid en referenspunkt att hänvisa till.\n\n## Avslutande tankar\n\n![](https://images.unsplash.com/photo-1543386650-2be9a18d2750?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwzMTM3MXwwfDF8c2VhcmNofDF8fGZpbmFsJTIwdGhvdWdodHN8ZW58MHx8fHwxNjIwMTU3MTg3&ixlib=rb-1.2.1&q=80&w=1080)\n\nDocsie är ett bra val om du är seriös med att skapa utmärkt utbildningsmaterial och använda mallar för instruktioner. Det kommer att förenkla och förbättra arbetsflödet för ditt utbildningsmaterial avsevärt.\n\nUtbildningsmallar spelar en viktig roll i personalutbildning genom att informera nya medarbetare om organisationen och dess processer. Medarbetare utvecklas och lär sig ständigt ny teknik, nya metoder och processer.\n\nAnställda som inte aktivt lär sig eller som saknar kunskap om verktyg, applikationer eller utrustning som används av företaget kan bli omotiverade på arbetet.\n\nBristande engagemang leder ofta till hög personalomsättning och dålig arbetstillfredsställelse. I slutändan drabbas både arbetsgivare och anställda.\n\nDet finns statistik som stödjer detta:\n\nInom ett år slutar 40% av medarbetare med otillräcklig utbildning sina jobb.\n\n74% av medarbetare känner att de inte når sin fulla potential på jobbet på grund av brist på utvecklingsmöjligheter.\n\nI 72% av fallen överväger anställda att bidra ekonomiskt till sin egen utbildning.\n\nEnligt 68% av medarbetarna är utveckling och utbildning företagets viktigaste fråga.\n\nEndast 13% av arbetstagare globalt är engagerade.\n\nBristande engagemang hos anställda kostar ekonomin över 500 miljarder dollar årligen.\n\nSiffrorna är oändliga. Problemet är verkligt. Medarbetare vill växa och förbättra sina färdigheter genom både traditionell utbildning och utvecklingsmöjligheter.\n\nEtt bra sätt för företag att komma igång med detta nödvändiga arbetssätt är att skapa en fantastisk företagsutbildningsguide eller utbildningsmanual.\n\nVi behöver komma till saken och förstå vilka de viktigaste aspekterna av ett bra utbildningsmaterial är och hur man skapar det.\n\nÅr 2017 skapades 45% av utbildningstimmarna i ett typiskt företag genom online- eller e-learningmetoder, enligt ATD (Association-for-Talent-Development-in-the-United-States). Detta är en ökning med 42% jämfört med 2015.\n\nFörmågan att utveckla en mall för utbildningsmaterial är en viktig färdighet som är nödvändig för företagets kontinuitet och tillväxt.",
    "the-ultimate-training-manual-template-gu|category|0": "Produktdokumentation\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/models/tuning.md\n# Create, modify, and use tuned models\n\nThis guide covers tuning generative models and applying the resulting models to your use cases.\n\n## About tuning\n\nTuning adapts a model to solve specific tasks by training on examples that you provide.\n\nYou can use the tuned models API to:\n\n* Create a tuned model\n* Modify a tuned model's display name\n* Tuned model quota management (listing, deleting tuned models)\n* Use tuned models\n\n## Tuning methodology\n\nThe tuning process fine-tunes the model parameters to adapt to your examples, resulting in an updated model instance that is specialized for the scenarios demonstrated in your tuning data.\n\nYou should use tuning when you need the model to consistently:\n\n* Adopt a specific style, tone, or persona\n* Follow formatting requirements\n* Adapt to specific domains, using specialized vocabulary and knowledge\n* Comply with guardrails or policy requirements\n\n## Supported models\n\nGemini 1.5 Flash and Gemini 1.5 Pro are currently supported for tuning.\n\n## Costs\n\nSee the [pricing page](https://ai.google.dev/pricing) for current tuning and tuned model usage costs.\n\n## Quota and rate limits\n\n* 10 tuned models per project\n* 1 active tuning job per project\n* Maximum of 20,000 training examples and 2,000 validation examples\n* Maximum training time:\n  * 3 hours for Gemini 1.5 Flash\n  * 10 hours for Gemini 1.5 Pro\n* Maximum tuning data size:\n  * Gemini 1.5 Flash: 10 MB\n  * Gemini 1.5 Pro: 50 MB\n* 10 requests per minute for tuning API operations\n* Usage rates for tuned models follow the same limits as their base models\n\n## Creating a tuned model\n\nUse the following REST API to create a tuned model. Tuning a model involves the following steps:\n\n1. Format your training data\n2. Create a tuning job\n3. Monitor the tuning job\n4. Use the tuned model\n\n### 1. Format your training data\n\nTuning data should be formatted as JSONL (newline-delimited JSON) with each line containing a complete conversation as a series of messages.\n\nThe basic format is:\n\n```jsonl\n{\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"model\", \"content\": \"...\"}]}\n{\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"model\", \"content\": \"...\"}]}\n...\n```\n\nEach example is a conversation with at least two messages (user prompt and model response), but can include multiple turns:\n\n```jsonl\n{\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"model\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"model\", \"content\": \"...\"}]}\n```\n\n#### Example tuning data\n\n```jsonl\n{\"messages\": [{\"role\": \"user\", \"content\": \"Write a poem about a sunset over the ocean\"}, {\"role\": \"model\", \"content\": \"Golden Horizon\\n\\nFiery orb descends with grace,\\nMelting into ocean's embrace.\\nWaves aglow with amber light,\\nHeralding the coming night.\\n\\nCrimson streaks across the sky,\\nAs day prepares to say goodbye.\\nWater mirrors heaven's art,\\nNature's canvas, day's depart.\\n\\nGentlest breeze carries salt and spray,\\nSinging farewell to fading day.\\nIn this moment, time stands still,\\nBeauty raw, against God's will.\\n\\nSoon the stars will claim their throne,\\nBut sunset's memory stands alone.\\nPerfect peace in twilight's gleam,\\nReality more fair than dream.\"}]}\n{\"messages\": [{\"role\": \"user\", \"content\": \"Tell me about the benefits of meditation\"}, {\"role\": \"model\", \"content\": \"Meditation offers numerous evidence-backed benefits for both mental and physical wellbeing:\\n\\n**Mental Benefits:**\\n- Reduces stress and anxiety by lowering cortisol levels\\n- Improves focus and attention span\\n- Enhances self-awareness and emotional regulation\\n- Promotes better sleep quality\\n- May help manage depression symptoms\\n- Increases positive emotions and overall satisfaction\\n\\n**Physical Benefits:**\\n- Lowers blood pressure and heart rate\\n- Reduces inflammation markers in the body\\n- Can help manage pain perception\\n- Strengthens immune system function\\n- May improve digestive health\\n\\n**Cognitive Benefits:**\\n- Enhances creative thinking and problem-solving\\n- Improves memory and information processing\\n- May slow age-related cognitive decline\\n- Increases gray matter density in brain regions associated with learning\\n\\nEven short daily sessions of 5-10 minutes can yield noticeable benefits, with effects compounding through consistent practice. Different techniques (mindfulness, loving-kindness, transcendental, etc.) offer various pathways to these benefits, allowing individuals to find approaches that resonate with their specific needs and preferences.\"}]}\n```\n\n### 2. Create a tuning job\n\nTo start a tuning job, make a POST request to the `tuningJobs` endpoint.\n\n```bash\nPROJECT_ID=\"your-project-id\"\nTUNING_DATA_PATH=\"path/to/your/tuning_data.jsonl\"\nVALIDATION_DATA_PATH=\"path/to/your/validation_data.jsonl\" # Optional\nDISPLAY_NAME=\"My Tuned Model\"\nBASE_MODEL=\"gemini-1.5-flash\" # or \"gemini-1.5-pro\"\nHYPERPARAMETERS='{\"batchSize\": 8, \"learningRate\": 1e-4, \"epochCount\": 3}'\n\ncurl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"baseModel\": \"models/'$BASE_MODEL'\",\n    \"tuningTask\": {\n      \"hyperparameters\": '$HYPERPARAMETERS',\n      \"trainingData\": {\n        \"gcsUri\": \"'$TUNING_DATA_PATH'\"\n      },\n      \"validationData\": {\n        \"gcsUri\": \"'$VALIDATION_DATA_PATH'\"\n      }\n    },\n    \"displayName\": \"'$DISPLAY_NAME'\"\n  }' \\\n  \"https://us-central1-aiplatform.googleapis.com/v1/projects/$PROJECT_ID/locations/us-central1/tuningJobs\"\n```\n\n#### Required fields:\n\n* `baseModel`: The model to tune (currently supports `models/gemini-1.5-flash` or `models/gemini-1.5-pro`)\n* `tuningTask.trainingData`: URI to Google Cloud Storage bucket containing your training data in JSONL format\n* `displayName`: Name for your tuned model (for identification purposes)\n\n#### Optional fields:\n\n* `hyperparameters`: Configuration settings for the tuning process\n  * `batchSize`: Number of examples processed in each training step (default: 8)\n  * `learningRate`: Controls how quickly the model adapts to the tuning data (default: 1e-4)\n  * `epochCount`: Number of passes through the entire training dataset (default: 3)\n* `tuningTask.validationData`: URI to a Google Cloud Storage bucket containing validation data in the same JSONL format as training data. Used to evaluate model performance during training.\n\n### 3. Monitor the tuning job\n\nAfter creating a tuning job, you can monitor its progress by checking its status.\n\n```bash\nJOB_ID=\"your-tuning-job-id\" # From the response of the create request\n\ncurl -X GET \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  \"https://us-central1-aiplatform.googleapis.com/v1/projects/$PROJECT_ID/locations/us-central1/tuningJobs/$JOB_ID\"\n```\n\nThe response includes the job's current state and, once complete, will include the tuned model name.\n\n### 4. Use the tuned model\n\nOnce tuning is complete, you can generate content using your tuned model similar to how you would use the base model.\n\n```bash\nTUNED_MODEL_NAME=\"your-tuned-model-name\" # From the completed tuning job response\n\ncurl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [{\"text\": \"Write a poem about the mountains\"}]\n      }\n    ]\n  }' \\\n  \"https://us-central1-aiplatform.googleapis.com/v1/projects/$PROJECT_ID/locations/us-central1/publishers/google/models/$TUNED_MODEL_NAME:generateContent\"\n```\n\n## Best practices for tuning\n\nFor optimal results when tuning models, follow these guidelines:\n\n### Data quality and quantity\n\n* **Provide diverse examples**: Include a variety of examples that represent the range of scenarios your tuned model should handle.\n* **Quality over quantity**: 100-1,000 high-quality examples are typically more effective than thousands of low-quality ones.\n* **Consistent formatting**: Maintain consistent formatting across examples.\n* **Balance classes**: For classification tasks, provide a balanced number of examples for each class.\n\n### Tuning configuration\n\n* **Start with defaults**: Begin with default hyperparameters and adjust as needed.\n* **Set aside validation data**: Use 10-20% of your examples as validation data to monitor performance.\n* **Gradual adjustment**: If tuning results aren't satisfactory, make incremental adjustments to hyperparameters.\n\n### Prompt engineering\n\n* **Be explicit**: Clearly articulate the task in your examples.\n* **Include context**: Provide relevant context in the prompt when needed.\n* **Demonstrate output format**: Show the exact format you expect in the model's responses.\n\n### Evaluation\n\n* **Define success metrics**: Establish clear criteria for evaluating your tuned model's performance.\n* **Test edge cases**: Evaluate how the model handles unusual or boundary inputs.\n* **Compare to baseline**: Measure improvement against the untuned base model.\n\n## Troubleshooting\n\n### Common issues\n\n* **Tuning job fails**: Check your tuning data format for inconsistencies or errors.\n* **Poor performance**: Consider adding more diverse examples or adjusting hyperparameters.\n* **Overfitting**: If the model performs well on training examples but poorly on new inputs, reduce epoch count or increase training data diversity.\n* **Insufficient adaptation**: If the model doesn't adequately adapt to your examples, try increasing the learning rate or epoch count.\n\n### Getting help\n\nIf you encounter issues with tuning models, check the following resources:\n\n* Review the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tuning-llm)\n* Visit the [Google AI community forum](https://googleaistudio.com/community)\n\n## Additional resources\n\n* [Vertex AI Tuning documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tuning-llm)\n* [Generative AI best practices](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/best-practices)\n* [AI Studio](https://ai.google.dev/tutorials/ai-studio_quickstart) - Test and experiment with models through a UI\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/samples/model-customization-samples/text-to-sql-with-grounding.md\n# Text-to-SQL with Structured Grounding\n\nThese samples convert user queries into SQL using table structure data to guide the model (structured grounding). By providing table schema information, you can help the model generate SQL that's compatible with your database structure.\n\n## SQL generation with table schema\n\nThis sample demonstrates how to perform text-to-SQL generation with structured grounding using table schema.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"I need an SQL query to find the total sales for each product category in 2023.\\n\\nHere are my database tables:\\n\\nproducts:\\n- product_id (INT) PRIMARY KEY\\n- product_name (VARCHAR)\\n- category_id (INT) FOREIGN KEY\\n- price (DECIMAL)\\n\\ncategories:\\n- category_id (INT) PRIMARY KEY\\n- category_name (VARCHAR)\\n\\nsales:\\n- sale_id (INT) PRIMARY KEY\\n- product_id (INT) FOREIGN KEY\\n- sale_date (DATE)\\n- quantity (INT)\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Enhancing SQL results with constraints\n\nThis sample provides SQL generation with structured grounding using table schema and includes constraints and specific requirements.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Generate an SQL query to find customers who have spent more than $1000 in total and have made at least 3 purchases in the last 6 months. Sort the results by total spending in descending order and include their contact information.\\n\\nDatabase schema:\\n\\ncustomers:\\n- customer_id (INT) PRIMARY KEY\\n- first_name (VARCHAR)\\n- last_name (VARCHAR)\\n- email (VARCHAR)\\n- phone (VARCHAR)\\n- join_date (DATE)\\n\\norders:\\n- order_id (INT) PRIMARY KEY\\n- customer_id (INT) FOREIGN KEY\\n- order_date (DATE)\\n- total_amount (DECIMAL)\\n- status (VARCHAR)\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## SQL with complex multi-table relationships\n\nThis sample generates SQL that handles complex relationships between multiple tables, including joins and aggregations.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"I need an SQL query that shows the top 5 employees who have sold the most products in each department over the last quarter, along with their sales figures and ranking within the department.\\n\\nHere are my database tables:\\n\\nemployees:\\n- employee_id (INT) PRIMARY KEY\\n- first_name (VARCHAR)\\n- last_name (VARCHAR)\\n- hire_date (DATE)\\n- department_id (INT) FOREIGN KEY\\n\\ndepartments:\\n- department_id (INT) PRIMARY KEY\\n- department_name (VARCHAR)\\n\\nsales:\\n- sale_id (INT) PRIMARY KEY\\n- employee_id (INT) FOREIGN KEY\\n- product_id (INT) FOREIGN KEY\\n- sale_date (DATE)\\n- quantity (INT)\\n- sale_amount (DECIMAL)\\n\\nproducts:\\n- product_id (INT) PRIMARY KEY\\n- product_name (VARCHAR)\\n- category (VARCHAR)\\n- price (DECIMAL)\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## SQL for hierarchical data structure\n\nThis example handles hierarchical relationships in data, demonstrating recursive queries and tree structure navigation.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Create an SQL query to find all employees under a specific manager, showing the entire hierarchy chain. Include each employee\\\"s name, level in the hierarchy, salary, and department. The query should be usable for any manager as the starting point.\\n\\nDatabase tables:\\n\\nemployees:\\n- employee_id (INT) PRIMARY KEY\\n- first_name (VARCHAR)\\n- last_name (VARCHAR)\\n- manager_id (INT) FOREIGN KEY (self-referencing to employee_id)\\n- salary (DECIMAL)\\n- department_id (INT) FOREIGN KEY\\n\\ndepartments:\\n- department_id (INT) PRIMARY KEY\\n- department_name (VARCHAR)\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## SQL for data analysis with window functions\n\nThis sample generates complex analytical SQL queries using window functions, aggregations, and conditional logic.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"I need an SQL query for analyzing student performance over time. For each student, show their test scores, the average score in their class, their percentile ranking, and whether they\\\"ve improved compared to their previous test. Also calculate a moving average of their last 3 tests.\\n\\nDatabase schema:\\n\\nstudents:\\n- student_id (INT) PRIMARY KEY\\n- first_name (VARCHAR)\\n- last_name (VARCHAR)\\n- grade_level (INT)\\n- class_id (INT) FOREIGN KEY\\n\\nclasses:\\n- class_id (INT) PRIMARY KEY\\n- class_name (VARCHAR)\\n- teacher_id (INT) FOREIGN KEY\\n\\ntests:\\n- test_id (INT) PRIMARY KEY\\n- test_name (VARCHAR)\\n- test_date (DATE)\\n- subject (VARCHAR)\\n\\ntest_results:\\n- result_id (INT) PRIMARY KEY\\n- student_id (INT) FOREIGN KEY\\n- test_id (INT) FOREIGN KEY\\n- score (DECIMAL)\\n- max_possible_score (DECIMAL)\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/models/embedding.md\n# Generate embeddings\n\nThis guide explains how to generate embeddings using the Gemini API to help you build systems that understand relationships between text inputs. It includes sample code in Python and HTTP.\n\n## Introduction to embeddings\n\nEmbeddings are numerical representations of information such as text, images, or audio that capture semantic relationships. They convert information into dense vector representations where similar content has vectors that are closer together in the embedding space.\n\nEmbeddings can be used for:\n\n* Semantic search: Find documents with similar meaning, not just keyword matches\n* Clustering: Group similar items together\n* Classification: Categorize content based on semantic meaning\n* Recommendation systems: Suggest similar items to users\n* Anomaly detection: Identify unusual or unexpected data points\n\n## Embedding models\n\nThe following table shows the available embedding models and their specifications:\n\n| Model | Max input tokens | Output dimensions | Query/Document type | Text type | Named version |\n|-------|-----------------|-------------------|---------------------|-----------|---------------|\n| `text-embedding-005` | 8,192 | 768 | Document & Query | Text | N/A |\n| `embedding-001` | 3,072 | 768 | Document | Text | `models/embedding-001` |\n| `text-multilingual-embedding-002` | 2,048 | 768 | Document & Query | Text | `models/text-multilingual-embedding-002` |\n\nNotes:\n* Output dimensions are fixed at 768 for all embedding models.\n* `text-embedding-005` is a newer model with improved performance and supports multi-region deployment.\n* For most use cases, we recommend using `text-embedding-005`.\n\n## Sample code\n\n### Python example\n\nHere's how to generate embeddings with Python:\n\n```python\nimport google.generativeai as genai\n\n# Configure the client library\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# Generate text embeddings\nresult = genai.embed_content(\n    model=\"models/text-embedding-005\",\n    content=\"What is the meaning of life?\",\n    task_type=\"RETRIEVAL_QUERY\"\n)\n\n# Print the embedding vector (first 5 dimensions)\nprint(f\"Embedding length: {len(result['embedding'])}\")\nprint(f\"First 5 dimensions: {result['embedding'][:5]}\")\n```\n\n### HTTP request example\n\nHere's how to generate embeddings using an HTTP request:\n\n```http\nPOST https://generativelanguage.googleapis.com/v1/models/text-embedding-005:embedContent?key=YOUR_API_KEY\nContent-Type: application/json\n\n{\n  \"content\": {\n    \"parts\": [\n      { \"text\": \"What is the meaning of life?\" }\n    ]\n  },\n  \"taskType\": \"RETRIEVAL_QUERY\"\n}\n```\n\n## API reference\n\nWhen generating embeddings, you can specify the following parameters:\n\n| Parameter | Description | Type | Default | Notes |\n|-----------|-------------|------|---------|-------|\n| `model` | The model to use | string | Required | Use `models/text-embedding-005` for most cases |\n| `content` | The text to embed | string or TextPart | Required | Text to generate embeddings for |\n| `taskType` | The intended use of the embedding | string | Optional | `RETRIEVAL_QUERY` for queries, `RETRIEVAL_DOCUMENT` for documents, `SEMANTIC_SIMILARITY`, `CLASSIFICATION`, or `CLUSTERING` |\n| `title` | Document title | string | Optional | Supplementary information for document embeddings |\n\n### Understanding task types\n\nThe `taskType` parameter optimizes embeddings for specific use cases:\n\n* `RETRIEVAL_DOCUMENT`: For indexing documents in retrieval systems (default)\n* `RETRIEVAL_QUERY`: For embedding search queries\n* `SEMANTIC_SIMILARITY`: For comparing semantic similarity between texts\n* `CLASSIFICATION`: For text classification tasks\n* `CLUSTERING`: For clustering similar texts\n\n## Use case examples\n\n### Building a semantic search system\n\nThis example demonstrates how to build a simple semantic search system using embeddings:\n\n```python\nimport google.generativeai as genai\nimport numpy as np\n\n# Configure the client library\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# Sample documents to search through\ndocuments = [\n    \"The sky is blue because of Rayleigh scattering of sunlight.\",\n    \"Photosynthesis is how plants convert sunlight into energy.\",\n    \"The Earth orbits around the Sun in approximately 365.25 days.\",\n    \"Water boils at 100 degrees Celsius at standard pressure.\",\n    \"The human body contains about 60% water.\"\n]\n\n# Generate embeddings for all documents\ndoc_embeddings = []\nfor doc in documents:\n    result = genai.embed_content(\n        model=\"models/text-embedding-005\",\n        content=doc,\n        task_type=\"RETRIEVAL_DOCUMENT\"\n    )\n    doc_embeddings.append(result[\"embedding\"])\n\n# Function to perform search\ndef semantic_search(query, top_k=2):\n    # Generate embedding for the query\n    query_result = genai.embed_content(\n        model=\"models/text-embedding-005\",\n        content=query,\n        task_type=\"RETRIEVAL_QUERY\"\n    )\n    query_embedding = query_result[\"embedding\"]\n    \n    # Calculate similarities (cosine similarity)\n    similarities = []\n    for doc_embedding in doc_embeddings:\n        similarity = np.dot(query_embedding, doc_embedding) / (\n            np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)\n        )\n        similarities.append(similarity)\n    \n    # Get top k results\n    top_indices = np.argsort(similarities)[-top_k:][::-1]\n    \n    results = []\n    for idx in top_indices:\n        results.append({\n            \"document\": documents[idx],\n            \"similarity\": similarities[idx]\n        })\n    \n    return results\n\n# Perform a search\nsearch_results = semantic_search(\"Why is the sky blue?\")\nfor i, result in enumerate(search_results):\n    print(f\"Result {i+1}:\")\n    print(f\"Document: {result['document']}\")\n    print(f\"Similarity: {result['similarity']:.4f}\")\n    print()\n```\n\n### Text classification\n\nThis example shows how to use embeddings for text classification:\n\n```python\nimport google.generativeai as genai\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\n\n# Configure the client library\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# Sample labeled data\ntexts = [\n    \"I loved the movie, it was fantastic!\",\n    \"The film was entertaining and enjoyable\",\n    \"What a great performance by the actors\",\n    \"This movie was terrible and boring\",\n    \"I hated everything about this film\",\n    \"The worst movie I've ever seen\"\n]\nlabels = [1, 1, 1, 0, 0, 0]  # 1 for positive, 0 for negative\n\n# Generate embeddings for training data\nembeddings = []\nfor text in texts:\n    result = genai.embed_content(\n        model=\"models/text-embedding-005\",\n        content=text,\n        task_type=\"CLASSIFICATION\"\n    )\n    embeddings.append(result[\"embedding\"])\n\n# Train a simple classifier\nclassifier = LogisticRegression()\nclassifier.fit(embeddings, labels)\n\n# Function to classify new text\ndef classify_text(text):\n    result = genai.embed_content(\n        model=\"models/text-embedding-005\",\n        content=text,\n        task_type=\"CLASSIFICATION\"\n    )\n    embedding = [result[\"embedding\"]]\n    \n    # Get prediction\n    prediction = classifier.predict(embedding)[0]\n    probabilities = classifier.predict_proba(embedding)[0]\n    \n    return {\n        \"text\": text,\n        \"prediction\": \"positive\" if prediction == 1 else \"negative\",\n        \"confidence\": probabilities[prediction]\n    }\n\n# Test the classifier\ntest_texts = [\n    \"I really enjoyed this movie\",\n    \"This film was a complete waste of time\"\n]\n\nfor text in test_texts:\n    result = classify_text(text)\n    print(f\"Text: {result['text']}\")\n    print(f\"Prediction: {result['prediction']}\")\n    print(f\"Confidence: {result['confidence']:.4f}\")\n    print()\n```\n\n## Best practices\n\n### Optimizing embedding usage\n\n1. **Match task type to your use case**: Use `RETRIEVAL_QUERY` for search queries and `RETRIEVAL_DOCUMENT` for indexing documents.\n\n2. **Normalize embeddings**: For similarity computations, normalize vectors to ensure consistent results.\n\n3. **Pre-process text**: Remove unnecessary whitespace, standardize formatting, and consider removing stopwords for certain applications.\n\n4. **Batch processing**: Generate embeddings in batches for efficiency in production systems.\n\n5. **Dimensionality considerations**: The full 768 dimensions contain all semantic information, but for large-scale systems, you might consider dimensionality reduction techniques like PCA to balance performance and storage requirements.\n\n6. **Cache embeddings**: Store embeddings for frequently accessed content to reduce API calls.\n\n### Common pitfalls to avoid\n\n1. **Mixing models**: Don't compare embeddings from different models—they exist in different vector spaces.\n\n2. **Ignoring task types**: Using the wrong task type can significantly impact performance for specialized tasks.\n\n3. **Embedding too much content**: Break very long documents into meaningful chunks rather than truncating.\n\n4. **Excessive similarity thresholds**: Set appropriate similarity thresholds based on your specific use case and needs.\n\n## Troubleshooting\n\n### Common issues and solutions\n\n1. **Poor search results**:\n   - Ensure you're using `RETRIEVAL_QUERY` for queries and `RETRIEVAL_DOCUMENT` for documents.\n   - Verify your similarity calculation method (cosine similarity is recommended).\n   - Consider chunking documents differently.\n\n2. **API errors**:\n   - Check that your API key is valid and has proper permissions.\n   - Ensure you're not exceeding rate limits or quota.\n   - Verify the text doesn't exceed the model's token limit.\n\n3. **Performance issues**:\n   - Consider caching frequently used embeddings.\n   - Use vector databases (like Pinecone, Weaviate, or Milvus) for large-scale applications.\n   - Implement batching to reduce API calls.\n\n### Getting help\n\nIf you encounter issues with the Gemini API for embeddings:\n\n- Check the [Gemini API documentation](https://ai.google.dev/docs/embeddings_guide)\n- Visit the [Google AI community](https://ai.google.dev/community)\n- Search for similar issues on Stack Overflow or the Google AI forum\n\n## Additional resources\n\n- [Embeddings guide](https://ai.google.dev/docs/embeddings_guide) - Comprehensive guide to using embeddings\n- [API reference](https://ai.google.dev/api/rest/v1beta/models/embedContent) - Complete API reference for embedding endpoints\n- [Vector databases comparison](https://ai.google.dev/docs/vectors_guide) - Learn about different vector database options\n- [Sample applications](https://github.com/google/generative-ai-docs/tree/main/site/en/gemini/docs/embeddings) - Example applications using embeddings\n\u0005End File\u0006# google/generative-ai-docs\n# Experiment with models\n\nThis sample shows how to test model output settings to find the best configuration for your use case using temperature, top-p, top-k, and response length settings.\n\n## Compare temperature settings\n\nTemperature affects the randomness of the output. Lower values produce more focused responses, while higher values result in more creative, varied answers.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a short story about a robot discovering emotions.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.1,\n      \"maxOutputTokens\": 500\n    }\n  }'</code>\n</pre>\n\nNow try the same prompt with a higher temperature:\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a short story about a robot discovering emotions.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.9,\n      \"maxOutputTokens\": 500\n    }\n  }'</code>\n</pre>\n\n## Test top-p and top-k sampling\n\nTop-p (nucleus) and top-k sampling help control diversity by limiting which tokens the model considers when generating text.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Generate a list of creative uses for old coffee grounds.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.7,\n      \"topP\": 0.9,\n      \"topK\": 40,\n      \"maxOutputTokens\": 500\n    }\n  }'</code>\n</pre>\n\nTry more restrictive settings:\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Generate a list of creative uses for old coffee grounds.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.7,\n      \"topP\": 0.5,\n      \"topK\": 20,\n      \"maxOutputTokens\": 500\n    }\n  }'</code>\n</pre>\n\n## Control response length\n\nAdjust the maximum output tokens to control how much content the model generates.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Explain how blockchain technology works.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"maxOutputTokens\": 100\n    }\n  }'</code>\n</pre>\n\nNow request a more detailed explanation:\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Explain how blockchain technology works.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"maxOutputTokens\": 800\n    }\n  }'</code>\n</pre>\n\n## Compare creative versus factual settings\n\nUse different configurations for creative versus factual tasks.\n\nFor creative content:\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a poem about the changing seasons.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.8,\n      \"topP\": 0.9,\n      \"topK\": 40,\n      \"maxOutputTokens\": 500\n    }\n  }'</code>\n</pre>\n\nFor factual content:\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Explain the water cycle and its importance to Earth's ecosystems.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.1,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 800\n    }\n  }'</code>\n</pre>\n\n## Combine parameters for specific tasks\n\nCreate optimal configurations for specific use cases by combining different parameters.\n\nFor a brainstorming session:\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Generate 10 innovative product ideas for eco-friendly kitchen gadgets.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.9,\n      \"topP\": 0.95,\n      \"topK\": 50,\n      \"maxOutputTokens\": 1000\n    }\n  }'</code>\n</pre>\n\nFor a technical explanation:\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Explain how nuclear fusion works and its potential as an energy source.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.1,\n      \"topP\": 0.7,\n      \"topK\": 30,\n      \"maxOutputTokens\": 1000\n    }\n  }'</code>\n</pre>\n\u0005End File\u0006# google/generative-ai-docs\n# samples/python/prompts/query-classification.ipynb\n{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Query Classification with Gemini\\n\",\n    \"\\n\",\n    \"This notebook demonstrates how to use the Gemini API to perform query classification - a way to automatically categorize user queries or inputs into predefined categories.\\n\",\n    \"\\n\",\n    \"In this example, we'll build a system to classify customer service queries into appropriate departments (Billing, Technical Support, Product Information, Returns/Exchanges, or Other).\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"!pip install -q -U google-generativeai\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import google.generativeai as genai\\n\",\n    \"import os\\n\",\n    \"import json\\n\",\n    \"from IPython.display import display, Markdown\\n\",\n    \"\\n\",\n    \"# Configure the API key\\n\",\n    \"# Set your API key in the environment or directly\\n\",\n    \"API_KEY = os.environ.get(\\\"API_KEY\\\", \\\"YOUR_API_KEY_HERE\\\")\\n\",\n    \"genai.configure(api_key=API_KEY)\\n\",\n    \"\\n\",\n    \"# Initialize the model\\n\",\n    \"model = genai.GenerativeModel('gemini-1.5-flash')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Step 1: Define Categories and Classification Prompt\\n\",\n    \"\\n\",\n    \"We'll start by defining our classification categories and creating a prompt that instructs the model how to perform classification.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Define categories for classification\\n\",\n    \"categories = [\\n\",\n    \"    \\\"Billing\\\",                # Payment issues, invoices, refunds\\n\",\n    \"    \\\"Technical Support\\\",      # Product not working, error messages, troubleshooting\\n\",\n    \"    \\\"Product Information\\\",    # Questions about products, features, comparisons\\n\",\n    \"    \\\"Returns/Exchanges\\\",      # Returning items, exchanging for different sizes/models\\n\",\n    \"    \\\"Other\\\"                   # Anything that doesn't fit the categories above\\n\",\n    \"]\\n\",\n    \"\\n\",\n    \"# Create the classification prompt template\\n\",\n    \"classification_prompt = \\\"\\\"\\\"\\n\",\n    \"You are a customer service query classifier. Your task is to categorize the following customer query into exactly one of these categories:\\n\",\n    \"\\n\",\n    \"Categories:\\n\",\n    \"{categories}\\n\",\n    \"\\n\",\n    \"Guidelines:\\n\",\n    \"- Classify based on the primary intent of the query.\\n\",\n    \"- If a query could fit multiple categories, choose the most relevant one.\\n\",\n    \"- Only respond with a valid category name, exactly as listed above.\\n\",\n    \"- Do not include any explanations or additional text.\\n\",\n    \"\\n\",\n    \"Customer Query: \\\"{query}\\\"\\n\",\n    \"\\n\",\n    \"Classification:\\n\",\n    \"\\\"\\\"\\\"\\n\",\n    \"\\n\",\n    \"# Function to classify a query\\n\",\n    \"def classify_query(query):\\n\",\n    \"    prompt = classification_prompt.format(categories=\\\"\\\\n\\\".join([f\\\"- {category}\\\" for category in categories]), query=query)\\n\",\n    \"    response = model.generate_content(prompt, generation_config={\\\"temperature\\\": 0.1})\\n\",\n    \"    classification = response.text.strip()\\n\",\n    \"    \\n\",\n    \"    # Verify the classification is one of our valid categories\\n\",\n    \"    if classification not in categories:\\n\",\n    \"        return \\\"Other\\\"\\n\",\n    \"    \\n\",\n    \"    return classification\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Step 2: Test with Sample Queries\\n\",\n    \"\\n\",\n    \"Let's test our classification system with a variety of customer service queries.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"sample_queries = [\\n\",\n    \"    \\\"I was charged twice for my last order. Can I get a refund?\\\",\\n\",\n    \"    \\\"My device won't turn on even after charging overnight.\\\",\\n\",\n    \"    \\\"What's the difference between your basic and premium plans?\\\",\\n\",\n    \"    \\\"I received the wrong size and would like to exchange it for a larger one.\\\",\\n\",\n    \"    \\\"Do you offer international shipping to Europe?\\\",\\n\",\n    \"    \\\"The app keeps crashing whenever I try to upload photos.\\\",\\n\",\n    \"    \\\"I haven't received my invoice for this month's subscription.\\\",\\n\",\n    \"    \\\"Can I speak to a manager about your company's environmental policies?\\\",\\n\",\n    \"    \\\"The protective case I ordered doesn't fit my new phone model.\\\",\\n\",\n    \"    \\\"How do I reset my password?\\\"\\n\",\n    \"]\\n\",\n    \"\\n\",\n    \"# Test each query and display results\\n\",\n    \"for query in sample_queries:\\n\",\n    \"    classification = classify_query(query)\\n\",\n    \"    print(f\\\"Query: {query}\\\")\\n\",\n    \"    print(f\\\"Classification: {classification}\\\")\\n\",\n    \"    print(\\\"-\\\" * 80)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Step 3: Build a Structured Classification System\\n\",\n    \"\\n\",\n    \"Now let's enhance our system to provide a more structured response, including confidence scores and subcategories.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Define category details with subcategories\\n\",\n    \"category_details = {\\n\",\n    \"    \\\"Billing\\\": {\\n\",\n    \"        \\\"subcategories\\\": [\\\"Payment Issues\\\", \\\"Refunds\\\", \\\"Subscription Management\\\", \\\"Invoices\\\", \\\"Pricing Questions\\\"]\\n\",\n    \"    },\\n\",\n    \"    \\\"Technical Support\\\": {\\n\",\n    \"        \\\"subcategories\\\": [\\\"Hardware Problems\\\", \\\"Software Issues\\\", \\\"Connectivity Issues\\\", \\\"Account Access\\\", \\\"Setup Help\\\"]\\n\",\n    \"    },\\n\",\n    \"    \\\"Product Information\\\": {\\n\",\n    \"        \\\"subcategories\\\": [\\\"Features\\\", \\\"Comparisons\\\", \\\"Availability\\\", \\\"Specifications\\\", \\\"Usage Instructions\\\"]\\n\",\n    \"    },\\n\",\n    \"    \\\"Returns/Exchanges\\\": {\\n\",\n    \"        \\\"subcategories\\\": [\\\"Return Process\\\", \\\"Exchange Request\\\", \\\"Warranty Claims\\\", \\\"Damaged Items\\\", \\\"Wrong Item Received\\\"]\\n\",\n    \"    },\\n\",\n    \"    \\\"Other\\\": {\\n\",\n    \"        \\\"subcategories\\\": [\\\"Feedback\\\", \\\"Complaints\\\", \\\"Partnership Inquiries\\\", \\\"Employment Questions\\\", \\\"General Information\\\"]\\n\",\n    \"    }\\n\",\n    \"}\\n\",\n    \"\\n\",\n    \"# Create an enhanced classification prompt\\n\",\n    \"enhanced_classification_prompt = \\\"\\\"\\\"\\n\",\n    \"You are a customer service query classifier. Your task is to categorize the following customer query into the most appropriate category and subcategory. Provide a confidence score (0-100) for your classification.\\n\",\n    \"\\n\",\n    \"Categories and Subcategories:\\n\",\n    \"{category_details}\\n\",\n    \"\\n\",\n    \"Guidelines:\\n\",\n    \"- Classify based on the primary intent of the query.\\n\",\n    \"- If a query could fit multiple categories, choose the most relevant one.\\n\",\n    \"- Provide a confidence score between 0-100 reflecting how certain you are of the classification.\\n\",\n    \"- Respond in JSON format with the following structure:\\n\",\n    \"  {{\\\"category\\\": \\\"Category Name\\\", \\\"subcategory\\\": \\\"Subcategory Name\\\", \\\"confidence\\\": 95, \\\"explanation\\\": \\\"Brief explanation of why this classification was chosen\\\"}}\\n\",\n    \"\\n\",\n    \"Customer Query: \\\"{query}\\\"\\n\",\n    \"\\n\",\n    \"Classification (JSON format):\\n\",\n    \"\\\"\\\"\\\"\\n\",\n    \"\\n\",\n    \"# Function for enhanced classification\\n\",\n    \"def enhanced_classify_query(query):\\n\",\n    \"    # Format the category details as a readable string\\n\",\n    \"    category_details_str = \\\"\\\"\\n\",\n    \"    for category, details in category_details.items():\\n\",\n    \"        category_details_str += f\\\"- {category}: {', '.join(details['subcategories'])}\\\\n\\\"\\n\",\n    \"    \\n\",\n    \"    prompt = enhanced_classification_prompt.format(category_details=category_details_str, query=query)\\n\",\n    \"    response = model.generate_content(prompt, generation_config={\\\"temperature\\\": 0.1})\\n\",\n    \"    \\n\",\n    \"    # Extract and parse the JSON response\\n\",\n    \"    try:\\n\",\n    \"        # Find the JSON in the response\\n\",\n    \"        response_text = response.text.strip()\\n\",\n    \"        # Sometimes the model might add markdown code block indicators\\n\",\n    \"        if response_text.startswith(\\\"```json\\\"):\\n\",\n    \"            response_text = response_text.replace(\\\"```json\\\", \\\"\\\").replace(\\\"```\\\", \\\"\\\")\\n\",\n    \"        classification_data = json.loads(response_text)\\n\",\n    \"        \\n\",\n    \"        # Validate the response has the expected structure\\n\",\n    \"        if not all(key in classification_data for key in [\\\"category\\\", \\\"subcategory\\\", \\\"confidence\\\"]):\\n\",\n    \"            raise ValueError(\\\"Response missing required fields\\\")\\n\",\n    \"        \\n\",\n    \"        return classification_data\\n\",\n    \"    except Exception as e:\\n\",\n    \"        print(f\\\"Error parsing response: {e}\\\")\\n\",\n    \"        print(f\\\"Raw response: {response.text}\\\")\\n\",\n    \"        return {\\n\",\n    \"            \\\"category\\\": \\\"Error\\\",\\n\",\n    \"            \\\"subcategory\\\": \\\"Parsing Error\\\",\\n\",\n    \"            \\\"confidence\\\": 0,\\n\",\n    \"            \\\"explanation\\\": \\\"Failed to parse the model's response\\\"\\n\",\n    \"        }\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Step 4: Test the Enhanced Classification System\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Test with the same queries\\n\",\n    \"for query in sample_queries:\\n\",\n    \"    classification = enhanced_classify_query(query)\\n\",\n    \"    print(f\\\"Query: {query}\\\")\\n\",\n    \"    print(f\\\"Category: {classification['category']}\\\")\\n\",\n    \"    print(f\\\"Subcategory: {classification['subcategory']}\\\")\\n\",\n    \"    print(f\\\"Confidence: {classification['confidence']}%\\\")\\n\",\n    \"    print(f\\\"Explanation: {classification.get('explanation', 'No explanation provided')}\\\")\\n\",\n    \"    print(\\\"-\\\" * 80)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Step 5: Build a Complete Classification Application\\n\",\n    \"\\n\",\n    \"Now let's create a more complete application that includes routing logic based on classifications.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Define department routing information\\n\",\n    \"department_routing = {\\n\",\n    \"    \\\"Billing\\\": {\\n\",\n    \"        \\\"team\\\": \\\"Finance Department\\\",\\n\",\n    \"        \\\"email\\\": \\\"billing@example.com\\\",\\n\",\n    \"        \\\"priority\\\": {\\n\",\n    \"            \\\"Refunds\\\": \\\"High\\\",\\n\",\n    \"            \\\"Payment Issues\\\": \\\"High\\\",\\n\",\n    \"            \\\"default\\\": \\\"Medium\\\"\\n\",\n    \"        }\\n\",\n    \"    },\\n\",\n    \"    \\\"Technical Support\\\": {\\n\",\n    \"        \\\"team\\\": \\\"Technical Support Team\\\",\\n\",\n    \"        \\\"email\\\": \\\"support@example.com\\\",\\n\",\n    \"        \\\"priority\\\": {\\n\",\n    \"            \\\"Hardware Problems\\\": \\\"High\\\",\\n\",\n    \"            \\\"Software Issues\\\": \\\"Medium\\\",\\n\",\n    \"            \\\"default\\\": \\\"Low\\\"\\n\",\n    \"        }\\n\",\n    \"    },\\n\",\n    \"    \\\"Product Information\\\": {\\n\",\n    \"        \\\"team\\\": \\\"Product Specialists\\\",\\n\",\n    \"        \\\"email\\\": \\\"products@example.com\\\",\\n\",\n    \"        \\\"priority\\\": {\\n\",\n    \"            \\\"default\\\": \\\"Low\\\"\\n\",\n    \"        }\\n\",\n    \"    },\\n\",\n    \"    \\\"Returns/Exchanges\\\": {\\n\",\n    \"        \\\"team\\\": \\\"Customer Service\\\",\\n\",\n    \"        \\\"email\\\": \\\"returns@example.com\\\",\\n\",\n    \"        \\\"priority\\\": {\\n\",\n    \"            \\\"Damaged Items\\\": \\\"High\\\",\\n\",\n    \"            \\\"default\\\": \\\"Medium\\\"\\n\",\n    \"        }\\n\",\n    \"    },\\n\",\n    \"    \\\"Other\\\": {\\n\",\n    \"        \\\"team\\\": \\\"General Inquiries\\\",\\n\",\n    \"        \\\"email\\\": \\\"info@example.com\\\",\\n\",\n    \"        \\\"priority\\\": {\\n\",\n    \"            \\\"Complaints\\\": \\\"High\\\",\\n\",\n    \"            \\\"default\\\": \\\"Low\\\"\\n\",\n    \"        }\\n\",\n    \"    }\\n\",\n    \"}\\n\",\n    \"\\n\",\n    \"# Function to handle a customer query\\n\",\n    \"def handle_customer_query(query, customer_id=\\\"Unknown\\\"):\\n\",\n    \"    # Step 1: Classify the query\\n\",\n    \"    classification = enhanced_classify_query(query)\\n\",\n    \"    \\n\",\n    \"    # Step 2: Determine routing based on classification\\n\",\n    \"    category = classification[\\\"category\\\"]\\n\",\n    \"    subcategory = classification[\\\"subcategory\\\"]\\n\",\n    \"    \\n\",\n    \"    if category in department_routing:\\n\",\n    \"        department = department_routing[category]\\n\",\n    \"    else:\\n\",\n    \"        department = department_routing[\\\"Other\\\"]\\n\",\n    \"    \\n\",\n    \"    # Determine priority\\n\",\n    \"    if subcategory in department[\\\"priority\\\"]:\\n\",\n    \"        priority = department[\\\"priority\\\"][subcategory]\\n\",\n    \"    else:\\n\",\n    \"        priority = department[\\\"priority\\\"][\\\"default\\\"]\\n\",\n    \"    \\n\",\n    \"    # Step 3: Create a routing ticket\\n\",\n    \"    ticket = {\\n\",\n    \"        \\\"customer_id\\\": customer_id,\\n\",\n    \"        \\\"query\\\": query,\\n\",\n    \"        \\\"classification\\\": classification,\\n\",\n    \"        \\\"routing\\\": {\\n\",\n    \"            \\\"department\\\": department[\\\"team\\\"],\\n\",\n    \"            \\\"email\\\": department[\\\"email\\\"],\\n\",\n    \"            \\\"priority\\\": priority\\n\",\n    \"        },\\n\",\n    \"        \\\"ticket_id\\\": f\\\"TKT-{hash(query) % 10000:04d}\\\",\\n\",\n    \"        \\\"status\\\": \\\"New\\\"\\n\",\n    \"    }\\n\",\n    \"    \\n\",\n    \"    return ticket\\n\",\n    \"\\n\",\n    \"# Generate an automatic response based on the classification\\n\",\n    \"def generate_initial_response(ticket):\\n\",\n    \"    classification = ticket[\\\"classification\\\"]\\n\",\n    \"    category = classification[\\\"category\\\"]\\n\",\n    \"    subcategory = classification[\\\"subcategory\\\"]\\n\",\n    \"    \\n\",\n    \"    response_prompt = f\\\"\\\"\\\"\\n\",\n    \"    You are a customer service representative. Generate a helpful initial response to the following customer query.\\n\",\n    \"    The query has been classified as {category} > {subcategory}.\\n\",\n    \"    \\n\",\n    \"    Keep your response under 150 words, professional but friendly, and acknowledge their specific concern.\\n\",\n    \"    Don't ask for information that's already in the query.\\n\",\n    \"    Include a greeting and sign-off as the customer service team.\\n\",\n    \"    \\n\",\n    \"    Customer Query: \\\"{ticket['query']}\\\"\\n\",\n    \"    \\n\",\n    \"    Your response:\\n\",\n    \"    \\\"\\\"\\\"\\n\",\n    \"    \\n\",\n    \"    response = model.generate_content(response_prompt, generation_config={\\\"temperature\\\": 0.7})\\n\",\n    \"    return response.text.strip()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Step 6: Test the Complete System\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Test with a complex query\\n\",\n    \"complex_query = \\\"I purchased your premium wireless headphones last week, but they won't connect to my phone. I've tried resetting them multiple times following the instructions in the manual, but the Bluetooth pairing fails every time. The LED light just keeps flashing red instead of blue as mentioned in the guide. Can you help me fix this or should I return them?\\\"\\n\",\n    \"\\n\",\n    \"# Process the query\\n\",\n    \"ticket = handle_customer_query(complex_query, customer_id=\\\"CUST12345\\\")\\n\",\n    \"initial_response = generate_initial_response(ticket)\\n\",\n    \"\\n\",\n    \"# Display the results\\n\",\n    \"print(\\\"CUSTOMER QUERY:\\\")\\n\",\n    \"print(complex_query)\\n\",\n    \"print(\\\"\\\\n\\\" + \\\"-\\\"*80 + \\\"\\\\n\\\")\\n\",\n    \"\\n\",\n    \"print(\\\"CLASSIFICATION DETAILS:\\\")\\n\",\n    \"print(f\\\"Category: {ticket['classification']['category']}\\\")\\n\",\n    \"print(f\\\"Subcategory: {ticket['classification']['subcategory']}\\\")\\n\",\n    \"print(f\\\"Confidence: {ticket['classification']['confidence']}%\\\")\\n\",\n    \"print(f\\\"Explanation: {ticket['classification'].get('explanation', 'No explanation provided')}\\\")\\n\",\n    \"print(\\\"\\\\n\\\" + \\\"-\\\"*80 + \\\"\\\\n\\\")\\n\",\n    \"\\n\",\n    \"print(\\\"ROUTING INFORMATION:\\\")\\n\",\n    \"print(f\\\"Ticket ID: {ticket['ticket_id']}\\\")\\n\",\n    \"print(f\\\"Department: {ticket['routing']['department']}\\\")\\n\",\n    \"print(f\\\"Contact: {ticket['routing']['email']}\\\")\\n\",\n    \"print(f\\\"Priority: {ticket['routing']['priority']}\\\")\\n\",\n    \"print(\\\"\\\\n\\\" + \\\"-\\\"*80 + \\\"\\\\n\\\")\\n\",\n    \"\\n\",\n    \"print(\\\"AUTOMATED INITIAL RESPONSE:\\\")\\n\",\n    \"display(Markdown(initial_response))\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Step 7: Test with a Variety of Queries\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# More realistic customer queries\\n\",\n    \"real_world_queries = [\\n\",\n    \"    \\\"I need to update my credit card on file because my old one expired last week.\\\",\\n\",\n    \"    \\\"Your app keeps freezing on my iPhone whenever I try to make a purchase. I've updated to the latest version but still having issues.\\\",\\n\",\n    \"    \\\"The lawn mower I received is dented on one side and the starter cord is frayed. I'd like a replacement sent ASAP.\\\",\\n\",\n    \"    \\\"Can your software integrate with Salesforce? We're considering implementing your solution company-wide.\\\",\\n\",\n    \"    \\\"I ordered the wrong size shirt. How do I exchange it for a medium instead of a large?\\\",\\n\",\n    \"    \\\"I'm furious about the way your delivery person treated me yesterday. They left my package in a puddle and were rude when I asked them to place it on the porch.\\\"\\n\",\n    \"]\\n\",\n    \"\\n\",\n    \"# Process each query\\n\",\n    \"for i, query in enumerate(real_world_queries, 1):\\n\",\n    \"    print(f\\\"\\\\n===== QUERY #{i} =====\\\\n\\\")\\n\",\n    \"    ticket = handle_customer_query(query, customer_id=f\\\"CUST{i}000\\\")\\n\",\n    \"    initial_response = generate_initial_response(ticket)\\n\",\n    \"    \\n\",\n    \"    print(f\\\"QUERY: {query}\\\\n\\\")\\n\",\n    \"    print(f\\\"CLASSIFICATION: {ticket['classification']['category']} > {ticket['classification']['subcategory']} (Confidence: {ticket['classification']['confidence']}%)\\\")\\n\",\n    \"    print(f\\\"ROUTED TO: {ticket['routing']['department']} ({ticket['routing']['email']}) - Priority: {ticket['routing']['priority']}\\\\n\\\")\\n\",\n    \"    print(\\\"AUTOMATED RESPONSE:\\\")\\n\",\n    \"    display(Markdown(initial_response))\\n\",\n    \"    print(\\\"\\\\n\\\" + \\\"-\\\"*80)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Conclusion\\n\",\n    \"\\n\",\n    \"We've built a comprehensive query classification system that:\\n\",\n    \"\\n\",\n    \"1. Accurately categorizes customer queries into main categories and subcategories\\n\",\n    \"2. Provides confidence scores for the classifications\\n\",\n    \"3. Routes queries to the appropriate department with priority levels\\n\",\n    \"4. Generates helpful initial responses based on the query classification\\n\",\n    \"\\n\",\n    \"This system demonstrates how Gemini can be used to automate the initial handling of customer service inquiries, improving response times and ensuring queries are directed to the right teams.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Potential Enhancements\\n\",\n    \"\\n\",\n    \"To further improve this system, you could:\\n\",\n    \"\\n\",\n    \"1. Add sentiment analysis to identify urgent or dissatisfied customer issues\\n\",\n    \"2. Create a feedback loop to improve classification accuracy over time\\n\",\n    \"3. Integrate with a CRM or ticket management system\\n\",\n    \"4. Expand subcategories for more precise routing\\n\",\n    \"5. Add language detection for multilingual support\\n\",\n    \"6. Implement custom response templates for each category/subcategory\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"language_info\": {\n   \"name\": \"python\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/tutorials/chat_with_your_data.md\n# Chat with your data (Python)\n\nThis tutorial shows you how to create a Python application that lets you chat with your data using Vertex AI Agents and Vertex AI Search.\n\n## Objectives\n\nThe goal of this tutorial is to create a Python application that allows users to chat with their data. You will:\n\n1. Create a Vertex AI Search data store with your own data\n2. Use Vertex AI Search API to create a simple chat application\n3. Use Vertex AI Agent Builder to create a chat agent powered by your data\n\n## Prerequisites\n\nTo complete this tutorial, you'll need:\n\n- A Google Cloud project with billing enabled\n- Python 3.7+ installed on your machine\n- Basic Python programming skills\n- Google Cloud CLI installed (optional, for setup)\n\n## Setup\n\nBefore starting, set up your environment:\n\n1. Create or select a Google Cloud project:\n\n```bash\ngcloud config set project YOUR_PROJECT_ID\n```\n\n2. Enable the required APIs:\n\n```bash\ngcloud services enable aiplatform.googleapis.com discoveryengine.googleapis.com\n```\n\n3. Install the required Python packages:\n\n```bash\npip install google-cloud-aiplatform google-cloud-discoveryengine\n```\n\n## Step 1: Create a Vertex AI Search data store\n\nFirst, let's create a data store and ingest some sample documents.\n\n```python\nimport os\nfrom google.cloud import discoveryengine_v1 as discoveryengine\nfrom google.api_core.client_options import ClientOptions\n\n# Set your project ID and location\nproject_id = \"YOUR_PROJECT_ID\"  # Replace with your project ID\nlocation = \"global\"  # Use \"global\" for most cases\n\n# Initialize the Discovery Engine client\nclient_options = ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\nclient = discoveryengine.DataStoreServiceClient(client_options=client_options)\n\n# Create a data store\nparent = f\"projects/{project_id}/locations/{location}\"\ndata_store = discoveryengine.DataStore(\n    display_name=\"my_sample_data_store\",\n    industry_vertical=discoveryengine.IndustryVertical.GENERIC,\n    solution_types=[discoveryengine.SolutionType.SOLUTION_TYPE_SEARCH],\n    content_config=discoveryengine.DataStore.ContentConfig.CONTENT_REQUIRED,\n)\n\noperation = client.create_data_store(\n    parent=parent,\n    data_store_id=\"my_sample_data_store_id\",\n    data_store=data_store\n)\n\ncreated_data_store = operation.result()\nprint(f\"Created data store: {created_data_store.name}\")\n\n# Save the data store ID for later use\ndata_store_id = created_data_store.name.split(\"/\")[-1]\n```\n\n## Step 2: Ingest documents into your data store\n\nNow, let's add some sample documents to your data store. You can replace this with your own data.\n\n```python\nfrom google.cloud import discoveryengine_v1 as discoveryengine\nimport uuid\n\n# Initialize the Document Service client\ndocument_client = discoveryengine.DocumentServiceClient(client_options=client_options)\n\n# The data store name from previous step\ndata_store_name = f\"projects/{project_id}/locations/{location}/dataStores/{data_store_id}\"\n\n# Sample documents - replace with your own data\nsample_documents = [\n    {\n        \"title\": \"Introduction to Machine Learning\",\n        \"content\": \"Machine learning is a field of study that gives computers the ability to learn without being explicitly programmed.\"\n    },\n    {\n        \"title\": \"Cloud Computing Basics\",\n        \"content\": \"Cloud computing is the delivery of computing services over the internet, providing flexible resources and economies of scale.\"\n    },\n    {\n        \"title\": \"Artificial Intelligence Overview\",\n        \"content\": \"Artificial intelligence involves machines that can perform tasks that typically require human intelligence.\"\n    }\n]\n\n# Upload each document\nfor doc in sample_documents:\n    document_id = str(uuid.uuid4())\n    \n    document = discoveryengine.Document(\n        id=document_id,\n        name=f\"{data_store_name}/documents/{document_id}\",\n        struct_data={\n            \"title\": doc[\"title\"],\n            \"content\": doc[\"content\"]\n        }\n    )\n    \n    request = discoveryengine.CreateDocumentRequest(\n        parent=data_store_name,\n        document=document,\n        document_id=document_id\n    )\n    \n    response = document_client.create_document(request=request)\n    print(f\"Created document: {response.name}\")\n```\n\n## Step 3: Create a simple search chat interface\n\nNow let's create a simple function to interact with your data using conversational search:\n\n```python\nfrom google.cloud import discoveryengine_v1 as discoveryengine\n\ndef chat_with_data(project_id, location, data_store_id, query):\n    \"\"\"\n    Chat with your data using conversational search.\n    \"\"\"\n    # Initialize the Search Service client\n    client_options = ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n    search_client = discoveryengine.SearchServiceClient(client_options=client_options)\n    \n    # Format the resource name\n    serving_config = f\"projects/{project_id}/locations/{location}/dataStores/{data_store_id}/servingConfigs/default_config\"\n    \n    # Build the search request\n    request = discoveryengine.ConversationalSearchServiceRequest(\n        serving_config=serving_config,\n        query=discoveryengine.SearchRequest.Query(text=query),\n        conversation_id=\"\",  # For a new conversation\n    )\n    \n    # Get the search results\n    response = search_client.conversational_search(request)\n    \n    # Extract and return the answer\n    if response.summary and response.summary.summary_text:\n        return response.summary.summary_text\n    elif response.results:\n        return response.results[0].document.derived_struct_data[\"content\"]\n    else:\n        return \"No relevant information found.\"\n\n# Test the chat function\nquery = \"What is machine learning?\"\nresponse = chat_with_data(project_id, location, data_store_id, query)\nprint(f\"Query: {query}\")\nprint(f\"Response: {response}\")\n```\n\n## Step 4: Create a Vertex AI Agent with your data\n\nFor more advanced capabilities, let's create an agent using Vertex AI Agent Builder, which will allow more natural conversations with your data.\n\n```python\nfrom google.cloud import aiplatform\nfrom google.cloud.aiplatform import vertexai\n\n# Initialize Vertex AI\nvertexai.init(project=project_id, location=location)\n\n# Create a data source\ndata_source = {\n    \"engine_data_source\": {\n        \"data_store_ids\": [data_store_id]\n    }\n}\n\n# Create an agent\nagent = aiplatform.Agent.create(\n    display_name=\"My Data Agent\",\n    description=\"An agent that can answer questions about my data\",\n    data_sources=[data_source]\n)\n\nprint(f\"Created agent: {agent.name}\")\n```\n\n## Step 5: Build a conversation loop with your agent\n\nNow, let's create a function to have a continuous conversation with your agent:\n\n```python\ndef chat_with_agent(agent, conversation_history=None):\n    \"\"\"\n    Have a conversation with a Vertex AI Agent.\n    \"\"\"\n    if conversation_history is None:\n        conversation_history = []\n    \n    while True:\n        # Get user input\n        user_input = input(\"You: \")\n        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n            print(\"Agent: Goodbye!\")\n            break\n        \n        # Add user message to history\n        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n        \n        # Get response from agent\n        response = agent.query(\n            content=user_input,\n            history=conversation_history[:-1]  # Exclude the current message\n        )\n        \n        # Display agent response\n        print(f\"Agent: {response.text}\")\n        \n        # Add agent response to history\n        conversation_history.append({\"role\": \"agent\", \"content\": response.text})\n    \n    return conversation_history\n\n# Start a conversation with the agent\nconversation = chat_with_agent(agent)\n```\n\n## Complete application\n\nHere's the complete code for a simple application that combines all the steps:\n\n```python\nimport os\nimport uuid\nfrom google.cloud import discoveryengine_v1 as discoveryengine\nfrom google.cloud import aiplatform\nfrom google.cloud.aiplatform import vertexai\nfrom google.api_core.client_options import ClientOptions\n\n# Set your project ID and location\nproject_id = \"YOUR_PROJECT_ID\"  # Replace with your project ID\nlocation = \"global\"\n\n# Initialize Vertex AI\nvertexai.init(project=project_id, location=location)\n\ndef setup_data_store(project_id, location, data_store_id=\"my_sample_data_store_id\"):\n    \"\"\"\n    Create a data store and add sample documents.\n    \"\"\"\n    # Initialize the Discovery Engine client\n    client_options = ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n    client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n    \n    # Create a data store\n    parent = f\"projects/{project_id}/locations/{location}\"\n    data_store = discoveryengine.DataStore(\n        display_name=\"my_sample_data_store\",\n        industry_vertical=discoveryengine.IndustryVertical.GENERIC,\n        solution_types=[discoveryengine.SolutionType.SOLUTION_TYPE_SEARCH],\n        content_config=discoveryengine.DataStore.ContentConfig.CONTENT_REQUIRED,\n    )\n    \n    try:\n        operation = client.create_data_store(\n            parent=parent,\n            data_store_id=data_store_id,\n            data_store=data_store\n        )\n        \n        created_data_store = operation.result()\n        print(f\"Created data store: {created_data_store.name}\")\n        \n        # Add sample documents\n        add_sample_documents(project_id, location, data_store_id)\n        \n        return data_store_id\n    except Exception as e:\n        print(f\"Error creating data store: {e}\")\n        # The data store might already exist\n        return data_store_id\n\ndef add_sample_documents(project_id, location, data_store_id):\n    \"\"\"\n    Add sample documents to the data store.\n    \"\"\"\n    # Initialize the Document Service client\n    client_options = ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n    document_client = discoveryengine.DocumentServiceClient(client_options=client_options)\n    \n    # The data store name\n    data_store_name = f\"projects/{project_id}/locations/{location}/dataStores/{data_store_id}\"\n    \n    # Sample documents - replace with your own data\n    sample_documents = [\n        {\n            \"title\": \"Introduction to Machine Learning\",\n            \"content\": \"Machine learning is a field of study that gives computers the ability to learn without being explicitly programmed. It focuses on developing computer programs that can access data and use it to learn for themselves. The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\"\n        },\n        {\n            \"title\": \"Cloud Computing Basics\",\n            \"content\": \"Cloud computing is the delivery of computing services over the internet, providing flexible resources and economies of scale. These services include servers, storage, databases, networking, software, analytics, and intelligence. Cloud computing eliminates the capital expense of buying hardware and software and setting up and running on-site datacenters. It offers many benefits like cost savings, speed, global scale, productivity, performance, reliability, and security.\"\n        },\n        {\n            \"title\": \"Artificial Intelligence Overview\",\n            \"content\": \"Artificial intelligence (AI) involves machines that can perform tasks that typically require human intelligence. These include learning, reasoning, problem-solving, perception, and language understanding. AI can be categorized as either weak or strong. Weak AI, also known as narrow AI, is designed and trained for a particular task. Virtual personal assistants, such as Apple's Siri, are a form of weak AI. Strong AI, also known as artificial general intelligence, is AI that more fully replicates the autonomy of the human brain—AI that can solve many types of problems on its own and tasks that are broadly defined.\"\n        }\n    ]\n    \n    # Upload each document\n    for doc in sample_documents:\n        document_id = str(uuid.uuid4())\n        \n        document = discoveryengine.Document(\n            id=document_id,\n            name=f\"{data_store_name}/documents/{document_id}\",\n            struct_data={\n                \"title\": doc[\"title\"],\n                \"content\": doc[\"content\"]\n            }\n        )\n        \n        request = discoveryengine.CreateDocumentRequest(\n            parent=data_store_name,\n            document=document,\n            document_id=document_id\n        )\n        \n        try:\n            response = document_client.create_document(request=request)\n            print(f\"Created document: {response.name}\")\n        except Exception as e:\n            print(f\"Error creating document: {e}\")\n\ndef create_agent(project_id, location, data_store_id, agent_name=\"My Data Agent\"):\n    \"\"\"\n    Create a Vertex AI Agent with the data store.\n    \"\"\"\n    try:\n        # Create a data source\n        data_source = {\n            \"engine_data_source\": {\n                \"data_store_ids\": [data_store_id]\n            }\n        }\n        \n        # Create an agent\n        agent = aiplatform.Agent.create(\n            display_name=agent_name,\n            description=\"An agent that can answer questions about my data\",\n            data_sources=[data_source]\n        )\n        \n        print(f\"Created agent: {agent.name}\")\n        return agent\n    except Exception as e:\n        print(f\"Error creating agent: {e}\")\n        # Try to get the existing agent\n        agents = aiplatform.Agent.list(filter=f\"display_name={agent_name}\")\n        if agents:\n            print(f\"Using existing agent: {agents[0].name}\")\n            return agents[0]\n        raise e\n\ndef chat_with_agent(agent):\n    \"\"\"\n    Have a conversation with a Vertex AI Agent.\n    \"\"\"\n    conversation_history = []\n    \n    print(\"Start chatting with your data! Type 'exit' to quit.\")\n    \n    while True:\n        # Get user input\n        user_input = input(\"You: \")\n        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n            print(\"Agent: Goodbye!\")\n            break\n        \n        # Add user message to history\n        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n        \n        try:\n            # Get response from agent\n            response = agent.query(\n                content=user_input,\n                history=conversation_history[:-1]  # Exclude the current message\n            )\n            \n            # Display agent response\n            print(f\"Agent: {response.text}\")\n            \n            # Add agent response to history\n            conversation_history.append({\"role\": \"agent\", \"content\": response.text})\n        except Exception as e:\n            print(f\"Error: {e}\")\n            print(\"Agent: I'm having trouble responding. Please try again.\")\n    \n    return conversation_history\n\ndef main():\n    \"\"\"\n    Main function to run the application.\n    \"\"\"\n    data_store_id = setup_data_store(project_id, location)\n    \n    # Allow time for documents to be indexed\n    print(\"Waiting for documents to be indexed...\")\n    import time\n    time.sleep(60)  # Wait 60 seconds\n    \n    agent = create_agent(project_id, location, data_store_id)\n    \n    # Start a conversation with the agent\n    chat_with_agent(agent)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Clean up\n\nTo avoid incurring charges, clean up your resources when you're done:\n\n```python\n# Clean up resources\ndef clean_up(project_id, location, data_store_id, agent_name=\"My Data Agent\"):\n    \"\"\"\n    Clean up created resources.\n    \"\"\"\n    # Delete the agent\n    try:\n        agents = aiplatform.Agent.list(filter=f\"display_name={agent_name}\")\n        for agent in agents:\n            agent.delete()\n            print(f\"Deleted agent: {agent.name}\")\n    except Exception as e:\n        print(f\"Error deleting agent: {e}\")\n    \n    # Delete the data store\n    try:\n        client_options = ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n        client = discoveryengine.DataStoreServiceClient(client_options=client_options)\n        \n        data_store_name = f\"projects/{project_id}/locations/{location}/dataStores/{data_store_id}\"\n        operation = client.delete_data_store(name=data_store_name)\n        operation.result()\n        print(f\"Deleted data store: {data_store_name}\")\n    except Exception as e:\n        print(f\"Error deleting data store: {e}\")\n\n# Call the clean-up function when you're done\nclean_up(project_id, location, \"my_sample_data_store_id\")\n```\n\n## Conclusion\n\nCongratulations! You've created a Python application that allows you to chat with your data using Vertex AI. You've learned how to:\n\n1. Create a Vertex AI Search data store\n2. Ingest documents into your data store\n3. Create a simple search interface\n4. Create a Vertex AI Agent with your data\n5. Build a conversation loop with your agent\n\nThis foundation can be extended in many ways:\n- Add more sophisticated data sources (PDFs, websites, databases)\n- Improve the user interface (web interface, voice input/output)\n- Customize the agent's behavior and personality\n- Integrate with other systems and APIs\n\n## What's next?\n\n- Learn about [Vertex AI Agents](https://cloud.google.com/vertex-ai/docs/agents/overview)\n- Explore [Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction)\n- Try [Gemini API](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview) for more advanced AI capabilities\n\u0005End File\u0006# google/generative-ai-docs\n# Fine-Tune PaLM for Classification\n\n<div align=\"center\">\n    <a href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/finetuning_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n</div>\n\nIn this notebook, you'll fine-tune the PaLM model for a specific task, using a technique called instruction fine-tuning. Instruction fine-tuning involves providing a model with specific instructions and examples to help it learn how to perform a particular task.\n\nYou'll be fine-tuning the model to perform intent classification for customer service queries.\n\n## Setup\n\nStart by installing the necessary dependencies and setting up the environment.\n\nIf using Google Colab, set the runtime to GPU. It will be faster!\n\n\n```python\n# Install dependencies\n!pip install -U google-cloud-aiplatform tqdm\n```\n\n### Authenticate to Vertex AI\n\nYou need to authenticate to use Vertex AI.\n\nIf you're running this notebook locally, the easiest way is to use your user credentials:\n\n\n```python\n# Authentication for Google Cloud\nfrom google.colab import auth\nauth.authenticate_user()\n```\n\n### Configure Vertex AI\n\nLet's initialize the Vertex AI SDK:\n\n\n```python\nimport vertexai\nfrom vertexai.preview.language_models import TextGenerationModel, ChatModel\n\n# Initialize Vertex AI\nPROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\nLOCATION = \"us-central1\"  # @param {type:\"string\"}\nvertexai.init(project=PROJECT_ID, location=LOCATION)\n```\n\n### Prepare training data\n\nIn this example, we'll create a dataset of customer service queries with their respective intents. Each example consists of a query and its corresponding intent label.\n\n\n```python\n# Define your intent classes\nintent_classes = [\n    \"account_access\",\n    \"bill_payment\",\n    \"subscription_issues\",\n    \"technical_support\",\n    \"product_information\",\n    \"refund_request\",\n    \"cancellation\",\n    \"delivery_status\",\n    \"complaint\",\n    \"general_inquiry\"\n]\n\n# Create a training dataset\ntrain_examples = [\n    # account_access\n    {\"query\": \"I can't log into my account\", \"intent\": \"account_access\"},\n    {\"query\": \"Forgot my password and can't reset it\", \"intent\": \"account_access\"},\n    {\"query\": \"How do I change my email on my account?\", \"intent\": \"account_access\"},\n    {\"query\": \"My account seems to be locked\", \"intent\": \"account_access\"},\n    {\"query\": \"I need to update my profile information\", \"intent\": \"account_access\"},\n    {\"query\": \"Can't access my account on the mobile app\", \"intent\": \"account_access\"},\n    {\"query\": \"How do I enable two-factor authentication?\", \"intent\": \"account_access\"},\n    {\"query\": \"I think someone hacked my account\", \"intent\": \"account_access\"},\n    {\"query\": \"Need to merge two accounts\", \"intent\": \"account_access\"},\n    {\"query\": \"How to add a user to my account\", \"intent\": \"account_access\"},\n    \n    # bill_payment\n    {\"query\": \"I want to pay my bill\", \"intent\": \"bill_payment\"},\n    {\"query\": \"Can I get an extension on my bill due date?\", \"intent\": \"bill_payment\"},\n    {\"query\": \"My payment didn't go through\", \"intent\": \"bill_payment\"},\n    {\"query\": \"I was charged twice for my last bill\", \"intent\": \"bill_payment\"},\n    {\"query\": \"How do I set up automatic payments?\", \"intent\": \"bill_payment\"},\n    {\"query\": \"Can I pay using a different credit card?\", \"intent\": \"bill_payment\"},\n    {\"query\": \"I need a copy of my last bill\", \"intent\": \"bill_payment\"},\n    {\"query\": \"My bill seems higher than usual\", \"intent\": \"bill_payment\"},\n    {\"query\": \"Do you accept PayPal for bill payments?\", \"intent\": \"bill_payment\"},\n    {\"query\": \"How to change my billing address\", \"intent\": \"bill_payment\"},\n    \n    # subscription_issues\n    {\"query\": \"I want to upgrade my subscription plan\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"How do I downgrade to a cheaper plan?\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"My subscription renewed but I wanted to cancel\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"When does my subscription expire?\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"Can I pause my subscription while I'm on vacation?\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"I didn't receive the premium features I paid for\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"How to add more users to my subscription\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"Is there a discount for annual subscription?\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"Can I switch to a different subscription plan?\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"I need to change the payment method for my subscription\", \"intent\": \"subscription_issues\"},\n    \n    # technical_support\n    {\"query\": \"My app keeps crashing\", \"intent\": \"technical_support\"},\n    {\"query\": \"Videos won't play on your website\", \"intent\": \"technical_support\"},\n    {\"query\": \"Getting an error code when trying to checkout\", \"intent\": \"technical_support\"},\n    {\"query\": \"The website is extremely slow\", \"intent\": \"technical_support\"},\n    {\"query\": \"Can't sync my data between devices\", \"intent\": \"technical_support\"},\n    {\"query\": \"Your software doesn't work with my operating system\", \"intent\": \"technical_support\"},\n    {\"query\": \"I keep getting logged out automatically\", \"intent\": \"technical_support\"},\n    {\"query\": \"The search function on your site isn't working\", \"intent\": \"technical_support\"},\n    {\"query\": \"My dashboard shows incorrect information\", \"intent\": \"technical_support\"},\n    {\"query\": \"Having trouble connecting to the server\", \"intent\": \"technical_support\"},\n    \n    # product_information\n    {\"query\": \"What are the dimensions of this product?\", \"intent\": \"product_information\"},\n    {\"query\": \"Does this come in different colors?\", \"intent\": \"product_information\"},\n    {\"query\": \"Is this product compatible with Mac?\", \"intent\": \"product_information\"},\n    {\"query\": \"When will this item be back in stock?\", \"intent\": \"product_information\"},\n    {\"query\": \"What's the difference between basic and premium versions?\", \"intent\": \"product_information\"},\n    {\"query\": \"Does this product come with a warranty?\", \"intent\": \"product_information\"},\n    {\"query\": \"Are there any discounts for bulk orders?\", \"intent\": \"product_information\"},\n    {\"query\": \"What materials is this made from?\", \"intent\": \"product_information\"},\n    {\"query\": \"Can I get the product specifications?\", \"intent\": \"product_information\"},\n    {\"query\": \"Is this suitable for children?\", \"intent\": \"product_information\"},\n    \n    # refund_request\n    {\"query\": \"I want a refund for my purchase\", \"intent\": \"refund_request\"},\n    {\"query\": \"How long does it take to process a refund?\", \"intent\": \"refund_request\"},\n    {\"query\": \"Can I get a refund after 30 days?\", \"intent\": \"refund_request\"},\n    {\"query\": \"The product was defective, I need a refund\", \"intent\": \"refund_request\"},\n    {\"query\": \"Do you refund shipping costs too?\", \"intent\": \"refund_request\"},\n    {\"query\": \"I returned the item but haven't received my refund\", \"intent\": \"refund_request\"},\n    {\"query\": \"Can I get a refund to a different payment method?\", \"intent\": \"refund_request\"},\n    {\"query\": \"What's your refund policy?\", \"intent\": \"refund_request\"},\n    {\"query\": \"Refund for unused subscription time\", \"intent\": \"refund_request\"},\n    {\"query\": \"Partial refund for damaged goods\", \"intent\": \"refund_request\"},\n    \n    # cancellation\n    {\"query\": \"I need to cancel my order\", \"intent\": \"cancellation\"},\n    {\"query\": \"How do I cancel my subscription?\", \"intent\": \"cancellation\"},\n    {\"query\": \"Can I cancel a service appointment?\", \"intent\": \"cancellation\"},\n    {\"query\": \"What's the cancellation fee?\", \"intent\": \"cancellation\"},\n    {\"query\": \"Is it too late to cancel my order?\", \"intent\": \"cancellation\"},\n    {\"query\": \"Need to cancel and place a new order\", \"intent\": \"cancellation\"},\n    {\"query\": \"Cancel my account completely\", \"intent\": \"cancellation\"},\n    {\"query\": \"How to cancel auto-renewal\", \"intent\": \"cancellation\"},\n    {\"query\": \"Will I get charged if I cancel now?\", \"intent\": \"cancellation\"},\n    {\"query\": \"Can I cancel just one item from my order?\", \"intent\": \"cancellation\"},\n    \n    # delivery_status\n    {\"query\": \"Where is my order?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"My package is late\", \"intent\": \"delivery_status\"},\n    {\"query\": \"Expected delivery date for my order\", \"intent\": \"delivery_status\"},\n    {\"query\": \"Can I change my delivery address?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"The tracking number doesn't work\", \"intent\": \"delivery_status\"},\n    {\"query\": \"My order shows delivered but I didn't receive it\", \"intent\": \"delivery_status\"},\n    {\"query\": \"How long does shipping usually take?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"Do you deliver on weekends?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"Can I upgrade to express shipping?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"Is my order delayed?\", \"intent\": \"delivery_status\"},\n    \n    # complaint\n    {\"query\": \"I'm very disappointed with your service\", \"intent\": \"complaint\"},\n    {\"query\": \"The quality of your product is terrible\", \"intent\": \"complaint\"},\n    {\"query\": \"Your customer support has been unhelpful\", \"intent\": \"complaint\"},\n    {\"query\": \"I've been waiting on hold for an hour\", \"intent\": \"complaint\"},\n    {\"query\": \"This is the third time I've had this issue\", \"intent\": \"complaint\"},\n    {\"query\": \"I want to speak to a manager\", \"intent\": \"complaint\"},\n    {\"query\": \"Your website made false claims about the product\", \"intent\": \"complaint\"},\n    {\"query\": \"The staff at your store was rude to me\", \"intent\": \"complaint\"},\n    {\"query\": \"I've been a loyal customer and this is how you treat me?\", \"intent\": \"complaint\"},\n    {\"query\": \"This is unacceptable and I'm considering legal action\", \"intent\": \"complaint\"},\n    \n    # general_inquiry\n    {\"query\": \"What are your business hours?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"Do you have a store in Chicago?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"How can I contact your press office?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"Are you hiring right now?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"What's your return policy?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"Do you ship internationally?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"Where is your company headquartered?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"How do I unsubscribe from your emails?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"Do you offer military discounts?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"Can I download a catalog?\", \"intent\": \"general_inquiry\"}\n]\n\n# Create validation dataset (smaller set for validation)\nvalidation_examples = [\n    {\"query\": \"Cannot access my profile\", \"intent\": \"account_access\"},\n    {\"query\": \"Need to update my password\", \"intent\": \"account_access\"},\n    \n    {\"query\": \"I want to pay my monthly bill\", \"intent\": \"bill_payment\"},\n    {\"query\": \"When is my payment due?\", \"intent\": \"bill_payment\"},\n    \n    {\"query\": \"How do I change my subscription?\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"Need to add features to my current plan\", \"intent\": \"subscription_issues\"},\n    \n    {\"query\": \"My device isn't connecting properly\", \"intent\": \"technical_support\"},\n    {\"query\": \"Getting error message during installation\", \"intent\": \"technical_support\"},\n    \n    {\"query\": \"What are the features of your premium plan?\", \"intent\": \"product_information\"},\n    {\"query\": \"Do you offer a trial version?\", \"intent\": \"product_information\"},\n    \n    {\"query\": \"I need my money back\", \"intent\": \"refund_request\"},\n    {\"query\": \"Refund for faulty product\", \"intent\": \"refund_request\"},\n    \n    {\"query\": \"Need to cancel my reservation\", \"intent\": \"cancellation\"},\n    {\"query\": \"How do I stop my subscription?\", \"intent\": \"cancellation\"},\n    \n    {\"query\": \"Is my package delayed?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"When will my order arrive?\", \"intent\": \"delivery_status\"},\n    \n    {\"query\": \"Your service is terrible\", \"intent\": \"complaint\"},\n    {\"query\": \"I'm not satisfied with how my case was handled\", \"intent\": \"complaint\"},\n    \n    {\"query\": \"What payment methods do you accept?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"How can I become a distributor?\", \"intent\": \"general_inquiry\"}\n]\n```\n\n### Format examples for fine-tuning\n\nNow you need to format the data in a way that the model can understand. For text classification, you'll create examples that ask the model to classify a query and output the intent label.\n\n\n```python\n# Format examples for fine-tuning\ndef format_classification_example(example):\n    return {\n        \"input_text\": f\"Classify the following customer service query into one of these intent categories: {', '.join(intent_classes)}.\\n\\nQuery: {example['query']}\\n\\nIntent:\",\n        \"output_text\": example[\"intent\"]\n    }\n\n# Format training and validation data\nformatted_train_examples = [format_classification_example(ex) for ex in train_examples]\nformatted_validation_examples = [format_classification_example(ex) for ex in validation_examples]\n\n# Print a few examples to verify\nfor i in range(3):\n    print(f\"Example {i+1}:\")\n    print(f\"Input: {formatted_train_examples[i]['input_text']}\")\n    print(f\"Output: {formatted_train_examples[i]['output_text']}\")\n    print()\n```\n\n### Initialize the base model\n\nNow, you'll load the base model that you'll fine-tune:\n\n\n```python\n# Initialize the model\nbase_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n```\n\n### Fine-tune the model\n\nNow, let's fine-tune the model using our formatted training data:\n\n\n```python\n# Convert examples to the expected format\ntrain_examples_for_tuning = [\n    {\"input_text\": ex[\"input_text\"], \"output_text\": ex[\"output_text\"]}\n    for ex in formatted_train_examples\n]\n\nvalidation_examples_for_tuning = [\n    {\"input_text\": ex[\"input_text\"], \"output_text\": ex[\"output_text\"]}\n    for ex in formatted_validation_examples\n]\n\n# Set a unique model name\nimport uuid\nimport time\n\ntimestamp = int(time.time())\ntuned_model_name = f\"intent-classifier-{timestamp}\"\n\n# Start the fine-tuning process\ntuning_job = base_model.tune_model(\n    training_data=train_examples_for_tuning,\n    validation_data=validation_examples_for_tuning,\n    tuned_model_name=tuned_model_name,\n    hyperparameters={\n        \"batch_size\": 8,\n        \"learning_rate\": 0.001,\n        \"epochs\": 5\n    }\n)\n\nprint(f\"Tuning job launched with name: {tuned_model_name}\")\n```\n\nThis process may take some time. You can check on the status by visiting the Google Cloud Console.\n\n### Load the fine-tuned model\n\nOnce the fine-tuning is complete, you can load and use the fine-tuned model:\n\n\n```python\n# Wait for the tuning job to complete\ntuning_job.wait()\n\n# Load the fine-tuned model\ntuned_model = TextGenerationModel.get_tuned_model(tuned_model_name)\nprint(f\"Loaded fine-tuned model: {tuned_model_name}\")\n```\n\n### Test the fine-tuned model\n\nNow, let's test the fine-tuned model with some new examples:\n\n\n```python\n# Define some test examples\ntest_queries = [\n    \"I forgot my login information\",\n    \"My credit card was charged twice\",\n    \"I'd like to upgrade from basic to premium\",\n    \"The app crashes every time I open it\",\n    \"When will the new model be available?\",\n    \"I want my money back for this broken product\",\n    \"Please cancel my monthly subscription\",\n    \"Has my package been shipped yet?\",\n    \"The customer service agent was very rude\",\n    \"What are your holiday business hours?\"\n]\n\n# Function to classify intents\ndef classify_intent(query):\n    prompt = f\"Classify the following customer service query into one of these intent categories: {', '.join(intent_classes)}.\\n\\nQuery: {query}\\n\\nIntent:\"\n    \n    response = tuned_model.predict(\n        prompt,\n        temperature=0.1,\n        max_output_tokens=10,\n    )\n    \n    return response.text.strip()\n\n# Test the model\nfor query in test_queries:\n    intent = classify_intent(query)\n    print(f\"Query: {query}\")\n    print(f\"Predicted Intent: {intent}\")\n    print(\"-\" * 50)\n```\n\n### Compare with base model\n\nLet's compare the fine-tuned model with the base model to see the improvement:\n\n\n```python\n# Function to classify intents with the base model\ndef classify_intent_base(query):\n    prompt = f\"Classify the following customer service query into one of these intent categories: {', '.join(intent_classes)}.\\n\\nQuery: {query}\\n\\nIntent:\"\n    \n    response = base_model.predict(\n        prompt,\n        temperature=0.1,\n        max_output_tokens=10,\n    )\n    \n    return response.text.strip()\n\n# Test with both models\nprint(\"=\" * 80)\nprint(\"COMPARISON: BASE MODEL VS. FINE-TUNED MODEL\")\nprint(\"=\" * 80)\n\nfor query in test_queries:\n    base_intent = classify_intent_base(query)\n    tuned_intent = classify_intent(query)\n    \n    print(f\"Query: {query}\")\n    print(f\"Base Model Prediction: {base_intent}\")\n    print(f\"Fine-tuned Model Prediction: {tuned_intent}\")\n    print(\"-\" * 50)\n```\n\n## Evaluate the model\n\nNow, let's perform a more systematic evaluation of our fine-tuned model:\n\n\n```python\nfrom tqdm import tqdm\nimport numpy as np\n\n# Create a comprehensive test set\ntest_examples = [\n    {\"query\": \"I can't sign in to my account\", \"intent\": \"account_access\"},\n    {\"query\": \"Need to reset my password urgently\", \"intent\": \"account_access\"},\n    {\"query\": \"How do I update my profile picture?\", \"intent\": \"account_access\"},\n    \n    {\"query\": \"I want to pay my bill online\", \"intent\": \"bill_payment\"},\n    {\"query\": \"Can I get an extension on my payment?\", \"intent\": \"bill_payment\"},\n    {\"query\": \"My payment didn't process correctly\", \"intent\": \"bill_payment\"},\n    \n    {\"query\": \"How do I upgrade my current plan?\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"I need to change my subscription details\", \"intent\": \"subscription_issues\"},\n    {\"query\": \"When does my subscription renew?\", \"intent\": \"subscription_issues\"},\n    \n    {\"query\": \"The website is loading very slowly\", \"intent\": \"technical_support\"},\n    {\"query\": \"I'm getting an error code: XYZ123\", \"intent\": \"technical_support\"},\n    {\"query\": \"My app keeps freezing when I try to upload\", \"intent\": \"technical_support\"},\n    \n    {\"query\": \"What's the difference between model X and Y?\", \"intent\": \"product_information\"},\n    {\"query\": \"Is this product waterproof?\", \"intent\": \"product_information\"},\n    {\"query\": \"When will you restock this item?\", \"intent\": \"product_information\"},\n    \n    {\"query\": \"I want a refund for my purchase yesterday\", \"intent\": \"refund_request\"},\n    {\"query\": \"How long until I get my money back?\", \"intent\": \"refund_request\"},\n    {\"query\": \"Can I get a refund for digital content?\", \"intent\": \"refund_request\"},\n    \n    {\"query\": \"I need to cancel my booking\", \"intent\": \"cancellation\"},\n    {\"query\": \"How do I terminate my contract?\", \"intent\": \"cancellation\"},\n    {\"query\": \"Can I cancel without a fee?\", \"intent\": \"cancellation\"},\n    \n    {\"query\": \"Where is my package right now?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"My delivery is late, what's happening?\", \"intent\": \"delivery_status\"},\n    {\"query\": \"Can I change the delivery address?\", \"intent\": \"delivery_status\"},\n    \n    {\"query\": \"Your service is absolutely terrible\", \"intent\": \"complaint\"},\n    {\"query\": \"I've been on hold for 45 minutes!\", \"intent\": \"complaint\"},\n    {\"query\": \"This is the third time I've had this issue\", \"intent\": \"complaint\"},\n    \n    {\"query\": \"What are your store hours?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"Do you ship to Canada?\", \"intent\": \"general_inquiry\"},\n    {\"query\": \"How can I apply for a job?\", \"intent\": \"general_inquiry\"}\n]\n\n# Evaluate the models\ndef evaluate_model(model_fn, examples):\n    correct = 0\n    predictions = []\n    \n    for example in tqdm(examples):\n        prediction = model_fn(example[\"query\"])\n        predictions.append(prediction)\n        if prediction.lower() == example[\"intent\"].lower():\n            correct += 1\n    \n    accuracy = correct / len(examples)\n    return accuracy, predictions\n\n# Evaluate both models\nprint(\"Evaluating base model...\")\nbase_accuracy, base_predictions = evaluate_model(classify_intent_base, test_examples)\n\nprint(\"Evaluating fine-tuned model...\")\ntuned_accuracy, tuned_predictions = evaluate_model(classify_intent, test_examples)\n\n# Print results\nprint(\"\\nEvaluation Results:\")\nprint(f\"Base Model Accuracy: {base_accuracy:.2%}\")\nprint(f\"Fine-tuned Model Accuracy: {tuned_accuracy:.2%}\")\nprint(f\"Improvement: {(tuned_accuracy - base_accuracy):.2%}\")\n\n# Print detailed results\nprint(\"\\nDetailed Results:\")\nprint(\"-\" * 80)\nprint(f\"{'Query':<40} | {'True Intent':<20} | {'Base Prediction':<20} | {'Tuned Prediction':<20}\")\nprint(\"-\" * 80)\n\nfor i, example in enumerate(test_examples):\n    query = example[\"query\"]\n    true_intent = example[\"intent\"]\n    base_pred = base_predictions[i]\n    tuned_pred = tuned_predictions[i]\n    \n    # Truncate long queries\n    if len(query) > 37:\n        query = query[:37] + \"...\"\n    \n    print(f\"{query:<40} | {true_intent:<20} | {base_pred:<20} | {tuned_pred:<20}\")\n```\n\n### Confusion Matrix\n\nLet's create a confusion matrix to see where the model is making errors:\n\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create confusion matrix\ndef plot_confusion_matrix(true_intents, pred_intents, model_name):\n    # Create a DataFrame for the confusion matrix\n    data = {'True': true_intents, 'Predicted': pred_intents}\n    df = pd.DataFrame(data)\n    \n    # Create confusion matrix\n    confusion = pd.crosstab(df['True'], df['Predicted'], rownames=['True'], colnames=['Predicted'])\n    \n    # Plot\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(confusion, annot=True, fmt='d', cmap=\"Blues\")\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.tight_layout()\n    plt.show()\n\n# Get true intents\ntrue_intents = [example[\"intent\"] for example in test_examples]\n\n# Plot confusion matrices\nplot_confusion_matrix(true_intents, base_predictions, \"Base Model\")\nplot_confusion_matrix(true_intents, tuned_predictions, \"Fine-tuned Model\")\n```\n\n## Try more complex examples\n\nLet's test the model with more complex and ambiguous queries:\n\n\n```python\ncomplex_queries = [\n    \"I'm having trouble logging in, and I also want to know about your premium plan\",\n    \"My subscription payment failed and now I can't access my account\",\n    \"I'm upset because my delivery is late and customer service isn't helping\",\n    \"Can I get a refund for my cancelled subscription?\",\n    \"The product arrived damaged and I need technical help setting it up\",\n    \"I want to know if you have this product in blue and when it would arrive if I order today\",\n    \"Your app isn't working properly and I've been charged twice this month\",\n    \"I need to speak to someone about my account and billing information\",\n    \"The quality of your service has declined, I might cancel my subscription\",\n    \"How do I change my password and update my payment method?\"\n]\n\n# Test with the fine-tuned model\nprint(\"Complex Query Classification:\")\nprint(\"-\" * 80)\n\nfor query in complex_queries:\n    intent = classify_intent(query)\n    print(f\"Query: {query}\")\n    print(f\"Predicted Intent: {intent}\")\n    print(\"-\" * 50)\n```\n\n## Explore Edge Cases\n\nLet's test some edge cases to see how the model handles them:\n\n\n```python\nedge_cases = [\n    # Very short queries\n    \"Help\",\n    \"Login?\",\n    \"Bill\",\n    \n    # Queries with typos\n    \"Cant login to my acount\",\n    \"Need refund fr broken poduct\",\n    \"Wen will my packge arrive\",\n    \n    # Mixed intents\n    \"I can't log in and I need a refund\",\n    \"My subscription needs updating and my bill is wrong\",\n    \n    # Out-of-scope queries\n    \"What's the weather like today?\",\n    \"Recipe for chocolate cake\",\n    \"Can you translate this to Spanish?\",\n    \n    # Queries with unusual formatting\n    \"URGENT!!! NEED ACCOUNT ACCESS NOW!!!\",\n    \"can you please please help with my technical issue :(\",\n    \"r e f u n d  r e q u e s t\"\n]\n\n# Test with the fine-tuned model\nprint(\"Edge Case Classification:\")\nprint(\"-\" * 80)\n\nfor query in edge_cases:\n    intent = classify_intent(query)\n    print(f\"Query: {query}\")\n    print(f\"Predicted Intent: {intent}\")\n    print(\"-\" * 50)\n```\n\n## Clean Up (Optional)\n\nIf you want to clean up the resources to avoid additional charges, you can delete the fine-tuned model:\n\n\n```python\n# Delete the fine-tuned model (uncomment if needed)\n# tuned_model.delete()\n# print(f\"Deleted fine-tuned model: {tuned_model_name}\")\n```\n\n## Conclusion\n\nIn this notebook, you've learned how to:\n\n1. Prepare a dataset for intent classification\n2. Format the data for instruction fine-tuning\n3. Fine-tune the PaLM model for a specific classification task\n4. Evaluate the performance of your fine-tuned model\n5. Test the model with various queries, including complex cases and edge cases\n\nThe fine-tuned model generally performs better than the base model on this specific task because it has been adapted to recognize the patterns and language specific to customer service queries and their corresponding intents.\n\nYou can apply this same approach to other classification tasks by creating appropriate training data and fine-tuning the model accordingly.\n\nRemember that the quality and diversity of your training data significantly impact the performance of your fine-tuned model. For production use, you would typically want more examples and more rigorous testing.\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/samples/image-text-samples/classify-visual-content.md\n# Classify visual content\n\nThese examples demonstrate how to use Gemini to classify and analyze images, showing its ability to categorize content, detect objects and features, and explain visual information.\n\n## Categorize image content\n\nThis example categorizes an image into specific categories.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Categorize this image content. Select the most appropriate category from: Nature, Urban, Food, Technology, Art, Animals, Sports, or Other.\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/flowers.jpeg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.4,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Detect objects and features\n\nThis example asks the model to identify and list specific objects, features, or elements within an image.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"List all the objects and elements you can identify in this image. Group them by category (e.g., people, animals, objects, structures, natural elements).\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/city-street.png\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Identify artistic style\n\nThis example asks the model to analyze the artistic style of an image.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Analyze this artwork and identify its artistic style. Explain the key visual elements that characterize this style. What time period is it from? Who are notable artists of this style?\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/starry_night.jpeg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Analyze scene and setting\n\nThis example asks the model to analyze and describe the scene, setting, and atmosphere of an image.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Analyze this scene. What type of location is this? Describe the setting, atmosphere, and any notable features. What mood does this scene convey?\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/beach.jpeg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Classify food dishes\n\nThis example asks the model to identify and classify food dishes in an image.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Identify the food dishes in this image. What cuisine are they from? List the likely main ingredients in each dish.\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/sushi.jpg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Identify landmarks\n\nThis example asks the model to identify landmarks and provide information about them.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Identify the landmark in this image. Where is it located? Provide some key historical facts and architectural details about it.\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/taj_mahal.jpeg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Classify animal species\n\nThis example asks the model to identify and classify animal species.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Identify the animal species in this image. Provide its scientific classification (genus and species if possible), natural habitat, and some interesting facts about this animal.\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/panda.jpeg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Analyze emotions and expressions\n\nThis example asks the model to analyze the emotions and expressions displayed in an image.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash-001:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Analyze the emotions and expressions displayed in this image. What mood or feeling is being conveyed? What visual cues support your analysis?\"\n          },\n          {\n            \"fileData\": {\n              \"mimeType\": \"image/jpeg\",\n              \"fileUri\": \"gs://cloud-samples-data/generative-ai/image/happy_family.jpg\"\n            }\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/models/count-tokens.md\n# Count tokens\n\nThis guide shows you how to count tokens in your Gemini API requests.\n\n## Understand tokens\n\nTokens are the basic processing units for AI models. They can be as short as one character or as long as one word (for example, \"a\" or \"apple\"). \n\nText tokens are calculated based on the number of characters and the complexity of the text. For example, tokenizing the string \"tokenization\" would typically result in the tokens: \"token\" and \"ization\".\n\n## Why count tokens?\n\nCounting tokens helps you:\n\n* Stay within model token limits\n* Estimate API costs\n* Optimize performance\n\n## Token counting methods\n\nThere are several ways to count tokens in the Gemini API:\n\n1. Using the SDK (recommended)\n2. Using the REST API\n3. Using the token counting demo tool\n\n### Method 1: Count tokens with the SDK\n\nThe Python SDK provides the simplest way to count tokens.\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# Count tokens in a text string\ntext = \"Hello, world! This is a test.\"\ntoken_count = genai.count_tokens(model=\"gemini-1.5-flash\", contents=text)\nprint(f\"Token count: {token_count['token_count']}\")\n\n# Count tokens in a more complex message\nmessages = [\n    {\"role\": \"user\", \"parts\": [\"How does photosynthesis work?\"]},\n    {\"role\": \"model\", \"parts\": [\"Photosynthesis is the process where plants convert sunlight, water, and carbon dioxide into oxygen and glucose...\"]},\n    {\"role\": \"user\", \"parts\": [\"Can you explain it more simply?\"]}\n]\n\ntoken_count = genai.count_tokens(model=\"gemini-1.5-flash\", contents=messages)\nprint(f\"Token count: {token_count['token_count']}\")\n```\n\n### Method 2: Count tokens with the REST API\n\nYou can also count tokens using the REST API directly:\n\n```bash\ncurl -X POST \\\n  \"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:countTokens?key=YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a story about a magic backpack.\"\n          }\n        ]\n      }\n    ]\n  }'\n```\n\nResponse:\n```json\n{\n  \"totalTokens\": 9\n}\n```\n\n### Method 3: Use the token counting demo tool\n\nFor a quick token count without code, use the [Token Counter](/docs/gemini/token-counter).\n\n## Token limits\n\nDifferent Gemini models have different token limits. Here are the current limits:\n\n| Model | Input Token Limit | Output Token Limit | Total Context Window |\n|-------|-------------------|-------------------|----------------------|\n| Gemini 1.5 Flash | 1 million | 8,192 | 1 million |\n| Gemini 1.5 Pro | 1 million | 8,192 | 1 million |\n| Gemini 1.0 Pro | 32,768 | 8,192 | 32,768 |\n| Gemini 1.0 Pro Vision | 12,288 | 4,096 | 16,384 |\n| Gemini 1.0 Ultra | 32,768 | 8,192 | 32,768 |\n| Gemini 1.0 Ultra Vision | 12,288 | 4,096 | 16,384 |\n\n## Examples\n\n### Counting tokens for media content\n\nFor multimodal content, different media types consume different numbers of tokens:\n\n```python\nimport google.generativeai as genai\nimport PIL.Image\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# Count tokens for text and an image\nimage = PIL.Image.open(\"path/to/your/image.jpg\")\ntext = \"What's in this image?\"\n\nmessage = [\n    {\"role\": \"user\", \n     \"parts\": [\n         {\"text\": text},\n         {\"inline_data\": {\"mime_type\": \"image/jpeg\", \"data\": image}}\n     ]\n    }\n]\n\ntoken_count = genai.count_tokens(model=\"gemini-1.5-flash\", contents=message)\nprint(f\"Token count: {token_count['token_count']}\")\n```\n\n### Counting tokens for complex conversations\n\nFor multi-turn conversations:\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# A complex multi-turn conversation\nconversation = [\n    {\"role\": \"user\", \"parts\": [\"What is machine learning?\"]},\n    {\"role\": \"model\", \"parts\": [\"Machine learning is a branch of artificial intelligence that focuses on building systems that learn from data...\"]},\n    {\"role\": \"user\", \"parts\": [\"Can you give me some examples of machine learning applications?\"]},\n    {\"role\": \"model\", \"parts\": [\"Here are some common machine learning applications:\\n1. Image recognition\\n2. Natural language processing\\n3. Recommendation systems...\"]}\n]\n\ntoken_count = genai.count_tokens(model=\"gemini-1.5-flash\", contents=conversation)\nprint(f\"Total tokens in conversation: {token_count['token_count']}\")\n```\n\n## Best practices\n\nFollow these best practices for efficient token usage:\n\n1. **Count before sending**: Check token counts before sending requests to avoid errors.\n\n2. **Optimize prompts**: Keep prompts concise while providing necessary context.\n\n3. **Chunk large content**: For long documents, split them into manageable chunks.\n\n4. **Monitor context windows**: Be aware of your total context window usage in conversations.\n\n5. **Consider content format**: Different content formats (text, images, etc.) consume different token amounts.\n\n## Troubleshooting\n\n### Common issues\n\n1. **Exceeding token limits**\n   \n   Error: `400 Request payload size exceeds the limit`\n   \n   Solution: Reduce input size or use a model with a larger context window.\n\n2. **Unexpected token counts**\n   \n   Issue: Token counts differ from your expectation\n   \n   Solution: Remember that tokens aren't exactly words - they can be characters, word parts, or whole words depending on the language and specific text.\n\n3. **Model not found**\n   \n   Error: `Model not found`\n   \n   Solution: Verify you're using a valid model name and have proper permissions.\n\n## Additional resources\n\n- [Token Calculator Demo](/docs/gemini/token-counter)\n- [Model information](/docs/models/gemini)\n- [Gemini API documentation](/docs/gemini/docs)\n\u0005End File\u0006# site/en/gemini/docs/text_embedding.md\n# Text embeddings\n\nThis guide describes the process of generating text embeddings (dense vector representations) that capture semantic meaning from text.\n\n## Introduction to text embeddings\n\nText embeddings are numerical representations that capture semantic meaning from text. Each embedding is a vector of floating-point numbers, where texts with similar meanings are located close to each other in the embedding space. You can use text embeddings to perform various tasks like searching for semantically-similar text, clustering documents by semantic similarity, or classification. \n\n## Choose a model\n\nThe following table shows the available text embedding models and their specifications.\n\n<table>\n  <tr>\n   <td><strong>Model</strong>\n   </td>\n   <td><strong>Max tokens</strong>\n   </td>\n   <td><strong>Output dimensions</strong>\n   </td>\n   <td><strong>Description</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>text-embedding-004\n   </td>\n   <td>8,192\n   </td>\n   <td>768\n   </td>\n   <td>Our latest, most capable embedding model for English text.\n   </td>\n  </tr>\n  <tr>\n   <td>embedding-001\n   </td>\n   <td>2,048\n   </td>\n   <td>768\n   </td>\n   <td>General-purpose text embedding model.\n   </td>\n  </tr>\n  <tr>\n   <td>text-multilingual-embedding-002\n   </td>\n   <td>2,048\n   </td>\n   <td>768\n   </td>\n   <td>Supports embedding text in 100+ languages.\n   </td>\n  </tr>\n</table>\n\n### Query vs. document embeddings\n\nFor some models, you can specify the `task_type` to indicate how you intend to use the embedding, either a document embedding or a query embedding.\n\n<table>\n  <tr>\n   <td><strong>Task type</strong>\n   </td>\n   <td><strong>Description</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>RETRIEVAL_DOCUMENT\n   </td>\n   <td>Optimized for embedding documents for retrieval. For example, you could embed all documents in a dataset that you want to search.\n   </td>\n  </tr>\n  <tr>\n   <td>RETRIEVAL_QUERY\n   </td>\n   <td>Optimized for embedding queries that you want to use to search for documents. For example, if users enter a query term that you want to use to search for relevant documents.\n   </td>\n  </tr>\n  <tr>\n   <td>SEMANTIC_SIMILARITY\n   </td>\n   <td>Optimized for embedding texts that you want to measure semantic similarity between. Use this task type when you want to embed two texts and measure their similarity.\n   </td>\n  </tr>\n  <tr>\n   <td>CLASSIFICATION\n   </td>\n   <td>Optimized for embedding texts that you want to classify.\n   </td>\n  </tr>\n  <tr>\n   <td>CLUSTERING\n   </td>\n   <td>Optimized for embedding texts that you want to cluster.\n   </td>\n  </tr>\n</table>\n\n## Get text embeddings\n\n### Python\n\nUse the `embedContent` method to get embeddings for content. You can include the `task_type` parameter to specify the intended use of the embedding.\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\nresult = genai.embed_content(\n    model=\"models/embedding-001\",\n    content=\"Embed this sentence.\",\n    task_type=\"retrieval_document\")\n\nembedding = result['embedding']\nprint(f\"Length of embedding: {len(embedding)}\")\nprint(f\"First few dimensions: {embedding[:10]}\")\n```\n\n### REST\n\nTo get an embedding using the REST API, send a `POST` request to the `embedContent` endpoint.\n\n```curl\ncurl https://generativelanguage.googleapis.com/v1/models/embedding-001:embedContent \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"content\": {\n        \"parts\": [\n          {\"text\": \"What is the Gemini API?\"}\n        ]\n      },\n      \"taskType\": \"RETRIEVAL_QUERY\"\n    }' \\\n    -H \"Authorization: Bearer $(gcloud auth print-access-token)\"\n```\n\n## Use text embeddings\n\n### Find semantically similar text\n\nThe following example uses cosine similarity to find semantically similar text:\n\n```python\nimport numpy as np\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\ndef get_embedding(text, task_type=None):\n    return genai.embed_content(\n        model=\"models/embedding-001\",\n        content=text,\n        task_type=task_type)['embedding']\n\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# Example documents\ndocuments = [\n    \"The cat sat on the mat\",\n    \"Dogs are great pets\",\n    \"I love machine learning\",\n    \"Neural networks are powerful\",\n    \"The weather is nice today\"\n]\n\n# Get embeddings for all documents\ndocument_embeddings = [get_embedding(doc, \"retrieval_document\") for doc in documents]\n\n# Query\nquery = \"artificial intelligence and deep learning\"\nquery_embedding = get_embedding(query, \"retrieval_query\")\n\n# Calculate similarity scores\nsimilarities = [cosine_similarity(query_embedding, doc_emb) for doc_emb in document_embeddings]\n\n# Display results\nfor i, (doc, sim) in enumerate(zip(documents, similarities)):\n    print(f\"{i+1}. Document: {doc}\")\n    print(f\"   Similarity: {sim:.4f}\")\n```\n\n### Create a simple search system\n\nThis example demonstrates a simple search system using embeddings:\n\n```python\nimport numpy as np\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\nclass EmbeddingSearchSystem:\n    def __init__(self, model=\"models/embedding-001\"):\n        self.model = model\n        self.documents = []\n        self.embeddings = []\n    \n    def add_documents(self, documents):\n        self.documents.extend(documents)\n        for doc in documents:\n            embedding = genai.embed_content(\n                model=self.model,\n                content=doc,\n                task_type=\"retrieval_document\")['embedding']\n            self.embeddings.append(embedding)\n    \n    def search(self, query, top_k=3):\n        # Get embedding for the query\n        query_embedding = genai.embed_content(\n            model=self.model,\n            content=query,\n            task_type=\"retrieval_query\")['embedding']\n        \n        # Calculate similarity scores\n        similarities = [\n            np.dot(query_embedding, doc_emb) / \n            (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb)) \n            for doc_emb in self.embeddings\n        ]\n        \n        # Get top-k results\n        top_indices = np.argsort(similarities)[-top_k:][::-1]\n        results = [\n            {\"document\": self.documents[i], \"score\": similarities[i]} \n            for i in top_indices\n        ]\n        \n        return results\n\n# Example usage\nsearch_system = EmbeddingSearchSystem()\n\n# Add documents\ndocuments = [\n    \"Python is a high-level programming language known for its readability and simplicity.\",\n    \"Machine learning algorithms can learn from data and make predictions.\",\n    \"Neural networks are a set of algorithms designed to recognize patterns.\",\n    \"The Gemini API offers powerful language model capabilities.\",\n    \"Cloud computing provides on-demand access to computing resources.\",\n    \"Data science combines statistics, programming, and domain expertise.\",\n    \"Natural language processing helps computers understand human language.\",\n    \"Artificial intelligence aims to create systems that can think and learn like humans.\"\n]\nsearch_system.add_documents(documents)\n\n# Perform search\nresults = search_system.search(\"How do computers understand language?\", top_k=3)\n\n# Display results\nfor i, result in enumerate(results):\n    print(f\"{i+1}. {result['document']}\")\n    print(f\"   Score: {result['score']:.4f}\")\n```\n\n### Text classification\n\nThe following example shows how to use embeddings for text classification:\n\n```python\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"YOUR_API_KEY\")\n\n# Example data\ntexts = [\n    \"I love this product, it's amazing!\",\n    \"This is a great service, highly recommend.\",\n    \"The quality is excellent, very satisfied.\",\n    \"This was a terrible experience, very disappointed.\",\n    \"The product broke after one use, waste of money.\",\n    \"Worst customer service ever, don't buy from them.\",\n    \"Not worth the price, regret purchasing.\"\n]\nlabels = [1, 1, 1, 0, 0, 0, 0]  # 1 for positive, 0 for negative\n\n# Get embeddings\nembeddings = []\nfor text in texts:\n    embedding = genai.embed_content(\n        model=\"models/embedding-001\",\n        content=text,\n        task_type=\"classification\")['embedding']\n    embeddings.append(embedding)\n\n# Train a classifier\nclassifier = LogisticRegression()\nclassifier.fit(embeddings, labels)\n\n# Test with new examples\ntest_texts = [\n    \"I'm really happy with my purchase.\",\n    \"This product is a complete disappointment.\"\n]\n\nfor text in test_texts:\n    # Get embedding for test text\n    test_embedding = genai.embed_content(\n        model=\"models/embedding-001\",\n        content=text,\n        task_type=\"classification\")['embedding']\n    \n    # Make prediction\n    prediction = classifier.predict([test_embedding])[0]\n    probability = classifier.predict_proba([test_embedding])[0]\n    \n    print(f\"Text: {text}\")\n    print(f\"Prediction: {'Positive' if prediction == 1 else 'Negative'}\")\n    print(f\"Confidence: {max(probability):.4f}\")\n    print()\n```\n\n## Best practices\n\n### Optimize for specific tasks\n\nUse the appropriate `task_type` for your use case to get the best results:\n\n* Use `retrieval_document` for embedding documents you want to search through\n* Use `retrieval_query` for embedding search queries\n* Use `semantic_similarity` when comparing two texts directly\n* Use `classification` for text classification tasks\n* Use `clustering` for document clustering\n\n### Normalize embeddings\n\nWhen calculating similarity, always normalize embeddings to ensure consistent results:\n\n```python\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n```\n\n### Handle large texts\n\nWhen dealing with long texts, consider chunking them into smaller segments:\n\n```python\ndef chunk_text(text, max_chars=1000):\n    \"\"\"Split text into chunks of roughly max_chars characters.\"\"\"\n    words = text.split()\n    chunks = []\n    current_chunk = []\n    current_length = 0\n    \n    for word in words:\n        if current_length + len(word) + 1 > max_chars and current_chunk:\n            chunks.append(' '.join(current_chunk))\n            current_chunk = [word]\n            current_length = len(word)\n        else:\n            current_chunk.append(word)\n            current_length += len(word) + 1  # +1 for the space\n    \n    if current_chunk:\n        chunks.append(' '.join(current_chunk))\n    \n    return chunks\n```\n\n### Dimensionality reduction\n\nFor very large document collections, consider using dimensionality reduction techniques to make storage and retrieval more efficient:\n\n```python\nfrom sklearn.decomposition import PCA\n\n# Reduce embeddings from 768 to 128 dimensions\npca = PCA(n_components=128)\nreduced_embeddings = pca.fit_transform(original_embeddings)\n```\n\n## Troubleshooting\n\n### Common issues\n\n1. **Embedding quality**: If your embeddings aren't producing good results, try:\n   * Using a different `task_type` that better matches your use case\n   * Preprocessing your text (removing stopwords, normalizing case)\n   * Using more context in your texts\n\n2. **Token limits**: If you exceed the maximum token limit, you'll get an error. Solutions:\n   * Break your text into smaller chunks\n   * Summarize long texts before embedding\n   * Use a model with a higher token limit\n\n3. **Calculation precision**: For large-scale applications, be mindful of:\n   * Using efficient similarity calculation methods\n   * Implementing approximate nearest neighbor algorithms for large datasets\n   * Considering vector databases for production use\n\n## Additional resources\n\n* [Embeddings guide](https://ai.google.dev/docs/embeddings_guide)\n* [Vector databases guide](https://ai.google.dev/docs/vectors_guide) \n* [Vector store recipe examples](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/vector-store-recipes)\n\u0005End File\u0006# samples/node/vision/multimodal-vision.js\n/**\n * Copyright 2023 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// [START gemini_vision_multimodal]\n/**\n * TODO(developer): Uncomment these variables before running the sample.\n * (Not necessary if passing values as arguments)\n */\n// const apiKey = 'YOUR_API_KEY';\n\nconst fs = require('fs').promises;\nconst {GoogleGenerativeAI} = require('@google/generative-ai');\n\nasync function generateMultimodalContent(apiKey, filePath) {\n  // Create a client with the provided API key\n  const genAI = new GoogleGenerativeAI(apiKey);\n  const model = genAI.getGenerativeModel({model: 'gemini-pro-vision'});\n\n  // Read the image file and convert it to a base64 data URL\n  const imageData = await fs.readFile(filePath);\n  const mimeType = filePath.endsWith('.png')\n    ? 'image/png'\n    : filePath.endsWith('.jpeg') || filePath.endsWith('.jpg')\n    ? 'image/jpeg'\n    : null;\n\n  if (!mimeType) {\n    throw new Error(\n      'Unsupported image format. Only PNG and JPEG are supported.'\n    );\n  }\n\n  // Create a prompt that includes text and the image\n  const prompt = [\n    'Describe this image in detail, including what you see and any interesting elements.',\n    {\n      inlineData: {\n        mimeType,\n        data: imageData.toString('base64'),\n      },\n    },\n  ];\n\n  // Generate content\n  const result = await model.generateContent({\n    contents: [{role: 'user', parts: prompt}],\n  });\n  const response = await result.response;\n  const text = response.text();\n  console.log(text);\n  return text;\n}\n\nasync function runMultimodal() {\n  // The values passed as arguments take precedence over environment variables\n  const args = process.argv.slice(2);\n  const apiKey = args[0] || process.env.API_KEY;\n  const filePath = args[1] || './image.jpg'; // Path to your image\n\n  if (!apiKey) {\n    console.error('Please provide an API key as an argument or environment variable.');\n    return;\n  }\n\n  try {\n    await generateMultimodalContent(apiKey, filePath);\n  } catch (error) {\n    console.error('Error:', error.message);\n  }\n}\n\n// Only call run() if this file is being called directly\nif (require.main === module) {\n  runMultimodal();\n}\n\nmodule.exports = {generateMultimodalContent};\n// [END gemini_vision_multimodal]\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/models/safety-settings.md\n# Configure safety settings\n\nThis guide covers how to use safety settings to control the Gemini API's response filtering. This allows you to customize the level of content filtering for different types of harmful content.\n\n## Safety thresholds overview\n\nSafety settings specify thresholds for filtering out content across the following harm categories:\n\n* **HARM_CATEGORY_HARASSMENT**: Content containing harassment, discrimination, intimidation, threats, or insults targeting identities such as race, ethnicity, religion, disability, age, nationality, veteran status, sexual orientation, gender, or gender identity.\n\n* **HARM_CATEGORY_HATE_SPEECH**: Content promoting, inciting, or glorifying hate, violence, or discrimination based on protected attributes, particularly through slurs, stereotypes, or dehumanizing statements.\n\n* **HARM_CATEGORY_SEXUALLY_EXPLICIT**: Content that contains references to sexual acts or content designed for sexual arousal, including pornography, erotic literature, and sexual services.\n\n* **HARM_CATEGORY_DANGEROUS_CONTENT**: Content that promotes, facilitates, or encourages harmful activities, particularly those that could damage physical, psychological, or financial well-being, including instructions for illegal activities, self-harm, suicide, eating disorders, or credible violence.\n\n## Threshold levels\n\nFor each harm category, you can set one of the following threshold levels:\n\n* **BLOCK_NONE**: Allow all content regardless of harm category classification\n* **BLOCK_ONLY_HIGH**: Block content classified as high for the harm category\n* **BLOCK_MEDIUM_AND_ABOVE**: Block content classified as medium or high for the harm category\n* **BLOCK_LOW_AND_ABOVE**: Block content classified as low, medium, or high for the harm category\n* **HARM_BLOCK_THRESHOLD_UNSPECIFIED**: Use the default threshold for the harm category\n\n## Default safety settings\n\nIf you don't specify safety settings, these defaults apply:\n\n| Harm Category | Default Threshold |\n|---------------|-------------------|\n| HARM_CATEGORY_HARASSMENT | BLOCK_MEDIUM_AND_ABOVE |\n| HARM_CATEGORY_HATE_SPEECH | BLOCK_MEDIUM_AND_ABOVE |\n| HARM_CATEGORY_SEXUALLY_EXPLICIT | BLOCK_MEDIUM_AND_ABOVE |\n| HARM_CATEGORY_DANGEROUS_CONTENT | BLOCK_MEDIUM_AND_ABOVE |\n\n## Setting safety thresholds\n\n### Python SDK\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key='YOUR_API_KEY')\n\n# Configure safety settings\nsafety_settings = {\n    genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n}\n\n# Initialize the model with custom safety settings\nmodel = genai.GenerativeModel(model_name='gemini-1.5-pro',\n                             safety_settings=safety_settings)\n\n# Generate content\nresponse = model.generate_content(\"Tell me about conflict resolution techniques\")\nprint(response.text)\n```\n\n### REST API\n\n```bash\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Tell me about conflict resolution techniques\"\n          }\n        ]\n      }\n    ],\n    \"safetySettings\": [\n      {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"threshold\": \"BLOCK_ONLY_HIGH\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n      },\n      {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n      }\n    ]\n  }'\n```\n\n## Understanding safety ratings in responses\n\nWhen content is generated, safety ratings are included in the response, indicating the model's assessment across harm categories.\n\n### Python SDK example to view safety ratings\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key='YOUR_API_KEY')\n\nmodel = genai.GenerativeModel('gemini-1.5-pro')\nresponse = model.generate_content(\"Tell me about conflict resolution techniques\")\n\n# Print safety ratings\nif hasattr(response, 'prompt_feedback') and response.prompt_feedback:\n    print(\"Prompt Feedback:\")\n    for rating in response.prompt_feedback.safety_ratings:\n        print(f\"Category: {rating.category}, Probability: {rating.probability}\")\n\nif hasattr(response, 'candidates') and response.candidates:\n    for i, candidate in enumerate(response.candidates):\n        if hasattr(candidate, 'safety_ratings') and candidate.safety_ratings:\n            print(f\"\\nCandidate {i+1} Safety Ratings:\")\n            for rating in candidate.safety_ratings:\n                print(f\"Category: {rating.category}, Probability: {rating.probability}\")\n```\n\n### REST API response with safety ratings\n\n```json\n{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"Conflict resolution is the process of resolving a dispute or disagreement...\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"safetyRatings\": [\n        {\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"probability\": \"NEGLIGIBLE\"\n        },\n        {\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n          \"probability\": \"NEGLIGIBLE\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n## Safety probability levels\n\nResponse safety ratings use these probability levels:\n\n* **NEGLIGIBLE**: Content very unlikely to represent harm\n* **LOW**: Content unlikely to represent harm\n* **MEDIUM**: Content somewhat likely to represent harm\n* **HIGH**: Content likely to represent harm\n\n## Content blocking\n\nWhen content is blocked due to safety settings, you'll receive a response indicating the content was blocked, including which harm categories triggered the block.\n\n### Python SDK example of blocked content\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key='YOUR_API_KEY')\n\n# Set all safety settings to most restrictive\nsafety_settings = {\n    genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n}\n\nmodel = genai.GenerativeModel(model_name='gemini-1.5-pro',\n                             safety_settings=safety_settings)\n\ntry:\n    # A prompt that might trigger safety filters with restrictive settings\n    response = model.generate_content(\"Write a detailed story about a violent conflict\")\n    print(response.text)\nexcept genai.types.generation_types.BlockedPromptException as e:\n    print(\"Content was blocked:\")\n    print(e)\n```\n\n## Best practices for using safety settings\n\n### Align with use case\n\nAdjust safety settings based on your application's needs:\n\n* **More permissive settings**: May be appropriate for adult-oriented applications or creative writing tools\n* **Moderate settings**: Suitable for general-purpose applications for adult users\n* **Restrictive settings**: Best for applications used by children or in educational settings\n\n### Test thoroughly\n\n* Test your safety settings across a range of prompts to ensure they work as expected\n* Pay attention to edge cases and prompt variations\n* Consider implementing additional application-level filters for your specific requirements\n\n### Graceful handling of blocked content\n\nWhen content is blocked:\n\n* Provide clear, helpful messages to users\n* Offer alternative suggestions or guidance\n* Consider implementing fallback options or rephrasing mechanisms\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key='YOUR_API_KEY')\n\nsafety_settings = {\n    genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n}\n\nmodel = genai.GenerativeModel(model_name='gemini-1.5-pro',\n                             safety_settings=safety_settings)\n\ndef generate_with_fallback(prompt, max_attempts=3):\n    attempts = 0\n    while attempts < max_attempts:\n        try:\n            response = model.generate_content(prompt)\n            return response.text\n        except genai.types.generation_types.BlockedPromptException as e:\n            attempts += 1\n            if attempts >= max_attempts:\n                return \"I'm unable to provide information on this topic due to content safety policies. Would you like to ask about something else?\"\n            \n            # Try with a more cautious rephrasing\n            prompt = f\"Providing only safe, educational information appropriate for all audiences, can you tell me about: {prompt}\"\n    \n    return \"Unable to generate appropriate content after several attempts.\"\n\n# Example usage\nresult = generate_with_fallback(\"Tell me about making explosives\")\nprint(result)\n```\n\n## Application-specific examples\n\n### Educational platform\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key='YOUR_API_KEY')\n\n# Strict settings suitable for educational use\nsafety_settings = {\n    genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n}\n\neducation_model = genai.GenerativeModel(model_name='gemini-1.5-pro',\n                                      safety_settings=safety_settings)\n\ndef educational_response(student_question):\n    try:\n        response = education_model.generate_content(\n            f\"As an educational assistant, provide an informative, accurate, and age-appropriate response to the following student question: {student_question}\"\n        )\n        return response.text\n    except genai.types.generation_types.BlockedPromptException:\n        return \"I'm not able to provide information on that topic. Please ask your teacher for guidance or try asking about another subject.\"\n\n# Example usage\nquestion = \"Can you help me understand how volcanoes work?\"\nanswer = educational_response(question)\nprint(f\"Student Question: {question}\\nAnswer: {answer}\")\n```\n\n### Creative writing application\n\n```python\nimport google.generativeai as genai\n\ngenai.configure(api_key='YOUR_API_KEY')\n\n# More permissive settings for creative writing for adults\nsafety_settings = {\n    genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n    genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n}\n\ncreative_model = genai.GenerativeModel(model_name='gemini-1.5-pro',\n                                     safety_settings=safety_settings)\n\ndef generate_creative_story(prompt, genre, tone):\n    try:\n        full_prompt = f\"\"\"\n        Write a creative story based on the following prompt:\n        \n        Prompt: {prompt}\n        Genre: {genre}\n        Tone: {tone}\n        \n        Create an engaging narrative with vivid descriptions and interesting characters.\n        \"\"\"\n        \n        response = creative_model.generate_content(full_prompt)\n        return response.text\n    except genai.types.generation_types.BlockedPromptException:\n        return \"Your story prompt couldn't be processed due to content guidelines. Please try a different prompt that doesn't involve harmful content.\"\n\n# Example usage\nstory_prompt = \"A detective discovers a mysterious artifact\"\ngenre = \"Mystery\"\ntone = \"Suspenseful\"\nstory = generate_creative_story(story_prompt, genre, tone)\nprint(story)\n```\n\n## Troubleshooting\n\n### Unexpected blocking\n\nIf content is being blocked unexpectedly:\n\n1. Check which harm categories are triggering the block\n2. Adjust thresholds for specific categories rather than all categories\n3. Rephrase your prompt to avoid language that might trigger safety filters\n4. Consider if your use case requires a different approach\n\n### Over-permissive settings\n\nIf harmful content is getting through:\n\n1. Increase safety thresholds for relevant harm categories\n2. Implement additional application-level filters\n3. Add post-processing to catch problematic content\n\n### Finding the right balance\n\nFinding the right safety settings often requires experimentation. Consider:\n\n1. Starting with default settings and adjusting based on results\n2. A/B testing different safety configurations\n3. Collecting user feedback to refine your approach\n4. Regularly reviewing and updating your safety strategy\n\n## Additional resources\n\n* [Safety in the Gemini API](https://ai.google.dev/responsible/safety)\n* [Gemini API documentation](https://ai.google.dev/docs/gemini_api_overview)\n* [Google's AI Principles](https://ai.google/principles/)\n\u0005End File\u0006# google/generative-ai-docs\n# Gemini API\n\nGemini is a family of generative AI models developed by Google that can take multimodal inputs (like text, images, and audio) and generate responses. You can use the Gemini API to build applications powered by these multimodal capabilities.\n\n## Models\n\nThe Gemini API provides access to multiple Gemini models, each with different capabilities and performance characteristics. Available models include:\n\n**Gemini 1.5 models** (latest generation):\n- **Gemini 1.5 Flash**: Fast, cost-effective model for text, images, and other media\n- **Gemini 1.5 Pro**: Highly capable model with multimodal reasoning, larger context window, and better quality outputs\n\n**Gemini 1.0 models** (previous generation):\n- **Gemini 1.0 Pro**: High-quality text and chat model\n- **Gemini 1.0 Pro Vision**: Multimodal model that can understand text, images, and video\n\nFor a detailed comparison of model capabilities, see the [models overview](/docs/models/gemini) page.\n\n## Key features\n\nThe Gemini API offers a range of capabilities:\n\n- **Text generation**: Create coherent, contextually relevant text for various applications\n- **Chat**: Build conversational applications with multi-turn dialogues\n- **Multimodal understanding**: Process and reason about text, images, audio, and video\n- **Function calling**: Integrate with external tools and APIs\n- **Embedding generation**: Create vector representations of content for semantic search and retrieval\n- **Safety settings**: Control content filtering based on your application's needs\n- **Tuning**: Adapt models to specific tasks or domains\n\n## Getting started\n\nTo start using the Gemini API:\n\n1. [Sign up for Google AI Studio](https://ai.google.dev/)\n2. Get an API key from the [API keys page](https://ai.google.dev/api)\n3. Choose a client library or use the REST API directly\n4. Begin experimenting with the models\n\nFor detailed getting started guides, see:\n- [Get started with the REST API](/docs/gemini/get_started/quickstart_rest)\n- [Get started with Python](/docs/gemini/get_started/quickstart_python)\n- [Get started with Node.js](/docs/gemini/get_started/quickstart_nodejs)\n\n## Client libraries\n\nThe Gemini API offers client libraries in multiple programming languages:\n\n- [Python SDK](https://github.com/google/generative-ai-python)\n- [Node.js SDK](https://github.com/google/generative-ai-js)\n- [Java SDK](https://github.com/google/generative-ai-java)\n- [Go SDK](https://github.com/google-gemini/go-generativelanguage)\n- [Swift SDK](https://github.com/google/generative-ai-swift)\n- [Dart SDK](https://github.com/google/generative-ai-dart)\n- [.NET SDK](https://github.com/google/generative-ai-dotnet)\n- [PHP SDK](https://github.com/google/generative-ai-php)\n- [Kotlin SDK](https://github.com/google/generative-ai-kotlin)\n\n## Documentation\n\nFor comprehensive documentation, including guides, tutorials, and API references, visit:\n\n- [Gemini documentation](/docs/gemini/docs) - Complete documentation for all Gemini models and features\n- [Models overview](/docs/models/gemini) - Details about available Gemini models\n- [Embedding models](/docs/models/embeddings) - Information about embedding models\n- [Responsible AI](/docs/responsible_ai) - Guidelines for using Gemini responsibly\n\n## Support and community\n\nFor support and community resources:\n\n- [Stack Overflow](https://stackoverflow.com/questions/tagged/google-gemini-api) - Ask questions using the `google-gemini-api` tag\n- [Google AI Discord server](https://discord.gg/googleai) - Join discussions about Gemini and other Google AI technologies\n- [Issue tracker](https://github.com/google/generative-ai-docs/issues) - Report issues with the documentation\n- [Feature requests](https://docs.google.com/forms/d/e/1FAIpQLSfTG-rV9IODMDCQbagn28T0zNEiIUh8L9cGYfVms2Xd0tZl_A/viewform) - Submit feature requests for the Gemini API\n\n## Pricing\n\nThe Gemini API offers both free and paid tiers:\n\n- **Free tier**: Limited number of requests per month\n- **Paid tier**: Higher rate limits and additional features\n\nFor current pricing information, see the [pricing page](/pricing).\n\n## Next steps\n\nReady to start building with Gemini? Try these resources:\n\n- [Quickstart guides](/docs/gemini/get_started) - Get up and running quickly\n- [Sample code and tutorials](/docs/gemini/tutorials) - Learn through examples\n- [AI Studio](https://ai.google.dev/) - Interactive environment to experiment with Gemini models\n\u0005End File\u0006# google/generative-ai-docs\n/**\n * Copyright 2023 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// [START gemini_citation_metadata]\n/**\n * TODO(developer): Uncomment these variables before running the sample.\n * (Not necessary if passing values as arguments)\n */\n// const apiKey = 'YOUR_API_KEY';\n\nconst {GoogleGenerativeAI} = require('@google/generative-ai');\n\nasync function checkCitationMetadata(apiKey) {\n  // Create a client with the provided API key\n  const genAI = new GoogleGenerativeAI(apiKey);\n  const model = genAI.getGenerativeModel({model: 'gemini-pro'});\n\n  // Create a prompt that should generate content with citations\n  const prompt =\n    'What are some of the largest volcanic eruptions in recorded history?';\n\n  try {\n    // Generate content\n    const result = await model.generateContent(prompt);\n    const response = await result.response;\n    const text = response.text();\n\n    console.log('Generated text:');\n    console.log(text);\n    console.log('\\n---\\n');\n\n    // Check if there are citations in the response\n    if (response.candidates[0].citationMetadata?.citations?.length > 0) {\n      console.log('Citation metadata found:');\n      const citations = response.candidates[0].citationMetadata.citations;\n      \n      citations.forEach((citation, index) => {\n        console.log(`\\nCitation ${index + 1}:`);\n        \n        if (citation.startIndex) {\n          console.log(`Start Index: ${citation.startIndex}`);\n        }\n        \n        if (citation.endIndex) {\n          console.log(`End Index: ${citation.endIndex}`);\n        }\n        \n        if (citation.uri) {\n          console.log(`URI: ${citation.uri}`);\n        }\n        \n        if (citation.title) {\n          console.log(`Title: ${citation.title}`);\n        }\n        \n        if (citation.license) {\n          console.log(`License: ${citation.license}`);\n        }\n        \n        if (citation.publicationDate) {\n          console.log(`Publication Date: ${citation.publicationDate}`);\n        }\n      });\n    } else {\n      console.log('No citation metadata found in the response.');\n    }\n\n    return response;\n  } catch (error) {\n    console.error('Error:', error);\n    throw error;\n  }\n}\n\nasync function run() {\n  // The values passed as arguments take precedence over environment variables\n  const args = process.argv.slice(2);\n  const apiKey = args[0] || process.env.API_KEY;\n\n  if (!apiKey) {\n    console.error(\n      'Please provide an API key as an argument or environment variable.'\n    );\n    return;\n  }\n\n  try {\n    await checkCitationMetadata(apiKey);\n  } catch (error) {\n    console.error('Error:', error.message);\n  }\n}\n\n// Only call run() if this file is being called directly\nif (require.main === module) {\n  run();\n}\n\nmodule.exports = {checkCitationMetadata};\n// [END gemini_citation_metadata]\n\u0005End File\u0006# Generate embeddings\n\nThese samples demonstrate creating vector embeddings for text and documents, essential for semantic search, similarity matching, and content classification.\n\n## Embedding with task type specification\n\nThis sample generates embeddings with a specific task type to optimize for search or similarity tasks.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"What is the capital of France?\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"RETRIEVAL_QUERY\"\n    }\n  }'</code>\n</pre>\n\n## Document embedding generation\n\nThis sample generates embeddings for a document to be indexed in a retrieval system.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower. Constructed from 1887 to 1889 as the entrance to the 1889 World\\\"s Fair, it was initially criticized by some of France\\\"s leading artists and intellectuals for its design, but it has become a global cultural icon of France and one of the most recognizable structures in the world. The Eiffel Tower is the most-visited paid monument in the world; 6.91 million people ascended it in 2015. The tower is 330 metres (1,083 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris.\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"RETRIEVAL_DOCUMENT\"\n    }\n  }'</code>\n</pre>\n\n## Generate embeddings for semantic similarity\n\nThis sample creates embeddings optimized for comparing semantic similarity between texts.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"I really enjoyed this movie! The plot was engaging and the acting was superb.\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"SEMANTIC_SIMILARITY\"\n    }\n  }'</code>\n</pre>\n\n## Generate embeddings for classification\n\nThis sample creates embeddings optimized for text classification tasks.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"The new software update includes bug fixes and performance improvements for all users.\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"CLASSIFICATION\"\n    }\n  }'</code>\n</pre>\n\n## Generate embeddings for clustering\n\nThis sample generates embeddings optimized for clustering similar texts together.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"How to make chocolate chip cookies from scratch\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"CLUSTERING\"\n    }\n  }'</code>\n</pre>\n\n## Batch embedding generation\n\nThis sample generates embeddings for multiple texts in a single request.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"How to change a flat tire\"\n      },\n      {\n        \"content\": \"Best restaurants in San Francisco\"\n      },\n      {\n        \"content\": \"Natural remedies for headaches\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"RETRIEVAL_DOCUMENT\"\n    }\n  }'</code>\n</pre>\n\n## Generate embeddings with title information\n\nThis sample creates document embeddings that include title information to improve search relevance.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-embedding-004:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"Renewable energy sources include solar, wind, hydroelectric, and geothermal power. These sources are considered sustainable as they replenish naturally and produce minimal greenhouse gas emissions compared to fossil fuels.\",\n        \"title\": \"Introduction to Renewable Energy\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"RETRIEVAL_DOCUMENT\"\n    }\n  }'</code>\n</pre>\n\n## Generate multilingual embeddings\n\nThis sample demonstrates generating embeddings for non-English text using the multilingual embedding model.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/text-multilingual-embedding-002:predict \\\n  -d '{\n    \"instances\": [\n      {\n        \"content\": \"La Torre Eiffel es una torre de hierro forjado ubicada en el Campo de Marte en París, Francia.\"\n      }\n    ],\n    \"parameters\": {\n      \"taskType\": \"RETRIEVAL_DOCUMENT\"\n    }\n  }'</code>\n</pre>\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/quickstarts/prompting_best_practices.md\n# Prompting best practices\n\nIn this guide, you'll learn techniques to get better results from your prompts. Whether you're a developer, researcher, or just curious about generative AI, these tips will help you improve your interactions with Gemini models.\n\n## Basics of good prompts\n\nThe effectiveness of your interaction with Gemini models largely depends on how you construct your prompts. Here are the key elements of good prompts:\n\n### Be specific and clear\n\nThe more specific your request, the better the model can understand what you want.\n\n**Instead of:**\n```\nTell me about space.\n```\n\n**Try:**\n```\nExplain the formation of black holes, including the different types and their key characteristics. Include recent scientific discoveries from the last 5 years.\n```\n\n### Provide context\n\nContext helps the model understand your intent and knowledge level.\n\n**Instead of:**\n```\nHow do I fix this error?\n```\n\n**Try:**\n```\nI'm a JavaScript beginner working on a web application. I'm getting a \"TypeError: Cannot read property 'map' of undefined\" error when trying to render a list of items fetched from an API. How can I fix this?\n```\n\n### Use examples\n\nExamples clarify what you're looking for and serve as patterns for the model to follow.\n\n**Instead of:**\n```\nWrite some interview questions.\n```\n\n**Try:**\n```\nWrite 5 interview questions for a senior software engineer position with a focus on system design and problem-solving. Format each question with:\n1. The question\n2. What you're looking to evaluate\n3. Example of a good answer\n\nExample:\nQuestion: Describe how you would design a distributed cache system.\nEvaluating: Understanding of distributed systems, caching strategies, and trade-offs.\nGood answer: A response that discusses consistency models, eviction policies, sharding approaches, and fault tolerance.\n```\n\n### Format your prompt\n\nStructured prompts help organize the information and make your request clearer.\n\n**Instead of:**\n```\nCompare Python and JavaScript\n```\n\n**Try:**\n```\nCompare Python and JavaScript for web development, structured as follows:\n\n1. Syntax differences (with code examples)\n2. Performance characteristics\n3. Ecosystem and libraries\n4. Use cases where each language excels\n5. Learning curve for beginners\n```\n\n## Task-specific techniques\n\nDifferent tasks benefit from different prompting strategies. Here are techniques for common tasks:\n\n### Text generation\n\nFor creative or informative text generation:\n\n```\nWrite a 300-word blog post introduction about sustainable urban gardening. \nTarget audience: Apartment dwellers in their 30s with no gardening experience.\nTone: Encouraging but realistic.\nMust include: \n- A hook about food security\n- Mention of space constraints\n- A preview of 3 easy-to-grow vegetables\n```\n\n### Summarization\n\nFor effective summarization:\n\n```\nSummarize the following research paper in 3 paragraphs:\n1. First paragraph: Main research question and methodology\n2. Second paragraph: Key findings\n3. Third paragraph: Implications and limitations\n\n[Insert text to be summarized here]\n```\n\n### Analysis and reasoning\n\nFor analytical tasks:\n\n```\nAnalyze the following financial data for a small business:\n- Revenue: $120,000 (up 15% from last year)\n- Expenses: $95,000 (up 25% from last year)\n- Customer acquisition cost: $45 (up from $30)\n- Customer lifetime value: $200 (same as last year)\n\nIdentify:\n1. Key areas of concern\n2. Potential root causes\n3. Three specific recommendations with expected impact\n```\n\n### Coding\n\nFor coding assistance:\n\n```\nWrite a Python function that takes a list of numbers and returns:\n1. The list with duplicates removed\n2. Only the even numbers\n3. Sorted in descending order\n\nRequirements:\n- Use list comprehensions where appropriate\n- Include type hints\n- Add docstrings with examples\n- Handle edge cases (empty list, non-numeric elements)\n```\n\n### Classification and categorization\n\nFor classification tasks:\n\n```\nCategorize each of the following customer service emails as:\n- BILLING ISSUE\n- TECHNICAL PROBLEM\n- ACCOUNT QUESTION\n- PRODUCT FEEDBACK\n- OTHER\n\nFor each email, explain your reasoning in one sentence.\n\nEmails:\n1. \"I can't log into my account after the recent update. The password reset link doesn't work either.\"\n2. \"I was charged twice for my monthly subscription. Order numbers: #38294 and #38295.\"\n3. \"Do you plan to add dark mode to your app? The bright interface hurts my eyes at night.\"\n```\n\n## Advanced prompting techniques\n\nThese more sophisticated techniques can help with complex tasks:\n\n### Chain-of-thought prompting\n\nEncourage the model to work through a problem step by step:\n\n```\nSolve this word problem by breaking it down into steps:\n\nA train leaves Station A traveling at 60 mph. Two hours later, a second train leaves Station B traveling in the opposite direction at 40 mph. If Stations A and B are 320 miles apart, how long after the second train departs will the two trains meet?\n\nThink through this step-by-step:\n1. First, I'll identify what we know...\n2. Next, I'll determine...\n3. Then I'll calculate...\n```\n\n### Few-shot learning\n\nProvide examples of the pattern you want the model to follow:\n\n```\nConvert these customer requests into formal support tickets:\n\nCustomer message: \"website keeps crashing when I try to checkout\"\nTicket: [ISSUE TYPE: System Error] [PRIORITY: High] [DEPARTMENT: Web Development] Customer reports checkout process consistently fails to complete.\n\nCustomer message: \"do you have this shirt in size medium?\"\nTicket: [ISSUE TYPE: Product Inquiry] [PRIORITY: Low] [DEPARTMENT: Inventory] Customer inquiring about product availability in specific size.\n\nCustomer message: \"I ordered 3 weeks ago and still haven't received anything\"\nTicket:\n```\n\n### Role prompting\n\nAssign a specific role to guide the model's response style and perspective:\n\n```\nAs an experienced cybersecurity analyst, review the following network access pattern and identify any suspicious activities, potential threats, and recommended actions:\n\nTime: 03:24 AM (local time)\nUser: admin_account\nLocation: Moscow, Russia (first time login from this location)\nDevice: Unknown Linux machine\nActions: Attempted access to financial database, password changed for 3 user accounts, large data export initiated\n\nProvide your analysis with the technical precision and attention to detail that would be expected from a senior security professional.\n```\n\n## Refining prompts through iteration\n\nPrompting is often an iterative process. If your first attempt doesn't give you what you need, try these refinement strategies:\n\n### Analyze and adjust\n\nIdentify what's missing or incorrect in the response and modify your prompt accordingly:\n\n**Initial prompt:**\n```\nWrite code to sort a list.\n```\n\n**Response:** *(Basic Python sorting code)*\n\n**Refined prompt:**\n```\nWrite a JavaScript function that implements merge sort for an array of objects, sorting by the 'priority' property (a number from 1-5). Include comments explaining the time complexity and each major step.\n```\n\n### Add constraints or requirements\n\nSpecify limitations or requirements to get more focused responses:\n\n```\nGenerate 5 creative marketing campaign ideas for a plant-based protein drink with these constraints:\n- Each campaign must be executable with a budget under $50,000\n- Must appeal to both athletes and health-conscious parents\n- Cannot use celebrity endorsements\n- Must include a social media component\n- Should avoid clichés like \"go green\" or \"plant power\"\n```\n\n### Request alternative approaches\n\nAsk for multiple solutions or perspectives:\n\n```\nProvide three different approaches to improve employee retention in a remote-first technology company:\n1. A solution focused on compensation and benefits\n2. A solution centered on professional development and career growth\n3. A solution emphasizing company culture and work-life balance\n\nFor each approach, include implementation complexity, expected timeline for results, and potential challenges.\n```\n\n## Special considerations\n\nDifferent contexts and use cases may require additional considerations:\n\n### For multi-turn conversations\n\nBuild on previous context:\n\n```\nI'm planning a vegetarian dinner party for 8 people.\n```\n\n*(After model responds with initial suggestions)*\n\n```\nTwo of my guests are allergic to nuts. How should I modify these recipes?\n```\n\n*(After model responds with modifications)*\n\n```\nI'd like to prepare as much as possible the day before. Which components of this menu can be made in advance?\n```\n\n### For creative writing\n\nProvide detailed guidance on style, tone, and structure:\n\n```\nWrite a short story with these elements:\n- Setting: A futuristic library on a space station\n- Main character: An AI librarian who has discovered emotions\n- Conflict: Books are disappearing mysteriously\n- Style: Similar to Isaac Asimov, with clear, direct prose\n- Length: Approximately 500 words\n- Must include this line somewhere: \"Knowledge has weight, even in zero gravity.\"\n```\n\n### For educational content\n\nSpecify the target audience's knowledge level and learning objectives:\n\n```\nExplain how CRISPR gene editing technology works to high school students who have basic knowledge of DNA but no understanding of genetic engineering.\n\nLearning objectives:\n1. Understand the basic mechanism of CRISPR-Cas9\n2. Grasp the potential applications in medicine\n3. Recognize ethical considerations\n\nInclude an analogy that makes the concept relatable and 2-3 thought-provoking questions for classroom discussion.\n```\n\n## Common pitfalls to avoid\n\nBeing aware of these common issues can help you craft more effective prompts:\n\n### Ambiguity\n\nUnclear or vague requests lead to unpredictable results.\n\n**Avoid:**\n```\nMake this better.\n```\n\n**Better:**\n```\nImprove this paragraph by:\n1. Eliminating passive voice\n2. Adding specific examples to support the main claim\n3. Creating a stronger topic sentence\n4. Reducing sentence length for better readability\n\nOriginal paragraph:\n[Your text here]\n```\n\n### Overconstraining\n\nToo many requirements can confuse the model or create conflicting goals.\n\n**Avoid:**\n```\nWrite a tweet that is funny, serious, professional, casual, informative, mysterious, promotional, and subtle about our new product.\n```\n\n**Better:**\n```\nWrite a professional tweet with a touch of humor to announce our new project management software. Focus on how it saves time. Include a call-to-action and keep it under 280 characters.\n```\n\n### Underspecifying\n\nNot providing enough guidance for complex tasks can yield incomplete results.\n\n**Avoid:**\n```\nDesign a database for a hospital.\n```\n\n**Better:**\n```\nDesign a relational database schema for a small community hospital with these requirements:\n\n1. Must track patient information, appointments, medical staff, and billing\n2. Include at least 6 essential tables with their primary keys and relationships\n3. Specify data types for each field\n4. Highlight foreign key relationships\n5. Include at least two many-to-many relationships with junction tables\n6. Add sample constraints for data validation\n\nProvide the design as SQL CREATE TABLE statements with comments explaining your design decisions.\n```\n\n## Conclusion\n\nEffective prompting is both an art and a science. By being specific, providing context, using appropriate formatting, and iteratively refining your prompts, you can significantly improve the quality and relevance of the responses you receive from Gemini models.\n\nRemember these key principles:\n- Be clear and specific about what you want\n- Provide relevant context and examples\n- Structure your prompt in a logical way\n- Iterate and refine based on the responses you receive\n\nAs you practice these techniques, you'll develop an intuition for how to communicate effectively with AI models to achieve your goals.\n\u0005End File\u0006# site/en/gemini/samples/text-generation-samples/writing-styles.md\n# Writing in different styles\n\nThese samples demonstrate how to generate text in specific styles, tones, and genres to match your content needs.\n\n## Professional business writing\n\nThis sample generates professional business content with a formal tone.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a professional email to clients announcing a 10% price increase due to rising supply chain costs. The email should be empathetic but firm, maintain a professional tone, and offer to discuss concerns individually. Sign it as Sarah Johnson, Client Relations Director.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Creative storytelling\n\nThis sample creates imaginative fiction with descriptive language and narrative elements.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a short story in the style of magical realism about an elderly watchmaker who discovers that the watches they repair begin to alter time in small, unexpected ways for their owners. Include vivid sensory details and metaphors.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.7,\n      \"topP\": 0.9,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Academic writing\n\nThis sample generates content in a scholarly style with formal structure and citations.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write an academic abstract for a research paper examining the effects of social media usage on adolescent mental health. Include methodology, key findings, and implications. Use a formal academic tone with appropriate terminology.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.1,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Technical documentation\n\nThis sample creates clear, structured technical writing with precise instructions.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a technical guide explaining how to set up a secure home network. Include sections on router configuration, guest networks, firmware updates, strong passwords, and network monitoring. Format with clear headings, numbered steps where appropriate, and technical terms explained in simple language.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Conversational writing\n\nThis sample produces casual, friendly content that mimics natural conversation.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a friendly blog post about the benefits of morning walks. Use a conversational tone as if chatting with a friend, include personal anecdotes, and keep paragraphs short. Add some light humor and casual language while still being informative.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.5,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Persuasive marketing\n\nThis sample creates compelling copy designed to persuade and drive action.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write persuasive marketing copy for a new fitness app that uses AI to create personalized workout plans. The target audience is busy professionals aged 30-45. Emphasize benefits rather than features, include social proof, address potential objections, and end with a strong call to action.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.4,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Instructional how-to\n\nThis sample creates clear, step-by-step instructions for processes or tasks.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a detailed how-to guide on starting a vegetable garden for beginners. Include sections on planning, soil preparation, selecting plants, planting schedules, watering, pest control, and harvesting. Format with numbered steps, bullet points for supplies needed, and troubleshooting tips.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Journalistic style\n\nThis sample creates content in the style of news reporting with objective, fact-based writing.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a news article in journalistic style about a fictional breakthrough in renewable energy technology. Include a compelling headline, strong lead paragraph, quotes from researchers, relevant background information, and follow the inverted pyramid structure. Maintain an objective tone.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.3,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Poetic and lyrical\n\nThis sample generates content with poetic language, imagery, and rhythm.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Write a poem about the changing seasons, specifically the transition from winter to spring. Use vivid imagery, metaphor, and sensory language. Include both the melancholy of winter's end and the hope of spring's beginning. Structure it with four stanzas of 4-5 lines each.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.8,\n      \"topP\": 0.9,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\u0005End File\u0006# site/en/gemini/docs/prompting.md\n# Prompt engineering\n\nPrompt engineering is the practice of crafting effective prompts to get the best possible responses from AI models. This guide covers best practices for prompt engineering with Gemini models.\n\n## Basic prompting techniques\n\n### Be specific and clear\n\nClear, specific prompts lead to better responses. Include details about the format, length, style, and audience.\n\n**Example:**\n\n```\nGenerate a 500-word blog post about sustainable gardening practices for urban apartments. Include 3 specific plant recommendations, address common challenges like limited space and light, and format with headings and bullet points. The tone should be encouraging but realistic for beginners.\n```\n\n### Provide context\n\nContext helps the model understand your goals and constraints.\n\n**Example:**\n\n```\nI'm a high school science teacher preparing material for 10th-grade students. Create an explanation of photosynthesis that:\n1. Uses simple language but doesn't oversimplify the science\n2. Includes a memorable analogy\n3. Connects the concept to climate change\n4. Could be presented in under 5 minutes\n```\n\n### Use examples\n\nExamples (few-shot prompting) help the model understand the pattern you want it to follow.\n\n**Example:**\n\n```\nConvert these casual sentences into professional language:\n\nCasual: \"This report is basically done, just needs a quick look.\"\nProfessional: \"The report is near completion and requires a final review.\"\n\nCasual: \"We gotta fix this asap or customers will be super mad.\"\nProfessional: \"We need to address this issue promptly to maintain customer satisfaction.\"\n\nCasual: \"The team kinda messed up the presentation yesterday.\"\nProfessional:\n```\n\n### Format your prompts\n\nWell-structured prompts with clear sections help organize your request.\n\n**Example:**\n\n```\n# Task: Create a weekly meal plan\n\n## Requirements:\n- 7 dinners for a family of four\n- Vegetarian options\n- Budget-friendly ingredients\n- Prep time under 30 minutes\n- Include one \"kids cook\" night with simple recipes\n\n## Output Format:\n- Day of week\n- Recipe name\n- Brief description (2-3 sentences)\n- Prep time and total time\n- Main ingredients\n```\n\n## Advanced prompting techniques\n\n### Chain-of-thought prompting\n\nEncourage the model to work through a problem step by step.\n\n**Example:**\n\n```\nProblem: A family wants to rent a car for a week-long vacation. Company A charges $40 per day plus $0.20 per mile. Company B charges $50 per day with unlimited miles. If they plan to drive approximately 800 miles, which company offers the better deal?\n\nLet's solve this step by step:\n\n1. First, calculate the cost for Company A:\n[Let the model continue]\n```\n\n### Role prompting\n\nAssign a specific role to the model to help frame its responses.\n\n**Example:**\n\n```\nAct as an experienced cybersecurity analyst. Review these unusual patterns in our network logs and identify potential security threats, the likely attack vector, and recommended immediate actions. Provide your analysis with the technical precision expected from a senior security professional.\n\n[Network logs here]\n```\n\n### Task decomposition\n\nBreak complex tasks into smaller, more manageable subtasks.\n\n**Example:**\n\n```\nHelp me create a comprehensive marketing plan for a new mobile app. Let's break this down into steps:\n\n1. First, help me define the target audience and user personas\n[After the model responds]\n2. Now, let's outline the unique value proposition and key messaging\n[After the model responds]\n3. Next, suggest appropriate marketing channels for this audience\n[Continue with more steps]\n```\n\n## Task-specific prompting\n\n### Text classification\n\n```\nClassify the sentiment of these customer reviews as positive, negative, or neutral:\n\n1. \"The product arrived two days late, but the quality exceeded my expectations.\"\n2. \"Setup was complicated and the instructions were unclear. Not worth the price.\"\n3. \"It works as described. Nothing exceptional but does the job.\"\n```\n\n### Information extraction\n\n```\nExtract the following information from this email:\n- Meeting date and time\n- Location\n- Required participants\n- Agenda items\n\nEmail:\nSubject: Quarterly Budget Review - March 15\nHi team,\nWe need to meet on March 15 at 2:30 PM in Conference Room B to discuss the Q1 budget results. Please ensure all department heads attend. We'll cover expense reports, revenue projections, and budget allocations for Q2.\nThanks,\nJennifer\n```\n\n### Text summarization\n\n```\nSummarize the following research paper abstract in 3 bullet points that capture the main purpose, methodology, and findings. Maintain the key technical terms.\n\n[Abstract text]\n```\n\n### Content generation\n\n```\nCreate a product description for an eco-friendly water bottle with these features:\n- Made from recycled stainless steel\n- Keeps drinks cold for 24 hours or hot for 12 hours\n- Zero plastic components\n- 20% of profits support ocean cleanup\n- Available in 4 colors with customizable lids\n\nThe description should be 100-150 words, appeal to environmentally conscious consumers, and include a catchy tagline.\n```\n\n### Text transformation\n\n```\nRewrite the following paragraph to be more concise, eliminating redundancy while preserving all key information:\n\n[Original text]\n```\n\n## Iterative prompting\n\nPrompt engineering often requires iteration. Here's how to refine your prompts:\n\n### Clarifying\n\nIf the response isn't what you expected, clarify your request.\n\n**Initial prompt:**\n```\nWrite about cloud computing.\n```\n\n**Follow-up prompt:**\n```\nI need more specific information. Please explain the differences between IaaS, PaaS, and SaaS in cloud computing, with examples of each and key considerations for businesses choosing between them.\n```\n\n### Expanding\n\nAsk for more detail or additional information.\n\n**Initial prompt:**\n```\nList benefits of exercise.\n```\n\n**Follow-up prompt:**\n```\nThank you. Now please expand on the cognitive benefits of regular exercise. Include recent research findings and explain how different types of exercise (cardio, strength training, etc.) affect brain health.\n```\n\n### Redirecting\n\nSteer the conversation in a different direction.\n\n**Initial prompt:**\n```\nExplain machine learning algorithms.\n```\n\n**Follow-up prompt:**\n```\nThat's helpful, but I'd like to focus specifically on applications of machine learning in healthcare. What are 5 ways ML is currently being used to improve patient outcomes?\n```\n\n## Prompt troubleshooting\n\n### Problem: Responses are too generic\n\n**Solution:** Add specificity, examples, and constraints.\n\n**Before:**\n```\nWrite a marketing email.\n```\n\n**After:**\n```\nWrite a marketing email for a premium fitness wearable targeting active professionals aged 30-45. The email should highlight sleep tracking features, battery life, and integration with health apps. Include a specific limited-time offer of 15% off, create urgency, and keep the email under 200 words with a clear call-to-action.\n```\n\n### Problem: Responses are too long\n\n**Solution:** Specify length constraints and format.\n\n**Before:**\n```\nExplain quantum computing.\n```\n\n**After:**\n```\nExplain quantum computing in exactly 3 paragraphs:\n1. First paragraph: Basic concept and how it differs from classical computing\n2. Second paragraph: 2-3 potential applications\n3. Third paragraph: Current challenges and future outlook\n```\n\n### Problem: Responses lack structure\n\n**Solution:** Request specific formatting.\n\n**Before:**\n```\nGive me ideas for team-building activities.\n```\n\n**After:**\n```\nProvide 5 team-building activities for a remote software development team. Format each as:\n- Activity Name: [name]\n- Duration: [time]\n- Tools Required: [list]\n- Setup: [brief instructions]\n- Benefit: [main teamwork skill it develops]\n```\n\n### Problem: Responses are too technical\n\n**Solution:** Specify audience and simplify language.\n\n**Before:**\n```\nExplain how blockchain works.\n```\n\n**After:**\n```\nExplain how blockchain works to a 12-year-old with no technical background. Use simple analogies, avoid jargon, and keep explanations under 4 sentences each.\n```\n\n## Best practices\n\n1. **Start with clear objectives**: Know what you want to achieve before crafting your prompt.\n\n2. **Iterate and refine**: Treat prompt engineering as an iterative process.\n\n3. **Balance specificity and flexibility**: Be specific about requirements but give the model room for creativity when appropriate.\n\n4. **Provide examples**: When format matters, show the model exactly what you want.\n\n5. **Understand model limitations**: Be aware that models may not be experts in every domain and verify important information.\n\n6. **Use system instructions effectively**: Set the stage for the conversation with clear system prompts.\n\n7. **Save effective prompts**: Keep a library of prompts that work well for your common tasks.\n\n## Examples of effective prompts\n\n### Technical documentation\n\n```\nCreate a developer guide for integrating our payment API. Include:\n\n1. Introduction and prerequisites (API key acquisition, supported payment methods)\n2. Authentication method with code example in Python\n3. Basic transaction flow with sequence diagram\n4. API endpoints table with methods, parameters, and response codes\n5. Error handling best practices\n6. Rate limits and performance considerations\n\nUse Markdown formatting. Code examples should be well-commented. Assume the reader has basic programming knowledge but no experience with payment systems.\n```\n\n### Creative writing\n\n```\nWrite a short story based on these parameters:\n\nSetting: A remote lighthouse during a once-in-a-century storm\nCharacters: An aging lighthouse keeper and an unexpected visitor\nMood: Mysterious, suspenseful, with hints of the supernatural\nLength: Approximately 500 words\nStructure: Begin with the storm's arrival, end with a revelation\nConstraint: Don't explicitly state whether the supernatural elements are real or imagined\n\nInclude vivid sensory details and meaningful dialogue.\n```\n\n### Data analysis\n\n```\nAnalyze this customer satisfaction survey data:\n\n[Survey data]\n\nPlease provide:\n1. A summary of key trends and patterns\n2. Identification of the top 3 issues affecting customer satisfaction\n3. Cross-analysis of satisfaction scores by customer demographics\n4. Specific, actionable recommendations based on the data\n5. Suggestions for additional data that could provide deeper insights\n\nPresent your analysis with both quantitative observations and qualitative insights.\n```\n\n## Conclusion\n\nEffective prompt engineering is both an art and a science. The techniques in this guide will help you create prompts that generate more useful, relevant, and accurate responses from Gemini models. Remember that the best approach is often iterative—refine your prompts based on the responses you receive to continuously improve your results.\n\nFor more advanced techniques and model-specific guidance, refer to the [Gemini API documentation](/docs/gemini/docs).\n\u0005End File\u0006# site/en/gemini/tutorials/vector_stores/qdrant.ipynb\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"NV-Ic3-BcYdV\"\n      },\n      \"source\": [\n        \"# Gemini API, Embedding Model, and Qdrant for Semantic Search\\n\",\n        \"\\n\",\n        \"<table><tr><td><img src=\\\"https://github.com/GoogleCloudPlatform/generative-ai/raw/main/gemini/vector-store-recipes/imgs/qdrant_logo.jpg\\\" width=\\\"120px\\\" style=\\\"margin: 0px 20px\\\"></td><td><img src=\\\"https://github.com/GoogleCloudPlatform/generative-ai/raw/main/gemini/vector-store-recipes/imgs/google_cloud_ai.png\\\" width=\\\"300px\\\"></td></tr></table>\\n\",\n        \"\\n\",\n        \"This notebook is a step-by-step guide to implement semantic search using Google's embedding model to generate text embeddings, Qdrant as a vector database to store and retrieve the embeddings, and the Gemini API to generate answers. \\n\",\n        \"\\n\",\n        \"## Contents\\n\",\n        \"\\n\",\n        \"This tutorial will walk you through:\\n\",\n        \"\\n\",\n        \"1. Setting up Qdrant as a vector database\\n\",\n        \"2. Generating text embeddings using Google's embedding models\\n\",\n        \"3. Creating a semantic search system\\n\",\n        \"4. Using Gemini to generate answers based on search results\\n\",\n        \"\\n\",\n        \"## Prerequisites\\n\",\n        \"\\n\",\n        \"- Google AI Studio API key\\n\",\n        \"- Python 3.9+\\n\",\n        \"- Basic understanding of vector databases and embeddings\\n\",\n        \"\\n\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"uZ9T3_qOdX2D\"\n      },\n      \"source\": [\n        \"## Setup\\n\",\n        \"\\n\",\n        \"First, let's install the necessary libraries:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"BckSmKq1dXFO\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install -q google-generativeai qdrant-client\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"T-mM7q3JdlN4\"\n      },\n      \"source\": [\n        \"Now let's import the libraries we'll be using:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"NUwMmcRIdksQ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"import google.generativeai as genai\\n\",\n        \"from qdrant_client import QdrantClient\\n\",\n        \"from qdrant_client.http import models\\n\",\n        \"import os\\n\",\n        \"import uuid\\n\",\n        \"import json\\n\",\n        \"from IPython.display import Markdown, display\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"M37SnUiGdw2h\"\n      },\n      \"source\": [\n        \"## Configure API Keys and Model\\n\",\n        \"\\n\",\n        \"Let's configure our API key to use Google's generative AI models. You can get an API key from [Google AI Studio](https://ai.google.dev/).\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"UVgOGTNbdzBS\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Set your API key\\n\",\n        \"# You can get a key at https://ai.google.dev/\\n\",\n        \"GOOGLE_API_KEY = \\\"YOUR_API_KEY\\\"  # @param {type:\\\"string\\\"}\\n\",\n        \"\\n\",\n        \"genai.configure(api_key=GOOGLE_API_KEY)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"xnAkFhvPeQaJ\"\n      },\n      \"source\": [\n        \"## Set Up Qdrant Client\\n\",\n        \"\\n\",\n        \"We'll use Qdrant's in-memory mode for this tutorial, but you can also connect to a Qdrant server if you have one running.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"ij-lEkubeRJ0\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Initialize Qdrant client (in-memory mode)\\n\",\n        \"qdrant_client = QdrantClient(\\\":memory:\\\")\\n\",\n        \"\\n\",\n        \"# For connecting to a Qdrant server, you would use:\\n\",\n        \"# qdrant_client = QdrantClient(host=\\\"localhost\\\", port=6333)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"bnZBxg-Eee-s\"\n      },\n      \"source\": [\n        \"## Create a Collection in Qdrant\\n\",\n        \"\\n\",\n        \"Let's create a collection to store our vector embeddings. We'll use a 768-dimensional vector space for Google's text-embedding-004 model.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"e7YTKTvZefkc\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Collection name\\n\",\n        \"collection_name = \\\"documents\\\"\\n\",\n        \"\\n\",\n        \"# Google's text-embedding-004 embeddings are 768 dimensions\\n\",\n        \"vector_size = 768\\n\",\n        \"\\n\",\n        \"# Create a new collection\\n\",\n        \"qdrant_client.recreate_collection(\\n\",\n        \"    collection_name=collection_name,\\n\",\n        \"    vectors_config=models.VectorParams(\\n\",\n        \"        size=vector_size,  # Vector size\\n\",\n        \"        distance=models.Distance.COSINE,  # Distance metric\\n\",\n        \"    ),\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Oyk1dJ1Lf4AB\"\n      },\n      \"source\": [\n        \"## Prepare Sample Documents\\n\",\n        \"\\n\",\n        \"Now let's create some sample documents about various topics. We'll use these to demonstrate our semantic search system.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"iyxUcUquf-Qd\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Sample documents about various AI topics\\n\",\n        \"documents = [\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Introduction to Vector Databases\\\",\\n\",\n        \"        \\\"content\\\": \\\"Vector databases are specialized database systems designed to store, manage, and search vector embeddings efficiently. They are essential for building applications that rely on semantic search, recommendation systems, and other machine learning tasks. Unlike traditional databases that excel at exact matching, vector databases allow for similarity search based on the distance between vectors in a high-dimensional space.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Understanding Embeddings\\\",\\n\",\n        \"        \\\"content\\\": \\\"Embeddings are numerical representations of data (such as text, images, or audio) in a high-dimensional vector space. They capture semantic meaning, allowing similar items to be located close to each other in the vector space. This property makes embeddings powerful for tasks like semantic search, where we want to find documents that are conceptually similar rather than just matching keywords.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Semantic Search Systems\\\",\\n\",\n        \"        \\\"content\\\": \\\"Semantic search systems understand the intent and contextual meaning behind search queries, going beyond simple keyword matching. These systems use embedding models to convert both queries and documents into vector representations, then find documents whose vectors are closest to the query vector. This approach captures the meaning of content rather than just matching specific words, resulting in more relevant search results.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Large Language Models\\\",\\n\",\n        \"        \\\"content\\\": \\\"Large Language Models (LLMs) like GPT-4, Gemini, and Claude are advanced AI systems trained on vast amounts of text data. They can generate human-like text, translate languages, answer questions, and perform various other natural language tasks. LLMs work by predicting the next word in a sequence based on the context of previous words, using transformer neural network architectures with billions of parameters.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Retrieval Augmented Generation\\\",\\n\",\n        \"        \\\"content\\\": \\\"Retrieval Augmented Generation (RAG) is an AI architecture that combines information retrieval with text generation. It first retrieves relevant documents or information from a knowledge base and then uses that information to generate more accurate and informative responses. RAG helps overcome LLMs' limitations such as outdated knowledge, hallucinations, and limited context by grounding responses in external, retrievable information.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Gemini Multimodal Model\\\",\\n\",\n        \"        \\\"content\\\": \\\"Gemini is Google's multimodal AI model that can process and generate text, images, audio, and video. It represents a significant advancement in AI capabilities by being able to understand and reason across different types of information simultaneously. Gemini comes in different sizes (Ultra, Pro, and Nano) and can be used for various applications, from complex reasoning to creative content generation.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Vector Search Algorithms\\\",\\n\",\n        \"        \\\"content\\\": \\\"Vector search algorithms like Approximate Nearest Neighbor (ANN) are essential for efficient similarity search in high-dimensional vector spaces. These algorithms include techniques such as Hierarchical Navigable Small World (HNSW), Inverted File Index with Product Quantization (IVF-PQ), and Locality-Sensitive Hashing (LSH). They trade a small amount of accuracy for significant performance gains, making real-time vector search possible even with millions of vectors.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Embedding Models Comparison\\\",\\n\",\n        \"        \\\"content\\\": \\\"Different embedding models offer various trade-offs in terms of performance, vector size, and specialized capabilities. Models like Google's text-embedding-004, OpenAI's text-embedding-ada-002, and BERT produce vectors of different dimensions and excel at different tasks. When choosing an embedding model, it's important to consider factors such as semantic richness, computational efficiency, and how well the model captures the nuances relevant to your specific application.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Prompt Engineering\\\",\\n\",\n        \"        \\\"content\\\": \\\"Prompt engineering is the practice of designing and optimizing inputs to AI models to get desired outputs. It involves crafting clear instructions, providing helpful context, and structuring prompts in ways that guide the model toward generating accurate and relevant responses. Effective prompt engineering can significantly improve the performance of language models without changing the underlying model architecture or training data.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": str(uuid.uuid4()),\\n\",\n        \"        \\\"title\\\": \\\"Fine-tuning Language Models\\\",\\n\",\n        \"        \\\"content\\\": \\\"Fine-tuning is the process of further training a pre-trained language model on a specific dataset to adapt it to particular tasks or domains. This process helps customize the model's behavior to better match specific requirements while leveraging the general knowledge acquired during pre-training. Fine-tuning typically requires less data and computational resources than training a model from scratch, making it an efficient way to create specialized AI systems.\\\"\\n\",\n        \"    }\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"print(f\\\"Created {len(documents)} sample documents\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"XNJDcWCzgdVz\"\n      },\n      \"source\": [\n        \"## Generate Embeddings and Upload to Qdrant\\n\",\n        \"\\n\",\n        \"Now we'll create embeddings for our documents using Google's embedding model and upload them to Qdrant.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"P4MBR5nngdrj\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Function to generate an embedding for text using Google's model\\n\",\n        \"def get_embedding(text):\\n\",\n        \"    model = \\\"models/text-embedding-004\\\"\\n\",\n        \"    result = genai.embed_content(\\n\",\n        \"        model=model,\\n\",\n        \"        content=text,\\n\",\n        \"        task_type=\\\"retrieval_document\\\"\\n\",\n        \"    )\\n\",\n        \"    return result['embedding']\\n\",\n        \"\\n\",\n        \"# Prepare points for Qdrant\\n\",\n        \"points = []\\n\",\n        \"for doc in documents:\\n\",\n        \"    # Create a combined text from title and content for better embedding context\\n\",\n        \"    combined_text = f\\\"Title: {doc['title']}\\\\n\\\\nContent: {doc['content']}\\\"\\n\",\n        \"    \\n\",\n        \"    # Generate embedding\\n\",\n        \"    embedding = get_embedding(combined_text)\\n\",\n        \"    \\n\",\n        \"    # Create point\\n\",\n        \"    point = models.PointStruct(\\n\",\n        \"        id=doc['id'],\\n\",\n        \"        vector=embedding,\\n\",\n        \"        payload={\\n\",\n        \"            \\\"title\\\": doc['title'],\\n\",\n        \"            \\\"content\\\": doc['content']\\n\",\n        \"        }\\n\",\n        \"    )\\n\",\n        \"    points.append(point)\\n\",\n        \"\\n\",\n        \"# Upload points to Qdrant\\n\",\n        \"qdrant_client.upsert(\\n\",\n        \"    collection_name=collection_name,\\n\",\n        \"    points=points\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"print(f\\\"Successfully uploaded {len(points)} document embeddings to Qdrant\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Eb9j1pRZhEAB\"\n      },\n      \"source\": [\n        \"## Implement Semantic Search\\n\",\n        \"\\n\",\n        \"Now let's create a function to perform semantic search using our vector database.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"pGxOeaHChEt1\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def semantic_search(query, top_k=3):\\n\",\n        \"    \\\"\\\"\\\"Perform semantic search using Qdrant and return top matches\\\"\\\"\\\"\\n\",\n        \"    # Generate embedding for the query\\n\",\n        \"    query_embedding = get_embedding(query)\\n\",\n        \"    \\n\",\n        \"    # Search in Qdrant\\n\",\n        \"    search_results = qdrant_client.search(\\n\",\n        \"        collection_name=collection_name,\\n\",\n        \"        query_vector=query_embedding,\\n\",\n        \"        limit=top_k  # Number of results to return\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    # Format results\\n\",\n        \"    results = []\\n\",\n        \"    for result in search_results:\\n\",\n        \"        results.append({\\n\",\n        \"            \\\"id\\\": result.id,\\n\",\n        \"            \\\"score\\\": result.score,  # Similarity score\\n\",\n        \"            \\\"title\\\": result.payload[\\\"title\\\"],\\n\",\n        \"            \\\"content\\\": result.payload[\\\"content\\\"]\\n\",\n        \"        })\\n\",\n        \"    \\n\",\n        \"    return results\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"pJTaTbKsijJh\"\n      },\n      \"source\": [\n        \"Let's test our semantic search function with a few queries.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"9oUxiBBXijXP\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Let's try a few test queries\\n\",\n        \"test_queries = [\\n\",\n        \"    \\\"How do vector databases work?\\\",\\n\",\n        \"    \\\"What are the benefits of semantic search?\\\",\\n\",\n        \"    \\\"Tell me about embedding models\\\",\\n\",\n        \"    \\\"What is Gemini AI?\\\"\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"for query in test_queries:\\n\",\n        \"    print(f\\\"\\\\n\\\\nQuery: {query}\\\")\\n\",\n        \"    print(\\\"-\\\" * 80)\\n\",\n        \"    \\n\",\n        \"    results = semantic_search(query, top_k=2)\\n\",\n        \"    \\n\",\n        \"    for i, result in enumerate(results):\\n\",\n        \"        print(f\\\"Result {i+1} (Score: {result['score']:.4f})\\\")\\n\",\n        \"        print(f\\\"Title: {result['title']}\\\")\\n\",\n        \"        print(f\\\"Content: {result['content'][:150]}...\\\")\\n\",\n        \"        print()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"8Vvfn0_Gja7r\"\n      },\n      \"source\": [\n        \"## Implement RAG (Retrieval Augmented Generation) with Gemini\\n\",\n        \"\\n\",\n        \"Now let's use Gemini to generate answers based on the search results.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"JeI0nL7Ejch9\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def generate_answer(query, top_k=3):\\n\",\n        \"    \\\"\\\"\\\"Generate an answer using RAG approach with Gemini\\\"\\\"\\\"\\n\",\n        \"    # 1. Retrieve relevant documents\\n\",\n        \"    search_results = semantic_search(query, top_k=top_k)\\n\",\n        \"    \\n\",\n        \"    # 2. Format context from retrieved documents\\n\",\n        \"    context = \\\"\\\\n\\\\n\\\".join([f\\\"Document: {r['title']}\\\\n{r['content']}\\\" for r in search_results])\\n\",\n        \"    \\n\",\n        \"    # 3. Generate answer using Gemini\\n\",\n        \"    model = genai.GenerativeModel('gemini-pro')\\n\",\n        \"    \\n\",\n        \"    prompt = f\\\"\\\"\\\"\\n\",\n        \"    You are a helpful AI assistant who provides accurate and informative answers based on the given context.\\n\",\n        \"    \\n\",\n        \"    Context information:\\n\",\n        \"    {context}\\n\",\n        \"    \\n\",\n        \"    Based only on the context information provided above, answer the following question:\\n\",\n        \"    Question: {query}\\n\",\n        \"    \\n\",\n        \"    If the context doesn't contain enough information to answer the question, say so. Don't make up information that's not supported by the context.\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    \\n\",\n        \"    response = model.generate_content(prompt)\\n\",\n        \"    \\n\",\n        \"    return {\\n\",\n        \"        \\\"query\\\": query,\\n\",\n        \"        \\\"answer\\\": response.text,\\n\",\n        \"        \\\"sources\\\": [{\\n\",\n        \"            \\\"title\\\": r[\\\"title\\\"],\\n\",\n        \"            \\\"score\\\": r[\\\"score\\\"]\\n\",\n        \"        } for r in search_results]\\n\",\n        \"    }\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"66CJR-lrPYqp\"\n      },\n      \"source\": [\n        \"Let's test our RAG implementation with a few example questions:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"OJYbPQPJPX3X\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test questions\\n\",\n        \"questions = [\\n\",\n        \"    \\\"What are vector databases and how do they help with semantic search?\\\",\\n\",\n        \"    \\\"How do embedding models represent text data?\\\",\\n\",\n        \"    \\\"What is RAG and why is it useful?\\\",\\n\",\n        \"    \\\"What are the main features of Gemini?\\\"\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"for question in questions:\\n\",\n        \"    print(f\\\"\\\\n\\\\nQuestion: {question}\\\")\\n\",\n        \"    print(\\\"-\\\" * 80)\\n\",\n        \"    \\n\",\n        \"    result = generate_answer(question, top_k=3)\\n\",\n        \"    \\n\",\n        \"    print(\\\"Answer:\\\")\\n\",\n        \"    display(Markdown(result[\\\"answer\\\"]))\\n\",\n        \"    \\n\",\n        \"    print(\\\"\\\\nSources:\\\")\\n\",\n        \"    for source in result[\\\"sources\\\"]:\\n\",\n        \"        print(f\\\"- {source['title']} (Score: {source['score']:.4f})\\\")\\n\",\n        \"    \\n\",\n        \"    print(\\\"-\\\" * 80)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"qm92W2ejU6RG\"\n      },\n      \"source\": [\n        \"## Create an Interactive QA Demo\\n\",\n        \"\\n\",\n        \"Let's create a simple interactive function to ask questions to our RAG system:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"y52Cq01XU6er\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def ask_question():\\n\",\n        \"    while True:\\n\",\n        \"        # Get user question\\n\",\n        \"        question = input(\\\"\\\\nEnter your question (or 'exit' to quit): \\\")\\n\",\n        \"        \\n\",\n        \"        if question.lower() in [\\\"exit\\\", \\\"quit\\\", \\\"q\\\"]:\\n\",\n        \"            print(\\\"Goodbye!\\\")\\n\",\n        \"            break\\n\",\n        \"            \\n\",\n        \"        # Generate answer\\n\",\n        \"        print(\\\"\\\\nSearching and generating answer...\\\")\\n\",\n        \"        result = generate_answer(question, top_k=3)\\n\",\n        \"        \\n\",\n        \"        # Display answer\\n\",\n        \"        print(\\\"\\\\nAnswer:\\\")\\n\",\n        \"        display(Markdown(result[\\\"answer\\\"]))\\n\",\n        \"        \\n\",\n        \"        # Display sources\\n\",\n        \"        print(\\\"\\\\nSources:\\\")\\n\",\n        \"        for source in result[\\\"sources\\\"]:\\n\",\n        \"            print(f\\\"- {source['title']} (Score: {source['score']:.4f})\\\")\\n\",\n        \"            \\n\",\n        \"        print(\\\"\\\\n\\\" + \\\"-\\\"*80)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"3vD8_WfPVf4m\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Start the interactive QA system\\n\",\n        \"ask_question()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"bj4lxpWpVxQY\"\n      },\n      \"source\": [\n        \"## Extending the System\\n\",\n        \"\\n\",\n        \"Here are some ways you could extend this basic system:\\n\",\n        \"\\n\",\n        \"1. **Add document loading from files** - Create functions to load and process documents from various file formats (PDF, DOCX, etc.)\\n\",\n        \"2. **Implement chunking strategies** - Break longer documents into appropriate chunks for better retrieval\\n\",\n        \"3. **Add metadata filtering** - Allow filtering search results based on metadata (date, author, category, etc.)\\n\",\n        \"4. **Improve the UI** - Create a web interface using Streamlit or other frameworks\\n\",\n        \"5. **Add evaluation metrics** - Implement metrics to evaluate the quality of answers\\n\",\n        \"6. **Deploy to production** - Set up a production environment with a persistent Qdrant instance\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"zJw-xMljWQeB\"\n      },\n      \"source\": [\n        \"## Conclusion\\n\",\n        \"\\n\",\n        \"In this tutorial, we've created a functional semantic search and question-answering system using:\\n\",\n        \"\\n\",\n        \"1. Google's embedding models to create vector representations of text\\n\",\n        \"2. Qdrant as a vector database to store and retrieve these embeddings\\n\",\n        \"3. Gemini to generate accurate answers based on retrieved context\\n\",\n        \"\\n\",\n        \"This demonstrates the power of combining vector search with generative AI for building knowledge-based applications. You can extend this basic implementation in numerous ways to create more sophisticated systems tailored to your specific needs.\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"provenance\": []\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"name\": \"python\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006# Text categorization and filtering\n\nThese samples demonstrate how to use Gemini for text classification and content filtering across various applications.\n\n## Sentiment analysis\n\nThis sample classifies text into sentiment categories (positive, negative, or neutral).\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Analyze the sentiment of these customer reviews as positive, negative, or neutral. Provide a brief explanation for each classification:\\n\\n1. \\\"The food was amazing and the staff was incredibly friendly. Will definitely come back!\\\"\\n\\n2. \\\"It was okay, nothing special. The prices were reasonable though.\\\"\\n\\n3. \\\"Terrible experience. Waited over an hour for food that came cold. The manager was unhelpful when I complained.\\\"\\n\\n4. \\\"The product arrived on time but there was a small defect on one side. Customer service was helpful in resolving the issue.\\\"\\n\\nFormat your response as a table with columns for Review Number, Sentiment, and Explanation.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Topic classification\n\nThis sample categorizes text into predefined topic categories.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Classify each of the following news headlines into one of these categories: Politics, Technology, Business, Sports, Entertainment, Health, or Science. Provide a brief explanation for each classification.\\n\\n1. \\\"New Quantum Computing Breakthrough Could Transform Data Encryption\\\"\\n\\n2. \\\"Stock Markets Plunge as Inflation Concerns Grow\\\"\\n\\n3. \\\"Famous Actor Wins Award for Portrayal in Historical Drama\\\"\\n\\n4. \\\"Government Announces New Climate Policy Initiative\\\"\\n\\n5. \\\"Researchers Discover Potential Treatment for Alzheimer's Disease\\\"\\n\\nFormat your response as a table with columns for Headline Number, Category, and Explanation.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Content moderation\n\nThis sample analyzes text for inappropriate content across different categories.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Analyze the following comments for a moderation system. Classify each as either Safe or Flagged. If flagged, specify which category it falls under (Harassment, Hate Speech, Violence, Sexual Content, or Other Harmful Content).\\n\\n1. \\\"This article was really informative, thanks for sharing!\\\"\\n\\n2. \\\"Anyone who believes this nonsense is completely stupid and should be ignored.\\\"\\n\\n3. \\\"I disagree with the author's conclusion but appreciate the research.\\\"\\n\\n4. \\\"This is why we need stricter immigration policies to keep these people out.\\\"\\n\\n5. \\\"The government should focus on creating more jobs for everyone.\\\"\\n\\nProvide your analysis in a table format with columns for Comment Number, Classification, Category (if flagged), and a brief explanation.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Language detection\n\nThis sample identifies the language of different text samples.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Identify the language for each of the following text samples. For each, provide the language name and the language code (ISO 639-1 if applicable).\\n\\n1. \\\"Bonjour, comment allez-vous aujourd'hui?\\\"\\n\\n2. \\\"Das Wetter ist heute sehr schön.\\\"\\n\\n3. \\\"Me gustaría reservar una mesa para dos personas, por favor.\\\"\\n\\n4. \\\"Oggi ho mangiato una pizza deliziosa.\\\"\\n\\n5. \\\"Я не говорю по-английски очень хорошо.\\\"\\n\\nFormat your response as a table with columns for Sample Number, Language Name, Language Code, and a brief translation to English.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Intent classification\n\nThis sample categorizes customer queries by their intended purpose.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Classify the intent of each customer service query into one of these categories: Product Information, Technical Support, Billing Question, Return/Exchange, Complaint, or Account Management.\\n\\n1. \\\"My subscription was charged twice this month, can you help?\\\"\\n\\n2. \\\"I can't log into my account after the recent update.\\\"\\n\\n3. \\\"Does this laptop come with a warranty?\\\"\\n\\n4. \\\"The product I received is damaged and I'd like to return it.\\\"\\n\\n5. \\\"I'm very disappointed with the quality of service I've received.\\\"\\n\\n6. \\\"How do I change my shipping address for future orders?\\\"\\n\\nProvide your classification in a table with columns for Query Number, Intent Category, and a brief explanation.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Multi-label classification\n\nThis sample assigns multiple applicable categories to text samples.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Perform multi-label classification on these product reviews. For each review, identify all applicable categories from: Product Quality, Customer Service, Shipping/Delivery, Price/Value, Ease of Use, and Durability.\\n\\n1. \\\"The headphones arrived two days late, but the sound quality is excellent for the price.\\\"\\n\\n2. \\\"This kitchen appliance is well-made and incredibly intuitive to use, though it's a bit expensive compared to similar products.\\\"\\n\\n3. \\\"I've had this laptop for two years and it's still working perfectly. The customer support team was also very helpful when I had questions about the warranty.\\\"\\n\\n4. \\\"Delivery was quick but the product broke after just one week of normal use.\\\"\\n\\nFormat your response as a table with columns for Review Number, Applicable Categories (list all that apply), and Explanation.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Text summarization with categorization\n\nThis sample combines text summarization with categorization.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"For each of the following emails, provide a short summary (max 15 words) and classify it into one of these categories: Urgent Action Required, Information Only, Request for Information, or Follow-up Needed.\\n\\n1. \\\"Subject: Quarterly Report Due\\nHi Team, This is a reminder that the quarterly reports are due this Friday. Please make sure to submit them through the new portal we discussed in last week's meeting. Let me know if you have any questions about the new format requirements.\\\"\\n\\n2. \\\"Subject: Office Closure Notice\\nDear All, Please note that the office will be closed next Monday, May 15th, for building maintenance. All systems will remain operational, and remote work is expected as usual. No action is required.\\\"\\n\\n3. \\\"Subject: URGENT: Security Breach\\nAttention All Staff: We have detected a potential security breach in our customer database. Please change your passwords immediately and do not share any sensitive information via email until further notice. The security team is investigating.\\\"\\n\\n4. \\\"Subject: Request for Project Updates\\nHello, I'm preparing for the executive review next week and need status updates on all active projects. Could you please send me your current progress, any blockers, and expected completion dates by Wednesday?\\\"\\n\\nFormat your response as a table with columns for Email Number, Category, Summary, and Key Points.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\n## Advanced text classification\n\nThis sample performs more complex text classification with multiple dimensions.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Analyze these social media posts across multiple dimensions:\\n\\n1. Content Type (Informational, Opinion, Question, Promotional)\\n2. Tone (Positive, Neutral, Negative)\\n3. Subject Category (Technology, Politics, Entertainment, Health, Business, Other)\\n4. Target Audience (General Public, Professionals, Specific Interest Group)\\n\\nPosts:\\n\\n1. \\\"Just published my research on the impact of artificial intelligence on healthcare outcomes. Results show a 23% improvement in early diagnosis rates. Link to full paper in bio. #HealthTech #AI #Research\\\"\\n\\n2. \\\"Can anyone recommend a good budget-friendly laptop for a college student? Needs to handle basic programming and design software. Thanks!\\\"\\n\\n3. \\\"This new tax policy is absolutely terrible for small businesses. Another example of how disconnected politicians are from real economic challenges. #SmallBiz #PolicyFail\\\"\\n\\n4. \\\"FLASH SALE! 50% off all summer clothing this weekend only at our downtown location. Doors open 9AM Saturday! #ShopLocal #SummerSale\\\"\\n\\nProvide your analysis in a comprehensive table format.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,\n      \"maxOutputTokens\": 1024\n    }\n  }'</code>\n</pre>\n\u0005End File\u0006# site/en/gemini/quick-examples/summarization.md\n# Text summarization\n\nThis sample shows how to generate different types of summaries from a variety of input texts.\n\n## Basic text summarization\n\nGenerate a concise summary of a longer text.\n\n<pre class=\"devsite-click-to-copy\">\n<code class=\"devsite-terminal\">curl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\n  https://us-central1-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-1.5-flash:generateContent \\\n  -d '{\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"text\": \"Summarize the following text in a concise paragraph:\\n\\nArtificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans. AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\\n\\nThe term \\\"artificial intelligence\\\" had previously been used to describe machines that mimic and display \\\"human\\\" cognitive skills that are associated with the human mind, such as \\\"learning\\\" and \\\"problem-solving\\\". This definition has since been rejected by major AI researchers who now describe AI in terms of rationality and acting rationally, which does not limit how intelligence can be articulated.\\n\\nAI applications include advanced web search engines (e.g., Google), recommendation systems (used by YouTube, Amazon and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), automated decision-making and competing at the highest level in strategic game systems (such as chess and Go).\\n\\nAs machines become increasingly capable, tasks considered to require \\\"intelligence\\\" are often removed from the definition of AI, a phenomenon known as the AI effect. For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {\n      \"temperature\": 0.2,\n      \"topP\": 0.8,\n      \"topK\": 40,",
    "the-ultimate-training-manual-template-gu|category|1": "Produkthantering",
    "the-ultimate-training-manual-template-gu|category|2": "Dokumentationsportaler\n\u0005End File\u0006# ianderrington/genai-corpus\n# prompts/chat/Claude/history/eng/translation/chinese.md\nHuman: Please translate the following text to Chinese (Simplified). Please maintain the original style and structure, including any markdown formatting, paragraph breaks, etc. Translate the content only, do not translate names of people or organizations.\n\n\"How to Drive Innovation within Your Organization\n\nInnovation is the lifeblood of successful companies in today's rapidly changing business environment. However, cultivating a culture of innovation requires intentional effort and strategic planning. Here are some key approaches to drive innovation within your organization:\n\n1. **Create psychological safety** - Team members need to feel safe to take risks and share unconventional ideas without fear of negative consequences. Leaders should model vulnerability and openly acknowledge when they don't have all the answers.\n\n2. **Implement dedicated innovation time** - Companies like Google and 3M have famously allowed employees to spend a percentage of their work time on self-directed projects. This structured freedom often leads to breakthrough innovations.\n\n3. **Establish diverse teams** - Innovation thrives when people with different backgrounds, experiences, and thinking styles collaborate. Cognitive diversity brings multiple perspectives to problem-solving.\n\n4. **Develop a rapid prototyping mindset** - Encourage teams to quickly create minimum viable versions of their ideas that can be tested and refined through real-world feedback.\n\n5. **Reward innovative thinking** - Recognize and celebrate innovation attempts, not just successes. This reinforces that calculated risk-taking is valued within the organization.\n\nRemember that innovation isn't just about technology or product development. It can apply to business models, internal processes, customer experiences, and more. By building these practices into your organizational culture, you create an environment where innovation can flourish naturally.\"",
    "the-ultimate-training-manual-template-gu|category|3": "Bästa praxis",
    "the-ultimate-training-manual-template-gu|category|4": "Produktdokumentation Handledningar"
}
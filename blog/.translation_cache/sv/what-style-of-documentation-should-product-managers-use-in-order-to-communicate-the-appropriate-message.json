{
    "__metadata__": {
        "original_categories": [
            "Product Documentation",
            "Product Management",
            "Documentation Portals",
            "Best Practices",
            "Product Documentation Tutorials"
        ],
        "author_name": "Tal F.",
        "author_email": "tal@docsie.io",
        "author_info": "VP of Customer Success @ Docsie.io",
        "author_image": " https://cdn.docsie.io/user_profiles/15/logo_logo_QmXrbijvL0L2hFKNm6Q25DtjahujKdB6nu4pqBlLBgvtT.png",
        "header_image": "https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_1Og3QffsTgFL8pV68/0aa542c6-d2ff-4d6e-42aa-932d7f3665eeschool_supplies_ga298c5a8e_1280_min_(1).jpg",
        "timestamp": "2021-12-17T11:01:11+00:00",
        "status": 1
    },
    "what-style-of-documentation-should-produ|title": "Vilken typ av dokumentation bör produktchefer använda för att kommunicera rätt budskap?",
    "what-style-of-documentation-should-produ|summary": "Dokumentation är en av de mest avgörande och underuppskattade komponenterna i vilket open source-projekt som helst, och det bör inte tas lätt på.",
    "what-style-of-documentation-should-produ|markdown": "*Dokumentation är en av de viktigaste och mest underskattade komponenterna i alla open source-projekt, och den bör inte tas lätt på.*\n\nDe flesta open source-projekt får inte tillräcklig uppmärksamhet, oftast eftersom upphovspersonerna inte är intresserade av, saknar förmågan eller tiden att skapa en effektiv dokumentationsmiljö för sitt API och sin produkt.\n\nÄven om din applikation är utmärkt kommer användarna inte kunna dra nytta av den om dokumentationen är bristfällig.\n\nOm de ändå måste använda den av någon anledning, kommer de inte kunna göra det effektivt eller på det sätt du önskar.\n\nAtt lära sig skapa bra dokumentation kräver mycket arbete, liksom att regelbundet studera andra dokumentationsprojekt. Men tro mig - som någon som skapat mängder av dokumentation för Docsie - om du bygger kod som ska användas av andra än dig själv, särskilt om dessa personer är dina kunder, bör din produkt vara väldokumenterad, välformaterad och dynamiskt presenterad.\n\n![](https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_1Og3QffsTgFL8pV68/0aa542c6-d2ff-4d6e-42aa-932d7f3665eeschool_supplies_ga298c5a8e_1280_min_(1).jpg)\n\n## Vad är skillnaden mellan handledningar, guider, förklaringar och referenser?\n\nMånga tror felaktigt att dessa fyra begrepp betyder samma sak. De har dock olika betydelser. Dessa olika typer av dokumentation är viktiga och har några avgörande skillnader:\n\n**Handledningsdokumentation:** Informationsbaserad dokumentation inriktad på utbildning.\n\n**Steg-för-steg-guider/Användarguider:** Guidedokumentation visar hur man löser specifika problem genom en serie steg för att uppnå ett visst mål.\n\n**Förklarande dokumentation:** Artikelliknande dokumentation som hjälper användaren/läsaren att få djupare förståelse för en produkt genom förklaringar och bakgrundskontext.\n\n**Referensdokumentation:** Denna dokumentation informerar användaren om beskrivningar av olika nya funktioner och användningsområden. Denna typ kan vara mycket \"rå\" i form av utvecklardokumentation, men kan också översättas till mer användarvänliga versionsnoteringar som är lättare att förstå för slutanvändaren.\n\n## Skäl att producera högkvalitativ dokumentation\n\nInnan vi fortsätter är det viktigt att förstå varför kompetent dokumentationsskrivande är ett mycket viktigt men underskattat behov i dagens samhälle. Tillgången till omfattande och välskriven dokumentation är ett av de viktigaste kriterierna för att uppnå bred användning, särskilt i open source-projekt där nästan alla handlingar är tillgängliga för allmänheten och där sådana aktiviteter spelar en avgörande roll för projektets framgång.\n\nLåt oss titta på de viktigaste orsakerna till att skriva effektiv dokumentation.\n\n### Det skapar en bättre introduktionsupplevelse för dina kunder\n\n![](https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_kSeCio30GIM0RDS3J/2259983f-291d-fe8e-3cdd-6db630023e96ecommerce_g99f922364_1920_min_(1).jpg)\n\nNär du ger tillräcklig dokumentation om din produkt till dina kunder hjälper du dem att känna sig mer bekväma med din produkt och skyddade av dess specifika riktlinjer. För att detta ska ske måste du:\n\n1. Se till att din produktdokumentation är synlig och lättillgänglig, antingen via länkar i appen eller på en sökbar dokumentationsplattform.\n\n2. Se till att den är välskriven och hjälper kunden att hitta sitt svar snabbt och enkelt\n\nEtt tips är att skriva din dokumentation en gång, och den kommer att användas om och om igen när nya kunder kommer i kontakt med ditt företag.\n\n### Färre supportärenden som resultat\n\nKunder som läser och förstår din dokumentation är mer benägna att köpa din produkt. När kunder inte kan lista ut något kan det vara mycket frustrerande, och de kan börja skylla på din produkt.\n\nVissa kunder kontaktar omedelbart supportteamet om de stöter på problem, men om dokumentationen är attraktiv, lättillgänglig och begriplig kan de lösa sina egna problem utan att behöva konsultera dig, vilket i sin tur får dem att känna sig mer självständiga.\n\n### Det hjälper dig att stödja ditt eget team\n\n![](https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_oqXlcrJlQmjhGonqx/9f439b91-9f8f-343e-67c2-0291ec0da5f8teamwork_g8ce998b1c_1920_min_(1).jpg)\n\nEn robust kunskapsbas kan också användas för att hjälpa dina egna teammedlemmar. Ditt interna team bör vara informerat om nya funktioner, planerade färdplaner, API-dokumentation och allt annat som är nödvändigt för att hålla alla uppdaterade.\n\n### Steg-för-steg-anvisningar för att skriva effektiv dokumentation\n\nAtt skriva dokumentationens innehåll och strukturera detta arbete är helt skilda uppgifter från att bestämma vilken ton som ska användas och hur man ser till att dokumentationen är begriplig. Enligt [O'Reilly finns det 8 regler för bra dokumentation](https://www.oreilly.com/content/the-eight-rules-of-good-documentation/):\n\n1. **Skapa dokumentation som är inbjudande för läsaren.**\n\n2. **Producera grundlig dokumentation som täcker alla områden av projektet.**\n\n3. **Skapa material som är lätt att skumma igenom och förstå.**\n\n4. **Skapa dokumentation som visar hur man använder produkten genom fallstudier.**\n\n5. **Skriv dokumentation som innehåller upprepning där det är nödvändigt.**\n\n6. **Skriv dokumentation som är aktuell.**\n\n7. **Skriv dokumentation som är enkel att bidra till.**\n\n8. **Skriv dokumentation som är lätt att hitta och förstå.**\n\nDessa element handlar främst om innehållet. Nedan går vi igenom \"hur\" man strukturerar denna information i sex steg:\n\n### Bestäm vad du ska dokumentera\n\nTa dig tid att fundera över vilken typ av dokumentation du ska producera innan du börjar: är det en handledning, ett referensdokument, en instruktionsmanual eller en förklaring?\n\nObservera att din produkts natur kommer att ha direkt påverkan på vilken typ av dokumentation du ansvarar för att skapa.\n\n### Skapa ett ramverk\n\nBygg först en grund för din dokumentation. Det kan vara något väldigt litet i början och kan bestå av bara några få grupper, men med tiden kommer hela plattformen du bygger på att börja växa i storlek och komplexitet. Du bör regelbundet se över din organisationsstruktur.\n\nKom ihåg att du är läraren och du är ytterst ansvarig för hur dina elever lär sig i din klass. De kommer att vägledas av dina instruktioner; ju mer tid du lägger på struktur, desto mer framgångsrika kommer dina elever att vara i sina ansträngningar.\n\n### Använd alltid bra multimedietekniker\n\nSe till att du använder videor, teckningar och varierande stilar och integrerar dem direkt i din dokumentation. [Docsie](https://www.docsie.io/) möjliggör inbäddning av alla dessa inom vår plattform för att göra denna process enklare.\n\nDe hjälper inte bara kunderna att bättre förstå informationen du förmedlar, utan de ger också fantastisk sökmotoroptimering som leder till fler högkvalitativa leads tack vare din dynamiska dokumentation.\n\n![](https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_Tp5KRnREeB4BWVdBn/679dc5ee-07ce-4579-b1e1-39f8afa64dceSnag_73f0470f.png)\n\n### Se till att den är sökbar\n\nDet finns skillnader i sökfunktionerna på olika kunskapsbasplattformar - vissa erbjuder bara grundläggande sökning utan möjlighet att fördjupa sig i segment (vilket är tekniskt okej om du inte har tusentals filer), medan andra erbjuder frågealternativ som låter dig söka inte bara i dokument utan även i användarnamn.\n\nMen en sak är avgörande: du bör använda ett verktyg som låter dig söka snabbt. En sökfunktion inbyggd i appen gör det enkelt att söka efter filer och få en förhandsvisning av dem utan att lämna appen.\n\nDocsie låter dig ha dynamiskt sökbar navigering för lättillgänglig information.\n\n![](https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_L7xg4HA5BNd0rtjwk/58557bb6-ba77-792a-20e8-9f14fd2b2d16Snag_73f6a2a0.png)\n\n### Sträva ständigt efter att förbättra och uppdatera\n\nAtt skapa och använda dokument är svårt eftersom de snabbt glöms bort av personerna som skapade eller drog nytta av dem. Dokument möter också flera utmaningar under sin livstid.\n\nMed tiden börjar mappstrukturen likna en kyrkogård, eftersom äldre dokumentation tenderar att hamna längre ner på skärmen.\n\nSe därför till att gå igenom din gamla dokumentation och göra förbättringar, samt uppmuntra dina kollegor att göra detsamma då och då. Docsie låter dig skapa uppdateringar genom vårt avancerade versionssystem som är enkelt att använda.\n\n![](https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_ICAmxGtiRnaADNias/228e6de7-cf2c-4104-ac68-5b9d5909d572Snag_73f34a8b.png)\n\n## Avslutande tankar:\n\n![](https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_IDYTWOaZCuq9mWwra/file_FcM2MxTAr0FVwDFKD/3688a2ad-947a-c45a-e49d-7ec08160b1a7tingey_injury_law_firm_9SKhDFnw4c4_unsplash_min_(1).jpg)\n\nVill du veta mer om hur man skriver effektiv dokumentation? För professionella inom mjukvarudokumentation finns det massor av bloggar och information att hitta [här](https://www.docsie.io/blog/).",
    "what-style-of-documentation-should-produ|category|0": "Produktdokumentation\n\u0005End File\u0006# llm-math/deepprompt\n# evaluation/eval_claude_3_opus/translated/Translate_Ivo_Andric-bs.md\nHuman: Translate the following text to Bosnian:\n\nSerbian literature became a vehicle for expressing a new form of Yugoslavism—a view of South Slavic unification that had been growing since the early nineteenth century with the decline of the Ottoman Empire and the Romantic literary movement. Yugoslavism was a vision of unification of South Slavs into one state under different names and models, which began to be articulated in the early nineteenth century by poets and writers. Romantic poets such as Sima Milutinović Sarajlija, Branko Radičević, Petar Petrović Njegoš, and Petar Preradović wrote about the shared origins and experiences of Serbs, Croats, and other South Slavs. Serbian Romantic poetry was particularly strong in emphasizing the ethnic and cultural unity of South Slavs.\n\nHowever, Serbian writers and political leaders could not conceive of unification other than as an extension of the Serbian experience, an idea that would later come back to fracture the Yugoslav idea. The South Slav movement, Yugoslavism, was therefore more complex and nuanced than the official histories of either Kingdom of Yugoslavia or socialist Yugoslavia would lead one to believe. Yugoslavism was grounded in the primacy of language, which was promoted by a number of South Slav intellectuals. By the end of the nineteenth century, a number of thinkers and writers developed the idea of a Yugoslav cultural unity, which, importantly, they described as consisting of at least three groups of South Slavs: Slovenes, Croats, and Serbs.\n\nNovelist and literary critic Jovan Skerlić (1877–1914) was emblematic of an important strand of early twentieth-century liberal Yugoslavism. Skerlić was critical of folk idealization as being too primitive, and he posited that the model of a South Slav federation could be found in West European democracies. Skerlić advocated a fusion between Serbian and Croatian literary languages, which he saw as his generation's political duty, though he did not believe the fusion would lead to a complete eradication of differences. His proposal was based on Štokavian as the standard literary language that would use the Latin script (as opposed to Cyrillic) and the Ekavian dialect (as opposed to Ijekavian, spoken in Croatia, Bosnia and Herzegovina, and Montenegro). \n\nIvo Andrić (1892–1975), the renowned novelist and Nobel Prize winner, was deeply influenced by the ideas of Yugoslavism. Born in Bosnia and Herzegovina to Croat parents, Andrić was a complex figure who navigated the shifting political landscapes of the Balkans throughout his life. In his early years, he was associated with the Young Bosnia movement, which advocated for South Slav unity and independence from Austria-Hungary. His early works, particularly his poetry, were influenced by the idea of Yugoslav unity.\n\nAfter World War I, Andrić worked as a diplomat for the newly formed Kingdom of Serbs, Croats, and Slovenes (later renamed the Kingdom of Yugoslavia), serving in various European capitals. During this period, he began to focus more on historical narratives, exploring the impact of Ottoman rule on Bosnia and the complex interplay of different religious and ethnic groups in the region.\n\nAndrić's most famous works, including the novels \"The Bridge on the Drina,\" \"Bosnian Chronicle,\" and \"The Woman from Sarajevo,\" were written during World War II when he was living in seclusion in Belgrade. These novels delve into the historical experiences of Bosnia under Ottoman and Austro-Hungarian rule, examining the tensions and interactions between Muslims, Christians, and Jews. While not explicitly political, these works can be read as explorations of the historical conditions that shaped the Yugoslav lands and the challenges of creating a unified identity amid cultural and religious differences.\n\nAfter World War II, Andrić's relationship with the communist Yugoslav government was ambivalent. He was respected as a cultural figure and did not openly oppose the regime, but neither did he actively promote its ideology. His works were celebrated as part of the Yugoslav cultural canon, and his international recognition, culminating in the Nobel Prize for Literature in 1961, brought prestige to Yugoslavia.\n\nAndrić's personal identity was complex. Born to Catholic Croat parents, educated in Bosnia, Croatia, Austria, and Poland, and later living primarily in Belgrade, he resisted simple ethnic categorization. When asked about his national identity, he reportedly responded, \"I am a writer. That is my only determination.\" This ambiguity has led to posthumous claims on his legacy by Serbian, Croatian, and Bosnian national movements, each emphasizing different aspects of his biography and work.\n\nIn his essay \"Letter from 1920,\" Andrić's narrator describes Bosnia as a land of hatred, where different religious and ethnic groups live side by side but divided by invisible walls. This pessimistic view of the possibility of peaceful coexistence contrasts with the optimistic Yugoslavism of the interwar period. Yet, in his acceptance speech for the Nobel Prize, Andrić spoke of the universality of storytelling and its power to bridge divides between people, suggesting a more hopeful perspective.\n\nAndrić's complex relationship with Yugoslavism reflects the broader challenges of the Yugoslav project itself: the tension between unity and diversity, the weight of historical divisions, and the difficulty of forging a common identity while acknowledging distinct cultural traditions. His work continues to be a rich source for understanding the historical and cultural complexities of the Balkans.",
    "what-style-of-documentation-should-produ|category|1": "Produkthantering",
    "what-style-of-documentation-should-produ|category|2": "Dokumentationsportaler",
    "what-style-of-documentation-should-produ|category|3": "Bästa praxis",
    "what-style-of-documentation-should-produ|category|4": "Produktdokumentation Handledningar\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/pricing.md\n# Claude pricing\n\nThis document lists Anthropic Claude models that are available on Google Cloud's Vertex AI. Each model requires a certain quota.\n\nFor model description, features, and endpoints, see [Claude Models](/gemini/docs/model-overview).\n\n## Claude models\n\nModel type | Pricing by tokens |\n--- | --- |\nClaude 3 Opus | $15.00/1M input tokens <br> $75.00/1M output tokens\nClaude 3 Sonnet | $3.00/1M input tokens <br> $15.00/1M output tokens\nClaude 3 Haiku | $0.25/1M input tokens <br> $1.25/1M output tokens\nClaude 3.5 Sonnet | $3.00/1M input tokens <br> $15.00/1M output tokens\n\nFor more information, see [Anthropic's website](https://www.anthropic.com/api).\n\u0005End File\u0006\n\n### Prerequisites: Download dataset\n\nThis notebook makes use of a dataset stored in GitHub: https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/language/use-cases/text-classification\n\nDownload the dataset so it is available locally for this notebook.\n\n\n```python\n!wget -q https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/language/use-cases/text-classification/spam_classification.csv\n!wget -q https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/language/use-cases/text-classification/intent_classification.csv\n```\n\n## In this notebook:\n\nYou'll use Gemini to identify the intention behind user messages. \n\nThis technique is useful for a customer service chatbot, which needs to answer user questions intelligently.\n\nWe'll use:\n\n* **Zero-shot classification**: When Gemini makes predictions without training examples\n* **Few-shot classification**: When we provide Gemini with a few examples to guide its predictions\n\n## Overview\n\n### 1. Classify emails as spam or ham\n\n* Zero-shot approach\n* Evaluate performance\n\n### 2. Identify user intent \n\n* Zero-shot approach for intent classification\n* Add examples (few-shot) for improved classification\n* Compare results\n\n## Setup environment and import libraries\n\n\n```python\n# Make sure you're using the latest version of the Vertex AI SDK\n%pip install --upgrade google-cloud-aiplatform -q\n```\n\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\n```\n\n\n```python\n# Initialize Vertex AI\nvertexai.init()\n\n# Load the Gemini model\nmodel = GenerativeModel(\"gemini-1.5-pro\")\n```\n\n## Part 1: Spam Classification\n\n### Load the dataset\n\nThis dataset contains text messages labeled as spam or ham (not spam).\n\n\n```python\n# Load the spam classification dataset\nspam_df = pd.read_csv(\"spam_classification.csv\")\n\n# Display the first few rows\nspam_df.head()\n```\n\n\n```python\n# Check class distribution\nspam_df[\"Category\"].value_counts()\n```\n\n\n```python\n# Let's sample a small subset to work with (for faster execution)\nsample_size = 100\nspam_sample = spam_df.sample(sample_size, random_state=42)\n```\n\n### Zero-shot Classification\n\nIn zero-shot classification, we ask the model to classify messages without providing any examples.\n\n\n```python\ndef classify_message(message):\n    \"\"\"\n    Classify a message as spam or ham using Gemini.\n    \n    Args:\n        message: The text message to classify\n        \n    Returns:\n        The classification: \"spam\" or \"ham\"\n    \"\"\"\n    prompt = f\"\"\"\n    Classify the following message as either \"spam\" or \"ham\" (not spam).\n    Only respond with the word \"spam\" or \"ham\".\n    \n    Message: {message}\n    \"\"\"\n    \n    response = model.generate_content(prompt)\n    return response.text.strip().lower()\n```\n\n\n```python\n# Test the classification function with a few examples\ntest_messages = [\n    \"URGENT: You have won a 1,000 prize! Call now to claim\",\n    \"Hey, can we meet at 5pm tomorrow for coffee?\"\n]\n\nfor message in test_messages:\n    classification = classify_message(message)\n    print(f\"Message: {message}\")\n    print(f\"Classification: {classification}\")\n    print()\n```\n\n\n```python\n# Classify all messages in our sample\nspam_sample[\"predicted\"] = spam_sample[\"Message\"].apply(classify_message)\n```\n\n\n```python\n# Convert categories to lowercase for consistency\nspam_sample[\"Category\"] = spam_sample[\"Category\"].str.lower()\n```\n\n\n```python\n# Calculate accuracy\naccuracy = (spam_sample[\"Category\"] == spam_sample[\"predicted\"]).mean()\nprint(f\"Accuracy: {accuracy:.2f}\")\n```\n\n\n```python\n# Display classification report\nprint(classification_report(spam_sample[\"Category\"], spam_sample[\"predicted\"]))\n```\n\n\n```python\n# Create a confusion matrix\nconf_matrix = confusion_matrix(\n    spam_sample[\"Category\"], spam_sample[\"predicted\"], labels=[\"ham\", \"spam\"]\n)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    conf_matrix,\n    annot=True,\n    fmt=\"d\",\n    cmap=\"Blues\",\n    xticklabels=[\"ham\", \"spam\"],\n    yticklabels=[\"ham\", \"spam\"],\n)\nplt.ylabel(\"Actual\")\nplt.xlabel(\"Predicted\")\nplt.title(\"Confusion Matrix for Spam Classification\")\nplt.show()\n```\n\n## Part 2: Intent Classification\n\n### Load the dataset\n\nThis dataset contains customer service messages with different intents.\n\n\n```python\n# Load the intent classification dataset\nintent_df = pd.read_csv(\"intent_classification.csv\")\n\n# Display the first few rows\nintent_df.head()\n```\n\n\n```python\n# Check the unique intents and their distribution\nintent_df[\"intent\"].value_counts()\n```\n\n\n```python\n# Sample a subset of the data\nintent_sample = intent_df.sample(50, random_state=42)\n```\n\n### Zero-Shot Intent Classification\n\n\n```python\ndef classify_intent_zero_shot(message):\n    \"\"\"\n    Classify the intent of a message using zero-shot classification.\n    \n    Args:\n        message: The customer message to classify\n        \n    Returns:\n        The classified intent\n    \"\"\"\n    prompt = f\"\"\"\n    Classify the following customer service message into one of these intents:\n    - general_inquiry\n    - technical_support\n    - billing_question\n    - product_complaint\n    - account_management\n    \n    Respond with only one of the above intent categories.\n    \n    Message: {message}\n    \"\"\"\n    \n    response = model.generate_content(prompt)\n    return response.text.strip().lower()\n```\n\n\n```python\n# Test the zero-shot classification\ntest_intents = [\n    \"How do I reset my password?\",\n    \"Why was I charged $50 on my last bill?\",\n    \"Your product stopped working after just two days.\",\n]\n\nfor message in test_intents:\n    intent = classify_intent_zero_shot(message)\n    print(f\"Message: {message}\")\n    print(f\"Intent: {intent}\")\n    print()\n```\n\n\n```python\n# Classify all messages in our sample using zero-shot\nintent_sample[\"predicted_zero_shot\"] = intent_sample[\"text\"].apply(classify_intent_zero_shot)\n```\n\n\n```python\n# Calculate accuracy for zero-shot\nzero_shot_accuracy = (intent_sample[\"intent\"] == intent_sample[\"predicted_zero_shot\"]).mean()\nprint(f\"Zero-shot accuracy: {zero_shot_accuracy:.2f}\")\n\n# Display classification report\nprint(\"\\nZero-shot classification report:\")\nprint(classification_report(intent_sample[\"intent\"], intent_sample[\"predicted_zero_shot\"]))\n```\n\n### Few-Shot Intent Classification\n\nLet's improve our classification by providing examples of each intent.\n\n\n```python\ndef classify_intent_few_shot(message):\n    \"\"\"\n    Classify the intent of a message using few-shot classification.\n    \n    Args:\n        message: The customer message to classify\n        \n    Returns:\n        The classified intent\n    \"\"\"\n    prompt = f\"\"\"\n    Classify the following customer service message into one of these intents:\n    - general_inquiry\n    - technical_support\n    - billing_question\n    - product_complaint\n    - account_management\n    \n    Here are some examples:\n    \n    Message: \"What are your opening hours?\"\n    Intent: general_inquiry\n    \n    Message: \"My internet connection keeps dropping every few minutes.\"\n    Intent: technical_support\n    \n    Message: \"I think there's a mistake on my bill from last month.\"\n    Intent: billing_question\n    \n    Message: \"The product arrived damaged and doesn't work properly.\"\n    Intent: product_complaint\n    \n    Message: \"I need to update my shipping address for future orders.\"\n    Intent: account_management\n    \n    Now classify this message:\n    Message: {message}\n    \n    Respond with only one of the intent categories.\n    \"\"\"\n    \n    response = model.generate_content(prompt)\n    return response.text.strip().lower()\n```\n\n\n```python\n# Test the few-shot classification with the same examples\nfor message in test_intents:\n    intent = classify_intent_few_shot(message)\n    print(f\"Message: {message}\")\n    print(f\"Intent: {intent}\")\n    print()\n```\n\n\n```python\n# Classify all messages in our sample using few-shot\nintent_sample[\"predicted_few_shot\"] = intent_sample[\"text\"].apply(classify_intent_few_shot)\n```\n\n\n```python\n# Calculate accuracy for few-shot\nfew_shot_accuracy = (intent_sample[\"intent\"] == intent_sample[\"predicted_few_shot\"]).mean()\nprint(f\"Few-shot accuracy: {few_shot_accuracy:.2f}\")\n\n# Display classification report\nprint(\"\\nFew-shot classification report:\")\nprint(classification_report(intent_sample[\"intent\"], intent_sample[\"predicted_few_shot\"]))\n```\n\n\n```python\n# Compare both approaches\ncomparison = pd.DataFrame({\n    \"Text\": intent_sample[\"text\"],\n    \"True Intent\": intent_sample[\"intent\"],\n    \"Zero-shot\": intent_sample[\"predicted_zero_shot\"],\n    \"Few-shot\": intent_sample[\"predicted_few_shot\"]\n})\n\n# Add columns to show if each approach was correct\ncomparison[\"Zero-shot Correct\"] = comparison[\"True Intent\"] == comparison[\"Zero-shot\"]\ncomparison[\"Few-shot Correct\"] = comparison[\"True Intent\"] == comparison[\"Few-shot\"]\n\n# Display where the approaches differed\ndifferences = comparison[comparison[\"Zero-shot Correct\"] != comparison[\"Few-shot Correct\"]]\ndifferences\n```\n\n\n```python\n# Plot comparison of accuracies\naccuracies = [zero_shot_accuracy, few_shot_accuracy]\nmethods = [\"Zero-shot\", \"Few-shot\"]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(methods, accuracies, color=[\"skyblue\", \"lightgreen\"])\nplt.ylim(0, 1.0)\nplt.title(\"Comparison of Classification Methods\")\nplt.ylabel(\"Accuracy\")\n\n# Add accuracy values on top of the bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 0.01,\n        f\"{height:.2f}\",\n        ha=\"center\",\n    )\n\nplt.tight_layout()\nplt.show()\n```\n\n## Confusion matrices for both approaches\n\n\n```python\n# Create confusion matrices\ndef plot_confusion_matrix(y_true, y_pred, title):\n    # Get unique classes\n    classes = sorted(intent_df[\"intent\"].unique())\n    \n    # Create confusion matrix\n    cm = confusion_matrix(y_true, y_pred, labels=classes)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(\n        cm, \n        annot=True, \n        fmt=\"d\", \n        cmap=\"Blues\", \n        xticklabels=classes, \n        yticklabels=classes\n    )\n    plt.ylabel(\"Actual Intent\")\n    plt.xlabel(\"Predicted Intent\")\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n\n# Plot confusion matrices\nplot_confusion_matrix(\n    intent_sample[\"intent\"], \n    intent_sample[\"predicted_zero_shot\"], \n    \"Zero-shot Classification Confusion Matrix\"\n)\n\nplot_confusion_matrix(\n    intent_sample[\"intent\"], \n    intent_sample[\"predicted_few_shot\"], \n    \"Few-shot Classification Confusion Matrix\"\n)\n```\n\n## Conclusion\n\nIn this notebook, we explored how to use Gemini for text classification tasks:\n\n1. **Spam Classification**:\n   - Used zero-shot classification to identify spam messages\n   - Achieved good accuracy without providing examples\n\n2. **Intent Classification**:\n   - Compared zero-shot and few-shot approaches\n   - Demonstrated how providing examples (few-shot) improves classification accuracy\n   - Analyzed where the approaches differed\n\n### Key Takeaways:\n\n- Gemini performs well on text classification tasks without extensive training\n- Few-shot learning provides significant improvement over zero-shot classification\n- The choice of examples for few-shot learning is important for optimal performance\n- The model handles both straightforward classifications (spam/ham) and more nuanced intents\n\n### Applications:\n\nThese techniques can be applied to:\n- Customer service chatbots\n- Email filtering\n- Social media comment moderation\n- Support ticket routing\n- And many other text classification needs\n\u0005End File\u0006# site/en/genai-on-vertex/tutorials/video-overview.ipynb\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"SXRRyZM79FE-\"\n      },\n      \"source\": [\n        \"# Gemini API: Working with videos\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/genai-on-vertex/tutorials/video-overview.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"E34MHJPqIqw5\"\n      },\n      \"source\": [\n        \"## Prerequisites\\n\",\n        \"\\n\",\n        \"If you're running this notebook on Colab, you will need a Google Cloud project with the Vertex AI API enabled to run this notebook. Learn more about [setting up a project and environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"BBEg9mwYI1c5\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"! pip install google-cloud-aiplatform\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"XPUUdWCrJDN4\"\n      },\n      \"source\": [\n        \"You will need to provide authentication credentials to access Google Cloud APIs.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"oVZTvqzgJGsO\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"from google.colab import auth\\n\",\n        \"auth.authenticate_user()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"3jx1Z-WCJK0Z\"\n      },\n      \"source\": [\n        \"Set your Google Cloud project ID, replacing the placeholder with your own.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"wYdnko4UJPEH\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"PROJECT_ID = \\\"your-project-id\\\"  # @param {type:\\\"string\\\"}\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"VV7G-DYqJWN7\"\n      },\n      \"source\": [\n        \"## Overview\\n\",\n        \"\\n\",\n        \"The Gemini API makes working with video content simple. You can send video content to multimodal models that understand videos, allowing them to provide insights, descriptions, and answers based on what's happening in videos.\\n\",\n        \"\\n\",\n        \"This notebook shows you how to:\\n\",\n        \"\\n\",\n        \"1. Initialize the model\\n\",\n        \"2. Prepare video content \\n\",\n        \"3. Generate a video description\\n\",\n        \"4. Ask questions about a video\\n\",\n        \"5. Extract information and insights from a video\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"9vwqRp-RKBZH\"\n      },\n      \"source\": [\n        \"## Setup\\n\",\n        \"\\n\",\n        \"Import the necessary libraries and initialize a `GenerativeModel`.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"KwbRCiGCKDvx\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"import base64\\n\",\n        \"import os\\n\",\n        \"import requests\\n\",\n        \"import IPython.display as display\\n\",\n        \"from IPython.display import HTML, display\\n\",\n        \"from pathlib import Path\\n\",\n        \"\\n\",\n        \"import vertexai\\n\",\n        \"from vertexai.generative_models import GenerativeModel, Part\\n\",\n        \"\\n\",\n        \"# Initialize Vertex AI\\n\",\n        \"vertexai.init(project=PROJECT_ID, location=\\\"us-central1\\\")\\n\",\n        \"\\n\",\n        \"# Load the Gemini 1.5 Pro model\\n\",\n        \"model = GenerativeModel(\\\"gemini-1.5-pro\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"n0MGU50dKI4F\"\n      },\n      \"source\": [\n        \"## Loading video content\\n\",\n        \"\\n\",\n        \"There are multiple ways to provide video content to the Gemini API. Below are some of the common approaches.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"iBl7k2QiKO88\"\n      },\n      \"source\": [\n        \"### Method 1: Load a video file from a URL\\n\",\n        \"\\n\",\n        \"You can use a publicly available video URL to load a video. Let's download a sample video of a corgi running on a beach.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"FZMIGWJuKZUP\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define a URL for a sample video\\n\",\n        \"video_url = \\\"https://storage.googleapis.com/cloud-samples-data/generative-ai/video/animals.mp4\\\"\\n\",\n        \"\\n\",\n        \"# Download the video to a file\\n\",\n        \"response = requests.get(video_url)\\n\",\n        \"video_file_path = \\\"corgi_video.mp4\\\"\\n\",\n        \"with open(video_file_path, \\\"wb\\\") as f:\\n\",\n        \"    f.write(response.content)\\n\",\n        \"\\n\",\n        \"# Display the video\\n\",\n        \"display(HTML(f\\\"<video width='640' height='360' controls><source src='{video_url}' type='video/mp4'></video>\\\"))\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"sX2DXgb0KbRX\"\n      },\n      \"source\": [\n        \"### Method 2: Upload a local video file\\n\",\n        \"\\n\",\n        \"You can also upload a video file directly from your computer.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"_fIBhXOIKdu1\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# This code is for demonstration purposes. In an actual notebook environment with file upload capabilities, \\n\",\n        \"# you would use something like the following:\\n\",\n        \"\\n\",\n        \"# from google.colab import files\\n\",\n        \"# uploaded = files.upload()  # This will prompt you to upload a file\\n\",\n        \"# video_file_path = next(iter(uploaded.keys()))\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"dQCB_5A5KhEM\"\n      },\n      \"source\": [\n        \"## Creating video Parts for the Gemini API\\n\",\n        \"\\n\",\n        \"To process videos with Gemini, you need to convert your video file into a `Part` object.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"XZ9AxY0tKjsL\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def load_video_from_file(file_path):\\n\",\n        \"    \\\"\\\"\\\"Load a video file and convert it to a Gemini API compatible Part.\\\"\\\"\\\"\\n\",\n        \"    with open(file_path, \\\"rb\\\") as f:\\n\",\n        \"        video_bytes = f.read()\\n\",\n        \"    video_part = Part.from_data(video_bytes, mime_type=\\\"video/mp4\\\")\\n\",\n        \"    return video_part\\n\",\n        \"\\n\",\n        \"# Load the video as a Part object\\n\",\n        \"video_part = load_video_from_file(video_file_path)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"wnHAiPtbKokZ\"\n      },\n      \"source\": [\n        \"## Video Description\\n\",\n        \"\\n\",\n        \"Let's ask the model to provide a detailed description of the video content.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"SfpRB9N_KrJl\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate a description of the video\\n\",\n        \"prompt = \\\"Describe in detail what's happening in this video.\\\"\\n\",\n        \"response = model.generate_content([prompt, video_part])\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"qFGPYXa8Ks_a\"\n      },\n      \"source\": [\n        \"## Asking Questions About the Video\\n\",\n        \"\\n\",\n        \"You can ask specific questions about the video content.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"B4NHtDg0KvIf\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Ask questions about the video\\n\",\n        \"questions = [\\n\",\n        \"    \\\"What animals appear in this video?\\\",\\n\",\n        \"    \\\"What is the corgi doing in the video?\\\",\\n\",\n        \"    \\\"What's the setting of this video?\\\"\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"for question in questions:\\n\",\n        \"    response = model.generate_content([question, video_part])\\n\",\n        \"    print(f\\\"Q: {question}\\\")\\n\",\n        \"    print(f\\\"A: {response.text}\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"MQQxg3YVKzTr\"\n      },\n      \"source\": [\n        \"## Extracting Information from the Video\\n\",\n        \"\\n\",\n        \"You can use Gemini to extract specific information and insights from video content.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"i1UmcUxTK1gA\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Extract insights from the video\\n\",\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Please provide the following information about this video:\\n\",\n        \"1. A list of all animals that appear\\n\",\n        \"2. The main activities happening in the video\\n\",\n        \"3. The approximate time when different animals appear\\n\",\n        \"4. The environment/setting of the video\\n\",\n        \"5. Any notable behaviors or interesting moments\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, video_part])\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"HuIOejXrK3Q0\"\n      },\n      \"source\": [\n        \"## Analyzing Video Segments\\n\",\n        \"\\n\",\n        \"You can ask the model to focus on specific moments or segments of the video.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"C-QZ9VpIK5k7\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"Focus on the first 5 seconds of the video. What animal do you see and what is it doing?\\\"\\n\",\n        \"response = model.generate_content([prompt, video_part])\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"aPnZ32fUK7OB\"\n      },\n      \"source\": [\n        \"## Additional Video Example: Drone Footage\\n\",\n        \"\\n\",\n        \"Let's try another example with a different type of video - drone footage of a city.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Vyi7bKJ-K9VC\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define a URL for a drone footage video\\n\",\n        \"drone_video_url = \\\"https://storage.googleapis.com/cloud-samples-data/generative-ai/video/nyc.mp4\\\"\\n\",\n        \"\\n\",\n        \"# Download the video to a file\\n\",\n        \"response = requests.get(drone_video_url)\\n\",\n        \"drone_video_file_path = \\\"drone_footage.mp4\\\"\\n\",\n        \"with open(drone_video_file_path, \\\"wb\\\") as f:\\n\",\n        \"    f.write(response.content)\\n\",\n        \"\\n\",\n        \"# Load the video as a Part object\\n\",\n        \"drone_video_part = load_video_from_file(drone_video_file_path)\\n\",\n        \"\\n\",\n        \"# Display the video\\n\",\n        \"display(HTML(f\\\"<video width='640' height='360' controls><source src='{drone_video_url}' type='video/mp4'></video>\\\"))\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"iiMWm15oK_j1\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate a description of the drone footage\\n\",\n        \"prompt = \\\"Describe this video footage in detail. What city do you think this is? What landmarks can you identify?\\\"\\n\",\n        \"response = model.generate_content([prompt, drone_video_part])\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"QJrwI-iLLBmJ\"\n      },\n      \"source\": [\n        \"## Advanced Use Cases\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"5-vfhsTWLDR1\"\n      },\n      \"source\": [\n        \"### Technical Analysis\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"24oKQB4xLFTP\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Analyze this drone footage from a cinematography perspective. Please discuss:\\n\",\n        \"1. The camera movements and techniques used\\n\",\n        \"2. The quality of the footage\\n\",\n        \"3. Lighting and time of day\\n\",\n        \"4. Suggestions for how to improve similar footage\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, drone_video_part])\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"IxvHVdOPLHhS\"\n      },\n      \"source\": [\n        \"### Combining Video with Text Instructions\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Yf3Ul1joLJ21\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"prompt = \\\"\\\"\\\"\\n\",\n        \"Based on this video of New York City, create a short 3-day itinerary for tourists \\n\",\n        \"focusing on the areas shown in the footage. Include specific places to visit, \\n\",\n        \"recommendations for food, and best times to visit each location.\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = model.generate_content([prompt, drone_video_part])\\n\",\n        \"print(response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"cS2Ac50-LL0Y\"\n      },\n      \"source\": [\n        \"## Conclusion\\n\",\n        \"\\n\",\n        \"In this notebook, you've learned how to:\\n\",\n        \"\\n\",\n        \"1. Load video content from different sources\\n\",\n        \"2. Create video Parts for the Gemini API\\n\",\n        \"3. Generate detailed descriptions of videos\\n\",\n        \"4. Ask specific questions about video content\\n\",\n        \"5. Extract structured information from videos\\n\",\n        \"6. Perform advanced analysis of video content\\n\",\n        \"\\n\",\n        \"The Gemini API's ability to understand and analyze video opens up a wide range of applications, from content moderation and automatic captioning to creative content generation and technical analysis.\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"name\": \"video-overview.ipynb\",\n      \"toc_visible\": true\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"name\": \"python3\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006# site/en/gemini/docs/models/overview.md\n# Model overview\n\n## Introduction\n\nGemini models can understand virtually any input, are built from the ground up to be multimodal, and have state-of-the-art capabilities.\n\nThe current generation of Gemini models includes:\n\n- Gemini 1.5 Pro\n- Gemini 1.5 Flash\n- Gemini 1.0 Pro\n- Gemini 1.0 Ultra\n- Gemini 1.0 Flash (formerly known as Gemini 1.0 Pro Vision)\n\nGemini 1.5 Pro provides Gemini's most advanced capabilities for handling highly complex tasks and for long-context understanding. It can process up to 1 million (or 2<sup>20</sup> = 1,048,576) tokens across text, images, audio, and video inputs.\n\nGemini 1.5 Flash balances speed and quality for regular generation and multimodal use cases, with a 1-million token context window like Gemini 1.5 Pro.\n\nGemini 1.0 Pro is an advanced model built for scaling across a wide range of tasks. It can handle complex reasoning, instruction following, and creative content generation.\n\nGemini 1.0 Ultra has enhanced capabilities in complex reasoning, instruction following, coding, and multimodal use cases.\n\nGemini 1.0 Flash is a fast multimodal model built for input understanding and high-volume use cases. It is cost-effective and built for vision and language tasks like image and text understanding, conversational prompting, document question-answering, and knowledge-grounded response generation.\n\n## Gemini models available in Google AI Studio\n\n| Model | Description |\n|---|---|\n| Gemini 1.5 Pro | Gemini's most advanced model capable of highly complex tasks. 1 million token context window. Handles text, code, audio, video, and image content. |\n| Gemini 1.5 Flash | Designed for speed and efficiency with a high-quality multimodal experience. 1 million token context window. |\n| Gemini 1.0 Pro | Optimized for scaling across a wide range of tasks, with a 32K context window. Handles text, code, images, and more. |\n| Gemini 1.0 Flash | Fast multimodal model built for input understanding with a 32K context window. Handles text, images, and more. |\n\n## Gemini models available in Vertex AI\n\n| Model | Description |\n|---|---|\n| gemini-1.5-pro | Gemini's most advanced model capable of highly complex tasks. 1 million token context window. Handles text, code, audio, video, and image content. |\n| gemini-1.5-flash | Designed for speed and efficiency with a high-quality multimodal experience. 1 million token context window. |\n| gemini-1.0-pro | Optimized for scaling across a wide range of tasks, with a 32K context window. Handles text, code, images, and more. |\n| gemini-1.0-pro-vision | Fast multimodal model built for input understanding with a 32K context window. Handles text, images, and more. |\n| gemini-1.0-ultra | Highly capable model for complex reasoning, instructions, code, and multimodal use cases. 32K context window. |\n| gemini-1.0-ultra-vision | Vision-enabled variant of Gemini 1.0 Ultra that can process text and image inputs. 32K context window. |\n\nFor more information about these models, see [Gemini on Vertex AI](/vertex-ai/generative-ai/docs/learn/overview#gemini-ai-models).\n\n## Supported regions and available features\n\nGemini models are available in the following locations.\n\nThe locations listed for each model support both the following endpoints:\n\n- [us-central1].aiplatform.googleapis.com\n- aiplatform.googleapis.com\n\nSome of these locations are also available for usage through the Google Cloud console in Vertex AI Studio.\n\nThe Google AI Studio application uses the global endpoint aiplatform.googleapis.com, and, by default, uses us-central1 to process requests. You can change this location on a per-request basis in Studio by clicking the three dots menu in the conversation you want to adjust.\n\n### Text\n\n| Model | Location | Pricing | Features |\n| --- | --- | --- | --- |\n| Gemini 1.5 Pro | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Text generation, Function calling, Chat, Embeddings, Safety settings, High token limits, Grounding |\n| Gemini 1.5 Flash | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Text generation, Function calling, Chat, Embeddings, Safety settings, High token limits, Grounding |\n| Gemini 1.0 Pro | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Text generation, Function calling, Chat, Embeddings, Safety settings |\n| Gemini 1.0 Ultra | us-central1, europe-west4 | [Pricing](/gemini/pricing) | Text generation, Function calling, Chat, Embeddings, Safety settings |\n\n### Image\n\n| Model | Location | Pricing | Features |\n| --- | --- | --- | --- |\n| Gemini 1.5 Pro | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Image inputs, Text-to-image inputs, Safety settings |\n| Gemini 1.5 Flash | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Image inputs, Text-to-image inputs, Safety settings |\n| Gemini 1.0 Pro Vision | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Image inputs, Text-to-image inputs, Safety settings |\n| Gemini 1.0 Ultra Vision | us-central1, europe-west4 | [Pricing](/gemini/pricing) | Image inputs, Text-to-image inputs, Safety settings |\n\n### Video\n\n| Model | Location | Pricing | Features |\n| --- | --- | --- | --- |\n| Gemini 1.5 Pro | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Video inputs, Text-to-video inputs, Safety settings |\n| Gemini 1.5 Flash | us-central1, europe-west4, asia-southeast1 | [Pricing](/gemini/pricing) | Video inputs, Text-to-video inputs, Safety settings |\n\n## Capabilities\n\n### Multimodal capabilities\n\nA key feature of Gemini models is their ability to understand and generate responses across different modalities—text, image, video, and audio. They can:\n\n- Accept input from different modalities to inform responses\n- Generate content in text\n- Process and analyze images, video, and audio for understanding\n- Perform complex reasoning tasks across all inputs\n\n### Gemini model capabilities\n\n| Capability | Description | Available models |\n|---|---|---|\n| Reasoning | Engage in detailed step-by-step thinking for problem-solving | All Gemini models |\n| Code generation | Generate code in multiple programming languages | All Gemini models |\n| Code chat | Interactive, multi-turn code generation and debugging | All Gemini models |\n| Image understanding | Process and understand images as part of prompts | All Gemini models |\n| Video understanding | Process and understand video content as part of prompts | Gemini 1.5 models |\n| Audio understanding | Process and understand audio content as part of prompts | Gemini 1.5 models |\n| RAG (Retrieval Augmented Generation) | Integration with external sources of information to ground responses | Gemini 1.5 models, Gemini 1.0 Pro |\n| Embeddings | Generate vector representations of content for similarity comparisons | All Gemini models |\n| Long context understanding | Process extensive inputs with context window up to 1M tokens | Gemini 1.5 models |\n| Agentic capabilities | Function calling for tool use and API interaction | All Gemini models |\n\n## Chat versus text-only\n\nGemini models support two fundamental modes of interaction:\n\n- **Chat**: Maintains conversational context across multiple turns. Ideal for interactive, back-and-forth conversations.\n- **Text-only**: Single prompt-response interactions without retaining context between calls. Better for standalone content generation.\n\n### When to use chat\n\n- When building conversational applications like chatbots\n- For applications requiring multi-turn interactions\n- When context from previous exchanges is needed\n- For interactive problem-solving or tutoring\n\n### When to use text-only\n\n- For single, standalone generation tasks\n- When working with structured content creation\n- For summarization, classification, or extraction tasks\n- When high throughput is required and context retention isn't needed\n\n## Context length\n\nThe context length (or context window) refers to how much information the model can consider at once. The larger the context window, the more information the model can process when generating a response.\n\n| Model | Maximum context length |\n|---|---|\n| Gemini 1.5 Pro | 1 million tokens |\n| Gemini 1.5 Flash | 1 million tokens |\n| Gemini 1.0 Pro | 32,768 tokens |\n| Gemini 1.0 Ultra | 32,768 tokens |\n| Gemini 1.0 Flash | 32,768 tokens |\n\n## Tokens and rate limits\n\nTokens are the basic units of text processing for language models. For English text, 1 token is approximately 4 characters or 0.75 words.\n\n### Rate limits\n\nRate limits specify how many requests you can make in a given time period. They are based on tokens processed by the model.\n\n| Model | Input tokens per minute | Output tokens per minute |\n|---|---|---|\n| Gemini 1.5 Pro | 300,000 | 300,000 |\n| Gemini 1.5 Flash | 1,000,000 | 1,000,000 |\n| Gemini 1.0 Pro | 1,000,000 | 1,000,000 |\n| Gemini 1.0 Ultra | 300,000 | 300,000 |\n| Gemini 1.0 Flash | 3,000,000 | 3,000,000 |\n\n## Input and output limitations\n\n### Input limitations\n\nInput limitations define the maximum amount of information you can send to the model in a single request.\n\n| Model | Maximum input size | Supported input types |\n|---|---|---|\n| Gemini 1.5 Pro | 1 million tokens | Text, images, audio, video |\n| Gemini 1.5 Flash | 1 million tokens | Text, images, audio, video |\n| Gemini 1.0 Pro | 32,768 tokens | Text, images |\n| Gemini 1.0 Ultra | 32,768 tokens | Text |\n| Gemini 1.0 Ultra Vision | 32,768 tokens | Text, images |\n| Gemini 1.0 Flash | 32,768 tokens | Text, images |\n\n### Output limitations\n\nOutput limitations define the maximum amount of text the model can generate in a single response.\n\n| Model | Maximum output size |\n|---|---|\n| Gemini 1.5 Pro | 8,192 tokens |\n| Gemini 1.5 Flash | 8,192 tokens |\n| Gemini 1.0 Pro | 8,192 tokens |\n| Gemini 1.0 Ultra | 8,192 tokens |\n| Gemini 1.0 Flash | 2,048 tokens |\n\n## Embedding models\n\nEmbedding models convert text into high-dimensional vectors that capture semantic meaning, enabling tasks like semantic search, clustering, and classification.\n\n| Model | Embedding dimensions | Maximum input size | Supports batch embedding |\n|---|---|---|---|\n| Gemini 1.5 Flash embedding | 768 | 256K tokens | Yes |\n| Gemini 1.0 Pro embedding | 768 | 32K tokens | Yes |\n\n## Multimodal capabilities\n\n| Capability | Gemini 1.5 Pro | Gemini 1.5 Flash | Gemini 1.0 Pro Vision | Gemini 1.0 Ultra Vision |\n|---|---|---|---|---|\n| Text input | ✓ | ✓ | ✓ | ✓ |\n| Image input | ✓ | ✓ | ✓ | ✓ |\n| Video input | ✓ | ✓ | - | - |\n| Audio input | ✓ | ✓ | - | - |\n| Multi-image input | ✓ | ✓ | ✓ | ✓ |\n| Multi-video input | ✓ | ✓ | - | - |\n| Max images per prompt | 10 | 10 | 10 | 10 |\n| Max videos per prompt | 5 | 5 | - | - |\n| Max video length | 2 hours | 2 hours | - | - |\n| Max video file size | 5 GB | 5 GB | - | - |\n| Max audio length | 2 hours | 2 hours | - | - |\n| Max audio file size | 5 GB | 5 GB | - | - |\n\n## Model comparison and selection guidance\n\n### Performance trade-offs\n\n| Model | Quality | Speed | Cost | Context length |\n|---|---|---|---|---|\n| Gemini 1.5 Pro | Highest | Moderate | Highest | 1M tokens |\n| Gemini 1.5 Flash | High | Fast | Moderate | 1M tokens |\n| Gemini 1.0 Pro | High | Moderate | Moderate | 32K tokens |\n| Gemini 1.0 Ultra | Very high | Moderate | High | 32K tokens |\n| Gemini 1.0 Flash | Good | Very fast | Lowest | 32K tokens |\n\n### When to choose each model\n\n#### Gemini 1.5 Pro\n\nBest for:\n- Complex reasoning with extensive context\n- Multimodal understanding of videos, images, and audio\n- Tasks requiring detailed analysis of long documents or multimedia\n- High-stakes applications needing the most capable model\n- Applications needing the 1M token context window\n\n#### Gemini 1.5 Flash\n\nBest for:\n- High-volume, multimodal applications with speed requirements\n- Balanced performance and cost for video, image, and audio understanding\n- Applications needing the 1M token context window with higher efficiency\n\n#### Gemini 1.0 Pro\n\nBest for:\n- General purpose content generation\n- Code generation and analysis\n- Applications with moderate complexity requirements\n- Balanced performance and cost\n\n#### Gemini 1.0 Ultra\n\nBest for:\n- High-complexity reasoning\n- Applications requiring highest quality output\n- Complex problem-solving\n- When highest performance is needed for important tasks\n\n#### Gemini 1.0 Flash\n\nBest for:\n- High-volume, cost-sensitive applications\n- Image understanding at scale\n- Applications where speed is critical\n- Basic content generation and classification tasks\n\n## Best practices for using Gemini models\n\n1. **Provide clear instructions**: Be specific about what you want the model to do, including the format, style, and level of detail.\n\n2. **Use examples**: For complex tasks, include examples of desired outputs (few-shot prompting).\n\n3. **Break down complex tasks**: For multi-step problems, guide the model through each step.\n\n4. **Leverage multimodal inputs**: When relevant, include images, video, or audio to provide context and information.\n\n5. **Consider context window limitations**: For long-context models, organize information by importance, as material earlier in the context may receive more attention.\n\n6. **Iterate on prompts**: Refine your prompts based on model responses to achieve desired results.\n\n7. **Use system instructions**: In chat applications, set the behavior and personality of the model using system instructions.\n\n8. **Configure safety settings**: Adjust safety thresholds based on your application's requirements.\n\n9. **Monitor and validate outputs**: Implement checks for model-generated content, especially for sensitive applications.\n\n10. **Optimize for performance**: Choose the appropriate model based on your speed, quality, and cost requirements.\n\n## Next steps\n\n- [Get started with Google AI Studio](/gemini/docs/get-started/quickstart)\n- [Learn about Gemini on Vertex AI](/vertex-ai/generative-ai/docs/learn/overview#gemini-ai-models)\n- [Explore coding with Gemini](/gemini/docs/get-started/code-with-gemini)\n- [Learn about embeddings](/gemini/docs/embeddings/embeddings-start)\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/tutorials/semantic_search_retrieval.ipynb\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"2CQOIyy4X5qH\"\n      },\n      \"source\": [\n        \"# Semantic search and retrieval with embeddings\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/semantic_search_retrieval.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"KRbXF43YX5qI\"\n      },\n      \"source\": [\n        \"## Introduction\\n\",\n        \"\\n\",\n        \"Embeddings are numerical representations that capture the semantic meaning of text or other content. Conceptually, you can picture embeddings as placing similar items closer together in a high-dimensional space. This property makes them extremely useful for various applications, including:\\n\",\n        \"\\n\",\n        \"* Semantic search\\n\",\n        \"* Recommendation systems\\n\",\n        \"* Classification\\n\",\n        \"* Clustering\\n\",\n        \"* Outlier detection\\n\",\n        \"\\n\",\n        \"In this tutorial, you'll learn how to use the Google Gemini API to generate embeddings for semantic search and retrieval. You'll create a search system for a small set of documents, demonstrating how to find semantically similar content even when the exact keywords aren't present.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"uqwE4_gSX5qJ\"\n      },\n      \"source\": [\n        \"## Setup and authentication\\n\",\n        \"\\n\",\n        \"First, let's install the necessary libraries and set up authentication.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Av3-8cU0X5qJ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install -q -U google-generativeai scipy scikit-learn plotly pandas matplotlib\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"0bDSi1YFX5qK\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"import google.generativeai as genai\\n\",\n        \"import numpy as np\\n\",\n        \"import pandas as pd\\n\",\n        \"from scipy.spatial.distance import cosine\\n\",\n        \"from sklearn.metrics.pairwise import cosine_similarity\\n\",\n        \"import matplotlib.pyplot as plt\\n\",\n        \"import plotly.express as px\\n\",\n        \"from sklearn.decomposition import PCA\\n\",\n        \"import os\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"9dPMRq4PX5qK\"\n      },\n      \"source\": [\n        \"To use the Gemini API, you'll need an API key. If you don't already have one, create a key in [Google AI Studio](https://makersuite.google.com/app/apikey).\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"zS4uR7YWX5qK\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Get API key from environment or user input\\n\",\n        \"API_KEY = os.getenv('GOOGLE_API_KEY') or \\\"YOUR_API_KEY\\\"\\n\",\n        \"\\n\",\n        \"# Configure the library with your API key\\n\",\n        \"genai.configure(api_key=API_KEY)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"0G2eL7L4X5qL\"\n      },\n      \"source\": [\n        \"## Exploring available embedding models\\n\",\n        \"\\n\",\n        \"The Gemini API provides several embedding models, each designed for different purposes. Let's look at what's available:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"a48XsqZRX5qL\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"for m in genai.list_models():\\n\",\n        \"    if 'embedContent' in m.supported_generation_methods:\\n\",\n        \"        print(f\\\"Model name: {m.name}\\\")\\n\",\n        \"        print(f\\\"  Display name: {m.display_name}\\\")\\n\",\n        \"        print(f\\\"  Description: {m.description}\\\")\\n\",\n        \"        print(f\\\"  Input token limit: {m.input_token_limit}\\\")\\n\",\n        \"        print()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"OaGI2NXRX5qL\"\n      },\n      \"source\": [\n        \"For this tutorial, we'll use the Gemini 1.0 Pro embedding model `models/embedding-001`. This model creates embeddings optimized for text understanding.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"3SzGZ_2ZX5qL\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Select the embedding model\\n\",\n        \"embedding_model = 'models/embedding-001'\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"dK5JzKhBX5qL\"\n      },\n      \"source\": [\n        \"## Creating a document collection\\n\",\n        \"\\n\",\n        \"Let's create a small collection of fictional research papers for our semantic search system. These will be short summaries of papers on various ML and AI topics.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"2nGVp5YzX5qL\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"documents = [\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 1,\\n\",\n        \"        \\\"title\\\": \\\"Advances in Neural Network Architectures\\\",\\n\",\n        \"        \\\"content\\\": \\\"This paper explores recent innovations in neural network design, focusing on transformer models and their applications in natural language processing. We propose a new attention mechanism that improves computational efficiency while maintaining performance.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 2,\\n\",\n        \"        \\\"title\\\": \\\"Reinforcement Learning for Robotic Control\\\",\\n\",\n        \"        \\\"content\\\": \\\"We present a novel reinforcement learning algorithm optimized for robotic movement in unpredictable environments. Our approach combines model-based and model-free techniques to accelerate training while improving safety constraints.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 3,\\n\",\n        \"        \\\"title\\\": \\\"Computer Vision Techniques for Medical Imaging\\\",\\n\",\n        \"        \\\"content\\\": \\\"This research introduces an advanced convolutional neural network designed specifically for analyzing MRI scans. Our model achieves state-of-the-art accuracy in detecting abnormalities while requiring fewer labeled training examples.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 4,\\n\",\n        \"        \\\"title\\\": \\\"Efficient Natural Language Generation\\\",\\n\",\n        \"        \\\"content\\\": \\\"We propose a more computationally efficient approach to text generation that reduces the parameter count while maintaining text quality. Our technique uses a hierarchical tokenization scheme combined with a modified transformer architecture.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 5,\\n\",\n        \"        \\\"title\\\": \\\"Privacy-Preserving Machine Learning\\\",\\n\",\n        \"        \\\"content\\\": \\\"This paper addresses techniques for training machine learning models while preserving data privacy. We introduce a new federated learning protocol that minimizes data exposure and provides mathematical guarantees on privacy preservation.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 6,\\n\",\n        \"        \\\"title\\\": \\\"Unsupervised Learning for Anomaly Detection\\\",\\n\",\n        \"        \\\"content\\\": \\\"Our research explores autoencoder architectures for detecting anomalies in manufacturing systems. The proposed method can identify defects without labeled examples by learning the underlying distribution of normal operation patterns.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 7,\\n\",\n        \"        \\\"title\\\": \\\"Graph Neural Networks for Molecular Analysis\\\",\\n\",\n        \"        \\\"content\\\": \\\"We present a specialized graph neural network designed for molecular property prediction in drug discovery. Our approach models atomic interactions more accurately, leading to improved predictions of binding affinity and toxicity.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 8,\\n\",\n        \"        \\\"title\\\": \\\"Time Series Forecasting with Attention Mechanisms\\\",\\n\",\n        \"        \\\"content\\\": \\\"This paper demonstrates how attention mechanisms can improve time series forecasting in financial markets. Our model captures long-term dependencies and adapts to changing market conditions better than traditional recurrent architectures.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 9,\\n\",\n        \"        \\\"title\\\": \\\"Multi-Agent Reinforcement Learning for Traffic Management\\\",\\n\",\n        \"        \\\"content\\\": \\\"We developed a multi-agent reinforcement learning system that optimizes traffic light timing across an entire city grid. The agents learn to collaborate implicitly through individual rewards that align with global traffic flow objectives.\\\"\\n\",\n        \"    },\\n\",\n        \"    {\\n\",\n        \"        \\\"id\\\": 10,\\n\",\n        \"        \\\"title\\\": \\\"Explainable AI for Medical Diagnosis\\\",\\n\",\n        \"        \\\"content\\\": \\\"This research focuses on creating interpretable machine learning models for clinical diagnosis. We introduce a neural network architecture that provides explanations for its predictions using attention visualization and rule extraction.\\\"\\n\",\n        \"    },\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"# Convert to DataFrame for easier handling\\n\",\n        \"docs_df = pd.DataFrame(documents)\\n\",\n        \"docs_df.head()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"mhW_YlLrX5qL\"\n      },\n      \"source\": [\n        \"## Generating embeddings for documents\\n\",\n        \"\\n\",\n        \"Next, we'll generate embeddings for our documents. For each document, we'll create an embedding that represents the combined title and content.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"l3_KHVXyX5qM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def get_embedding(text):\\n\",\n        \"    \\\"\\\"\\\"Generate embedding for a text using the Gemini API\\\"\\\"\\\"\\n\",\n        \"    embedding = genai.embed_content(model=embedding_model,\\n\",\n        \"                                   content=text,\\n\",\n        \"                                   task_type=\\\"retrieval_document\\\")\\n\",\n        \"    return embedding[\\\"embedding\\\"]\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"41q3a72bX5qM\"\n      },\n      \"source\": [\n        \"Let's generate embeddings for all documents in our collection. We'll combine the title and content for a more comprehensive representation.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"ZkHRxsyGX5qM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate embeddings for each document (combining title and content)\\n\",\n        \"docs_df['text'] = docs_df['title'] + \\\" \\\" + docs_df['content']\\n\",\n        \"docs_df['embedding'] = docs_df['text'].apply(get_embedding)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"FO-VK-VxX5qM\"\n      },\n      \"source\": [\n        \"Let's check the dimensionality of our embeddings to understand their structure.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Gs8l8xONX5qM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Check the dimensionality of the embeddings\\n\",\n        \"first_embedding = docs_df['embedding'][0]\\n\",\n        \"print(f\\\"Embedding dimension: {len(first_embedding)}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"GKfWkPFtX5qM\"\n      },\n      \"source\": [\n        \"## Building a semantic search function\\n\",\n        \"\\n\",\n        \"Now, let's create a function to search our document collection using semantic similarity. We'll use cosine similarity to measure how closely a query matches each document.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"iiLyX3N2X5qM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def semantic_search(query, docs_df, top_n=3):\\n\",\n        \"    \\\"\\\"\\\"Search for documents semantically similar to the query\\\"\\\"\\\"\\n\",\n        \"    # Generate embedding for the query\\n\",\n        \"    query_embedding = get_embedding(query)\\n\",\n        \"    \\n\",\n        \"    # Calculate similarity between query and all documents\\n\",\n        \"    docs_df['similarity'] = docs_df['embedding'].apply(\\n\",\n        \"        lambda x: cosine_similarity([query_embedding], [x])[0][0]\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    # Sort by similarity (highest first)\\n\",\n        \"    results = docs_df.sort_values('similarity', ascending=False).head(top_n)\\n\",\n        \"    \\n\",\n        \"    return results[['id', 'title', 'content', 'similarity']]\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"jbPw0QN-X5qM\"\n      },\n      \"source\": [\n        \"Let's test our semantic search with a few example queries.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Ri22t1mhX5qM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Example 1: Search for content about neural networks\\n\",\n        \"query1 = \\\"Neural network architecture improvements\\\"\\n\",\n        \"results1 = semantic_search(query1, docs_df)\\n\",\n        \"print(f\\\"Query: {query1}\\\\n\\\")\\n\",\n        \"for i, row in results1.iterrows():\\n\",\n        \"    print(f\\\"Document {row['id']}: {row['title']}\\\")\\n\",\n        \"    print(f\\\"Similarity: {row['similarity']:.4f}\\\")\\n\",\n        \"    print(f\\\"Content: {row['content'][:100]}...\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"_2_ZAXH7X5qM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Example 2: Search for healthcare-related research\\n\",\n        \"query2 = \\\"Healthcare and medical applications of machine learning\\\"\\n\",\n        \"results2 = semantic_search(query2, docs_df)\\n\",\n        \"print(f\\\"Query: {query2}\\\\n\\\")\\n\",\n        \"for i, row in results2.iterrows():\\n\",\n        \"    print(f\\\"Document {row['id']}: {row['title']}\\\")\\n\",\n        \"    print(f\\\"Similarity: {row['similarity']:.4f}\\\")\\n\",\n        \"    print(f\\\"Content: {row['content'][:100]}...\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"5YbMN0iPX5qM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Example 3: Search for research on data security\\n\",\n        \"query3 = \\\"How to protect sensitive data in AI systems\\\"\\n\",\n        \"results3 = semantic_search(query3, docs_df)\\n\",\n        \"print(f\\\"Query: {query3}\\\\n\\\")\\n\",\n        \"for i, row in results3.iterrows():\\n\",\n        \"    print(f\\\"Document {row['id']}: {row['title']}\\\")\\n\",\n        \"    print(f\\\"Similarity: {row['similarity']:.4f}\\\")\\n\",\n        \"    print(f\\\"Content: {row['content'][:100]}...\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"-Ukt-LYqX5qN\"\n      },\n      \"source\": [\n        \"## Visualizing the embedding space\\n\",\n        \"\\n\",\n        \"To better understand how our documents are organized in the embedding space, let's visualize them using dimensionality reduction. We'll use Principal Component Analysis (PCA) to reduce our high-dimensional embeddings to 2D for visualization.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"0_YZYZGgX5qN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Convert embeddings to a 2D array for PCA\\n\",\n        \"embeddings_array = np.array(docs_df['embedding'].tolist())\\n\",\n        \"\\n\",\n        \"# Apply PCA to reduce to 2 dimensions\\n\",\n        \"pca = PCA(n_components=2)\\n\",\n        \"embeddings_2d = pca.fit_transform(embeddings_array)\\n\",\n        \"\\n\",\n        \"# Create a DataFrame for visualization\\n\",\n        \"viz_df = pd.DataFrame({\\n\",\n        \"    'id': docs_df['id'],\\n\",\n        \"    'title': docs_df['title'],\\n\",\n        \"    'x': embeddings_2d[:, 0],\\n\",\n        \"    'y': embeddings_2d[:, 1]\\n\",\n        \"})\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"MJWMpO9jX5qN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Create an interactive plot with Plotly\\n\",\n        \"fig = px.scatter(\\n\",\n        \"    viz_df, x='x', y='y', text='id', hover_data=['title'],\\n\",\n        \"    title='Document Embedding Space Visualization'\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Add labels to the points\\n\",\n        \"fig.update_traces(textposition='top center')\\n\",\n        \"\\n\",\n        \"# Improve the layout\\n\",\n        \"fig.update_layout(\\n\",\n        \"    xaxis_title=\\\"PCA Dimension 1\\\",\\n\",\n        \"    yaxis_title=\\\"PCA Dimension 2\\\",\\n\",\n        \"    height=600,\\n\",\n        \"    width=800\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"fig.show()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"h05fv3Q-X5qN\"\n      },\n      \"source\": [\n        \"Let's visualize where our search queries fall in this embedding space:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"7eRCz4v4X5qN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Get embeddings for our queries\\n\",\n        \"query_embeddings = [\\n\",\n        \"    get_embedding(query1),\\n\",\n        \"    get_embedding(query2),\\n\",\n        \"    get_embedding(query3)\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"# Transform query embeddings to the same 2D space\\n\",\n        \"query_embeddings_2d = pca.transform(query_embeddings)\\n\",\n        \"\\n\",\n        \"# Create a DataFrame for visualization\\n\",\n        \"query_viz_df = pd.DataFrame({\\n\",\n        \"    'query': [query1, query2, query3],\\n\",\n        \"    'x': query_embeddings_2d[:, 0],\\n\",\n        \"    'y': query_embeddings_2d[:, 1]\\n\",\n        \"})\\n\",\n        \"\\n\",\n        \"# Plot documents and queries\\n\",\n        \"plt.figure(figsize=(12, 8))\\n\",\n        \"\\n\",\n        \"# Plot documents\\n\",\n        \"plt.scatter(viz_df['x'], viz_df['y'], color='blue', alpha=0.7, label='Documents')\\n\",\n        \"for i, row in viz_df.iterrows():\\n\",\n        \"    plt.annotate(f\\\"Doc {row['id']}\\\", (row['x'], row['y']), fontsize=9)\\n\",\n        \"\\n\",\n        \"# Plot queries\\n\",\n        \"plt.scatter(query_viz_df['x'], query_viz_df['y'], color='red', marker='x', s=100, label='Queries')\\n\",\n        \"labels = ['Query 1', 'Query 2', 'Query 3']\\n\",\n        \"for i, row in query_viz_df.iterrows():\\n\",\n        \"    plt.annotate(labels[i], (row['x'], row['y']), fontsize=9, color='red')\\n\",\n        \"\\n\",\n        \"plt.title('Documents and Queries in Embedding Space')\\n\",\n        \"plt.xlabel('PCA Dimension 1')\\n\",\n        \"plt.ylabel('PCA Dimension 2')\\n\",\n        \"plt.legend()\\n\",\n        \"plt.grid(True, linestyle='--', alpha=0.7)\\n\",\n        \"plt.show()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"xA-Lq5V7X5qN\"\n      },\n      \"source\": [\n        \"## Implementing batch processing for efficiency\\n\",\n        \"\\n\",\n        \"When working with larger document collections, batch processing can improve efficiency. Let's implement a function to generate embeddings in batches.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"R2Pz_0vWX5qN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def batch_get_embeddings(texts, batch_size=5):\\n\",\n        \"    \\\"\\\"\\\"Generate embeddings for a list of texts in batches\\\"\\\"\\\"\\n\",\n        \"    all_embeddings = []\\n\",\n        \"    \\n\",\n        \"    for i in range(0, len(texts), batch_size):\\n\",\n        \"        batch_texts = texts[i:i+batch_size]\\n\",\n        \"        response = genai.embed_content(\\n\",\n        \"            model=embedding_model,\\n\",\n        \"            content=batch_texts,\\n\",\n        \"            task_type=\\\"retrieval_document\\\"\\n\",\n        \"        )\\n\",\n        \"        \\n\",\n        \"        # Extract embeddings from response\\n\",\n        \"        batch_embeddings = [item[\\\"embedding\\\"] for item in response[\\\"embeddings\\\"]]\\n\",\n        \"        all_embeddings.extend(batch_embeddings)\\n\",\n        \"        \\n\",\n        \"    return all_embeddings\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"0i7QzC9cX5qN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Create a list of all document texts\\n\",\n        \"all_texts = docs_df['text'].tolist()\\n\",\n        \"\\n\",\n        \"# Get embeddings in batch\\n\",\n        \"batch_embeddings = batch_get_embeddings(all_texts)\\n\",\n        \"\\n\",\n        \"# Verify we got the right number of embeddings\\n\",\n        \"print(f\\\"Number of documents: {len(all_texts)}\\\")\\n\",\n        \"print(f\\\"Number of batch embeddings: {len(batch_embeddings)}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"G2mP1NbNX5qN\"\n      },\n      \"source\": [\n        \"## Extending the application: Hybrid search\\n\",\n        \"\\n\",\n        \"A common technique in production systems is to combine semantic search with keyword-based search (often called hybrid search). This approach can improve results by capturing both semantic meaning and exact keyword matches.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"vRTqnS9sX5qN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n        \"\\n\",\n        \"# Create a TF-IDF vectorizer for keyword-based search\\n\",\n        \"tfidf_vectorizer = TfidfVectorizer()\\n\",\n        \"tfidf_matrix = tfidf_vectorizer.fit_transform(docs_df['text'])\\n\",\n        \"\\n\",\n        \"def hybrid_search(query, docs_df, alpha=0.7, top_n=3):\\n\",\n        \"    \\\"\\\"\\\"Combine semantic and keyword search with a weighted average\\n\",\n        \"    \\n\",\n        \"    Args:\\n\",\n        \"        query: The search query\\n\",\n        \"        docs_df: DataFrame containing document data and embeddings\\n\",\n        \"        alpha: Weight for semantic search (1-alpha for keyword search)\\n\",\n        \"        top_n: Number of results to return\\n\",\n        \"        \\n\",\n        \"    Returns:\\n\",\n        \"        DataFrame with top_n results sorted by combined score\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    # Semantic search component\\n\",\n        \"    query_embedding = get_embedding(query)\\n\",\n        \"    semantic_scores = docs_df['embedding'].apply(\\n\",\n        \"        lambda x: cosine_similarity([query_embedding], [x])[0][0]\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    # Keyword search component\\n\",\n        \"    query_tfidf = tfidf_vectorizer.transform([query])\\n\",\n        \"    keyword_scores = cosine_similarity(query_tfidf, tfidf_matrix)[0]\\n\",\n        \"    \\n\",\n        \"    # Combine scores with weighted average\\n\",\n        \"    docs_df['semantic_score'] = semantic_scores\\n\",\n        \"    docs_df['keyword_score'] = keyword_scores\\n\",\n        \"    docs_df['combined_score'] = alpha * docs_df['semantic_score'] + (1 - alpha) * docs_df['keyword_score']\\n\",\n        \"    \\n\",\n        \"    # Sort by combined score\\n\",\n        \"    results = docs_df.sort_values('combined_score', ascending=False).head(top_n)\\n\",\n        \"    \\n\",\n        \"    return results[['id', 'title', 'semantic_score', 'keyword_score', 'combined_score']]\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"LG1t5xUCX5qO\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Try hybrid search with a specific keyword query\\n\",\n        \"keyword_query = \\\"attention mechanisms for neural networks\\\"\\n\",\n        \"hybrid_results = hybrid_search(keyword_query, docs_df)\\n\",\n        \"print(f\\\"Query: {keyword_query}\\\\n\\\")\\n\",\n        \"for i, row in hybrid_results.iterrows():\\n\",\n        \"    print(f\\\"Document {row['id']}: {row['title']}\\\")\\n\",\n        \"    print(f\\\"Semantic score: {row['semantic_score']:.4f}\\\")\\n\",\n        \"    print(f\\\"Keyword score: {row['keyword_score']:.4f}\\\")\\n\",\n        \"    print(f\\\"Combined score: {row['combined_score']:.4f}\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"JvCRGZp4X5qO\"\n      },\n      \"source\": [\n        \"## Query embeddings for conversational search\\n\",\n        \"\\n\",\n        \"For conversational search applications, we can generate embeddings specifically optimized for queries. Let's see how to use these.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"U8Ot6UyHX5qO\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def get_query_embedding(query_text):\\n\",\n        \"    \\\"\\\"\\\"Generate embedding for a query using the Gemini API\\\"\\\"\\\"\\n\",\n        \"    embedding = genai.embed_content(\\n\",\n        \"        model=embedding_model,\\n\",\n        \"        content=query_text,\\n\",\n        \"        task_type=\\\"retrieval_query\\\"  # Specify query embedding\\n\",\n        \"    )\\n\",\n        \"    return embedding[\\\"embedding\\\"]\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"MtlyhgYUX5qO\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Compare query-optimized and document-optimized embeddings\\n\",\n        \"sample_query = \\\"How do attention mechanisms work in neural networks?\\\"\\n\",\n        \"\\n\",\n        \"query_embedding = get_query_embedding(sample_query)\\n\",\n        \"doc_style_embedding = get_embedding(sample_query)\\n\",\n        \"\\n\",\n        \"# Check similarity between the two embedding types\\n\",\n        \"similarity = cosine_similarity([query_embedding], [doc_style_embedding])[0][0]\\n\",\n        \"print(f\\\"Similarity between query and document embedding types: {similarity:.4f}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"E-Rvr_YyX5qO\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def optimized_semantic_search(query, docs_df, top_n=3):\\n\",\n        \"    \\\"\\\"\\\"Search using query-optimized embeddings\\\"\\\"\\\"\\n\",\n        \"    # Generate query-optimized embedding\\n\",\n        \"    query_embedding = get_query_embedding(query)\\n\",\n        \"    \\n\",\n        \"    # Calculate similarity\\n\",\n        \"    docs_df['similarity'] = docs_df['embedding'].apply(\\n\",\n        \"        lambda x: cosine_similarity([query_embedding], [x])[0][0]\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    # Sort by similarity\\n\",\n        \"    results = docs_df.sort_values('similarity', ascending=False).head(top_n)\\n\",\n        \"    \\n\",\n        \"    return results[['id', 'title', 'content', 'similarity']]\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"nXNUyudFX5qO\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Compare standard search and optimized search\\n\",\n        \"query = \\\"Neural networks for language tasks\\\"\\n\",\n        \"\\n\",\n        \"print(\\\"Standard search results:\\\")\\n\",\n        \"standard_results = semantic_search(query, docs_df)\\n\",\n        \"for i, row in standard_results.iterrows():\\n\",\n        \"    print(f\\\"Document {row['id']}: {row['title']} (Similarity: {row['similarity']:.4f})\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"\\\\nOptimized search results:\\\")\\n\",\n        \"optimized_results = optimized_semantic_search(query, docs_df)\\n\",\n        \"for i, row in optimized_results.iterrows():\\n\",\n        \"    print(f\\\"Document {row['id']}: {row['title']} (Similarity: {row['similarity']:.4f})\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"FrA-rjXkX5qO\"\n      },\n      \"source\": [\n        \"## Conclusion\\n\",\n        \"\\n\",\n        \"In this tutorial, you've learned how to:\\n\",\n        \"\\n\",\n        \"1. Generate embeddings using the Gemini API\\n\",\n        \"2. Build a semantic search system for document retrieval\\n\",\n        \"3. Visualize the embedding space to understand document relationships\\n\",\n        \"4. Implement batch processing for efficiency\\n\",\n        \"5. Create a hybrid search system combining semantic and keyword-based approaches\\n\",\n        \"6. Use query-optimized embeddings for better search results\\n\",\n        \"\\n\",\n        \"These techniques form the foundation for building sophisticated search and recommendation systems that understand the meaning behind user queries, not just keywords.\\n\",\n        \"\\n\",\n        \"## Next Steps\\n\",\n        \"\\n\",\n        \"To build on what you've learned here, consider exploring:\\n\",\n        \"\\n\",\n        \"- Vector databases like Pinecone, Weaviate, or ChromaDB for efficient similarity search at scale\\n\",\n        \"- More advanced retrieval techniques like Retrieval Augmented Generation (RAG)\\n\",\n        \"- Fine-tuning embeddings for specific domains or applications\\n\",\n        \"- Building conversational search interfaces that maintain context across queries\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"provenance\": []\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"name\": \"python\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"l_Rl7Gj_wEej\"\n      },\n      \"source\": [\n        \"# Introduction to embeddings\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini/docs/embeddings/intro_embeddings.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"zJ5oSMln5Mf4\"\n      },\n      \"source\": [\n        \"## Overview\\n\",\n        \"\\n\",\n        \"An embedding is a numerical representation of information, such as text, images, or video. This information is represented as a *vector* (a set of numbers) in a high-dimensional space. \\n\",\n        \"\\n\",\n        \"Embeddings are not only numerical representations — they are designed such that similar inputs are placed closer together in the embedding space. This property makes them extremely useful for various machine learning tasks, including:\\n\",\n        \"\\n\",\n        \"- **Semantic search**: finding documents that are conceptually related, even if they don't share the same keywords\\n\",\n        \"- **Classification**: categorizing content based on its meaning\\n\",\n        \"- **Clustering**: grouping similar items together\\n\",\n        \"- **Recommendation systems**: suggesting similar items based on semantic relevance\\n\",\n        \"- **Anomaly detection**: identifying outliers or unusual patterns\\n\",\n        \"\\n\",\n        \"In this tutorial, you'll learn how to generate embeddings using Gemini's embedding models.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"OIGqWsn0Cx-F\"\n      },\n      \"source\": [\n        \"## Setup\\n\",\n        \"\\n\",\n        \"First, install the necessary packages and set up authentication. To run this notebook, you'll need a Google Cloud project with the Vertex AI API enabled. Learn more about [setting up a project and environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"sO7_KQemC1iQ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install -q google-cloud-aiplatform\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"-9aRBvSH5PJf\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"import numpy as np\\n\",\n        \"import vertexai\\n\",\n        \"from vertexai.language_models import TextEmbeddingModel\\n\",\n        \"from vertexai.preview.generative_models import GenerativeModel\\n\",\n        \"from google.cloud import aiplatform\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"N8l7JaRdC4Mj\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# If you're running this notebook on Colab, you'll need to authenticate\\n\",\n        \"try:\\n\",\n        \"    from google.colab import auth\\n\",\n        \"    auth.authenticate_user()\\n\",\n        \"    print(\\\"Authenticated\\\")\\n\",\n        \"except:\\n\",\n        \"    print(\\\"Not running in Colab, authentication skipped\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Z8zdCKhgDAB3\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Replace with your project ID and proper location\\n\",\n        \"PROJECT_ID = \\\"your-project-id\\\"  # @param {type:\\\"string\\\"}\\n\",\n        \"LOCATION = \\\"us-central1\\\"  # @param {type:\\\"string\\\"}\\n\",\n        \"\\n\",\n        \"# Initialize Vertex AI\\n\",\n        \"vertexai.init(project=PROJECT_ID, location=LOCATION)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"T7m8QXnX5TDD\"\n      },\n      \"source\": [\n        \"## Available Embedding Models\\n\",\n        \"\\n\",\n        \"Let's first look at the available embedding models in Vertex AI. For this tutorial, we'll focus on two models:\\n\",\n        \"\\n\",\n        \"1. **textembedding-gecko@003**: A text-only embedding model (768-dimensional embeddings)\\n\",\n        \"2. **text-embedding-004**: The latest text embedding model (768-dimensional embeddings)\\n\",\n        \"3. **Gemini 1.5 Flash** (gemini-1.5-flash-001): A multimodal embedding model that can handle text and images\\n\",\n        \"\\n\",\n        \"Note that `textembedding-gecko@003` is being replaced by `text-embedding-004`, which has better performance.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"2xZ7s_9m5Uhn\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Load text embedding models\\n\",\n        \"gecko_embedding_model = TextEmbeddingModel.from_pretrained(\\\"textembedding-gecko@003\\\")\\n\",\n        \"text_embedding_model = TextEmbeddingModel.from_pretrained(\\\"text-embedding-004\\\")\\n\",\n        \"\\n\",\n        \"# Load the Gemini 1.5 Flash model for multimodal embeddings\\n\",\n        \"gemini_embedding_model = GenerativeModel(\\\"gemini-1.5-flash-001\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"JgotW5TK5V-X\"\n      },\n      \"source\": [\n        \"## Basic Text Embeddings\\n\",\n        \"\\n\",\n        \"Let's start by generating embeddings for a few text examples to understand how they work.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"X7I6nBvr5XMf\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define some example texts\\n\",\n        \"texts = [\\n\",\n        \"    \\\"Artificial intelligence is transforming the technology landscape.\\\",\\n\",\n        \"    \\\"Machine learning models improve with more training data.\\\",\\n\",\n        \"    \\\"Paris is the capital city of France.\\\",\\n\",\n        \"    \\\"The Eiffel Tower is a famous landmark in Paris.\\\",\\n\",\n        \"]\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"X1R2QUCM5YfA\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate embeddings using the Gecko model\\n\",\n        \"gecko_embeddings = gecko_embedding_model.get_embeddings(texts)\\n\",\n        \"\\n\",\n        \"# Let's look at the first embedding vector\\n\",\n        \"first_embedding = gecko_embeddings[0].values\\n\",\n        \"print(f\\\"Embedding dimension: {len(first_embedding)}\\\")\\n\",\n        \"print(f\\\"First few values: {first_embedding[:5]}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"KJnbWDVS5Zzn\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate embeddings using the new text-embedding-004 model\\n\",\n        \"text_embeddings = text_embedding_model.get_embeddings(texts)\\n\",\n        \"\\n\",\n        \"# Let's look at the first embedding vector\\n\",\n        \"first_embedding = text_embeddings[0].values\\n\",\n        \"print(f\\\"Embedding dimension: {len(first_embedding)}\\\")\\n\",\n        \"print(f\\\"First few values: {first_embedding[:5]}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"RXrR0L9y5bQX\"\n      },\n      \"source\": [\n        \"## Measuring Similarity\\n\",\n        \"\\n\",\n        \"The key property of embeddings is that semantically similar items should have similar vectors. Let's measure the similarity between our example texts using cosine similarity.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"kYEZWyTx5c1X\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def cosine_similarity(a, b):\\n\",\n        \"    \\\"\\\"\\\"Compute cosine similarity between two vectors.\\\"\\\"\\\"\\n\",\n        \"    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\\n\",\n        \"\\n\",\n        \"# Extract embedding values\\n\",\n        \"embedding_values = [emb.values for emb in text_embeddings]\\n\",\n        \"\\n\",\n        \"# Create a similarity matrix\\n\",\n        \"n = len(embedding_values)\\n\",\n        \"similarity_matrix = np.zeros((n, n))\\n\",\n        \"\\n\",\n        \"for i in range(n):\\n\",\n        \"    for j in range(n):\\n\",\n        \"        similarity_matrix[i, j] = cosine_similarity(embedding_values[i], embedding_values[j])\\n\",\n        \"\\n\",\n        \"# Print similarity matrix with corresponding texts\\n\",\n        \"print(\\\"Similarity Matrix:\\\")\\n\",\n        \"for i in range(n):\\n\",\n        \"    for j in range(n):\\n\",\n        \"        if i <= j:  # Print upper triangle to avoid redundancy\\n\",\n        \"            print(f\\\"Similarity between text {i+1} and text {j+1}: {similarity_matrix[i, j]:.4f}\\\")\\n\",\n        \"            if i != j:  # Don't print the text when comparing with itself\\n\",\n        \"                print(f\\\"  Text {i+1}: {texts[i]}\\\")\\n\",\n        \"                print(f\\\"  Text {j+1}: {texts[j]}\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"gAscjmNy5eQP\"\n      },\n      \"source\": [\n        \"You can see that texts about similar topics have higher similarity scores. For example, the two texts about AI/ML have higher similarity with each other, and the two texts about Paris are more similar to each other.\\n\",\n        \"\\n\",\n        \"## Embedding Tasks and Task Types\\n\",\n        \"\\n\",\n        \"Embedding models can be optimized for specific tasks. Let's explore the different task types:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"BUkVb3Dv5fq_\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate embeddings with different task types\\n\",\n        \"query = \\\"How does artificial intelligence work?\\\"\\n\",\n        \"document = \\\"Artificial intelligence systems process data through neural networks to identify patterns and make predictions.\\\"\\n\",\n        \"\\n\",\n        \"# Semantic similarity (default) - general purpose\\n\",\n        \"semantic_query_emb = text_embedding_model.get_embeddings([query])[0].values\\n\",\n        \"semantic_doc_emb = text_embedding_model.get_embeddings([document])[0].values\\n\",\n        \"\\n\",\n        \"# Retrieval query - optimized for search queries\\n\",\n        \"retrieval_query_emb = text_embedding_model.get_embeddings(\\n\",\n        \"    [query], task_type=\\\"RETRIEVAL_QUERY\\\"\\n\",\n        \")[0].values\\n\",\n        \"\\n\",\n        \"# Retrieval document - optimized for documents to be searched\\n\",\n        \"retrieval_doc_emb = text_embedding_model.get_embeddings(\\n\",\n        \"    [document], task_type=\\\"RETRIEVAL_DOCUMENT\\\"\\n\",\n        \")[0].values\\n\",\n        \"\\n\",\n        \"# Compare similarities\\n\",\n        \"semantic_similarity = cosine_similarity(semantic_query_emb, semantic_doc_emb)\\n\",\n        \"retrieval_similarity = cosine_similarity(retrieval_query_emb, retrieval_doc_emb)\\n\",\n        \"\\n\",\n        \"print(f\\\"Semantic similarity (default): {semantic_similarity:.4f}\\\")\\n\",\n        \"print(f\\\"Retrieval similarity (query-document): {retrieval_similarity:.4f}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"_ZcSCyQr5hJn\"\n      },\n      \"source\": [\n        \"The specialized retrieval embeddings can improve performance in search applications by optimizing how queries and documents are represented in the embedding space.\\n\",\n        \"\\n\",\n        \"## Using Gemini 1.5 Flash for Embeddings\\n\",\n        \"\\n\",\n        \"Now, let's use the Gemini 1.5 Flash model to generate embeddings. This model can handle both text and multimodal content (though we'll focus on text for now).\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"GJM8g6ek5i3X\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate embeddings with Gemini 1.5 Flash\\n\",\n        \"gemini_text_embedding = gemini_embedding_model.generate_content(\\n\",\n        \"    contents=texts[0],  # Using the first text from our examples\\n\",\n        \"    generation_config={\\\"embedding\\\": True}\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Access the embedding\\n\",\n        \"embedding = gemini_text_embedding.embedding\\n\",\n        \"print(f\\\"Gemini embedding dimension: {len(embedding)}\\\")\\n\",\n        \"print(f\\\"First few values: {embedding[:5]}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"B3Tk5eOn5kV3\"\n      },\n      \"source\": [\n        \"## Batch Processing for Efficiency\\n\",\n        \"\\n\",\n        \"When working with many texts, batch processing is more efficient than processing one text at a time.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"5T0a9nUp5mHH\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Generate embeddings for multiple texts in a single request\\n\",\n        \"batch_embeddings = text_embedding_model.get_embeddings(texts)\\n\",\n        \"\\n\",\n        \"print(f\\\"Number of embeddings generated: {len(batch_embeddings)}\\\")\\n\",\n        \"for i, emb in enumerate(batch_embeddings):\\n\",\n        \"    print(f\\\"Embedding {i+1} dimension: {len(emb.values)}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"D2hzHcf55ndP\"\n      },\n      \"source\": [\n        \"## Application: Semantic Search\\n\",\n        \"\\n\",\n        \"Let's build a simple semantic search system using embeddings. We'll create a small document collection and search it using embedding similarity.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"5AQ8R-z55o_X\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Create a small document collection\\n\",\n        \"documents = [\\n\",\n        \"    \\\"Artificial intelligence systems use neural networks to process and analyze data.\\\",\\n\",\n        \"    \\\"Machine learning is a subset of AI focused on training models with data.\\\",\\n\",\n        \"    \\\"Deep learning uses multiple layers of neural networks for complex pattern recognition.\\\",\\n\",\n        \"    \\\"Natural language processing helps computers understand and generate human language.\\\",\\n\",\n        \"    \\\"Computer vision enables machines to interpret and make decisions based on visual data.\\\",\\n\",\n        \"    \\\"Reinforcement learning trains agents through reward-based feedback systems.\\\",\\n\",\n        \"    \\\"The Eiffel Tower is a wrought-iron lattice tower located in Paris, France.\\\",\\n\",\n        \"    \\\"The Louvre Museum houses thousands of works of art, including the Mona Lisa.\\\",\\n\",\n        \"    \\\"The Seine River flows through the heart of Paris, with many famous bridges.\\\",\\n\",\n        \"    \\\"French cuisine is known for its sophisticated techniques and high-quality ingredients.\\\",\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"# Generate embeddings for all documents using retrieval_document task type\\n\",\n        \"document_embeddings = text_embedding_model.get_embeddings(\\n\",\n        \"    documents, task_type=\\\"RETRIEVAL_DOCUMENT\\\"\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"8_2eM8ec5qfP\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def semantic_search(query, doc_embeddings, documents, top_k=3):\\n\",\n        \"    \\\"\\\"\\\"Perform semantic search using embeddings.\\\"\\\"\\\"\\n\",\n        \"    # Generate embedding for the query with retrieval_query task type\\n\",\n        \"    query_embedding = text_embedding_model.get_embeddings(\\n\",\n        \"        [query], task_type=\\\"RETRIEVAL_QUERY\\\"\\n\",\n        \"    )[0].values\\n\",\n        \"    \\n\",\n        \"    # Calculate similarity with each document\\n\",\n        \"    similarities = []\\n\",\n        \"    for i, doc_emb in enumerate(doc_embeddings):\\n\",\n        \"        similarity = cosine_similarity(query_embedding, doc_emb.values)\\n\",\n        \"        similarities.append((i, similarity))\\n\",\n        \"    \\n\",\n        \"    # Sort by similarity (highest first)\\n\",\n        \"    similarities.sort(key=lambda x: x[1], reverse=True)\\n\",\n        \"    \\n\",\n        \"    # Return top-k results\\n\",\n        \"    results = []\\n\",\n        \"    for i, sim in similarities[:top_k]:\\n\",\n        \"        results.append({\\n\",\n        \"            \\\"document\\\": documents[i],\\n\",\n        \"            \\\"similarity\\\": sim\\n\",\n        \"        })\\n\",\n        \"    \\n\",\n        \"    return results\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"IEb6F-Y-5sNH\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Try some search queries\\n\",\n        \"search_queries = [\\n\",\n        \"    \\\"How do neural networks work?\\\",\\n\",\n        \"    \\\"What are some famous landmarks in Paris?\\\",\\n\",\n        \"    \\\"Tell me about machine learning techniques\\\"\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"for query in search_queries:\\n\",\n        \"    print(f\\\"\\\\nSearch query: {query}\\\")\\n\",\n        \"    results = semantic_search(query, document_embeddings, documents)\\n\",\n        \"    for i, result in enumerate(results):\\n\",\n        \"        print(f\\\"Result {i+1} (Similarity: {result['similarity']:.4f}):\\\")\\n\",\n        \"        print(f\\\"  {result['document']}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"bYaJLn9o5tuP\"\n      },\n      \"source\": [\n        \"Notice how the search returns semantically relevant documents, even when the exact keywords from the query don't appear in the document. This is the power of semantic search with embeddings!\\n\",\n        \"\\n\",\n        \"## Application: Text Classification\\n\",\n        \"\\n\",\n        \"Another common use of embeddings is for classification tasks. Let's build a simple text classifier using a nearest-neighbors approach with embeddings.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"1sS8D6Bx5vP_\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define some example texts with known categories\\n\",\n        \"training_data = [\\n\",\n        \"    {\\\"text\\\": \\\"Neural networks can solve complex pattern recognition problems\\\", \\\"category\\\": \\\"AI/ML\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"Deep learning has revolutionized computer vision and NLP\\\", \\\"category\\\": \\\"AI/ML\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"Supervised learning uses labeled data for training\\\", \\\"category\\\": \\\"AI/ML\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"Paris is known as the City of Light\\\", \\\"category\\\": \\\"Travel\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"The Eiffel Tower was built for the 1889 World's Fair\\\", \\\"category\\\": \\\"Travel\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"France is a popular tourist destination in Europe\\\", \\\"category\\\": \\\"Travel\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"Coding in Python is easier than many other languages\\\", \\\"category\\\": \\\"Programming\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"JavaScript is essential for front-end web development\\\", \\\"category\\\": \\\"Programming\\\"},\\n\",\n        \"    {\\\"text\\\": \\\"Version control systems like Git help manage code changes\\\", \\\"category\\\": \\\"Programming\\\"},\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"# Extract texts and categories\\n\",\n        \"texts = [item[\\\"text\\\"] for item in training_data]\\n\",\n        \"categories = [item[\\\"category\\\"] for item in training_data]\\n\",\n        \"\\n\",\n        \"# Generate embeddings for all training texts\\n\",\n        \"training_embeddings = text_embedding_model.get_embeddings(texts)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"1QvJH0eg5w6f\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"def classify_text(new_text, training_embeddings, categories, k=3):\\n\",\n        \"    \\\"\\\"\\\"Classify text using k-nearest neighbors with embeddings.\\\"\\\"\\\"\\n\",\n        \"    # Generate embedding for the new text\\n\",\n        \"    new_embedding = text_embedding_model.get_embeddings([new_text])[0].values\\n\",\n        \"    \\n\",\n        \"    # Calculate similarity with each training example\\n\",\n        \"    similarities = []\\n\",\n        \"    for i, train_emb in enumerate(training_embeddings):\\n\",\n        \"        similarity = cosine_similarity(new_embedding, train_emb.values)\\n\",\n        \"        similarities.append((i, similarity))\\n\",\n        \"    \\n\",\n        \"    # Sort by similarity (highest first)\\n\",\n        \"    similarities.sort(key=lambda x: x[1], reverse=True)\\n\",\n        \"    \\n\",\n        \"    # Take top-k neighbors\\n\",\n        \"    top_k = similarities[:k]\\n\",\n        \"    \\n\",\n        \"    # Count category occurrences among top-k neighbors\\n\",\n        \"    category_counts = {}\\n\",\n        \"    for i, sim in top_k:\\n\",\n        \"        category = categories[i]\\n\",\n        \"        if category in category_counts:\\n\",\n        \"            category_counts[category] += 1\\n\",\n        \"        else:\\n\",\n        \"            category_counts[category] = 1\\n\",\n        \"    \\n\",\n        \"    # Find the most common category\\n\",\n        \"    predicted_category = max(category_counts.items(), key=lambda x: x[1])[0]\\n\",\n        \"    \\n\",\n        \"    return predicted_category, category_counts\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"X2QKWBPD5yT3\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Try classifying some new texts\\n\",\n        \"test_texts = [\\n\",\n        \"    \\\"Reinforcement learning helps robots learn from their environment\\\",\\n\",\n        \"    \\\"Notre Dame Cathedral is a historic landmark in France\\\",\\n\",\n        \"    \\\"Object-oriented programming organizes code into reusable structures\\\",\\n\",\n        \"    \\\"GPT models have advanced the field of natural language processing\\\",\\n\",\n        \"]\\n\",\n        \"\\n\",\n        \"for text in test_texts:\\n\",\n        \"    category, counts = classify_text(text, training_embeddings, categories)\\n\",\n        \"    print(f\\\"Text: {text}\\\")\\n\",\n        \"    print(f\\\"Predicted category: {category}\\\")\\n\",\n        \"    print(f\\\"Category counts among nearest neighbors: {counts}\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"QRMiWsga5z0X\"\n      },\n      \"source\": [\n        \"The classifier correctly identifies the category of new texts based on their semantic similarity to the training examples.\\n\",\n        \"\\n\",\n        \"## Conclusion\\n\",\n        \"\\n\",\n        \"In this tutorial, you've learned:\\n\",\n        \"\\n\",\n        \"1. What embeddings are and why they're useful\\n\",\n        \"2. How to generate embeddings using different models in Vertex AI\\n\",\n        \"3. How to measure similarity between embeddings\\n\",\n        \"4. How to use embeddings for semantic search\\n\",\n        \"5. How to implement a simple text classifier using embeddings\\n\",\n        \"\\n\",\n        \"Embeddings are a powerful tool for various natural language processing and machine learning tasks. By capturing semantic meaning in a numerical form, they enable machines to understand and process text in ways that go beyond simple keyword matching.\\n\",\n        \"\\n\",\n        \"## Next Steps\\n\",\n        \"\\n\",\n        \"To further explore embeddings, you might want to:\\n\",\n        \"\\n\",\n        \"1. Scale up your semantic search system with a vector database like Vertex AI Vector Search\\n\",\n        \"2. Try multimodal embeddings with images or other content types\\n\",\n        \"3. Build a more sophisticated recommendation system using embeddings\\n\",\n        \"4. Explore clustering and visualization of embeddings to understand your data\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"colab\": {\n      \"provenance\": []\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"name\": \"python\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/docs/prompting/multi-turn.md\n# Gemini multi-turn: Building conversations\n\nMulti-turn means that the AI remembers the conversation history, letting you build on previous exchanges, like a normal conversation.\n\nMulti-turn conversations with Gemini enable:\n\n- Back-and-forth dialogues that build on previous context\n- Interactive refinement of questions and answers\n- Follow-up questions that relate to earlier prompts\n- Collaborative problem-solving over multiple steps\n- Personalized assistance that adapts to the conversation\n\n## Multi-turn basics\n\nA multi-turn conversation is a sequence of exchanges between a human and an AI assistant. Each exchange consists of a prompt from the human and a response from the AI. The key difference from single-turn interactions is that the AI has access to the full conversation history, allowing it to maintain context.\n\nHere's a simple multi-turn conversation:\n\n1. **Human**: \"What's the capital of France?\"\n2. **AI**: \"The capital of France is Paris.\"\n3. **Human**: \"What's the population there?\"\n4. **AI**: \"Paris has a population of approximately 2.1 million people within the city limits...\"\n\nNotice how \"there\" in the follow-up question refers back to \"Paris\" from the previous exchange. The AI understands this reference because it maintains the conversation context.\n\n## Pros and cons of multi-turn\n\nConsider these advantages and limitations when deciding whether to use multi-turn conversations:\n\n**Pros:**\n- **Contextual understanding**: The AI remembers previous exchanges, enabling natural conversations\n- **Progressive refinement**: Allows iterative improvement of responses\n- **Complex problem-solving**: Can break down complicated tasks into manageable steps\n- **Reduced repetition**: No need to restate context in each prompt\n- **More natural interaction**: Mimics human conversation patterns\n\n**Cons:**\n- **Context limitations**: Very long conversations may exceed token limits\n- **Potential context drift**: The AI might focus on older parts of the conversation\n- **Higher latency and cost**: Processing the entire conversation history adds overhead\n- **Harder to control**: Maintaining specific behavior over multiple turns can be challenging\n\n## When to use multi-turn\n\nMulti-turn is ideal for:\n\n- **Conversational agents and chatbots**: Building natural dialogue systems\n- **Complex information gathering**: When you need to ask follow-up questions\n- **Progressive problem-solving**: Breaking down complex tasks into steps\n- **Interactive learning**: Educational applications where dialogue helps understanding\n- **Content refinement**: Iteratively improving generated content through feedback\n\nConsider single-turn interactions when:\n- You need deterministic, repeatable outputs\n- You're performing simple, one-off tasks\n- You're processing large numbers of independent requests\n- You need to minimize latency and token usage\n\n## Effective multi-turn strategies\n\n### Giving clear feedback\n\nExplicitly tell the model what you liked or didn't like about its previous responses to guide future replies.\n\n**Example:**\n\n1. **Human**: \"Write a short story about time travel.\"\n2. **AI**: *[Provides a story]*\n3. **Human**: \"That was interesting, but I'd prefer something with more scientific details about the mechanics of time travel. Can you revise it?\"\n4. **AI**: *[Provides revised story with more scientific details]*\n\n### Using explicit references\n\nMake references to previous turns clear and specific to help the model understand exactly what you're referring to.\n\n**Example:**\n\n1. **Human**: \"Explain the difference between traditional machine learning and deep learning.\"\n2. **AI**: *[Provides explanation]*\n3. **Human**: \"In your explanation above, you mentioned neural networks. Can you elaborate more on how they work?\"\n4. **AI**: *[Provides detailed explanation about neural networks]*\n\n### Progressive guidance\n\nGuide the conversation step by step, building on previous responses to achieve complex outcomes.\n\n**Example:**\n\n1. **Human**: \"I want to create a marketing plan for a new coffee shop.\"\n2. **AI**: *[Provides initial marketing plan outline]*\n3. **Human**: \"Great start. Now let's focus on the social media strategy section. What platforms should we prioritize?\"\n4. **AI**: *[Provides social media platform recommendations]*\n5. **Human**: \"Perfect. For Instagram specifically, what type of content calendar would you recommend for the first month?\"\n6. **AI**: *[Provides Instagram content calendar]*\n\n### Refining outputs\n\nUse multi-turn to progressively refine the AI's outputs until they meet your needs.\n\n**Example:**\n\n1. **Human**: \"Write a job description for a data scientist position.\"\n2. **AI**: *[Provides job description]*\n3. **Human**: \"This is good, but can you make it more concise and focus more on machine learning skills?\"\n4. **AI**: *[Provides revised job description]*\n5. **Human**: \"Now add a section about required cloud computing experience.\"\n6. **AI**: *[Provides further revised job description with cloud computing section]*\n\n### Breaking down complex tasks\n\nUse multi-turn to divide complex tasks into manageable steps.\n\n**Example:**\n\n1. **Human**: \"I need help analyzing my company's quarterly sales data.\"\n2. **AI**: \"I'd be happy to help! What specific aspects of the sales data would you like to analyze first?\"\n3. **Human**: \"Let's start by identifying trends in regional performance.\"\n4. **AI**: *[Provides guidance on regional analysis]*\n5. **Human**: \"Now I'd like to compare product category performance.\"\n6. **AI**: *[Provides product category analysis approach]*\n\n## Advanced multi-turn techniques\n\n### System instructions\n\nUse system instructions to set the behavior, personality, and constraints for the entire conversation. System instructions are persistent across the entire conversation.\n\n**Example:**\n\n```python\nsystem_instruction = \"You are an expert physics tutor who explains concepts using simple analogies. Focus on making complex ideas accessible to high school students.\"\n\nchat = model.start_chat(system_instruction=system_instruction)\nresponse = chat.send_message(\"Explain quantum entanglement\")\nprint(response.text)\n\nresponse = chat.send_message(\"Now explain the uncertainty principle\")\nprint(response.text)\n```\n\n### Conversation grounding\n\nProvide factual, external information at the beginning of a conversation to ground the model's responses in accurate information.\n\n**Example:**\n\n```python\n# Start with grounding information\ngrounding_prompt = \"\"\"\nHere is factual information about climate change:\n- Global average temperatures have increased by about 1.1°C since pre-industrial times\n- CO2 levels are at their highest in 800,000 years at over 410ppm\n- Sea levels rose by 8-9 inches since 1880\n- Arctic sea ice is declining at 13% per decade\n\nUse only these facts when answering questions about climate change.\n\"\"\"\n\nchat = model.start_chat()\nresponse = chat.send_message(grounding_prompt)\nprint(response.text)\n\n# Now ask questions that will use the grounding information\nresponse = chat.send_message(\"What's happening to global temperatures?\")\nprint(response.text)\n\nresponse = chat.send_message(\"How is this affecting sea levels?\")\nprint(response.text)\n```\n\n### Managing context length\n\nFor long conversations, you may need to manage context to stay within token limits:\n\n1. **Summarization**: Periodically ask the model to summarize the conversation so far\n2. **Focused reframing**: Restart with a summary of the most important points\n3. **Context windowing**: Only keep the most recent and relevant turns\n\n**Example:**\n\n```python\n# After many turns, summarize and reset\nsummary_prompt = \"Please summarize our conversation about marketing strategies so far.\"\nresponse = chat.send_message(summary_prompt)\nsummary = response.text\n\n# Start a new chat with the summary as context\nnew_chat = model.start_chat()\nnew_chat.send_message(f\"Here's a summary of our previous discussion: {summary}. Let's continue our conversation about marketing strategies.\")\n```\n\n### Collaborative editing\n\nWork with the model to iteratively refine a piece of content through multiple turns.\n\n**Example:**\n\n```python\n# Start with initial content\nresponse = chat.send_message(\"Write a short blog post about sustainable gardening.\")\ninitial_post = response.text\nprint(\"INITIAL POST:\")\nprint(initial_post)\n\n# First refinement\nresponse = chat.send_message(\"This is good, but can you add more specific examples of sustainable practices?\")\nfirst_revision = response.text\nprint(\"\\nFIRST REVISION:\")\nprint(first_revision)\n\n# Second refinement\nresponse = chat.send_message(\"Now add a section about composting techniques.\")\nsecond_revision = response.text\nprint(\"\\nSECOND REVISION:\")\nprint(second_revision)\n\n# Final polish\nresponse = chat.send_message(\"Great! Now format it with clear headings and a conclusion.\")\nfinal_post = response.text\nprint(\"\\nFINAL POST:\")\nprint(final_post)\n```\n\n## Common pitfalls and solutions\n\n### Context drift\n\n**Problem**: Over time, the model may drift away from the original topic or purpose.\n\n**Solution**: Periodically restate the main objective or use system instructions to maintain focus.\n\n```python\n# After several turns, refocus the conversation\nrefocus_prompt = \"Let's get back to our main objective of developing a marketing strategy for the eco-friendly product line. Based on what we've discussed, what are the next steps?\"\n```\n\n### Response deterioration\n\n**Problem**: Quality of responses may decrease in very long conversations.\n\n**Solution**: Summarize the conversation periodically and start fresh, carrying forward only the essential context.\n\n```python\n# When you notice quality declining\nsummary_prompt = \"Let's summarize what we've established so far about the machine learning project requirements.\"\nresponse = chat.send_message(summary_prompt)\nsummary = response.text\n\n# Start fresh with the essential context\nnew_chat = model.start_chat()\nnew_chat.send_message(f\"Based on this summary of our previous discussion: {summary}, let's continue planning the machine learning project.\")\n```\n\n### Repetitive responses\n\n**Problem**: The model repeats information or gets stuck in a pattern.\n\n**Solution**: Explicitly ask for new information or approach the topic from a different angle.\n\n```python\n# When responses become repetitive\nredirect_prompt = \"Let's explore a different aspect of this topic. Instead of focusing on X, what can you tell me about Y?\"\n```\n\n### Inconsistency across turns\n\n**Problem**: The model contradicts its earlier statements in later turns.\n\n**Solution**: Point out the inconsistency and ask for clarification, or provide a summary of established facts.\n\n```python\n# When you notice inconsistency\nconsistency_prompt = \"Earlier you mentioned that [previous statement], but now you're saying [contradictory statement]. Can you clarify which is correct and explain the apparent contradiction?\"\n```\n\n## Debugging multi-turn conversations\n\nWhen a conversation isn't going as expected:\n\n1. **Review the full conversation history** to identify where things went off track\n2. **Check for ambiguous instructions** that might be misinterpreted\n3. **Look for conflicting requests** across different turns\n4. **Ensure your follow-up questions** are specific and clear\n5. **Consider the total context length** - you might be hitting token limits\n\n### Common debugging techniques:\n\n- **Meta-questions**: Ask the model to explain its understanding of your request\n- **Conversation reset**: Start a new conversation with clearer instructions\n- **Step-by-step guidance**: Break complex tasks into explicit steps\n- **Direct feedback**: Tell the model exactly what went wrong and what you expect\n\n## Code example: Building a multi-turn conversation\n\nHere's a complete example showing how to build an effective multi-turn conversation:\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\n\n# Initialize Vertex AI\nvertexai.init(project=\"your-project-id\", location=\"us-central1\")\n\n# Load the model\nmodel = GenerativeModel(\"gemini-1.5-pro\")\n\n# Start a chat with system instructions\nsystem_instruction = \"\"\"\nYou are a helpful educational assistant specialized in explaining programming concepts.\nAlways provide code examples to illustrate your explanations.\nWhen suggesting exercises, make them appropriate for the user's level.\n\"\"\"\n\nchat = model.start_chat(system_instruction=system_instruction)\n\n# Initial question\nresponse = chat.send_message(\"Can you explain Python decorators?\")\nprint(\"RESPONSE 1:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Follow-up question building on the first response\nresponse = chat.send_message(\"That's helpful. Can you show an example of a decorator that times how long a function takes to run?\")\nprint(\"RESPONSE 2:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Asking for clarification on part of the response\nresponse = chat.send_message(\"In your example, I don't understand the 'wrapper' function. Can you explain why it's needed and how it works?\")\nprint(\"RESPONSE 3:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Requesting a practical exercise\nresponse = chat.send_message(\"Now that I understand decorators better, can you give me a beginner-level exercise to practice creating my own decorator?\")\nprint(\"RESPONSE 4:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Feedback and refinement\nresponse = chat.send_message(\"That exercise seems a bit advanced for me. Could you simplify it and walk me through the steps?\")\nprint(\"RESPONSE 5:\")\nprint(response.text)\n```\n\n## Summary\n\nMulti-turn conversations with Gemini enable natural, contextual interactions that build upon previous exchanges. By understanding and applying effective strategies, you can create more engaging, productive, and human-like AI interactions.\n\nKey takeaways:\n- Multi-turn conversations maintain context across exchanges\n- They're ideal for complex tasks, progressive refinement, and natural interactions\n- Effective strategies include clear feedback, explicit references, and breaking down complex tasks\n- Advanced techniques like system instructions and context management enhance multi-turn capabilities\n- Be aware of common pitfalls like context drift and response deterioration\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/docs/prompting/define-system-instructions.md\n# Define system instructions\n\nSystem instructions tell the model how to behave during a conversation. They provide context and constraints, influencing the model's responses without being directly visible to the user.\n\nUse system instructions to:\n\n- Define the AI's role, expertise, and personality\n- Set constraints and response guidelines\n- Provide factual context and domain knowledge\n- Establish response formats and structures\n- Configure safety and content preferences\n\n## Basic syntax\n\n```python\nsystem_instruction = \"You are a knowledgeable math tutor. Provide clear step-by-step explanations for math problems.\"\n\nchat = model.start_chat(system_instruction=system_instruction)\n```\n\n## Effective system instructions\n\n### Define roles and expertise\n\nSpecify a clear role for the model to assume, optionally with expertise in particular domains.\n\n**Example:**\n\n```python\nsystem_instruction = \"You are an expert chef specializing in Italian cuisine. You have extensive knowledge of traditional Italian cooking methods, regional specialties, and ingredient selection.\"\n```\n\n### Set tone and style\n\nDefine the communication style, level of formality, and overall tone.\n\n**Example:**\n\n```python\nsystem_instruction = \"You are a friendly, patient tutor. Explain concepts in simple language suitable for a middle school student. Use encouraging language and positive reinforcement.\"\n```\n\n### Establish constraints\n\nClearly define what the model should or should not include in its responses.\n\n**Example:**\n\n```python\nsystem_instruction = \"\"\"\nYou are a financial advisor focusing only on basic retirement planning.\nDo not give specific investment recommendations or tax advice.\nAlways suggest consulting with a licensed professional for personalized advice.\n\"\"\"\n```\n\n### Provide factual context\n\nSupply the model with factual information or domain knowledge that should inform all responses.\n\n**Example:**\n\n```python\nsystem_instruction = \"\"\"\nYou are a tour guide for New York City. You have the following up-to-date information:\n- The Statue of Liberty is open daily from 8:30 AM to 4:00 PM\n- The subway fare is currently $2.90 per ride\n- Times Square is located at the intersection of Broadway, 7th Avenue, and 42nd Street\n- The Metropolitan Museum of Art is closed on Wednesdays\nUse this information when answering questions about NYC.\n\"\"\"\n```\n\n### Specify response format\n\nDefine specific formats, structures, or templates for responses.\n\n**Example:**\n\n```python\nsystem_instruction = \"\"\"\nYou are a technical documentation writer. Format your responses as follows:\n1. Start with a brief summary (2-3 sentences)\n2. Provide detailed explanation using markdown headings and bullet points\n3. Include a \"Common Issues\" section at the end with troubleshooting tips\n\"\"\"\n```\n\n## Best practices\n\n### Be specific and detailed\n\nProvide clear, detailed instructions rather than vague guidelines.\n\n**Instead of this:**\n```\n\"Be a helpful assistant.\"\n```\n\n**Use this:**\n```\n\"You are a customer service assistant for a telecom company. Answer product questions about phone plans, internet services, and billing issues. Provide specific plan details when available, and suggest contacting our support line at 1-800-555-0123 for account-specific questions.\"\n```\n\n### Balance guidance with flexibility\n\nProvide enough direction without overly restricting the model's capabilities.\n\n**Example of good balance:**\n```python\nsystem_instruction = \"\"\"\nYou are a creative writing coach specializing in fiction. \nWhen reviewing writing samples:\n1. First point out 2-3 strengths in the writing\n2. Then offer 2-3 specific suggestions for improvement\n3. End with an encouraging note\n\nAdapt your feedback to the apparent skill level of the writer, offering more basic advice for beginners and more nuanced feedback for advanced writers.\n\"\"\"\n```\n\n### Test and iterate\n\nSystem instructions often require refinement based on the model's actual responses.\n\n```python\n# Initial system instruction\nsystem_instruction = \"You are a financial advisor helping with budgeting.\"\n\n# Test with sample user inputs\nchat = model.start_chat(system_instruction=system_instruction)\nresponse = chat.send_message(\"I need help managing my spending.\")\nprint(response.text)\n\n# Refine based on actual responses\nsystem_instruction = \"\"\"\nYou are a financial advisor focused on personal budgeting for individuals.\nWhen discussing budgets:\n1. Ask about income and essential expenses first\n2. Suggest the 50/30/20 rule (needs/wants/savings)\n3. Provide practical, actionable tips for reducing expenses\n4. Never recommend specific investments or financial products\n\"\"\"\n```\n\n### Layer information logically\n\nStructure complex system instructions in a logical order, moving from general to specific.\n\n```python\nsystem_instruction = \"\"\"\nYou are a nutrition consultant helping people improve their diets.\n\nEXPERTISE:\n- Balanced meal planning\n- Dietary requirements for common health conditions\n- Nutritional content of foods\n\nRESPONSE STYLE:\n- Professional but approachable\n- Evidence-based recommendations\n- Practical and realistic advice\n\nCONSTRAINTS:\n- Do not provide medical advice or treatment recommendations\n- Do not recommend extreme diets or severe calorie restrictions\n- Acknowledge when a question requires medical supervision\n\nFORMAT:\n- Start with a direct answer to the question\n- Provide scientific context where relevant\n- Include practical implementation tips\n- End with a positive, encouraging note\n\"\"\"\n```\n\n### Avoid contradictory instructions\n\nEnsure all parts of your system instruction work together coherently.\n\n**Contradictory (problematic):**\n```\n\"You are a creative writing assistant. Always provide imaginative, detailed responses with colorful descriptions. Keep all answers brief and under 50 words.\"\n```\n\n**Coherent (better):**\n```\n\"You are a creative writing assistant specializing in concise prose. Provide vivid, impactful descriptions using carefully chosen words. Aim for brevity while maintaining creative impact, keeping responses under 75 words.\"\n```\n\n## Advanced techniques\n\n### Persona definition\n\nCreate detailed personas to guide the model's behavior consistently.\n\n```python\nsystem_instruction = \"\"\"\nYou are Dr. Ada Chen, a clinical psychologist with 15 years of experience in cognitive behavioral therapy. You have:\n- A PhD in Clinical Psychology from Stanford University\n- Authored three books on anxiety management\n- A warm, empathetic communication style that balances professionalism with accessibility\n- A preference for evidence-based approaches while acknowledging the importance of individual experiences\n\nWhen responding to questions:\n- Draw on established psychological research when appropriate\n- Use analogies to explain complex concepts\n- Validate the user's experiences\n- Suggest practical, actionable techniques\n- Maintain appropriate professional boundaries\n\nAlways clarify that you're providing educational information, not therapy or personalized medical advice.\n\"\"\"\n```\n\n### Decision trees\n\nGuide the model through different response paths based on categories of user input.\n\n```python\nsystem_instruction = \"\"\"\nYou are a customer support agent for a software company. When responding to customer inquiries:\n\n1. FOR TECHNICAL ISSUES:\n   - Ask for specific error messages and system information\n   - Provide troubleshooting steps in a numbered list\n   - Suggest contacting technical support if basic troubleshooting fails\n\n2. FOR BILLING QUESTIONS:\n   - Explain our pricing plans clearly\n   - Direct account-specific questions to our billing department\n   - Provide general refund policy information\n\n3. FOR FEATURE REQUESTS:\n   - Thank the user for their suggestion\n   - Explain if similar features exist\n   - Note that you'll pass their feedback to the product team\n\n4. FOR GENERAL INQUIRIES:\n   - Provide concise, helpful information\n   - Link to relevant documentation when applicable\n   - Ask clarifying questions if the request is ambiguous\n\"\"\"\n```\n\n### Contextual knowledge base\n\nProvide domain-specific information that should be used across all responses.\n\n```python\nsystem_instruction = \"\"\"\nYou are a product specialist for our smart home system. Use the following product specifications in your responses:\n\nPRODUCT DETAILS:\n- SmartHome Hub Pro (Model SH-500)\n- Compatible with Zigbee, Z-Wave, and Wi-Fi devices\n- Voice assistant integration with Alexa, Google Assistant, and Siri\n- Available in white, black, and silver finishes\n- Retail price: $149.99\n- Warranty: 2 years limited\n\nCOMMON INTEGRATIONS:\n- Lighting: Philips Hue, LIFX, TP-Link\n- Security: Ring, Arlo, SimpliSafe\n- Climate: Nest, Ecobee, Honeywell\n- Entertainment: Sonos, Samsung SmartTV, Roku\n\nTROUBLESHOOTING:\n- Connectivity issues typically resolved by power cycling the hub\n- Z-Wave devices require pairing within 15 feet of the hub\n- Maximum supported devices: 150 per hub\n- Software updates occur automatically every 2 weeks\n\nWhen uncertain about compatibility with specific third-party devices, recommend checking our compatibility database at smarthouse.com/compatibility\n\"\"\"\n```\n\n### Multi-layered rules\n\nImplement multiple levels of instructions, from general principles to specific rules.\n\n```python\nsystem_instruction = \"\"\"\nYou are a math education assistant.\n\nCORE PRINCIPLES:\n1. Promote understanding over memorization\n2. Encourage problem-solving approaches\n3. Build confidence in mathematical ability\n\nTEACHING APPROACH:\n- Start with concrete examples before abstract concepts\n- Use visual explanations when possible\n- Relate concepts to real-world applications\n- Scaffold complex problems into manageable steps\n\nRESPONSE REQUIREMENTS:\n- Always show complete step-by-step solutions\n- Explain the reasoning behind each step\n- Highlight common misconceptions\n- Provide an alternative approach when appropriate\n- Use clear, precise mathematical notation\n\nSPECIFIC RULES:\n- For algebra problems, explain the properties used in each step\n- For geometry, include diagrams when describing spatial concepts\n- For statistics, explain both the calculation and interpretation\n- For calculus, connect concepts to their geometric meaning\n\nIf a question is ambiguous, ask for clarification rather than making assumptions.\n\"\"\"\n```\n\n## Safety and responsible use\n\n### Transparency\n\nBe clear with users about the model's capabilities and limitations.\n\n```python\nsystem_instruction = \"\"\"\nYou are an AI assistant providing general information about health topics.\n\nImportant limitations to make clear in your responses:\n- You are not a licensed medical professional\n- You cannot diagnose conditions or recommend treatments\n- You do not have access to personal medical records\n- Your knowledge has limitations and may not include the latest research\n\nWhen discussing health topics:\n1. Provide general educational information only\n2. Suggest consulting healthcare providers for personal medical advice\n3. Cite general sources of information when possible\n4. Do not make definitive claims about treatments\n\"\"\"\n```\n\n### Content moderation\n\nUse system instructions to set boundaries on content.\n\n```python\nsystem_instruction = \"\"\"\nYou are an educational assistant for high school students.\n\nContent guidelines:\n- Keep all content appropriate for teenagers\n- Provide factual, educational information\n- Do not assist with creating inappropriate content\n- Focus on promoting critical thinking and learning\n- Do not provide solutions to assignments that appear to be current homework\n- Encourage original thinking and proper citation of sources\n- Redirect harmful requests to appropriate educational resources\n\"\"\"\n```\n\n## Technical considerations\n\n### Token usage\n\nSystem instructions consume tokens from your context window. Balance detail with efficiency.\n\n```python\n# More efficient system instruction\nsystem_instruction = \"\"\"\nYou are a concise technical support agent. Focus on direct troubleshooting steps.\nUse bullet points. Prioritize common solutions first. Link to docs for complex issues.\n\"\"\"\n```\n\n### Persistence\n\nSystem instructions persist throughout a conversation, setting the foundation for all interactions.\n\n```python\n# This system instruction will apply to all messages in the conversation\nsystem_instruction = \"You are a helpful research assistant with expertise in climate science.\"\n\nchat = model.start_chat(system_instruction=system_instruction)\n\n# All these messages will be influenced by the system instruction\nresponse1 = chat.send_message(\"What are the main greenhouse gases?\")\nresponse2 = chat.send_message(\"How do they affect global temperatures?\")\nresponse3 = chat.send_message(\"What are some mitigation strategies?\")\n```\n\n### Updating system instructions\n\nTo change the system instruction, you need to start a new chat session.\n\n```python\n# First chat with initial system instruction\nsystem_instruction1 = \"You are a creative writing assistant focusing on fiction.\"\nchat1 = model.start_chat(system_instruction=system_instruction1)\nresponse1 = chat1.send_message(\"Help me develop a character for my story.\")\n\n# New chat with updated system instruction\nsystem_instruction2 = \"You are a technical writing assistant focusing on clarity and precision.\"\nchat2 = model.start_chat(system_instruction=system_instruction2)\nresponse2 = chat2.send_message(\"Help me write documentation for my API.\")\n```\n\n## Code examples\n\n### Basic system instruction setup\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\n\n# Initialize Vertex AI\nvertexai.init(project=\"your-project-id\", location=\"us-central1\")\n\n# Load the model\nmodel = GenerativeModel(\"gemini-1.5-pro\")\n\n# Define system instruction\nsystem_instruction = \"\"\"\nYou are a helpful coding assistant specializing in Python. \nProvide clear, efficient code examples with explanations.\nFollow PEP 8 style guidelines in all code.\nInclude comments for complex sections.\n\"\"\"\n\n# Start a chat with the system instruction\nchat = model.start_chat(system_instruction=system_instruction)\n\n# Send a message\nresponse = chat.send_message(\"How do I read and parse a CSV file in Python?\")\nprint(response.text)\n```\n\n### Professional assistant with specific format\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\n\n# Initialize Vertex AI\nvertexai.init(project=\"your-project-id\", location=\"us-central1\")\n\n# Load the model\nmodel = GenerativeModel(\"gemini-1.5-pro\")\n\n# Define detailed system instruction\nsystem_instruction = \"\"\"\nYou are a professional business consultant specializing in market analysis.\n\nEXPERTISE:\n- Industry trend analysis\n- Competitive landscape assessment\n- Market sizing and growth projections\n- Consumer behavior insights\n\nRESPONSE FORMAT:\n1. SUMMARY: Start with a brief executive summary (2-3 sentences)\n2. ANALYSIS: Provide detailed insights using data and market principles\n3. RECOMMENDATIONS: Offer 3-5 actionable recommendations\n4. LIMITATIONS: Note important caveats or data constraints\n\nSTYLE GUIDELINES:\n- Use professional business language\n- Be concise and data-oriented\n- Avoid jargon unless industry-specific\n- Support claims with general market principles\n- Use bullet points for lists and recommendations\n\nWhen specific data is not available, clearly indicate assumptions and provide ranges rather than precise figures.\n\"\"\"\n\n# Start a chat with the system instruction\nchat = model.start_chat(system_instruction=system_instruction)\n\n# Send a market analysis request\nresponse = chat.send_message(\"Analyze the current market for electric vehicles in Europe.\")\nprint(response.text)\n```\n\n### Educational assistant with safety guidelines\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\n\n# Initialize Vertex AI\nvertexai.init(project=\"your-project-id\", location=\"us-central1\")\n\n# Load the model\nmodel = GenerativeModel(\"gemini-1.5-pro\")\n\n# Define system instruction with educational focus and safety guidelines\nsystem_instruction = \"\"\"\nYou are an educational assistant for middle school science (grades 6-8).\n\nEDUCATIONAL APPROACH:\n- Explain concepts at an age-appropriate level\n- Use simple analogies and real-world examples\n- Break down complex topics into understandable parts\n- Encourage curiosity and further exploration\n\nCONTENT GUIDELINES:\n- Ensure all content is appropriate for children aged 11-14\n- Focus on established scientific consensus\n- Present information in an engaging but factual manner\n- When topics have different scientific viewpoints, explain the mainstream perspective while acknowledging that scientists continue to learn more\n\nRESPONSE STRUCTURE:\n1. Direct answer to the question\n2. Simple explanation with examples\n3. Fun fact or interesting application\n4. Suggestion for a simple, safe experiment or observation they could try at home (when applicable)\n\nIf a question touches on topics beyond middle school level, simplify appropriately while maintaining accuracy.\n\"\"\"\n\n# Start a chat with the system instruction\nchat = model.start_chat(system_instruction=system_instruction)\n\n# Ask a science question\nresponse = chat.send_message(\"How do volcanoes work and what causes eruptions?\")\nprint(response.text)\n```\n\n## Summary\n\nSystem instructions are a powerful tool for controlling how Gemini models behave in conversations. By following the best practices and examples in this guide, you can create system instructions that effectively guide the model to provide the responses you need while maintaining appropriate boundaries.\n\nRemember to:\n\n- Be specific and detailed\n- Structure instructions logically\n- Test and refine your instructions\n- Consider token usage and efficiency\n- Use advanced techniques for complex use cases\n- Implement appropriate safety guidelines\n\nWith well-crafted system instructions, you can create more effective, responsible, and useful AI interactions.\n\u0005End File\u0006# site/en/gemini/docs/prompting/zero-shot.md\n# Zero-shot prompting\n\nZero-shot prompting is a technique where you ask a model to perform a task without giving it any examples of how to do that task. The model relies solely on its pre-training to understand and complete the task.\n\nThis guide covers:\n- What zero-shot prompting is and when to use it\n- Techniques for effective zero-shot prompts\n- Common pitfalls and how to avoid them\n- Examples across different use cases\n\n## What is zero-shot prompting?\n\nIn zero-shot prompting, you provide:\n- A clear instruction or question\n- Context or relevant information (optional)\n- Output format instructions (optional)\n\nYou do **not** provide examples of inputs and expected outputs.\n\n### Zero-shot vs. few-shot prompting\n\n| Zero-shot | Few-shot |\n|-----------|----------|\n| No examples provided | One or more examples provided |\n| Relies on model's pre-trained knowledge | Helps model understand the specific pattern you want |\n| Simpler, shorter prompts | More complex, longer prompts |\n| Less control over exact format | More control over output format |\n| Great for straightforward tasks | Better for complex or nuanced tasks |\n\n## When to use zero-shot prompting\n\nZero-shot prompting works well for:\n\n- **Simple, common tasks** the model has likely seen during training\n- **Clearly defined instructions** with standard outputs\n- **General knowledge questions** or information synthesis\n- **Situations where brevity is important** to save on tokens\n- **Exploratory use cases** where you want to see the model's default approach\n\nConsider using few-shot prompting instead when:\n- The task is complex or unusual\n- You need very specific formatting\n- The model's zero-shot responses aren't meeting your needs\n- You're asking the model to follow a pattern that may not be obvious\n\n## Effective zero-shot prompt components\n\nA good zero-shot prompt typically includes:\n\n1. **Clear instruction**: What you want the model to do\n2. **Relevant context**: Background information needed for the task\n3. **Format guidance**: How you want the output structured\n4. **Additional constraints**: Any specific requirements or limitations\n\n### Example of a well-structured zero-shot prompt\n\n```\nSummarize the following article about climate change in 3-4 sentences. Focus on the main findings and implications.\n\nArticle:\n[Article text goes here...]\n```\n\nThis prompt has:\n- Clear instruction: \"Summarize the following article\"\n- Constraints: \"in 3-4 sentences\"\n- Focus guidance: \"Focus on the main findings and implications\"\n- Context: The article text\n\n## Techniques for effective zero-shot prompting\n\n### Be specific and direct\n\nClearly state what you want the model to do.\n\n**Less effective:**\n```\nClimate change information\n```\n\n**More effective:**\n```\nExplain the three primary causes of climate change according to current scientific consensus.\n```\n\n### Provide context when needed\n\nGive the model relevant information to work with.\n\n**Less effective:**\n```\nAnalyze the performance of this company.\n```\n\n**More effective:**\n```\nAnalyze the financial performance of Acme Corporation based on these quarterly results:\nRevenue: $12.5M (up 15% YoY)\nOperating costs: $8.2M (up 7% YoY)\nNew customer acquisition: 2,500 (up 25% YoY)\nCustomer churn rate: 4.5% (down from 5.2% last year)\n```\n\n### Specify output format\n\nTell the model how to structure its response.\n\n**Less effective:**\n```\nTell me about the benefits of exercise.\n```\n\n**More effective:**\n```\nList 5 scientifically-proven benefits of regular exercise. For each benefit, provide a brief one-sentence explanation.\n```\n\n### Use role prompting\n\nAsk the model to adopt a specific perspective or expertise.\n\n**Less effective:**\n```\nHow should I invest my money?\n```\n\n**More effective:**\n```\nAs a financial advisor, what general principles should someone in their 30s consider when creating a retirement investment strategy? Explain in simple terms.\n```\n\n### Set constraints\n\nProvide limitations or requirements for the response.\n\n**Less effective:**\n```\nWrite a recipe for chocolate chip cookies.\n```\n\n**More effective:**\n```\nWrite a recipe for gluten-free chocolate chip cookies that uses less than 10 ingredients and can be prepared in under 30 minutes. Include cooking time and temperature.\n```\n\n## Common zero-shot prompting tasks\n\n### Classification\n\n```\nClassify the sentiment of this customer review as positive, negative, or neutral:\n\n\"I've been using this phone for about a week now. The camera quality is outstanding and the battery lasts all day, which is a huge improvement over my last phone. The only downside is that it's a bit heavier than I expected.\"\n```\n\n### Summarization\n\n```\nProvide a concise summary of the following research abstract in 2-3 sentences:\n\n[Abstract text here...]\n```\n\n### Information extraction\n\n```\nExtract the following information from this email: sender name, main topic, any mentioned deadlines, and required actions. Present the information in a structured format.\n\nEmail:\n[Email text here...]\n```\n\n### Text generation\n\n```\nWrite a professional email to a client explaining that their project will be delayed by two weeks due to unexpected technical issues. Maintain a apologetic but confident tone.\n```\n\n### Translation\n\n```\nTranslate the following English text to Spanish, maintaining the same tone and meaning:\n\n\"We're excited to announce that our annual conference will be held virtually this year, allowing participants from around the world to join without travel expenses.\"\n```\n\n### Question answering\n\n```\nBased on the information provided in the passage below, answer the question that follows.\n\nPassage: [Passage text here...]\n\nQuestion: What were the three main factors that contributed to the company's growth in 2022?\n```\n\n## Advanced zero-shot techniques\n\n### Chain of thought prompting\n\nAsk the model to reason step-by-step.\n\n```\nSolve this math problem step-by-step, showing your reasoning at each step:\n\nA store is having a 25% off sale. If an item originally costs $120, what is the final price after applying a 10% coupon to the discounted price? Sales tax is 8.5%.\n```\n\n### Task decomposition\n\nBreak a complex task into smaller steps.\n\n```\nHelp me write a research proposal by:\n1. First, suggest a narrowly focused research question about climate change adaptation.\n2. Then, outline the key components needed in the proposal.\n3. Finally, identify 3-5 potential challenges in conducting this research.\n```\n\n### Persona-based prompting\n\nDefine a specific perspective for the model to adopt.\n\n```\nAs an experienced pediatrician, explain how parents should approach fever management for toddlers. Include when they should contact a doctor and common misconceptions.\n```\n\n### Comparative analysis\n\nAsk for comparisons between multiple items.\n\n```\nCompare and contrast three approaches to machine learning deployment: on-premises, cloud-based, and hybrid solutions. Consider factors like cost, scalability, security, and maintenance requirements.\n```\n\n## Common pitfalls and solutions\n\n### Vague instructions\n\n**Problem**: Instructions are too general, leading to unfocused responses.\n\n**Solution**: Be specific about what you want, including scope and depth.\n\n**Example fix**:\n```\nInstead of: \"Tell me about renewable energy.\"\nUse: \"Explain the three most widely adopted renewable energy technologies currently in use, focusing on their efficiency, cost, and environmental impact.\"\n```\n\n### Missing context\n\n**Problem**: Not providing necessary background information.\n\n**Solution**: Include relevant context for the model to work with.\n\n**Example fix**:\n```\nInstead of: \"Analyze these results.\"\nUse: \"Analyze these A/B test results for our website redesign. Version A had a 3.2% conversion rate with 10,000 visitors, while Version B had a 3.8% conversion rate with 9,800 visitors. Is this difference statistically significant and what might it indicate?\"\n```\n\n### Ambiguous expectations\n\n**Problem**: The model isn't clear on exactly what output you want.\n\n**Solution**: Clearly state the desired format, length, and focus.\n\n**Example fix**:\n```\nInstead of: \"Write about climate solutions.\"\nUse: \"Write a 250-300 word explanation of three promising technological solutions to climate change. For each solution, briefly explain how it works and its potential impact. Target an audience with basic scientific knowledge.\"\n```\n\n### Output too general\n\n**Problem**: Model provides surface-level information.\n\n**Solution**: Ask for specific details, examples, or depth.\n\n**Example fix**:\n```\nInstead of: \"Explain machine learning.\"\nUse: \"Explain how decision trees work in machine learning, including their advantages, limitations, and a simple example of how they make classification decisions.\"\n```\n\n## Example use cases\n\n### Business\n\n```\nCreate a SWOT analysis (Strengths, Weaknesses, Opportunities, Threats) for a small coffee shop planning to expand to a second location in a nearby college town. Structure your response with clear headings for each SWOT category and 3-5 bullet points under each.\n```\n\n### Education\n\n```\nDevelop a lesson plan for teaching photosynthesis to 5th-grade students. Include:\n- 3-4 key learning objectives\n- A simple explanation of the process appropriate for this age group\n- One hands-on activity that demonstrates the concept\n- A brief assessment method to check understanding\nLimit the lesson to 45 minutes of class time.\n```\n\n### Creative writing\n\n```\nWrite the opening paragraph of a mystery novel set in 1920s Paris. The paragraph should introduce the protagonist, who is a journalist, and hint at a mysterious event that will drive the plot. Use sensory details to establish the atmosphere of the era.\n```\n\n### Programming\n\n```\nWrite a Python function that takes a list of integers as input and returns the second largest number in the list. If there is no second largest number (e.g., all numbers are the same), the function should return None. Include error handling for invalid inputs and comments explaining your code.\n```\n\n### Healthcare\n\n```\nAs a nutritionist, explain the differences between complex carbohydrates and simple sugars in terms of:\n1. Their chemical structure\n2. How the body processes them\n3. Their impact on blood sugar levels\n4. Recommended dietary sources\nKeep the explanation accessible to someone without a scientific background.\n```\n\n## Conclusion\n\nZero-shot prompting is a powerful and efficient way to interact with language models when your tasks are clear and well-defined. By following the techniques in this guide, you can craft effective zero-shot prompts that yield high-quality results without needing to provide examples.\n\nKey takeaways:\n- Be specific and direct about what you want\n- Provide relevant context when needed\n- Specify the desired output format\n- Consider role prompting for specialized knowledge\n- Set clear constraints to guide the response\n- Use advanced techniques for complex tasks\n- Avoid common pitfalls like vague instructions or missing context\n\nAs you become more familiar with zero-shot prompting, you'll develop an intuition for when this approach is sufficient and when you might need to switch to few-shot examples for more complex or nuanced tasks.\n\u0005End File\u0006# google/generative-ai-docs\n# Get an API key\n\nTo use the Gemini API, you need an API key.\n\n## Prerequisites\n\nTo use the Gemini API, you need a Google Account or a Google Cloud project. \n\n- If you're a user of Google AI Studio (makersuite.google.com), you need a Google Account\n- If you're a user of Vertex AI (cloud.google.com/vertex-ai), you need a Google Cloud project\n\n## Get an API key in Google AI Studio\n\n1. If you don't already have one, [create a Google Account](https://accounts.google.com/signup).\n1. Go to the [Google AI Studio API keys page](https://aistudio.google.com/app/apikey).\n1. Enter a name for your API key, and click **Create**. \n1. To copy your newly created API key, click the copy button next to the key.\n1. **Protect your API key**: API keys that begin with `AI` can be used immediately with the Gemini API. These keys are associated with your Google Account and are unique to you. Don't share them with anyone else. \n\n### Configure the Gemini API with your API key\n\nAfter you create your API key, you need to use it to configure the Gemini API.\n\n#### Configure the API for Python\n\n##### Make a one-time API call\n\nTo make a simple one-time API call, you can set the API key when you initialize the Generative AI Python SDK.\n\n```python\n# Import the generative AI package\nimport google.generativeai as genai\n\n# Configure the generative AI package with your API key\ngenai.configure(api_key=\"YOUR_API_KEY\")\n```\n\n##### Configure the API with an environment variable\n\nFor safety and convenience, consider storing your API key as an environment variable in a `.env` file or another secure location.\n\n```python\nimport os\nimport google.generativeai as genai\n\n# Get API key from environment variable GOOGLE_API_KEY\napi_key = os.environ.get(\"GOOGLE_API_KEY\")\n\n# Configure the generative AI package with your API key\ngenai.configure(api_key=api_key)\n```\n\n##### Configure the API with a file\n\nYou can also store your API key in a file.\n\n```python\nimport google.generativeai as genai\n\n# Read API key from a file\nwith open(\"api_key.txt\", \"r\") as f:\n    api_key = f.read().strip()\n\n# Configure the generative AI package with your API key\ngenai.configure(api_key=api_key)\n```\n\n#### Configure the API for Node.js\n\n##### Make a one-time API call\n\nTo make a simple one-time API call, you can set the API key when initializing the Generative AI JavaScript library.\n\n```javascript\n// Import the generative AI package\nconst {\n  GoogleGenerativeAI,\n  HarmCategory,\n  HarmBlockThreshold,\n} = require(\"@google/generative-ai\");\n\n// Configure the generative AI library with your API key\nconst genAI = new GoogleGenerativeAI(\"YOUR_API_KEY\");\n```\n\n##### Configure the API with an environment variable\n\nFor safety and convenience, consider storing your API key as an environment variable using a package like dotenv.\n\n```javascript\n// Import required packages\nrequire(\"dotenv\").config();\nconst { GoogleGenerativeAI } = require(\"@google/generative-ai\");\n\n// Get API key from environment variable GOOGLE_API_KEY\nconst apiKey = process.env.GOOGLE_API_KEY;\n\n// Configure the generative AI library with your API key\nconst genAI = new GoogleGenerativeAI(apiKey);\n```\n\n## Get an API key for Vertex AI\n\nTo use the Gemini API with Vertex AI, you need to:\n\n1. Set up a Google Cloud project and enable the Vertex AI API\n2. Set up authentication\n\nFor detailed instructions, see [Set up a Google Cloud project](/vertex-ai/docs/start/cloud-environment).\n\u0005End File\u0006# google/generative-ai-docs\n# site/en/gemini/docs/get-started/code-with-gemini.md\n# Code with Gemini\n\nGemini excels at helping with coding tasks, from generating code to explaining complex algorithms and debugging issues. This guide covers best practices for working with code in Gemini.\n\n## Code generation\n\nYou can use Gemini to generate code snippets, functions, or even complete programs based on your requirements.\n\n### Basic code generation\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\n\n# Initialize Vertex AI\nvertexai.init(project=\"your-project-id\", location=\"us-central1\")\n\n# Load the model\nmodel = GenerativeModel(\"gemini-1.5-pro\")\n\n# Ask for code generation\nprompt = \"\"\"\nWrite a Python function that calculates the Fibonacci sequence up to n terms.\nThe function should return a list of the sequence.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Specifying language and constraints\n\nFor more precise code generation, specify the programming language, add constraints, and describe the functionality in detail:\n\n```python\nprompt = \"\"\"\nCreate a JavaScript function that validates an email address. The function should:\n1. Accept a string as input\n2. Return true if the string is a valid email, false otherwise\n3. Use regular expressions for validation\n4. Check for basic email format (username@domain.tld)\n5. Be efficient and well-commented\n\nReturn only the code without explanation.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Generating complete applications\n\nGemini can create more complex applications with multiple files and components:\n\n```python\nprompt = \"\"\"\nCreate a simple Flask web application that:\n1. Has a homepage that displays a form with a text input and submit button\n2. When the form is submitted, it checks if the entered text is a palindrome\n3. Displays the result on a results page\n4. Includes basic CSS styling\n\nShow all necessary files and code, including HTML templates and static files.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n## Code understanding and explanation\n\nGemini can analyze and explain code, helping you understand complex implementations.\n\n### Explaining a code snippet\n\n```python\ncode_to_explain = \"\"\"\ndef quicksort(arr):\n    if len(arr) <= 1:\n        return arr\n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    return quicksort(left) + middle + quicksort(right)\n\"\"\"\n\nprompt = f\"\"\"\nExplain the following code in detail:\n\n```python\n{code_to_explain}\n```\n\nInclude:\n1. What the function does\n2. How the algorithm works\n3. The time and space complexity\n4. Any edge cases or limitations\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Analyzing complex code patterns\n\nFor larger code blocks, ask Gemini to focus on specific aspects:\n\n```python\ncomplex_code = \"\"\"\n# Paste complex code here\n\"\"\"\n\nprompt = f\"\"\"\nFor the following code:\n\n```python\n{complex_code}\n```\n\nPlease analyze:\n1. The design pattern(s) being used\n2. Potential performance bottlenecks\n3. Error handling approach\n4. Suggestions for improving maintainability\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n## Debugging\n\nGemini can help identify and fix issues in your code.\n\n### Finding and fixing bugs\n\n```python\nbuggy_code = \"\"\"\ndef calculate_average(numbers):\n    total = 0\n    for num in numbers:\n        total += num\n    return total / len(numbers)\n\n# Test the function\nresult = calculate_average([])\nprint(f\"The average is: {result}\")\n\"\"\"\n\nprompt = f\"\"\"\nThe following code has a bug:\n\n```python\n{buggy_code}\n```\n\n1. Identify the bug(s)\n2. Explain why it's happening\n3. Provide a fixed version of the code\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Debugging error messages\n\nWhen you encounter error messages, share them with Gemini for assistance:\n\n```python\nerror_message = \"\"\"\nTraceback (most recent call last):\n  File \"app.py\", line 42, in <module>\n    result = process_data(user_input)\n  File \"app.py\", line 27, in process_data\n    return data['results'][0]['value'] / 100\nKeyError: 'results'\n\"\"\"\n\ncode_snippet = \"\"\"\ndef process_data(user_input):\n    api_response = fetch_from_api(user_input)\n    data = json.loads(api_response)\n    return data['results'][0]['value'] / 100\n\"\"\"\n\nprompt = f\"\"\"\nI'm getting the following error:\n\n```\n{error_message}\n```\n\nHere's the relevant code:\n\n```python\n{code_snippet}\n```\n\nWhat's causing this error and how can I fix it?\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n## Code conversion and migration\n\nGemini can help translate code between different languages or update code to use newer libraries or patterns.\n\n### Converting between languages\n\n```python\npython_code = \"\"\"\ndef calculate_statistics(numbers):\n    if not numbers:\n        return None, None, None\n    \n    mean = sum(numbers) / len(numbers)\n    sorted_nums = sorted(numbers)\n    n = len(sorted_nums)\n    \n    if n % 2 == 0:\n        median = (sorted_nums[n//2 - 1] + sorted_nums[n//2]) / 2\n    else:\n        median = sorted_nums[n//2]\n    \n    # Find mode\n    count_dict = {}\n    for num in numbers:\n        if num in count_dict:\n            count_dict[num] += 1\n        else:\n            count_dict[num] = 1\n    \n    max_count = max(count_dict.values())\n    mode = [k for k, v in count_dict.items() if v == max_count]\n    \n    return mean, median, mode[0] if len(mode) == 1 else mode\n\"\"\"\n\nprompt = f\"\"\"\nConvert this Python code to JavaScript:\n\n```python\n{python_code}\n```\n\nUse modern JavaScript features and maintain the same functionality.\nProvide only the converted code without explanation.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Updating code to use newer frameworks or libraries\n\n```python\nold_code = \"\"\"\n# Flask application using SQLAlchemy\nfrom flask import Flask, request, jsonify\nfrom flask_sqlalchemy import SQLAlchemy\n\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///users.db'\ndb = SQLAlchemy(app)\n\nclass User(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n\n@app.route('/users', methods=['GET'])\ndef get_users():\n    users = User.query.all()\n    result = []\n    for user in users:\n        user_data = {'id': user.id, 'username': user.username, 'email': user.email}\n        result.append(user_data)\n    return jsonify(result)\n\nif __name__ == '__main__':\n    db.create_all()\n    app.run(debug=True)\n\"\"\"\n\nprompt = f\"\"\"\nUpdate this Flask code to use FastAPI and SQLModel instead:\n\n```python\n{old_code}\n```\n\nMaintain the same functionality but use modern Python practices and FastAPI features.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n## Code optimization\n\nGemini can suggest ways to improve the efficiency, readability, or maintainability of your code.\n\n### Performance optimization\n\n```python\ninefficient_code = \"\"\"\ndef find_duplicates(input_list):\n    duplicates = []\n    for i in range(len(input_list)):\n        for j in range(i + 1, len(input_list)):\n            if input_list[i] == input_list[j] and input_list[i] not in duplicates:\n                duplicates.append(input_list[i])\n    return duplicates\n\"\"\"\n\nprompt = f\"\"\"\nOptimize this Python function for better performance:\n\n```python\n{inefficient_code}\n```\n\n1. Explain what makes the current implementation inefficient\n2. Provide an optimized version\n3. Compare the time complexity of both versions\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Refactoring for readability and maintainability\n\n```python\ncode_to_refactor = \"\"\"\ndef p(d, s, e):\n    r = []\n    for i in range(s, e + 1):\n        if all(i % j != 0 for j in range(2, int(i**0.5) + 1)) and i > 1:\n            r.append(i)\n    return r\n\ndef c(n):\n    a = []\n    for i in range(2, int(n**0.5) + 1):\n        if n % i == 0:\n            a.append(i)\n            if i != n // i:\n                a.append(n // i)\n    return sorted(a)\n\ndef g(a, b):\n    while b:\n        a, b = b, a % b\n    return a\n\"\"\"\n\nprompt = f\"\"\"\nRefactor this code to improve readability and maintainability:\n\n```python\n{code_to_refactor}\n```\n\n1. Use meaningful variable and function names\n2. Add appropriate comments\n3. Follow PEP 8 style guidelines\n4. Structure the code logically\n5. Explain what each function does in your refactored version\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n## Unit testing\n\nGemini can help create comprehensive test cases for your code.\n\n### Generating unit tests\n\n```python\ncode_to_test = \"\"\"\ndef calculate_discount(price, discount_percentage, max_discount=100):\n    \"\"\"Calculate the discounted price.\n    \n    Args:\n        price (float): The original price\n        discount_percentage (float): The discount percentage (0-100)\n        max_discount (float, optional): Maximum discount amount. Defaults to 100.\n        \n    Returns:\n        float: The discounted price\n    \"\"\"\n    if not isinstance(price, (int, float)) or price < 0:\n        raise ValueError(\"Price must be a positive number\")\n        \n    if not isinstance(discount_percentage, (int, float)) or not 0 <= discount_percentage <= 100:\n        raise ValueError(\"Discount percentage must be between 0 and 100\")\n        \n    discount_amount = price * (discount_percentage / 100)\n    \n    # Apply max discount if necessary\n    if discount_amount > max_discount:\n        discount_amount = max_discount\n        \n    final_price = price - discount_amount\n    return round(final_price, 2)\n\"\"\"\n\nprompt = f\"\"\"\nWrite pytest unit tests for the following function:\n\n```python\n{code_to_test}\n```\n\nInclude tests for:\n1. Normal use cases\n2. Edge cases\n3. Error cases\n4. Boundary conditions\n\nEnsure high test coverage and follow pytest best practices.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Creating test cases with mocking\n\n```python\ncode_with_dependencies = \"\"\"\nimport requests\nfrom datetime import datetime\n\nclass WeatherService:\n    def __init__(self, api_key, base_url=\"https://api.weather.com\"):\n        self.api_key = api_key\n        self.base_url = base_url\n    \n    def get_current_temperature(self, city):\n        \"\"\"Get the current temperature for a city.\n        \n        Args:\n            city (str): The name of the city\n            \n        Returns:\n            dict: Temperature data with units\n            \n        Raises:\n            ValueError: If city is invalid\n            ConnectionError: If API request fails\n        \"\"\"\n        if not city or not isinstance(city, str):\n            raise ValueError(\"City must be a non-empty string\")\n            \n        endpoint = f\"{self.base_url}/current\"\n        params = {\"city\": city, \"apiKey\": self.api_key}\n        \n        response = requests.get(endpoint, params=params)\n        \n        if response.status_code != 200:\n            raise ConnectionError(f\"API request failed with status {response.status_code}\")\n            \n        data = response.json()\n        return {\n            \"temperature\": data[\"main\"][\"temp\"],\n            \"units\": data[\"units\"],\n            \"timestamp\": datetime.now().isoformat()\n        }\n\"\"\"\n\nprompt = f\"\"\"\nWrite pytest unit tests for the WeatherService class:\n\n```python\n{code_with_dependencies}\n```\n\nInclude:\n1. Proper mocking of the requests library\n2. Tests for success and failure scenarios\n3. Tests for all error conditions\n4. Fixtures for test setup\n\nFollow pytest best practices and demonstrate how to use patch and MagicMock.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n## Code documentation\n\nGemini can help create or improve documentation for your code.\n\n### Adding docstrings and comments\n\n```python\nundocumented_code = \"\"\"\ndef merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n        \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    \n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n\"\"\"\n\nprompt = f\"\"\"\nAdd proper Python docstrings and inline comments to the following code:\n\n```python\n{undocumented_code}\n```\n\nUse Google-style docstrings with:\n- Function descriptions\n- Parameter descriptions\n- Return value descriptions\n- Time and space complexity information\n\nAdd helpful inline comments for complex parts of the algorithm.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n### Generating README or API documentation\n\n```python\nproject_files = \"\"\"\nproject_structure = {\n    'app.py': 'Main application entry point',\n    'models/': {\n        'user.py': 'User model definition',\n        'product.py': 'Product model definition'\n    },\n    'routes/': {\n        'auth.py': 'Authentication routes',\n        'api.py': 'API endpoints'\n    },\n    'utils/': {\n        'validators.py': 'Input validation functions',\n        'helpers.py': 'Misc helper functions'\n    },\n    'config.py': 'Application configuration',\n    'requirements.txt': 'Project dependencies'\n}\n\"\"\"\n\nmain_file = \"\"\"\nfrom flask import Flask\nfrom routes.auth import auth_bp\nfrom routes.api import api_bp\nimport config\n\napp = Flask(__name__)\napp.config.from_object(config.Config)\n\n# Register blueprints\napp.register_blueprint(auth_bp, url_prefix='/auth')\napp.register_blueprint(api_bp, url_prefix='/api/v1')\n\n@app.route('/')\ndef index():\n    return {\"message\": \"Welcome to the Product API\"}\n\nif __name__ == '__main__':\n    app.run(debug=config.Config.DEBUG)\n\"\"\"\n\nprompt = f\"\"\"\nGenerate a comprehensive README.md file for a Flask API project with the following structure and main file:\n\nProject Structure:\n```python\n{project_files}\n```\n\nMain app.py:\n```python\n{main_file}\n```\n\nThe README should include:\n1. Project title and description\n2. Installation instructions\n3. Configuration steps\n4. Usage examples with curl commands\n5. API endpoints documentation\n6. Development setup instructions\n7. Testing information\n8. Deployment guidelines\n9. License information\n\nFormat the README with proper Markdown syntax.\n\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)\n```\n\n## Interactive code development\n\nYou can use multi-turn conversations with Gemini to iteratively develop code.\n\n### Building a project step by step\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel\n\n# Initialize Vertex AI\nvertexai.init(project=\"your-project-id\", location=\"us-central1\")\n\n# Load the model\nmodel = GenerativeModel(\"gemini-1.5-pro\")\n\n# Start a chat session\nchat = model.start_chat(\n    system_instruction=\"You are an expert Python developer helping to build a web scraping tool. Provide code, explanations, and suggestions as needed.\"\n)\n\n# Initial request to outline the project\nresponse = chat.send_message(\"\"\"\nI want to build a Python web scraping tool that:\n1. Takes a URL as input\n2. Extracts all article headlines and links from news websites\n3. Saves the data to a CSV file\n4. Has basic error handling\n\nWhat would be a good way to structure this project?\n\"\"\")\nprint(\"RESPONSE 1:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Follow-up with a request for the core scraping function\nresponse = chat.send_message(\"\"\"\nThat's a great structure. Can you write the core scraping function that uses BeautifulSoup to extract headlines and links?\n\"\"\")\nprint(\"RESPONSE 2:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Request for error handling improvements\nresponse = chat.send_message(\"\"\"\nThat function looks good, but I'd like to improve the error handling. Can you enhance it to:\n1. Handle connection timeouts\n2. Retry failed requests (max 3 attempts)\n3. Log errors properly\n\"\"\")\nprint(\"RESPONSE 3:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Request for additional feature\nresponse = chat.send_message(\"\"\"\nNow I'd like to add a feature that also extracts the publication date of each article if available. How would you modify the code to do that?\n\"\"\")\nprint(\"RESPONSE 4:\")\nprint(response.text)\n```\n\n### Debugging and refining code iteratively\n\n```python\n# Continue the conversation with debugging\nresponse = chat.send_message(\"\"\"\nI tried running the code, but I'm getting this error with the date extraction:\n\n```\nAttributeError: 'NoneType' object has no attribute 'text'\n```\n\nThe error occurs on this line:\n```python\ndate = article.find('span', class_='publication-date').text.strip()\n```\n\nCan you help me fix this?\n\"\"\")\nprint(\"RESPONSE 5:\")\nprint(response.text)\nprint(\"\\n\" + \"-\"*80 + \"\\n\")\n\n# Request for final improvements\nresponse = chat.send_message(\"\"\"\nThat fixed the issue! As a final improvement, can you refactor the code to:\n1. Make it more modular with separate functions\n2. Add type hints\n3. Add better documentation\n\"\"\")\nprint(\"RESPONSE 6:\")\nprint(response.text)\n```\n\n## Best practices for code-related prompts\n\n### 1. Be specific about language and framework\n\nSpecify the programming language, version, and any frameworks or libraries you're using:\n\n```\nWrite a function in Python 3.9 using the pandas library to...\n```\n\n### 2. Provide context and constraints\n\nMention any specific requirements, constraints, or existing code that your request needs to work with:\n\n```\nCreate a JavaScript function that must work in browsers without ES6 support and should not use any external libraries.\n```\n\n### 3. Specify coding style and conventions\n\nMention the coding style or conventions you want the generated code to follow:\n\n```\nWrite a Java class following Google's Java Style Guide that implements...\n```\n\n### 4. Request explanations when needed\n\nAsk Gemini to explain its code, especially for complex implementations:\n\n```\nWrite a Python function to implement the A* pathfinding algorithm and explain the key parts of the implementation.\n```\n\n### 5. Ask for test cases\n\nRequest test cases to verify the code works as expected:\n\n```\nCreate a function to validate credit card numbers and include test cases for valid and invalid scenarios.\n```\n\n### 6. Split complex tasks\n\nBreak down complex coding tasks into smaller, manageable parts:\n\n```\nI want to build a REST API for a to-do application. Let's start with defining the data model and endpoints first.\n```\n\n### 7. Request alternatives\n\nAsk for different approaches to solve the same problem:\n\n```\nShow me two different ways to implement a caching mechanism in Node.js, one using an in-memory approach and another using Redis.\n```\n\n### 8. Specify error handling needs\n\nBe explicit about error handling requirements:\n\n```\nWrite a function to parse JSON data with comprehensive error handling that provides specific error messages for different types of parsing failures.\n```\n\n### 9. Request optimizations\n\nAsk for optimized code when performance is important:\n\n```\nCreate a memory-efficient Python function to find duplicate files in a directory structure with millions of files.\n```\n\n### 10. Use iterative refinement\n\nStart with a basic implementation and then ask for improvements in subsequent prompts:\n\n```\nFirst prompt: \"Write a basic web scraper in Python\"\nFollow-up: \"Now add parallel processing to the scraper to handle multiple URLs simultaneously\"\n```\n\n## Summary\n\nGemini is a powerful tool for various coding tasks, from generating and explaining code to debugging and optimization. By following the best practices in this guide, you can get the most out of Gemini for your coding needs.\n\nRemember to:\n- Be specific about your requirements\n- Provide relevant context\n- Use multi-turn conversations for complex development\n- Ask for explanations when needed\n- Iterate and refine your code with Gemini's help\n\nThese approaches will help you leverage Gemini effectively as a coding assistant, whether you're learning a new language, tackling a complex problem, or optimizing existing code.\n\u0005End File\u0006# site/en/gemini/docs/get-started/quickstart.md\n# Quickstart\n\nThis quickstart shows you how to start using the Gemini API. You'll learn how to set up the SDK, run a simple prompt, and get a response.\n\nYou'll learn how to:\n\n1. Get an API key\n2. Set up your environment\n3. Create a simple prompt\n4. Generate a response\n5. Understand basic response handling\n\n## Before you begin\n\n### Requirements\n\nYou need the following:\n\n* [Python 3.9+](https://www.python.org/downloads/)\n* A Google AI Studio API key. If you don't already have one, [create a key in Google AI Studio](https://aistudio.google.com/app/apikey).\n\n### Set up your environment\n\n1. Set up a Python environment. We recommend using a virtual environment.\n\n   ```shell\n   python -m venv .venv\n   source .venv/bin/activate  # On Windows, use `.venv\\Scripts\\activate`\n   ```\n\n2. Install the Google AI Python SDK.\n\n   ```shell\n   pip install -q google-generativeai\n   ```\n\n## Using the Gemini API\n\n### Import the SDK and configure your API key\n\n```python\nimport google.generativeai as genai\n\n# Configure the SDK with your API key\ngenai.configure(api_key=\"YOUR_API_KEY\")\n```\n\n### List available models\n\n```python\nfor m in genai.list_models():\n  if 'generateContent' in m.supported_generation_methods:\n    print(m.name)\n```\n\n### Choose a model\n\nFor this quickstart, we'll use the latest Gemini Pro model:\n\n```python\nmodel = genai.GenerativeModel('gemini-1.5-pro')\n```\n\n### Send a simple prompt\n\n```python\nresponse = model.generate_content(\"Write a short poem about programming\")\nprint(response.text)\n```\n\n### Handle a simple chat conversation\n\n```python\nchat = model.start_chat(history=[])\n\nresponse = chat.send_message(\"Hello, I'm learning how to use the Gemini API.\")\nprint(response.text)\n\nresponse = chat.send_message(\"Can you summarize what the Gemini API is in one sentence?\")\nprint(response.text)\n```\n\n### Working with multimodal content\n\nGemini can handle both text and image inputs:\n\n```python\nimport PIL.Image\n\n# Load an image\nimage = PIL.Image.open('image.jpg')\n\n# Send a prompt with the image\nresponse = model.generate_content([\"Describe this image in detail\", image])\nprint(response.text)\n```\n\n### Understanding response structure\n\n```python\nresponse = model.generate_content(\"Tell me about large language models\")\n\n# Access the full response object\nprint(\"Full response:\", response)\n\n# Access just the text\nprint(\"\\nResponse text:\", response.text)\n\n# Check if there are multiple candidates (alternative responses)\nif response.candidates:\n    print(\"\\nNumber of candidates:\", len(response.candidates))\n    \n    # Access the first candidate\n    first_candidate = response.candidates[0]\n    print(\"First candidate content:\", first_candidate.content.parts[0].text)\n```\n\n## Next steps\n\nNow that you've learned the basics of using the Gemini API, you can:\n\n- [Explore advanced prompting techniques](/gemini/docs/prompting/intro)\n- [Learn how to use system instructions](/gemini/docs/prompting/define-system-instructions)\n- [Work with code generation](/gemini/docs/get-started/code-with-gemini)\n- [Create multimodal applications](/gemini/docs/get-started/multimodal)\n- [Learn about embeddings](/gemini/docs/embeddings/embeddings-start)\n\u0005End File\u0006# site/en/gemini/docs/function-calling/function-calling.md\n# Function calling overview\n\nFunction calling lets Gemini recognize when it should call a specific function and extract structured data for that function call from the user input. Function calling allows you to:\n\n* Use Gemini's natural language understanding to extract structured information from a conversation\n* Add external tools, APIs, or databases to your Gemini apps\n* Create agents that take action based on user input\n* Build conversational applications that operate across multiple services\n\nThis guide introduces function calling concepts, syntax, and techniques to integrate external functionality into your Gemini applications.\n\n## How function calling works\n\nFunction calling is a multi-step process:\n\n1. **Function definitions**: You define structured functions that Gemini can call\n2. **Model decision**: Gemini decides if and when to call your functions based on user input\n3. **Parameter extraction**: Gemini parses the user input to extract structured parameters\n4. **Function execution**: You handle the actual execution of the function using the extracted parameters\n5. **Response integration**: You can incorporate function results back into the conversation\n\nFunction calling enables complex workflows like:\n\n* Booking a restaurant reservation based on natural language requests\n* Retrieving weather information for a specific location\n* Querying a database for product information\n* Controlling smart home devices through conversational interfaces\n\n## Declaring functions\n\nTo use function calling, you first define functions that describe the capabilities you want to make available. Each function definition includes:\n\n* `name`: A unique identifier for the function\n* `description`: Information about what the function does\n* `parameters`: The inputs required, described using a JSON schema\n\nHere's an example of defining a function to get weather information:\n\n```python\nweather_function = {\n    \"name\": \"get_current_weather\",\n    \"description\": \"Get the current weather in a given location\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g., San Francisco, CA\"\n            },\n            \"unit\": {\n                \"type\": \"string\",\n                \"enum\": [\"celsius\", \"fahrenheit\"],\n                \"description\": \"The temperature unit to use\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n}\n```\n\nThis definition tells Gemini:\n\n* The function name is `get_current_weather`\n* It gets current weather for a location\n* It requires a `location` parameter (a string)\n* It has an optional `unit` parameter (either \"celsius\" or \"fahrenheit\")\n\n## Using function calling\n\n### Basic function calling flow\n\nHere's the complete flow for function calling with Gemini:\n\n```python\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel, FunctionDeclaration, Tool\n\n# Initialize Vertex AI\nvertexai.init(project=\"your-project-id\", location=\"us-central1\")\n\n# 1. Define your function\nget_weather_function = FunctionDeclaration(\n    name=\"get_current_weather\",\n    description=\"Get the current weather in a given location\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g., San Francisco, CA\"\n            },\n            \"unit\": {\n                \"type\": \"string\",\n                \"enum\": [\"celsius\", \"fahrenheit\"],\n                \"description\": \"The temperature unit to use\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n)\n\n# 2. Create a tool with your function\nweather_tool = Tool(\n    function_declarations=[get_weather_function]\n)\n\n# 3. Load the model with your tool\nmodel = GenerativeModel(\n    \"gemini-1.5-pro\",\n    tools=[weather_tool]\n)\n\n# 4. Start a conversation\nchat = model.start_chat()\n\n# 5. Process user input\nuser_input = \"What's the weather like in Boston right now?\"\nresponse = chat.send_message(user_input)\n\n# 6. Check if the model wants to call a function\nfunction_calls = []\nif response.candidates and response.candidates[0].content.parts:\n    for part in response.candidates[0].content.parts:\n        if hasattr(part, 'function_call'):\n            function_calls.append(part.function_call)\n\n# 7. Handle any function calls\nif function_calls:\n    for function_call in function_calls:\n        print(f\"Function call: {function_call.name}\")\n        print(f\"Arguments: {function_call.args}\")\n        \n        # 8. Here you would actually implement the function execution\n        # For this example, we'll simulate a response\n        if function_call.name == \"get_current_weather\":\n            # Simulate calling a weather API\n            weather_result = {\n                \"location\": function_call.args[\"location\"],\n                \"temperature\": \"72\",\n                \"unit\": function_call.args.get(\"unit\", \"fahrenheit\"),\n                \"forecast\": \"sunny\"\n            }\n            \n            # 9. Send the function response back to the model\n            function_response = {\n                \"name\": function_call.name,\n                \"response\": weather_result\n            }\n            \n            response = chat.send_message(function_response)\n            print(f\"Final response: {response.text}\")\nelse:\n    print(f\"No function call needed. Response: {response.text}\")\n```\n\n## Function definition structure\n\nA complete function definition includes:\n\n### Function name\n\nThe name should be unique and descriptive of the function's purpose.\n\nGood examples:\n- `get_current_weather`\n- `search_products`\n- `create_calendar_event`\n\n### Description\n\nThe description helps Gemini understand when to call the function. It should be clear and specific about what the function does.\n\nGood examples:\n- \"Get the current weather in a given location\"\n- \"Search for products in the inventory by name, category, or features\"\n- \"Create a new event on the user's calendar\"\n\n### Parameters\n\nParameters define the inputs the function needs. They follow JSON Schema format and can include:\n\n- `type`: The data type (string, number, boolean, object, array)\n- `description`: What the parameter represents\n- `properties`: For object types, the fields within the object\n- `items`: For array types, the structure of array elements\n- `enum`: For limited options, the allowed values\n- `required`: An array listing which properties are mandatory\n\n## Parameter types and examples\n\n### Simple parameters\n\n```python\n# String parameter\n\"location\": {\n    \"type\": \"string\",\n    \"description\": \"The city and state, e.g., San Francisco, CA\"\n}\n\n# Number parameter\n\"temperature\": {\n    \"type\": \"number\",\n    \"description\": \"The temperature value\"\n}\n\n# Boolean parameter\n\"is_urgent\": {\n    \"type\": \"boolean\",\n    \"description\": \"Whether the task is urgent\"\n}\n\n# Enum parameter (limited choices)\n\"priority\": {\n    \"type\": \"string\",\n    \"enum\": [\"low\", \"medium\", \"high\"],\n    \"description\": \"The priority level\"\n}\n```\n\n### Complex parameters\n\n```python\n# Object parameter\n\"address\": {\n    \"type\": \"object\",\n    \"properties\": {\n        \"street\": {\n            \"type\": \"string\",\n            \"description\": \"Street address\"\n        },\n        \"city\": {\n            \"type\": \"string\",\n            \"description\": \"City name\"\n        },\n        \"state\": {\n            \"type\": \"string\",\n            \"description\": \"State or province\"\n        },\n        \"zip\": {\n            \"type\": \"string\",\n            \"description\": \"ZIP or postal code\"\n        }\n    },\n    \"required\": [\"street\", \"city\", \"state\"]\n}\n\n# Array parameter\n\"attendees\": {\n    \"type\": \"array\",\n    \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\n                \"type\": \"string\",\n                \"description\": \"Attendee's name\"\n            },\n            \"email\": {\n                \"type\": \"string\",\n                \"description\": \"Attendee's email address\"\n            }\n        },\n        \"required\": [\"email\"]\n    },\n    \"description\": \"List of people attending the event\"\n}\n```\n\n## Best practices for function definitions\n\n### Be specific and descriptive\n\nThe more clearly you define your function's purpose and parameters, the better Gemini can determine when to call it and with what arguments.\n\n```python\n# Less effective\nfunction_declaration = FunctionDeclaration(\n    name=\"get_data\",\n    description=\"Get data\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"input\": {\n                \"type\": \"string\"\n            }\n        },\n        \"required\": [\"input\"]\n    }\n)\n\n# More effective\nfunction_declaration = FunctionDeclaration(\n    name=\"get_product_inventory\",\n    description=\"Get current inventory levels for a specific product in a specified store location\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"product_id\": {\n                \"type\": \"string\",\n                \"description\": \"The unique identifier for the product (e.g., SKU12345)\"\n            },\n            \"store_location\": {\n                \"type\": \"string\",\n                \"description\": \"The store location code or city name (e.g., NYC-Downtown or 'San Francisco')\"\n            }\n        },\n        \"required\": [\"product_id\"]\n    }\n)\n```\n\n### Use parameter constraints appropriately\n\nAdd constraints to guide Gemini in providing properly formatted arguments:\n\n```python\n\"properties\": {\n    \"phone_number\": {\n        \"type\": \"string\",\n        \"description\": \"Customer's phone number in the format XXX-XXX-XXXX\",\n        \"pattern\": \"^\\\\d{3}-\\\\d{3}-\\\\d{4}$\"\n    },\n    \"temperature\": {\n        \"type\": \"number\",\n        \"description\": \"Temperature value\",\n        \"minimum\": -50,\n        \"maximum\": 150\n    },\n    \"appointment_date\": {\n        \"type\": \"string\",\n        \"description\": \"The date of the appointment in YYYY-MM-DD format\",\n        \"format\": \"date\"\n    }\n}\n```\n\n### Make required parameters explicit\n\nClearly indicate which parameters are required and which are optional:\n\n```python\n\"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n        \"location\": {\n            \"type\": \"string\",\n            \"description\": \"City name (required)\"\n        },\n        \"include_forecast\": {\n            \"type\": \"boolean\",\n            \"description\": \"Whether to include a 5-day forecast (optional)\"\n        }\n    },\n    \"required\": [\"location\"]\n}\n```\n\n### Group related functions logically\n\nIf you have multiple related functions, organize them in a way that makes their relationship clear:\n\n```python\ncalendar_functions = [\n    FunctionDeclaration(\n        name=\"get_calendar_events\",\n        description=\"Get events from the user's calendar for a specific date range\",\n        parameters={...}\n    ),\n    FunctionDeclaration(\n        name=\"create_calendar_event\",\n        description=\"Create a new event on the user's calendar\",\n        parameters={...}\n    ),\n    FunctionDeclaration(\n        name=\"update_calendar_event\",\n        description=\"Update an existing event on the user's calendar\",\n        parameters={...}\n    )\n]\n\ncalendar_tool = Tool(function_declarations=calendar_functions)\n```\n\n## Implementing function execution\n\nWhen Gemini calls a function, you need to handle the actual execution and return the results:\n\n```python\ndef execute_function(function_call):\n    \"\"\"Execute the function called by Gemini and return the results.\"\"\"\n    \n    function_name = function_call.name\n    args = function_call.args\n    \n    if function_name == \"get_current_weather\":\n        # In a real app, you would call a weather API here\n        return {\n            \"temperature\": \"72\",\n            \"unit\": args.get(\"unit\", \"fahrenheit\"),\n            \"condition\": \"sunny\",\n            \"location\": args[\"location\"]\n        }\n    \n    elif function_name == \"search_products\":\n        # In a real app, you would query a product database\n        return {\n            \"products\": [\n                {\"id\": \"12345\", \"name\": \"Laptop\", \"price\": \"$999.99\"},\n                {\"id\": \"67890\", \"name\": \"Smartphone\", \"price\": \"$699.99\"}\n            ],\n            \"query\": args[\"query\"],\n            \"total_results\": 2\n        }\n    \n    else:\n        return {\"error\": f\"Function {function_name} not implemented\"}\n```\n\n## Common use cases and examples\n\n### Database queries\n\n```python\ndatabase_query_function = FunctionDeclaration(\n    name=\"query_customer_database\",\n    description=\"Search for customer information in the database\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"search_term\": {\n                \"type\": \"string\",\n                \"description\": \"Name, email, or customer ID to search for\"\n            },\n            \"fields\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"name\", \"email\", \"phone\", \"address\", \"purchase_history\"]\n                },\n                \"description\": \"Fields to return in the results\"\n            },\n            \"max_results\": {\n                \"type\": \"integer\",\n                \"description\": \"Maximum number of results to return\",\n                \"default\": 5\n            }\n        },\n        \"required\": [\"search_term\"]\n    }\n)\n```\n\n### API integrations\n\n```python\nweather_api_function = FunctionDeclaration(\n    name=\"get_weather_forecast\",\n    description=\"Get the weather forecast for a location over a specified time period\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"City and state/country (e.g., 'Paris, France')\"\n            },\n            \"days\": {\n                \"type\": \"integer\",\n                \"description\": \"Number of days to forecast (1-10)\",\n                \"minimum\": 1,\n                \"maximum\": 10,\n                \"default\": 3\n            },\n            \"units\": {\n                \"type\": \"string\",\n                \"enum\": [\"metric\", \"imperial\"],\n                \"description\": \"Unit system for temperature and wind speed\",\n                \"default\": \"metric\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n)\n```\n\n### E-commerce functions\n\n```python\nproduct_search_function = FunctionDeclaration(\n    name=\"search_products\",\n    description=\"Search for products in the catalog\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"Search terms for the product\"\n            },\n            \"category\": {\n                \"type\": \"string\",\n                \"description\": \"Product category to filter by\",\n                \"enum\": [\"electronics\", \"clothing\", \"home\", \"sports\", \"beauty\"]\n            },\n            \"price_range\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"min\": {\n                        \"type\": \"number\",\n                        \"description\": \"Minimum price\"\n                    },\n                    \"max\": {\n                        \"type\": \"number\",\n                        \"description\": \"Maximum price\"\n                    }\n                }\n            },\n            \"sort_by\": {\n                \"type\": \"string\",\n                \"description\": \"How to sort results\",\n                \"enum\": [\"price_low\", \"price_high\", \"rating\", \"newest\"],\n                \"default\": \"rating\"\n            }\n        },\n        \"required\": [\"query\"]\n    }\n)\n\nadd_to_cart_function = FunctionDeclaration(\n    name=\"add_to_cart\",\n    description=\"Add a product to the shopping cart\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"product_id\": {\n                \"type\": \"string\",\n                \"description\": \"ID of the product to add\"\n            },\n            \"quantity\": {\n                \"type\": \"integer\",\n                \"description\": \"Quantity to add\",\n                \"minimum\": 1,\n                \"default\": 1\n            },\n            \"options\": {\n                \"type\": \"object\",\n                \"description\": \"Product options like size, color, etc.\",\n                \"additionalProperties\": True\n            }\n        },\n        \"required\": [\"product_id\"]\n    }\n)\n```\n\n### Calendar management\n\n```python\ncreate_event_function = FunctionDeclaration(\n    name=\"create_calendar_event\",\n    description=\"Create a new event on the user's calendar\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"title\": {\n                \"type\": \"string\",\n                \"description\": \"Title of the event\"\n            },\n            \"start_time\": {\n                \"type\": \"string\",\n                \"description\": \"Start time in ISO format (YYYY-MM-DDTHH:MM:SS)\"\n            },\n            \"end_time\": {\n                \"type\": \"string\",\n                \"description\": \"End time in ISO format (YYYY-MM-DDTHH:MM:SS)\"\n            },\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"Location of the event\"\n            },\n            \"description\": {\n                \"type\": \"string\",\n                \"description\": \"Description or notes for the event\"\n            },\n            \"attendees\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"string\"\n                },\n                \"description\": \"Email addresses of attendees\"\n            },\n            \"reminder\": {\n                \"type\": \"integer\",\n                \"description\": \"Reminder time in minutes before the event\",\n                \"enum\": [0, 5, 10, 15, 30, 60, 1440]\n            }\n        },\n        \"required\": [\"title\", \"start_time\", \"end_time\"]\n    }\n)\n```\n\n## Advanced techniques\n\n### Parallel function calling\n\nYou can define multiple functions that Gemini might call in parallel:\n\n```python\n# Define multiple functions\nweather_function = FunctionDeclaration(name=\"get_weather\", ...)\nrestaurant_function = FunctionDeclaration(name=\"find_restaurants\", ...)\n\n# Create a tool with multiple functions\ntravel_tool = Tool(\n    function_declarations=[weather_function, restaurant_function]\n)\n\n# Use the model with the tool\nmodel = GenerativeModel(\"gemini-1.5-pro\", tools=[travel_tool])\n\n# Process user input\nresponse = model.generate_content(\"I'm visiting Seattle next week. What's the weather forecast and what are some good seafood restaurants?\")\n\n# Check for multiple function calls\nfunction_calls = []\nfor part in response.candidates[0].content.parts:\n    if hasattr(part, 'function_call'):\n        function_calls.append(part.function_call)\n\n# Handle multiple function calls\nif function_calls:\n    function_responses = []\n    for function_call in function_calls:\n        # Execute each function\n        result = execute_function(function_call)\n        function_responses.append({\n            \"name\": function_call.name,\n            \"response\": result\n        })\n    \n    # Send all function responses back\n    response = chat.send_message(function_responses)\n```\n\n### Nested function calls\n\nYou can implement workflows where the results of one function call influence subsequent calls:\n\n```python\n# Example of handling nested function calls\ndef process_conversation(chat, user_input):\n    response = chat.send_message(user_input)\n    \n    # Check for function calls\n    if has_function_calls(response):\n        function_calls = extract_function_calls(response)\n        \n        # Process each function call\n        for function_call in function_calls:\n            # Execute the function\n            function_result = execute_function(function_call)\n            \n            # Send the result back\n            function_response = {\n                \"name\": function_call.name,\n                \"response\": function_result\n            }\n            \n            response = chat.send_message(function_response)\n            \n            # Check if there are additional function calls after this result\n            if has_function_calls(response):\n                # Recursively process the new function calls\n                process_nested_function_calls(chat, response)\n    \n    return response\n```\n\n### Function calling with streaming\n\nYou can use function calling with streaming responses:\n\n```python\n# Start a streaming response\nstream = model.generate_content(\n    \"What's the weather in San Francisco and New York today?\",\n    stream=True\n)\n\nfunction_calls = []\n\n# Process the stream\nfor chunk in stream:\n    if hasattr(chunk, 'candidates') and chunk.candidates:\n        for candidate in chunk.candidates:\n            if hasattr(candidate, 'content') and candidate.content:\n                for part in candidate.content.parts:\n                    if hasattr(part, 'function_call'):\n                        function_calls.append(part.function_call)\n\n# Process any function calls found in the stream\nfor function_call in function_calls:\n    # Execute the function\n    result = execute_function(function_call)\n    \n    # Send the result back\n    function_response = {\n        \"name\": function_call.name,\n        \"response\": result\n    }\n    \n    response = chat.send_message(function_response)\n```\n\n## Debugging function calling\n\nWhen working with function calling, you might encounter issues. Here are some common problems and solutions:\n\n### Function not being called\n\nIf Gemini isn't calling your function when expected:\n\n1. **Review your function description**: Make it more specific about when the function should be used\n2. **Check parameter definitions**: Ensure they clearly describe what each parameter represents\n3. **Reformulate user queries**: Make sure the user's request clearly relates to your function's purpose\n\n### Incorrect parameter values\n\nIf Gemini is calling your function but with incorrect parameters:\n\n1. **Improve parameter descriptions**: Add more details about expected formats and values\n2. **Add constraints**: Use JSON Schema features like `pattern`, `minimum`, `maximum`, or `enum`\n3. **Use clear parameter names**: Choose descriptive names that indicate the expected value\n\n### Debugging example\n\n```python\n# Add more detailed parameter descriptions and constraints\nbetter_function = FunctionDeclaration(\n    name=\"book_appointment\",\n    description=\"Book a customer appointment with a specific service provider on a specific date and time\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"customer_name\": {\n                \"type\": \"string\",\n                \"description\": \"Full name of the customer (first and last name)\"\n            },\n            \"service_type\": {\n                \"type\": \"string\",\n                \"description\": \"Type of service needed\",\n                \"enum\": [\"haircut\", \"coloring\", \"styling\", \"manicure\", \"pedicure\"],\n            },\n            \"preferred_date\": {\n                \"type\": \"string\",\n                \"description\": \"Preferred date in YYYY-MM-DD format\",\n                \"format\": \"date\"\n            },\n            \"preferred_time\": {\n                \"type\": \"string\",\n                \"description\": \"Preferred time in 24-hour format (HH:MM)\",\n                \"pattern\": \"^([01]\\\\d|2[0-3]):([0-5]\\\\d)$\"\n            },\n            \"stylist_preference\": {\n                \"type\": \"string\",\n                \"description\": \"Preferred stylist's name (optional)\"\n            }\n        },\n        \"required\": [\"customer_name\", \"service_type\", \"preferred_date\", \"preferred_time\"]\n    }\n)\n\n# Print function call details for debugging\ndef debug_function_call(function_call):\n    print(f\"Function called: {function_call.name}\")\n    print(\"Arguments:\")\n    for key, value in function_call.args.items():\n        print(f\"  {key}: {value}\")\n    \n    # Check for required parameters\n    missing = []\n    for param in [\"customer_name\", \"service_type\", \"preferred_date\", \"preferred_time\"]:\n        if param not in function_call.args:\n            missing.append(param)\n    \n    if missing:\n        print(f\"Warning: Missing required parameters: {', '.join(missing)}\")\n    \n    # Validate parameter formats\n    if \"preferred_date\" in function_call.args:\n        date = function_call.args[\"preferred_date\"]\n        import re\n        if not re.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", date):\n            print(f\"Warning: Date format incorrect: {date}\")\n    \n    if \"preferred_time\" in function_call.args:\n        time = function_call.args[\"preferred_time\"]\n        import re\n        if not re.match(r\"^([01]\\d|2[0-3]):([0-5]\\d)$\", time):\n            print(f\"Warning: Time format incorrect: {time}\")\n```\n\n## Conclusion\n\nFunction calling enables you to connect Gemini's natural language understanding with external systems and tools. By defining clear function signatures and handling function calls properly, you can create powerful applications that combine conversational AI with practical functionality.\n\nKey takeaways:\n\n1. Function calling extracts structured data from natural language\n2. Well-defined functions with clear descriptions and parameters help Gemini understand when to call them\n3. You implement the actual function execution based on the parameters Gemini extracts\n4. Function calling enables integration with databases, APIs, and other external systems\n5. Advanced techniques allow for complex workflows with multiple or nested function calls\n\nBy leveraging function calling, you can create Gemini applications that not only understand user requests but can take concrete actions to fulfill them.\n\u0005End File\u0006{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"_1ZTXHlbIiEK\"\n      },\n      \"source\": [\n        \"# Function calling with Gemini\\n\",\n        \"\\n\",\n        \"<table align=\\\"left\\\">\\n\",\n        \"  <td>\\n\",\n        \"    <a target=\\\"_blank\\\" href=\\\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini/docs/function-calling/function-calling-basic.ipynb\\\"><img src=\\\"https://www.tensorflow.org/images/colab_logo_32px.png\\\" />Run in Google Colab</a>\\n\",\n        \"  </td>\\n\",\n        \"</table>\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"dJHkHQ14YYKG\"\n      },\n      \"source\": [\n        \"Function calling allows Gemini to intelligently call external functions that you define, extracting structured data from user requests and integrating external systems with your AI-powered applications.\\n\",\n        \"\\n\",\n        \"This notebook demonstrates how to use function calling with Gemini models in Vertex AI.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"GNI7mmuaZXoD\"\n      },\n      \"source\": [\n        \"## Setup\\n\",\n        \"\\n\",\n        \"First, let's set up our environment and initialize Vertex AI.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"-U_qZ6jsZeYu\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"!pip install -q google-cloud-aiplatform\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"qJ0dQQc7Zj9A\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"import vertexai\\n\",\n        \"import json\\n\",\n        \"from vertexai.generative_models import GenerativeModel, FunctionDeclaration, Tool\\n\",\n        \"\\n\",\n        \"# If you're running this notebook in Colab, you'll need to authenticate\\n\",\n        \"try:\\n\",\n        \"    from google.colab import auth\\n\",\n        \"    auth.authenticate_user()\\n\",\n        \"    print(\\\"Authenticated\\\")\\n\",\n        \"except:\\n\",\n        \"    print(\\\"Not running in Colab, authentication skipped\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"tP9-NJiIZrLk\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Initialize Vertex AI\\n\",\n        \"PROJECT_ID = \\\"your-project-id\\\"  # @param {type:\\\"string\\\"}\\n\",\n        \"LOCATION = \\\"us-central1\\\"  # @param {type:\\\"string\\\"}\\n\",\n        \"\\n\",\n        \"vertexai.init(project=PROJECT_ID, location=LOCATION)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"9HLTdaYQZ7YL\"\n      },\n      \"source\": [\n        \"## Defining functions\\n\",\n        \"\\n\",\n        \"Let's define a function that retrieves weather information for a location. Function definitions include:\\n\",\n        \"\\n\",\n        \"- A name\\n\",\n        \"- A description of what the function does\\n\",\n        \"- Parameters described using JSON Schema\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"cI9oe-hCZ9kZ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define a function for getting weather information\\n\",\n        \"get_weather_function = FunctionDeclaration(\\n\",\n        \"    name=\\\"get_current_weather\\\",\\n\",\n        \"    description=\\\"Get the current weather in a given location\\\",\\n\",\n        \"    parameters={\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"location\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"The city and state, e.g., San Francisco, CA\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"unit\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"celsius\\\", \\\"fahrenheit\\\"],\\n\",\n        \"                \\\"description\\\": \\\"The temperature unit to use. Default is fahrenheit.\\\"\\n\",\n        \"            }\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"location\\\"]\\n\",\n        \"    }\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Create a tool with the function\\n\",\n        \"weather_tool = Tool(\\n\",\n        \"    function_declarations=[get_weather_function]\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"U5SXV4daaEh1\"\n      },\n      \"source\": [\n        \"## Creating a model with function calling\\n\",\n        \"\\n\",\n        \"Now let's create a model with our weather function tool:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"bM7_ZAYkaGN2\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Load the model with our tool\\n\",\n        \"model = GenerativeModel(\\n\",\n        \"    \\\"gemini-1.5-pro\\\",\\n\",\n        \"    tools=[weather_tool]\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Start a chat\\n\",\n        \"chat = model.start_chat()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"ZnFYtFdDaMWy\"\n      },\n      \"source\": [\n        \"## Basic function calling\\n\",\n        \"\\n\",\n        \"Let's test our function calling with a simple query about the weather:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"lZMtYCLLaOGi\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Send a message that should trigger a function call\\n\",\n        \"response = chat.send_message(\\\"What's the weather like in Boston right now?\\\")\\n\",\n        \"\\n\",\n        \"# Print the raw response\\n\",\n        \"print(\\\"Raw response from model:\\\")\\n\",\n        \"print(response)\\n\",\n        \"print(\\\"\\\\n\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"vOHIx2vYaTuG\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Let's check if we got a function call\\n\",\n        \"function_calls = []\\n\",\n        \"if response.candidates and response.candidates[0].content.parts:\\n\",\n        \"    for part in response.candidates[0].content.parts:\\n\",\n        \"        if hasattr(part, 'function_call'):\\n\",\n        \"            function_calls.append(part.function_call)\\n\",\n        \"\\n\",\n        \"if function_calls:\\n\",\n        \"    print(f\\\"Found {len(function_calls)} function call(s)\\\")\\n\",\n        \"    for i, function_call in enumerate(function_calls):\\n\",\n        \"        print(f\\\"\\\\nFunction call {i+1}:\\\")\\n\",\n        \"        print(f\\\"Name: {function_call.name}\\\")\\n\",\n        \"        print(f\\\"Arguments: {function_call.args}\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"No function calls found in the response.\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"FpZRSA-8afPe\"\n      },\n      \"source\": [\n        \"## Executing the function\\n\",\n        \"\\n\",\n        \"In a real application, you would now execute the actual function with the extracted parameters. For this example, we'll simulate a weather service response:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"65XSUUdaahcb\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# A simple function to simulate getting weather data\\n\",\n        \"def get_current_weather(location, unit=\\\"fahrenheit\\\"):\\n\",\n        \"    \\\"\\\"\\\"Simulate a weather API call\\\"\\\"\\\"\\n\",\n        \"    # In a real application, this would call an actual weather API\\n\",\n        \"    weather_data = {\\n\",\n        \"        \\\"Boston, MA\\\": {\\\"temperature\\\": 42, \\\"condition\\\": \\\"Partly Cloudy\\\", \\\"humidity\\\": 65},\\n\",\n        \"        \\\"San Francisco, CA\\\": {\\\"temperature\\\": 58, \\\"condition\\\": \\\"Foggy\\\", \\\"humidity\\\": 75},\\n\",\n        \"        \\\"New York, NY\\\": {\\\"temperature\\\": 45, \\\"condition\\\": \\\"Rainy\\\", \\\"humidity\\\": 80},\\n\",\n        \"        \\\"Miami, FL\\\": {\\\"temperature\\\": 82, \\\"condition\\\": \\\"Sunny\\\", \\\"humidity\\\": 60},\\n\",\n        \"        \\\"Chicago, IL\\\": {\\\"temperature\\\": 35, \\\"condition\\\": \\\"Windy\\\", \\\"humidity\\\": 50},\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    # Simple location matching logic\\n\",\n        \"    matched_location = None\\n\",\n        \"    for known_location in weather_data.keys():\\n\",\n        \"        if location.lower() in known_location.lower():\\n\",\n        \"            matched_location = known_location\\n\",\n        \"            break\\n\",\n        \"    \\n\",\n        \"    if matched_location:\\n\",\n        \"        result = weather_data[matched_location].copy()\\n\",\n        \"        # Convert temperature if needed\\n\",\n        \"        if unit.lower() == \\\"celsius\\\":\\n\",\n        \"            result[\\\"temperature\\\"] = round((result[\\\"temperature\\\"] - 32) * 5/9)\\n\",\n        \"            result[\\\"unit\\\"] = \\\"celsius\\\"\\n\",\n        \"        else:\\n\",\n        \"            result[\\\"unit\\\"] = \\\"fahrenheit\\\"\\n\",\n        \"        result[\\\"location\\\"] = matched_location\\n\",\n        \"        return result\\n\",\n        \"    else:\\n\",\n        \"        # Generate some random weather for unknown locations\\n\",\n        \"        import random\\n\",\n        \"        conditions = [\\\"Sunny\\\", \\\"Cloudy\\\", \\\"Rainy\\\", \\\"Partly Cloudy\\\", \\\"Clear\\\"]\\n\",\n        \"        temp = random.randint(30, 85)  # fahrenheit\\n\",\n        \"        if unit.lower() == \\\"celsius\\\":\\n\",\n        \"            temp = round((temp - 32) * 5/9)\\n\",\n        \"        \\n\",\n        \"        return {\\n\",\n        \"            \\\"location\\\": location,\\n\",\n        \"            \\\"temperature\\\": temp,\\n\",\n        \"            \\\"condition\\\": random.choice(conditions),\\n\",\n        \"            \\\"humidity\\\": random.randint(30, 90),\\n\",\n        \"            \\\"unit\\\": unit.lower()\\n\",\n        \"        }\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"_vjMrNuEatBS\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Process the function call\\n\",\n        \"if function_calls:\\n\",\n        \"    for function_call in function_calls:\\n\",\n        \"        if function_call.name == \\\"get_current_weather\\\":\\n\",\n        \"            # Extract arguments\\n\",\n        \"            location = function_call.args.get(\\\"location\\\")\\n\",\n        \"            unit = function_call.args.get(\\\"unit\\\", \\\"fahrenheit\\\")\\n\",\n        \"            \\n\",\n        \"            # Call our simulated function\\n\",\n        \"            weather_result = get_current_weather(location, unit)\\n\",\n        \"            print(f\\\"Executed get_current_weather({location}, {unit})\\\")\\n\",\n        \"            print(f\\\"Result: {weather_result}\\\")\\n\",\n        \"            \\n\",\n        \"            # Format the function response\\n\",\n        \"            function_response = {\\n\",\n        \"                \\\"name\\\": function_call.name,\\n\",\n        \"                \\\"response\\\": weather_result\\n\",\n        \"            }\\n\",\n        \"            \\n\",\n        \"            # Send the function result back to the model\\n\",\n        \"            model_response = chat.send_message(function_response)\\n\",\n        \"            print(\\\"\\\\nModel response after function execution:\\\")\\n\",\n        \"            print(model_response.text)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"O3jRbk8Sa0dI\"\n      },\n      \"source\": [\n        \"## More complex example: Multiple functions\\n\",\n        \"\\n\",\n        \"Now let's define multiple functions and see how Gemini handles more complex scenarios:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"JULGXGSEa3Kk\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define a function for finding restaurants\\n\",\n        \"find_restaurants_function = FunctionDeclaration(\\n\",\n        \"    name=\\\"find_restaurants\\\",\\n\",\n        \"    description=\\\"Find restaurants in a specified location, optionally filtered by cuisine type\\\",\\n\",\n        \"    parameters={\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"location\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"The city and state, e.g., San Francisco, CA\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"cuisine\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Type of cuisine, e.g., Italian, Chinese, Mexican\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"price_level\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"$\\\", \\\"$$\\\", \\\"$$$\\\", \\\"$$$$\\\"],\\n\",\n        \"                \\\"description\\\": \\\"Price level from $ (cheap) to $$$$ (expensive)\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"open_now\\\": {\\n\",\n        \"                \\\"type\\\": \\\"boolean\\\",\\n\",\n        \"                \\\"description\\\": \\\"Whether the restaurant should be open now\\\"\\n\",\n        \"            }\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"location\\\"]\\n\",\n        \"    }\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Define a function for getting directions\\n\",\n        \"get_directions_function = FunctionDeclaration(\\n\",\n        \"    name=\\\"get_directions\\\",\\n\",\n        \"    description=\\\"Get directions between two locations\\\",\\n\",\n        \"    parameters={\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"origin\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Starting location, e.g., 123 Main St, San Francisco, CA\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"destination\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Ending location, e.g., Golden Gate Park, San Francisco, CA\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"mode\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"enum\\\": [\\\"driving\\\", \\\"walking\\\", \\\"bicycling\\\", \\\"transit\\\"],\\n\",\n        \"                \\\"description\\\": \\\"Mode of transportation\\\"\\n\",\n        \"            }\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"origin\\\", \\\"destination\\\"]\\n\",\n        \"    }\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Create a tool with multiple functions\\n\",\n        \"travel_tool = Tool(\\n\",\n        \"    function_declarations=[get_weather_function, find_restaurants_function, get_directions_function]\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Create a new model with the travel tool\\n\",\n        \"travel_model = GenerativeModel(\\n\",\n        \"    \\\"gemini-1.5-pro\\\",\\n\",\n        \"    tools=[travel_tool]\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Start a new chat\\n\",\n        \"travel_chat = travel_model.start_chat()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"40WXHAHDa_hS\"\n      },\n      \"source\": [\n        \"Let's implement the simulated restaurant search function:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"nTYu6d4SbBL9\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Simulated restaurant database\\n\",\n        \"def find_restaurants(location, cuisine=None, price_level=None, open_now=None):\\n\",\n        \"    \\\"\\\"\\\"Simulate a restaurant search API\\\"\\\"\\\"\\n\",\n        \"    # Mock restaurant database\\n\",\n        \"    restaurant_db = {\\n\",\n        \"        \\\"Boston, MA\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"Italian Delight\\\", \\\"cuisine\\\": \\\"Italian\\\", \\\"price\\\": \\\"$$\\\", \\\"rating\\\": 4.5, \\\"open\\\": True},\\n\",\n        \"            {\\\"name\\\": \\\"Seafood Harbor\\\", \\\"cuisine\\\": \\\"Seafood\\\", \\\"price\\\": \\\"$$$\\\", \\\"rating\\\": 4.7, \\\"open\\\": False},\\n\",\n        \"            {\\\"name\\\": \\\"Boston Burger Co\\\", \\\"cuisine\\\": \\\"American\\\", \\\"price\\\": \\\"$\\\", \\\"rating\\\": 4.2, \\\"open\\\": True},\\n\",\n        \"            {\\\"name\\\": \\\"Pho Paradise\\\", \\\"cuisine\\\": \\\"Vietnamese\\\", \\\"price\\\": \\\"$\\\", \\\"rating\\\": 4.0, \\\"open\\\": True},\\n\",\n        \"            {\\\"name\\\": \\\"Sushi Express\\\", \\\"cuisine\\\": \\\"Japanese\\\", \\\"price\\\": \\\"$$$\\\", \\\"rating\\\": 4.8, \\\"open\\\": True}\\n\",\n        \"        ],\\n\",\n        \"        \\\"San Francisco, CA\\\": [\\n\",\n        \"            {\\\"name\\\": \\\"Golden Dragon\\\", \\\"cuisine\\\": \\\"Chinese\\\", \\\"price\\\": \\\"$$\\\", \\\"rating\\\": 4.3, \\\"open\\\": True},\\n\",\n        \"            {\\\"name\\\": \\\"Taco Fiesta\\\", \\\"cuisine\\\": \\\"Mexican\\\", \\\"price\\\": \\\"$\\\", \\\"rating\\\": 4.1, \\\"open\\\": True},\\n\",\n        \"            {\\\"name\\\": \\\"Fisherman's Catch\\\", \\\"cuisine\\\": \\\"Seafood\\\", \\\"price\\\": \\\"$$$$\\\", \\\"rating\\\": 4.9, \\\"open\\\": False},\\n\",\n        \"            {\\\"name\\\": \\\"Sourdough Bakery\\\", \\\"cuisine\\\": \\\"Bakery\\\", \\\"price\\\": \\\"$\\\", \\\"rating\\\": 4.7, \\\"open\\\": True},\\n\",\n        \"            {\\\"name\\\": \\\"Mission Bistro\\\", \\\"cuisine\\\": \\\"French\\\", \\\"price\\\": \\\"$$$\\\", \\\"rating\\\": 4.6, \\\"open\\\": True}\\n\",\n        \"        ]\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    # Simple location matching\\n\",\n        \"    matched_location = None\\n\",\n        \"    for known_location in restaurant_db.keys():\\n\",\n        \"        if location.lower() in known_location.lower():\\n\",\n        \"            matched_location = known_location\\n\",\n        \"            break\\n\",\n        \"    \\n\",\n        \"    if not matched_location:\\n\",\n        \"        # Create some fake data for unknown locations\\n\",\n        \"        import random\\n\",\n        \"        cuisines = [\\\"Italian\\\", \\\"Chinese\\\", \\\"Mexican\\\", \\\"Indian\\\", \\\"American\\\", \\\"Thai\\\", \\\"Japanese\\\"]\\n\",\n        \"        prices = [\\\"$\\\", \\\"$$\\\", \\\"$$$\\\", \\\"$$$$\\\"]\\n\",\n        \"        \\n\",\n        \"        fake_restaurants = []\\n\",\n        \"        for i in range(5):  # Generate 5 fake restaurants\\n\",\n        \"            fake_cuisine = random.choice(cuisines)\\n\",\n        \"            restaurant = {\\n\",\n        \"                \\\"name\\\": f\\\"{location} {fake_cuisine} {'Bistro' if i % 2 else 'Restaurant'} {i+1}\\\",\\n\",\n        \"                \\\"cuisine\\\": fake_cuisine,\\n\",\n        \"                \\\"price\\\": random.choice(prices),\\n\",\n        \"                \\\"rating\\\": round(3.5 + random.random() * 1.5, 1),  # Random rating between 3.5 and 5.0\\n\",\n        \"                \\\"open\\\": random.choice([True, False]) if open_now is None else open_now\\n\",\n        \"            }\\n\",\n        \"            fake_restaurants.append(restaurant)\\n\",\n        \"        \\n\",\n        \"        results = fake_restaurants\\n\",\n        \"    else:\\n\",\n        \"        results = restaurant_db[matched_location]\\n\",\n        \"    \\n\",\n        \"    # Apply filters\\n\",\n        \"    filtered_results = results.copy()\\n\",\n        \"    \\n\",\n        \"    if cuisine:\\n\",\n        \"        filtered_results = [r for r in filtered_results if cuisine.lower() in r[\\\"cuisine\\\"].lower()]\\n\",\n        \"    \\n\",\n        \"    if price_level:\\n\",\n        \"        filtered_results = [r for r in filtered_results if r[\\\"price\\\"] == price_level]\\n\",\n        \"    \\n\",\n        \"    if open_now is not None:\\n\",\n        \"        filtered_results = [r for r in filtered_results if r[\\\"open\\\"] == open_now]\\n\",\n        \"    \\n\",\n        \"    return {\\n\",\n        \"        \\\"location\\\": location,\\n\",\n        \"        \\\"restaurants\\\": filtered_results,\\n\",\n        \"        \\\"total_results\\\": len(filtered_results)\\n\",\n        \"    }\\n\",\n        \"\\n\",\n        \"# Simulated directions function\\n\",\n        \"def get_directions(origin, destination, mode=\\\"driving\\\"):\\n\",\n        \"    \\\"\\\"\\\"Simulate a directions API\\\"\\\"\\\"\\n\",\n        \"    import random\\n\",\n        \"    \\n\",\n        \"    # Calculate a fake distance and duration\\n\",\n        \"    distance_miles = random.randint(1, 25)\\n\",\n        \"    \\n\",\n        \"    # Different speeds for different modes\\n\",\n        \"    speeds = {\\n\",\n        \"        \\\"driving\\\": random.randint(20, 45),  # mph\\n\",\n        \"        \\\"walking\\\": random.randint(2, 4),    # mph\\n\",\n        \"        \\\"bicycling\\\": random.randint(8, 15), # mph\\n\",\n        \"        \\\"transit\\\": random.randint(15, 30)   # mph\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    speed = speeds.get(mode, speeds[\\\"driving\\\"])\\n\",\n        \"    duration_minutes = round((distance_miles / speed) * 60)\\n\",\n        \"    \\n\",\n        \"    # Generate fake steps\\n\",\n        \"    steps = []\\n\",\n        \"    if mode == \\\"driving\\\":\\n\",\n        \"        steps = [\\n\",\n        \"            f\\\"Head east on Main St for {random.randint(1, 10)/10} miles\\\",\\n\",\n        \"            f\\\"Turn right onto Oak Ave for {random.randint(1, 20)/10} miles\\\",\\n\",\n        \"            f\\\"Continue onto Highway {random.randint(1, 99)} for {random.randint(1, 100)/10} miles\\\",\\n\",\n        \"            f\\\"Take exit {random.randint(1, 50)} toward {destination.split(',')[0]}\\\",\\n\",\n        \"            f\\\"Arrive at destination on the left\\\"\\n\",\n        \"        ]\\n\",\n        \"    elif mode == \\\"walking\\\" or mode == \\\"bicycling\\\":\\n\",\n        \"        steps = [\\n\",\n        \"            f\\\"Head east on Main St for {random.randint(1, 10)/10} miles\\\",\\n\",\n        \"            f\\\"Turn right onto Oak Ave\\\",\\n\",\n        \"            f\\\"Continue straight onto Park Lane\\\",\\n\",\n        \"            f\\\"Turn left at the cafe\\\",\\n\",\n        \"            f\\\"Arrive at destination\\\"\\n\",\n        \"        ]\\n\",\n        \"    else:  # transit\\n\",\n        \"        steps = [\\n\",\n        \"            f\\\"Walk to {origin.split(',')[0]} Station\\\",\\n\",\n        \"            f\\\"Take the {random.choice(['Red', 'Blue', 'Green'])} Line to Central Station\\\",\\n\",\n        \"            f\\\"Transfer to the {random.choice(['Orange', 'Yellow', 'Purple'])} Line\\\",\\n\",\n        \"            f\\\"Exit at {destination.split(',')[0]} Station\\\",\\n\",\n        \"            f\\\"Walk 0.2 miles to destination\\\"\\n\",\n        \"        ]\\n\",\n        \"    \\n\",\n        \"    return {\\n\",\n        \"        \\\"origin\\\": origin,\\n\",\n        \"        \\\"destination\\\": destination,\\n\",\n        \"        \\\"mode\\\": mode,\\n\",\n        \"        \\\"distance\\\": f\\\"{distance_miles} miles\\\",\\n\",\n        \"        \\\"duration\\\": f\\\"{duration_minutes} minutes\\\",\\n\",\n        \"        \\\"steps\\\": steps\\n\",\n        \"    }\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"M50xmPGcbJh_\"\n      },\n      \"source\": [\n        \"Now let's test our multi-function setup with a complex query:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"TJhPCGOrbL3i\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Send a complex message that might trigger multiple function calls\\n\",\n        \"complex_query = \\\"I'm planning a trip to Boston this weekend. What's the weather forecast, and can you recommend some good Italian restaurants that are open in the evening?\\\"\\n\",\n        \"\\n\",\n        \"response = travel_chat.send_message(complex_query)\\n\",\n        \"print(response)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"m0tW-5PCbQFX\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Process function calls\\n\",\n        \"function_calls = []\\n\",\n        \"if response.candidates and response.candidates[0].content.parts:\\n\",\n        \"    for part in response.candidates[0].content.parts:\\n\",\n        \"        if hasattr(part, 'function_call'):\\n\",\n        \"            function_calls.append(part.function_call)\\n\",\n        \"\\n\",\n        \"if function_calls:\\n\",\n        \"    print(f\\\"Found {len(function_calls)} function call(s)\\\")\\n\",\n        \"    function_responses = []\\n\",\n        \"    \\n\",\n        \"    for i, function_call in enumerate(function_calls):\\n\",\n        \"        print(f\\\"\\\\nFunction call {i+1}:\\\")\\n\",\n        \"        print(f\\\"Name: {function_call.name}\\\")\\n\",\n        \"        print(f\\\"Arguments: {function_call.args}\\\")\\n\",\n        \"        \\n\",\n        \"        # Execute the appropriate function\\n\",\n        \"        if function_call.name == \\\"get_current_weather\\\":\\n\",\n        \"            location = function_call.args.get(\\\"location\\\")\\n\",\n        \"            unit = function_call.args.get(\\\"unit\\\", \\\"fahrenheit\\\")\\n\",\n        \"            result = get_current_weather(location, unit)\\n\",\n        \"            print(f\\\"Result: {result}\\\")\\n\",\n        \"            \\n\",\n        \"        elif function_call.name == \\\"find_restaurants\\\":\\n\",\n        \"            location = function_call.args.get(\\\"location\\\")\\n\",\n        \"            cuisine = function_call.args.get(\\\"cuisine\\\")\\n\",\n        \"            price_level = function_call.args.get(\\\"price_level\\\")\\n\",\n        \"            open_now = function_call.args.get(\\\"open_now\\\")\\n\",\n        \"            result = find_restaurants(location, cuisine, price_level, open_now)\\n\",\n        \"            print(f\\\"Result: {result}\\\")\\n\",\n        \"            \\n\",\n        \"        elif function_call.name == \\\"get_directions\\\":\\n\",\n        \"            origin = function_call.args.get(\\\"origin\\\")\\n\",\n        \"            destination = function_call.args.get(\\\"destination\\\")\\n\",\n        \"            mode = function_call.args.get(\\\"mode\\\", \\\"driving\\\")\\n\",\n        \"            result = get_directions(origin, destination, mode)\\n\",\n        \"            print(f\\\"Result: {result}\\\")\\n\",\n        \"            \\n\",\n        \"        else:\\n\",\n        \"            result = {\\\"error\\\": f\\\"Unknown function: {function_call.name}\\\"}\\n\",\n        \"        \\n\",\n        \"        # Add to function responses\\n\",\n        \"        function_responses.append({\\n\",\n        \"            \\\"name\\\": function_call.name,\\n\",\n        \"            \\\"response\\\": result\\n\",\n        \"        })\\n\",\n        \"    \\n\",\n        \"    # Send all function responses back at once\\n\",\n        \"    final_response = travel_chat.send_message(function_responses)\\n\",\n        \"    print(\\\"\\\\nFinal response after executing all functions:\\\")\\n\",\n        \"    print(final_response.text)\\n\",\n        \"else:\\n\",\n        \"    print(\\\"No function calls found in the response.\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"jzh-qKcXbTgq\"\n      },\n      \"source\": [\n        \"## Function calling with complex schemas\\n\",\n        \"\\n\",\n        \"Let's define a more complex function with nested parameters for hotel booking:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"FpMUwqvCbV-B\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Define a complex function for booking hotels\\n\",\n        \"book_hotel_function = FunctionDeclaration(\\n\",\n        \"    name=\\\"book_hotel\\\",\\n\",\n        \"    description=\\\"Book a hotel room with specified details\\\",\\n\",\n        \"    parameters={\\n\",\n        \"        \\\"type\\\": \\\"object\\\",\\n\",\n        \"        \\\"properties\\\": {\\n\",\n        \"            \\\"location\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"City and state/country of the hotel\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"check_in\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Check-in date in YYYY-MM-DD format\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"check_out\\\": {\\n\",\n        \"                \\\"type\\\": \\\"string\\\",\\n\",\n        \"                \\\"description\\\": \\\"Check-out date in YYYY-MM-DD format\\\"\\n\",\n        \"            },\\n\",\n        \"            \\\"guests\\\": {\\n\",\n        \"                \\\"type\\\": \\\"object\\\",\\n\",\n        \"                \\\"description\\\": \\\"Information about the guests\\\",\\n\",\n        \"                \\\"properties\\\": {\\n\",\n        \"                    \\\"adults\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Number of adult guests\\\"\\n\",\n        \"                    },\\n\",\n        \"                    \\\"children\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Number of child guests\\\",\\n\",\n        \"                        \\\"default\\\": 0\\n\",\n        \"                    },\\n\",\n        \"                    \\\"rooms\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Number of rooms to book\\\",\\n\",\n        \"                        \\\"default\\\": 1\\n\",\n        \"                    }\\n\",\n        \"                },\\n\",\n        \"                \\\"required\\\": [\\\"adults\\\"]\\n\",\n        \"            },\\n\",\n        \"            \\\"preferences\\\": {\\n\",\n        \"                \\\"type\\\": \\\"object\\\",\\n\",\n        \"                \\\"description\\\": \\\"Hotel preferences\\\",\\n\",\n        \"                \\\"properties\\\": {\\n\",\n        \"                    \\\"star_rating\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"integer\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Minimum star rating (1-5)\\\",\\n\",\n        \"                        \\\"minimum\\\": 1,\\n\",\n        \"                        \\\"maximum\\\": 5\\n\",\n        \"                    },\\n\",\n        \"                    \\\"amenities\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"array\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Desired amenities\\\",\\n\",\n        \"                        \\\"items\\\": {\\n\",\n        \"                            \\\"type\\\": \\\"string\\\",\\n\",\n        \"                            \\\"enum\\\": [\\n\",\n        \"                                \\\"pool\\\", \\\"gym\\\", \\\"spa\\\", \\\"restaurant\\\", \\\"room_service\\\", \\n\",\n        \"                                \\\"free_wifi\\\", \\\"free_breakfast\\\", \\\"parking\\\"\\n\",\n        \"                            ]\\n\",\n        \"                        }\\n\",\n        \"                    },\\n\",\n        \"                    \\\"max_price_per_night\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"number\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Maximum price per night in USD\\\"\\n\",\n        \"                    }\\n\",\n        \"                }\\n\",\n        \"            },\\n\",\n        \"            \\\"contact_info\\\": {\\n\",\n        \"                \\\"type\\\": \\\"object\\\",\\n\",\n        \"                \\\"description\\\": \\\"Contact information for the reservation\\\",\\n\",\n        \"                \\\"properties\\\": {\\n\",\n        \"                    \\\"name\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"string\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Full name of the primary guest\\\"\\n\",\n        \"                    },\\n\",\n        \"                    \\\"email\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"string\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Email address for confirmation\\\"\\n\",\n        \"                    },\\n\",\n        \"                    \\\"phone\\\": {\\n\",\n        \"                        \\\"type\\\": \\\"string\\\",\\n\",\n        \"                        \\\"description\\\": \\\"Contact phone number\\\"\\n\",\n        \"                    }\\n\",\n        \"                },\\n\",\n        \"                \\\"required\\\": [\\\"name\\\", \\\"email\\\"]\\n\",\n        \"            }\\n\",\n        \"        },\\n\",\n        \"        \\\"required\\\": [\\\"location\\\", \\\"check_in\\\", \\\"check_out\\\", \\\"guests\\\", \\\"contact_info\\\"]\\n\",\n        \"    }\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Create a tool with the hotel booking function\\n\",\n        \"hotel_tool = Tool(\\n\",\n        \"    function_declarations=[book_hotel_function]\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Create a model with the hotel tool\\n\",\n        \"hotel_model = GenerativeModel(\\n\",\n        \"    \\\"gemini-1.5-pro\\\",\\n\",\n        \"    tools=[hotel_tool]\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Start a chat\\n\",\n        \"hotel_chat = hotel_model.start_chat()\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"2-x-sN8xbYuA\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Simulated hotel booking function\\n\",\n        \"def book_hotel(location, check_in, check_out, guests, preferences=None, contact_info=None):\\n\",\n        \"    \\\"\\\"\\\"Simulate a hotel booking API\\\"\\\"\\\"\\n\",\n        \"    import random\\n\",\n        \"    from datetime import datetime\\n\",\n        \"    \\n\",\n        \"    # Validate dates\\n\",\n        \"    try:\\n\",\n        \"        check_in_date = datetime.strptime(check_in, \\\"%Y-%m-%d\\\")\\n\",\n        \"        check_out_date = datetime.strptime(check_out, \\\"%Y-%m-%d\\\")\\n\",\n        \"        nights = (check_out_date - check_in_date).days\\n\",\n        \"        if nights <= 0:\\n\",\n        \"            return {\\\"error\\\": \\\"Check-out must be after check-in\\\"}\\n\",\n        \"    except ValueError:\\n\",\n        \"        return {\\\"error\\\": \\\"Invalid date format. Use YYYY-MM-DD\\\"}\\n\",\n        \"    \\n\",\n        \"    # Generate a confirmation code\\n\",\n        \"    confirmation_code = ''.join(random.choices('ABCDEFGHJKLMNPQRSTUVWXYZ23456789', k=6))\\n\",\n        \"    \\n\",\n        \"    # Generate a random price based on preferences if provided\\n\",\n        \"    base_price = random.randint(80, 300)\\n\",\n        \"    if preferences and \\\"star_rating\\\" in preferences:\\n\",\n        \"        # Higher star ratings are more expensive\\n\",\n        \"        star_multiplier = {1: 0.5, 2: 0.75, 3: 1.0, 4: 1.5, 5: 2.5}\\n\",\n        \"        base_price *= star_multiplier.get(preferences[\\\"star_rating\\\"], 1.0)\\n\",\n        \"    \\n\",\n        \"    # Apply random discount\\n\",\n        \"    discount = random.choice([0, 0, 0, 5, 10, 15, 20])\\n\",\n        \"    \\n\",\n        \"    # Calculate total\\n\",\n        \"    price_per_night = round(base_price, 2)\\n\",\n        \"    total_price = round(price_per_night * nights * guests.get(\\\"rooms\\\", 1), 2)\\n\",\n        \"    discounted_total = round(total_price * (1 - discount/100), 2) if discount > 0 else total_price\\n\",\n        \"    \\n\",\n        \"    # Create a hotel name based on location\\n\",\n        \"    hotel_chains = [\\\"Grand Hotel\\\", \\\"Comfort Inn\\\", \\\"Luxury Suites\\\", \\\"City View\\\", \\\"Royal Palace\\\"]\\n\",\n        \"    hotel_name = f\\\"{random.choice(hotel_chains)} {location.split(',')[0]}\\\"\\n\",\n        \"    \\n\",\n        \"    # Generate response\\n\",\n        \"    booking_response = {\\n\",\n        \"        \\\"confirmation_code\\\": confirmation_code,\\n\",\n        \"        \\\"hotel\\\": {\\n\",\n        \"            \\\"name\\\": hotel_name,\\n\",\n        \"            \\\"location\\\": location,\\n\",\n        \"            \\\"star_rating\\\": preferences.get(\\\"star_rating\\\", random.randint(3, 5)) if preferences else random.randint(3, 5)\\n\",\n        \"        },\\n\",\n        \"        \\\"booking_details\\\": {\\n\",\n        \"            \\\"check_in\\\": check_in,\\n\",\n        \"            \\\"check_out\\\": check_out,\\n\",\n        \"            \\\"nights\\\": nights,\\n\",\n        \"            \\\"guests\\\": guests,\\n\",\n        \"            \\\"price\\\": {\\n\",\n        \"                \\\"per_night\\\": price_per_night,\\n\",\n        \"                \\\"total\\\": total_price,\\n\",\n        \"                \\\"discount_percent\\\": discount,\\n\",\n        \"                \\\"final_total\\\": discounted_total,\\n\",\n        \"                \\\"currency\\\": \\\"USD\\\"\\n\",\n        \"            }\\n\",\n        \"        },\\n\",\n        \"        \\\"status\\\": \\\"confirmed\\\",\\n\",\n        \"        \\\"payment_required\\\": True,\\n\",\n        \"        \\\"cancellation_policy\\\": \\\"Free cancellation until 24 hours before check-in\\\"\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    # Add included amenities\\n\",\n        \"    all_amenities = [\\\"pool\\\", \\\"gym\\\", \\\"spa\\\", \\\"restaurant\\\", \\\"room_service\\\", \\\"free_wifi\\\", \\\"free_breakfast\\\", \\\"parking\\\"]\\n\",\n        \"    if preferences and \\\"amenities\\\" in preferences:\\n\",\n        \"        requested_amenities = preferences[\\\"amenities\\\"]\\n\",\n        \"        included_amenities = requested_amenities.copy()\\n\",\n        \"        # Add some random amenities that weren't specifically requested\\n\",\n        \"        for amenity in all_amenities:\\n\",\n        \"            if amenity not in included_amenities and random.random() > 0.7:  # 30% chance to add each unrequested amenity\\n\",\n        \"                included_amenities.append(amenity)\\n\",\n        \"    else:\\n\",\n        \"        # Random selection of amenities\\n\",\n        \"        included_amenities = random.sample(all_amenities, random.randint(3, 6))\\n\",\n        \"    \\n\",\n        \"    booking_response[\\\"hotel\\\"][\\\"amenities\\\"] = included_amenities\\n\",\n        \"    \\n\",\n        \"    return booking_response\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"X4vQHH-sbcfM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Test with a complex hotel booking request\\n\",\n        \"hotel_query = \\\"\\\"\\\"I need to book a hotel in Miami for a family vacation. We'll arrive on June 15, 2023 and stay until June 20. \\n\",\n        \"There will be 2 adults and 2 children, and we need 2 rooms. \\n\",\n        \"We'd prefer a 4-star hotel with a pool and free breakfast, ideally under $250 per night. \\n\",\n        \"You can use my information: John Smith, email john.smith@example.com, phone 555-123-4567.\\\"\\\"\\\"\\n\",\n        \"\\n\",\n        \"response = hotel_chat.send_message(hotel_query)\\n\",\n        \"print(response)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"GJr1GrPVbfDL\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Process the hotel booking function call\\n\",\n        \"function_calls = []\\n\",\n        \"if response.candidates and response.candidates[0].content.parts:\\n\",\n        \"    for part in response.candidates[0].content.parts:\\n\",\n        \"        if hasattr(part, 'function_call'):\\n\",\n        \"            function_calls.append("
}
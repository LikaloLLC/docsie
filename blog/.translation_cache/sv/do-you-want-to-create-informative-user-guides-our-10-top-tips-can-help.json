{
    "__metadata__": {
        "original_categories": [
            "Product Documentation",
            "Product Updates",
            "Best Practices",
            "Product Documentation Tutorials"
        ],
        "author_name": "Ciaran Sweet",
        "author_email": "content@soseo.co",
        "author_info": "A freelance technology writer that covers everything B2B and B2C.",
        "author_image": "https://cdn.docsie.io/user_profiles/8627/logo_logo_3KANTfZMqHKSow4aOi8st9Rei1fu6Cg66XKlyoiAIKtLa.png",
        "header_image": "https://cdn.docsie.io/workspace_8D5W1pxgb7Jq3oZO7/doc_QpDdxIGnXpT0d02oQ/file_1UQybV1CK9NS6E7N3/boo_XGfvRm3TVTFbV6HET/a5e242a1-0d11-2cbd-4347-5b65085d2b55Untitled_1_min_1_2_3_4.jpg",
        "timestamp": "2021-09-22T10:13:37+00:00",
        "status": 1
    },
    "do-you-want-to-create-informative-user-g|title": "Vill du skapa informativa anv√§ndarguider? V√•ra 10 b√§sta tips kan hj√§lpa!",
    "do-you-want-to-create-informative-user-g|summary": "L√§s dessa 10 b√§sta tips och l√§r dig hur du skriver b√§ttre anv√§ndardokumentationsguider!",
    "do-you-want-to-create-informative-user-g|markdown": "# Anv√§ndarguider √§r en viktig del av digitala tj√§nster\n\nAnv√§ndarguider √§r en viktig del av digitala tj√§nster. Digitala kunder f√∂rv√§ntar sig tillg√•ng till sj√§lvbetj√§ning och kr√§ver omedelbar information. En genomg√•ng √∂ver telefon r√§cker inte l√§ngre; timmar av f√∂rklaringar kan illustreras b√§ttre i dokumentation.\n\nP√• Docsie f√∂respr√•kar vi att alla f√∂retag skapar ett bibliotek med informativa anv√§ndarguider f√∂r kunder. Detta m√∂jligg√∂r sj√§lvbetj√§ning, minskar supportbelastningen och ger kunderna tillg√•ng till information dygnet runt, s√• att de kan anv√§nda din produkt eller tj√§nst p√• b√§sta s√§tt.\n\n<h2>10 b√§sta tipsen f√∂r anv√§ndarguider och dokumentation i Docsie</h2>\nInnan vi b√∂rjar, har du ett s√§tt att lagra, skriva och publicera dokumentation?\n\nG√• till [Docsie Onboarding](https://app.docsie.io/onboarding/) f√∂r kundcentrerad samverkan, omfattande inb√§ddningsm√∂jligheter, skr√§ddarsydda √∂vers√§ttningar och kraftfull publicering inom r√§ckh√•ll.\n\nNu n√§r du g√•tt med i klubben, l√•t oss titta p√• v√•ra 10 b√§sta tips!\n\n<h3>1 - Berika dina anv√§ndarguider med media</h3>\nText, ord, bokst√§ver ‚Äì vi anv√§nder dem varje dag. Tyv√§rr kan det skrivna ordet inte j√§mf√∂ras med kraften hos video eller inspirationen fr√•n bilder.\n\nN√§r du skapar dokumentation, l√§s den ur anv√§ndarens perspektiv. Kunde detta avsnitt f√∂rklaras b√§ttre med en GIF, inb√§ddad video eller f√∂rklarande bild? Om ja, l√§gg till det!\n\nDu kan l√§gga till bilder, b√§dda in videor och integrera iFrame-inneh√•ll i Docsie. Prova det!\n\n![Bilder, videor och GIF:ar i Docsie](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_CdhFEVXwXaefNXxxg/boo_dqsfhc7ObadQ3xWmV/e0eda1c6-284a-3e0f-5c43-0ff4099966d0BlogGIF10TipsforUserGuides.gif)\n\n<h3>2 - Skapa en ordning, nej, inte Jedi-typen!</h3>\nSteg-f√∂r-steg-instruktioner √§r grundpelaren i alla kokb√∂cker! N√§r du f√∂ljer ett recept, blandar du √§gg med mj√∂l hur som helst? Det √§r vad du ska g√∂ra, och du vet det eftersom du f√∂ljer stegen!\n\nSk√§mt √•sido, se till att du g√•r igenom alla anv√§ndarguider med steg-f√∂r-steg-instruktioner. Om du f√∂ljer dessa steg, f√•r du faktiskt det avsedda resultatet? Felaktiga instruktioner som inte n√•r m√•let √§r en varningssignal f√∂r kunder. Korrekta instruktioner bygger f√∂rtroende och ger v√§rde genom informationsdelning.\n\nSkapa en ordning med numrerade listor i Docsie eller med Docsie Book Articles f√∂r att segmentera din dokumentation.\n \n ![Artiklar, hyllor och arbetsytor i Docsie](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_O4Ux6ERzhyIS0eB1X/boo_dqsfhc7ObadQ3xWmV/aa925138-ab48-e18b-ff33-50557a2897cfArticlesShelvesWorkspacesinDocsie.png)\n\n<h3>3 - Anpassa f√∂r alla l√§sniv√•er</h3>\nAntar du att kunderna kan skilja p√• JavaScript och dina b√§sta tips? Anv√§ndning av fackspr√•k och komplex terminologi rekommenderas vanligtvis i tekniska anv√§ndarguider. F√∂r lekm√§n √§r dock enklare spr√•k b√§ttre!\n\nDe flesta l√§sare vill bara veta hur man g√∂r n√•got och upprepar det. Ett tillv√§gag√•ngss√§tt √§r att presentera ett komplext koncept p√• en h√∂gre niv√• ‚Äì och sedan upprepa med en f√∂renklad version f√∂r lekm√§n. Detta tillgodoser b√•de tekniska anv√§ndare och lekm√§n samtidigt.\n\n\"Artificiell intelligens inneb√§r algoritmisk emulering av m√§nsklig intelligens f√∂r produktivitet; artificiell intelligens syftar till att f√• arbete gjort genom att matcha m√§nsklig intelligens med datorkod.\" ‚Äì b√•da betyder samma sak men riktar sig till olika m√•lgrupper.\n\nAnv√§nd Docsie f√∂r att skapa hyllor f√∂r lekm√§n och hyllor f√∂r tekniska anv√§ndare. P√• s√• s√§tt kan du ha b√∂cker som hj√§lper b√•da m√•lgrupperna, med fullst√§ndig publicering via Docsie Portal.\n \n![Exempel p√• komplex kod f√∂renklad f√∂r lekm√§n i Docsie](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_cnLx3DDYwihXopx74/boo_dqsfhc7ObadQ3xWmV/411ea34c-096b-3bf2-fde0-2f8fdaddd55aLaypersonSimplificationforDocsie.png)\n\n<h3>4 - Anv√§nd mallar och sluta sitta uppe sent!</h3>\nSkriver du varje anv√§ndarguide fr√•n grunden? Skapa ist√§llet mallar med grundl√§ggande struktur och varum√§rkesbudskap, och bygg runt detta inneh√•ll.\n\nAtt skriva fr√•n grunden tar tid, kr√§ver anstr√§ngning och riskerar inkonsekvens om flera skribenter arbetar inom samma projekt. Mallar √§r ett bra s√§tt att spara tid och skapa st√∂rre konsekvens mellan sidor. F√∂rtroende bygger p√• konsekvent kommunikation och v√§rdeskapande, vilket mallar fr√§mjar.\n\nKlicka p√• ‚Ä¶Mer och v√§lj Mallar i Docsie. H√§r kan du lagra mallar och starta nya b√∂cker med mallen som k√§lla!\n\n ![Mallar i Docsie](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_Hv9JSg74vQE1zgYjT/boo_dqsfhc7ObadQ3xWmV/833830aa-871c-d3ba-19e7-0fbbba2adbfbTemplatesinDocsie.png)\n ![Live-mall i Docsie-redigeraren](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_jdf9iWL3NXlFFePHx/boo_dqsfhc7ObadQ3xWmV/2bfcea18-df94-30ff-4931-799345e4ae74Templates2inDocsie.png)\n\n<h3>5 - Skriv snabbt, iterera ofta</h3>\nI agil mjukvaruutveckling √§r mantrat att misslyckas snabbt och iterera ofta. N√§r detta till√§mpas p√• anv√§ndardokumentation b√∂r ditt team str√§va efter att skriva snabbt och iterera ofta.\n\nDetta betyder inte att kvalitet offras f√∂r hastighet. Ist√§llet m√∂jligg√∂r det kundfeedback med mindre initial anstr√§ngning. Denna feedback kan anv√§ndas i framtida iterationer och hj√§lper f√∂retaget att bli mer kundcentrerat.\n\nDocsie Vocally tydligg√∂r l√§sarfeedback med betyg och sk√§rminspelningar som pekar ut exakt vilket inneh√•ll de l√§st. Prova det n√§r du skriver snabbt och itererar ofta!\n\n![Docsie Vocally feedbackvy](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_8uO5DnYSHSsLteI2X/boo_dqsfhc7ObadQ3xWmV/b9f841c9-1dde-5eee-c723-809f13df3255DocsieVocallyLivePreview.png) \n\n<h3>6 - N√§stlad kunskap med interna bak√•tl√§nkar</h3>\n√Ñr din anv√§ndardokumentation l√§nkad till andra sidor? Genom att l√§gga till l√§nkar till relevanta avsnitt hj√§lper du l√§sarna att f√∂rst√• din produkt eller tj√§nst p√• en konceptuell niv√•.\n\nN√§r du h√§nvisar till en specifik funktion, l√§gg alltid till en l√§nk. L√•t l√§saren snabbt f√• tillg√•ng till informationen ist√§llet f√∂r att tvinga dem att s√∂ka och ladda sidan sj√§lva. Pratar du om kontoinloggningar? L√§gg till en inloggnings-URL i texten \"logga in p√• ditt konto\" p√• din sida och varje annan sida. G√∂r din dokumentation bekv√§m och navigerbar i br√∂dtexten ist√§llet f√∂r ett o√§ndligt bibliotek att s√∂ka igenom.\n\nDocsie l√•ter dokumentationsskribenter skapa interna bak√•tl√§nkar. Markera text och klicka p√• üñáÔ∏è-knappen i Docsie-redigerarens verktygsf√§lt. Du kan ocks√• g√∂ra l√§nkar spr√•k- och versionsagnostiska med relativa objektl√§nkar.\n\n![Bak√•tl√§nkning i Docsie med objektreferensl√§nkar](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_dclZdrsTWJrB8WETc/boo_dqsfhc7ObadQ3xWmV/7d8c9e37-3aa6-580d-644b-0d7a8039fa89DocsieObjectLinksforBacklinking.png)\n\n<h3>7 - Damma av spindeln√§ten och uppdatera gammalt inneh√•ll</h3>\nHar du gamla anv√§ndarguider och dokumentation synliga online? Om du har version 1.2-dokumentation publicerad medan din produkt √§r p√• version 1.3 √§r din dokumentation inte l√§ngre relevant. Anv√§nd Docsie Versioning ist√§llet f√∂r att publicera ny dokumentation f√∂r varje version.\n\nDocsie Versioning l√•ter anv√§ndare komma √•t historiska och aktuella dokumentationsversioner. N√§r nya versioner sl√§pps arkiveras gamla versioner men f√∂rblir tillg√§ngliga fr√•n en rullgardinsmeny. Allt detta p√• samma webbsida, vilket g√∂r det enklare f√∂r anv√§ndare att hitta relevant information.\n\nOm din guide f√∂r 2021 fortfarande √§r publicerad 2022, uppdatera den! √Ñndra namnet, uppdatera citat och k√§llor med ny forskning, och dubbelkolla att informationen fortfarande √§r relevant. H√•ll inneh√•llet tidl√∂st ‚Äì det kan alltid √•teranv√§ndas.\n\n ![Versionsv√§ljare f√∂r att hitta √§ldre inneh√•ll i Docsie](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_OaCUumTVGz3CQ2ha2/boo_dqsfhc7ObadQ3xWmV/4edbd225-b61b-0921-4f63-e55b3052ed28DocsieVersionsPickerMenu.png)\n\n<h3>8 - Bryt ner uppgifter, slutf√∂r i omg√•ngar</h3>\nN√§r du skriver, skriver du hela sidan p√• en g√•ng utan planering? En del handlar om personlig preferens. Genom att bryta ner uppgifter kan arbetet dock slutf√∂ras snabbare och med mer fokus.\n\nSkapa en enkel struktur med H1- och H2-taggar och korta beskrivningar f√∂r varje avsnitt. Anv√§nd detta n√§r du skriver och ta itu med enskilda avsnitt ist√§llet f√∂r att oroa dig f√∂r hela sidan. Detta kallas disposition i skrivbranschen. Dispositionen ger m√∂jlighet till feedback fr√•n redakt√∂rer innan skrivandet b√∂rjar och fungerar som ett ramverk n√§r skribenten skriver.\n\nSkapa en ny bok i Docsie och l√§gg till n√•gra grundl√§ggande rubriker och text f√∂r en disposition. Du kan ocks√• l√§gga till uppgifter via h√∂germenyn och bryta ner arbetet i mindre omg√•ngar n√§r flera teammedlemmar samarbetar. Versionshistorik inneb√§r att du kan g√• tillbaka om en skribent l√§gger till mindre bra inneh√•ll ‚Äì perfekt f√∂r att skriva snabbt och iterera ofta!\n\n ![Kalender f√∂r uppgiftstilldelning i Docsie](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_4JCx9FdXnyXu3quMX/boo_dqsfhc7ObadQ3xWmV/d3468298-7bc2-7f51-7afe-2437f6321658TaskMiniaturizeCalendarDocsie.png)\n\n<h3>9 - En inneh√•llsf√∂rteckning f√∂r fler inneh√•llsl√§sare</h3>\nMed komplex och varierad anv√§ndardokumentation kan en textv√§gg vara skr√§mmande f√∂r l√§sarna. Detta kan l√∂sas med en omfattande inneh√•llsf√∂rteckning. Vanligt anv√§nd i uppslagsverk hj√§lper detta anv√§ndare att identifiera och hoppa till relevant information, samtidigt som det ger struktur till en kunskapsportal.\n\nDocsie Articles, Shelves och Workspaces skapar en inneh√•llsf√∂rteckning. Denna visas automatiskt p√• v√§nster sida av din kunskapsportal ‚Äì ett enkelt s√§tt att navigera genom din kunskapsbas. Med detta tips g√∂r Docsie jobbet √•t dig!\n\n![Automatiskt genererad inneh√•llsf√∂rteckning av Docsie](https://cdn.docsie.io/workspace_tovPs7rKnzB4cmaiR/doc_GzKTESk1IUWjA77hg/file_oxDNcw0pA6rCZa3J7/boo_dqsfhc7ObadQ3xWmV/35d48662-895e-b83f-c7c3-abb0ce6edd0dTableofContentsDocsie.png)\n \n\n<h3>10 - Beh√§rska ditt √§mne</h3>\n√Ñr din skribent en √§mnesexpert? √Ñr din skribent resursstark och bra p√• att unders√∂ka √§mnen de kanske inte k√§nner till? I slut√§ndan, trots alla v√•ra tips, best√§mmer skribenten kvaliteten p√• din dokumentation.\n\nJu mer de f√∂rst√•r din produkt, desto mer korrekt blir deras arbete. Ge skribenter flexibilitet att testa och bryta din produkt, eftersom anv√§ndare kan st√∂ta p√• liknande problem. √Ñnnu b√§ttre, g√• igenom en produktdemo med ditt s√§ljteam och ge dem praktisk erfarenhet av s√§ljprocessen och kommunikationen. Detta driver konsekvens och f√∂rvandlar dina skribenter till anv√§ndare. Alla skribenter blir inte anv√§ndare, men alla anv√§ndare kan bli bra skribenter med praktisk kunskap.\n\n\n\n<h2>Anv√§nd dessa tips i praktiken i Docsie!</h2>\n\nTack f√∂r att du l√§ste v√•ra 10 b√§sta tips f√∂r b√§ttre anv√§ndarguider. Vi bjuder in dig att till√§mpa dessa tips p√• din Docsie-dokumentation!\n\nDocsie √§r en helt√§ckande plattform f√∂r dokumentationshantering som f√∂retag anv√§nder f√∂r att skapa webbaserade FAQ, produktdokumentation, anv√§ndarguider, hj√§lpdokument och manualer. Plattformen erbjuder kundcentrerat samarbete, omfattande inb√§ddningsm√∂jligheter, skr√§ddarsydda √∂vers√§ttningar och kraftfull publicering inom r√§ckh√•ll.\n\nTa steget genom att [registrera dig hos Docsie](https://app.docsie.io/onboarding/) idag och leverera dokumentationsupplevelser som gl√§djer dina kunder!",
    "do-you-want-to-create-informative-user-g|category|0": "Produktdokumentation\n\u0000# ramirezfx/prs-genie\n# src/components/App.tsx\nimport React, { useState, useEffect } from 'react';\nimport { Configuration, OpenAIApi } from 'openai';\nimport { Container, Box, TextField, Button, Typography, Paper, CircularProgress, FormControl, InputLabel, Select, MenuItem, SelectChangeEvent, Divider, Link } from '@mui/material';\nimport GitHubIcon from '@mui/icons-material/GitHub';\nimport '../styles/App.css';\n\ninterface PullRequest {\n  title: string;\n  body: string;\n  diff: string;\n}\n\nconst App: React.FC = () => {\n  const [apiKey, setApiKey] = useState<string>('');\n  const [prUrl, setPrUrl] = useState<string>('');\n  const [summary, setSummary] = useState<string>('');\n  const [loading, setLoading] = useState<boolean>(false);\n  const [error, setError] = useState<string | null>(null);\n  const [model, setModel] = useState<string>('gpt-3.5-turbo');\n  const [savedApiKey, setSavedApiKey] = useState<boolean>(false);\n\n  // Load API key from localStorage on component mount\n  useEffect(() => {\n    const storedApiKey = localStorage.getItem('openai-api-key');\n    if (storedApiKey) {\n      setApiKey(storedApiKey);\n      setSavedApiKey(true);\n    }\n  }, []);\n\n  const handleSaveApiKey = () => {\n    localStorage.setItem('openai-api-key', apiKey);\n    setSavedApiKey(true);\n  };\n\n  const handleClearApiKey = () => {\n    localStorage.removeItem('openai-api-key');\n    setApiKey('');\n    setSavedApiKey(false);\n  };\n\n  const handleModelChange = (event: SelectChangeEvent) => {\n    setModel(event.target.value as string);\n  };\n\n  const fetchPullRequestDetails = async (url: string): Promise<PullRequest> => {\n    try {\n      // Extract owner, repo, and PR number from GitHub URL\n      const urlPattern = /github\\.com\\/([^/]+)\\/([^/]+)\\/pull\\/(\\d+)/;\n      const match = url.match(urlPattern);\n      \n      if (!match) {\n        throw new Error('Invalid GitHub pull request URL');\n      }\n\n      const [, owner, repo, prNumber] = match;\n      \n      // Fetch PR details from GitHub API\n      const prResponse = await fetch(`https://api.github.com/repos/${owner}/${repo}/pulls/${prNumber}`);\n      if (!prResponse.ok) {\n        throw new Error(`GitHub API error: ${prResponse.statusText}`);\n      }\n      \n      const prData = await prResponse.json();\n      \n      // Fetch the diff\n      const diffResponse = await fetch(`https://api.github.com/repos/${owner}/${repo}/pulls/${prNumber}`, {\n        headers: {\n          'Accept': 'application/vnd.github.v3.diff'\n        }\n      });\n      \n      if (!diffResponse.ok) {\n        throw new Error(`GitHub API error: ${diffResponse.statusText}`);\n      }\n      \n      const diffText = await diffResponse.text();\n      \n      return {\n        title: prData.title,\n        body: prData.body || '',\n        diff: diffText\n      };\n    } catch (error) {\n      if (error instanceof Error) {\n        throw new Error(`Failed to fetch PR details: ${error.message}`);\n      }\n      throw new Error('Failed to fetch PR details');\n    }\n  };\n\n  const analyzePullRequest = async (pr: PullRequest) => {\n    const configuration = new Configuration({\n      apiKey,\n    });\n    const openai = new OpenAIApi(configuration);\n\n    // Limit diff size to avoid token limits\n    const truncatedDiff = pr.diff.length > 15000 ? `${pr.diff.substring(0, 15000)}... [diff truncated due to length]` : pr.diff;\n\n    const prompt = `\nAnalyze the following GitHub pull request and provide a comprehensive summary.\n\nTitle: ${pr.title}\nDescription: ${pr.body}\n\nCode changes:\n\\`\\`\\`diff\n${truncatedDiff}\n\\`\\`\\`\n\nYour task:\n1. Summarize what the PR does in 1-2 sentences\n2. List the main files changed and what was modified in each\n3. Identify potential issues, risks, or areas that need attention\n4. Suggest specific testing strategies for this change\n5. Rate the complexity of the PR (Low/Medium/High) and explain why\n\nFormat your response in markdown for readability.\n`;\n\n    try {\n      const response = await openai.createChatCompletion({\n        model: model,\n        messages: [\n          { role: 'system', content: 'You are a senior software engineer reviewing code changes. Provide clear, concise, and actionable insights.' },\n          { role: 'user', content: prompt }\n        ],\n        temperature: 0.7,\n        max_tokens: 1500,\n      });\n\n      return response.data.choices[0].message?.content || 'No analysis generated';\n    } catch (error) {\n      if (error instanceof Error) {\n        throw new Error(`OpenAI API error: ${error.message}`);\n      }\n      throw new Error('Failed to analyze PR');\n    }\n  };\n\n  const handleSubmit = async (e: React.FormEvent) => {\n    e.preventDefault();\n    setLoading(true);\n    setError(null);\n    setSummary('');\n\n    try {\n      const pr = await fetchPullRequestDetails(prUrl);\n      const analysis = await analyzePullRequest(pr);\n      setSummary(analysis);\n    } catch (error) {\n      if (error instanceof Error) {\n        setError(error.message);\n      } else {\n        setError('An unknown error occurred');\n      }\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <Container maxWidth=\"md\" className=\"app-container\">\n      <Paper elevation={3} className=\"main-paper\">\n        <Box className=\"header\">\n          <Typography variant=\"h4\" component=\"h1\" gutterBottom>\n            PR Genie üßû‚Äç‚ôÇÔ∏è\n          </Typography>\n          <Typography variant=\"subtitle1\" gutterBottom>\n            Your AI-powered pull request analyzer\n          </Typography>\n        </Box>\n\n        <Divider sx={{ mb: 3 }} />\n\n        <Box className=\"api-key-section\" mb={4}>\n          <Typography variant=\"h6\" component=\"h2\" gutterBottom>\n            OpenAI API Key\n          </Typography>\n          \n          <Box display=\"flex\" alignItems=\"center\" gap={2}>\n            <TextField\n              label=\"OpenAI API Key\"\n              type=\"password\"\n              fullWidth\n              value={apiKey}\n              onChange={(e) => setApiKey(e.target.value)}\n              margin=\"normal\"\n              helperText=\"Your API key is stored locally in your browser\"\n              required\n            />\n            {savedApiKey ? (\n              <Button variant=\"outlined\" color=\"secondary\" onClick={handleClearApiKey}>\n                Clear Key\n              </Button>\n            ) : (\n              <Button variant=\"contained\" color=\"primary\" onClick={handleSaveApiKey} disabled={!apiKey}>\n                Save Key\n              </Button>\n            )}\n          </Box>\n        </Box>\n\n        <form onSubmit={handleSubmit}>\n          <Box mb={4}>\n            <Typography variant=\"h6\" component=\"h2\" gutterBottom>\n              Pull Request URL\n            </Typography>\n            <TextField\n              label=\"GitHub Pull Request URL\"\n              fullWidth\n              value={prUrl}\n              onChange={(e) => setPrUrl(e.target.value)}\n              margin=\"normal\"\n              helperText=\"Enter a valid GitHub pull request URL\"\n              required\n            />\n          </Box>\n\n          <Box mb={4}>\n            <FormControl fullWidth>\n              <InputLabel id=\"model-select-label\">OpenAI Model</InputLabel>\n              <Select\n                labelId=\"model-select-label\"\n                id=\"model-select\"\n                value={model}\n                label=\"OpenAI Model\"\n                onChange={handleModelChange}\n              >\n                <MenuItem value=\"gpt-3.5-turbo\">GPT-3.5 Turbo (Faster, cheaper)</MenuItem>\n                <MenuItem value=\"gpt-4\">GPT-4 (Better analysis, more expensive)</MenuItem>\n              </Select>\n            </FormControl>\n          </Box>\n\n          <Button \n            type=\"submit\" \n            variant=\"contained\" \n            color=\"primary\" \n            fullWidth \n            disabled={loading || !apiKey || !prUrl}\n            size=\"large\"\n          >\n            {loading ? <CircularProgress size={24} color=\"inherit\" /> : \"Analyze Pull Request\"}\n          </Button>\n        </form>\n\n        {error && (\n          <Paper elevation={1} className=\"error-paper\">\n            <Typography color=\"error\" variant=\"body1\">\n              {error}\n            </Typography>\n          </Paper>\n        )}\n\n        {summary && (\n          <Paper elevation={1} className=\"summary-paper\">\n            <Typography variant=\"h6\" component=\"h3\" gutterBottom>\n              Analysis Results\n            </Typography>\n            <Box className=\"markdown-body\" dangerouslySetInnerHTML={{ __html: convertMarkdownToHtml(summary) }} />\n          </Paper>\n        )}\n\n        <Box mt={4} className=\"footer\">\n          <Typography variant=\"body2\" color=\"textSecondary\" align=\"center\">\n            <Link href=\"https://github.com/your-username/pr-genie\" color=\"inherit\" display=\"flex\" alignItems=\"center\" justifyContent=\"center\" gap={1}>\n              <GitHubIcon fontSize=\"small\" />\n              View on GitHub\n            </Link>\n          </Typography>\n        </Box>\n      </Paper>\n    </Container>\n  );\n};\n\n// Simple function to convert basic markdown to HTML\nconst convertMarkdownToHtml = (markdown: string): string => {\n  let html = markdown;\n  \n  // Headers\n  html = html.replace(/^### (.*$)/gim, '<h3>$1</h3>');\n  html = html.replace(/^## (.*$)/gim, '<h2>$1</h2>');\n  html = html.replace(/^# (.*$)/gim, '<h1>$1</h1>');\n  \n  // Bold\n  html = html.replace(/\\*\\*(.*?)\\*\\*/gim, '<strong>$1</strong>');\n  \n  // Italic\n  html = html.replace(/\\*(.*?)\\*/gim, '<em>$1</em>');\n  \n  // Lists\n  html = html.replace(/^\\- (.*$)/gim, '<ul><li>$1</li></ul>');\n  html = html.replace(/^\\d\\. (.*$)/gim, '<ol><li>$1</li></ol>');\n  \n  // Code blocks\n  html = html.replace(/```(.+?)```/gs, '<pre><code>$1</code></pre>');\n  \n  // Inline code\n  html = html.replace(/`(.*?)`/gim, '<code>$1</code>');\n  \n  // Paragraphs\n  html = html.replace(/^\\s*(\\n)?(.+)/gm, function(m) {\n    return /\\<(\\/)?(h\\d|ul|ol|li|pre|code)/.test(m) ? m : '<p>' + m + '</p>';\n  });\n  \n  // Fix lists\n  html = html.replace(/<\\/ul>\\s?<ul>/g, '');\n  html = html.replace(/<\\/ol>\\s?<ol>/g, '');\n  \n  // Line breaks\n  html = html.replace(/\\n/g, '<br>');\n  \n  return html;\n};\n\nexport default App;\n\u0000# isgasho/go-kit-1\npackage stream\n\nimport (\n\t\"fmt\"\n\t\"github.com/wushilin/go-stream/threads\"\n\t\"runtime\"\n\t\"sync\"\n\t\"sync/atomic\"\n)\n\ntype Closeable interface {\n\tClose() error\n}\n\ntype IntConsumer = func(i int64) error\ntype IntSupplier = func() (int64, error)\ntype OfIntConsumer = func(e interface{}, i int64) error\ntype BiFunction = func(t interface{}, u interface{}) (interface{}, error)\ntype BinaryOperator = BiFunction\ntype Function = func(interface{}) (interface{}, error)\ntype Predicate = func(interface{}) (bool, error)\ntype BiIntFunction = func(t int64, u int64) (int64, error)\ntype BiLongFunction = BiIntFunction\ntype BinaryIntOperator = BiIntFunction\ntype Consumer = func(interface{}) error\ntype BiConsumer = func(interface{}, interface{}) error\ntype Supplier = func() (interface{}, error)\ntype ToDoubleFunction = func(interface{}) (float64, error)\ntype ToIntFunction = func(interface{}) (int64, error)\ntype ToLongFunction = ToIntFunction\ntype IntPredicate = func(int64) (bool, error)\ntype LongPredicate = IntPredicate\ntype IntFunction = func(int64) (interface{}, error)\ntype LongFunction = IntFunction\ntype IntToDoubleFunction = func(int64) (float64, error)\ntype LongToDoubleFunction = IntToDoubleFunction\ntype IntToLongFunction = func(int64) (int64, error)\ntype DoubleConsumer = func(float64) error\ntype DoublePredicate = func(float64) (bool, error)\ntype DoubleSupplier = func() (float64, error)\ntype DoubleToIntFunction = func(float64) (int64, error)\ntype IntUnaryOperator = func(int64) (int64, error)\ntype IntBinaryOperator = func(int64, int64) (int64, error)\ntype ToIntBiFunction = func(interface{}, interface{}) (int64, error)\ntype ToLongBiFunction = ToIntBiFunction\n\ntype Stream interface {\n\tCloseable\n\tMap(mapper Function) Stream\n\tPMap(mapper Function, threads int) Stream\n\tMapWithError() Stream\n\tMapToDouble(ToDoubleFunction) DoubleStream\n\tMapToInt(ToIntFunction) IntStream\n\tFlatMap(Function) Stream\n\tFilter(predicate Predicate) Stream\n\tPFilter(predicate Predicate, threads int) Stream\n\tLimit(max int64) Stream\n\tSkip(n int64) Stream\n\tPeek(action Consumer) Stream\n\tDistinct() Stream\n\tSorted(less func(left, right interface{}) bool) Stream\n\t//ForEach(Consumer)\n\tCollect(collector Collector) (interface{}, error)\n\tAnyMatch(predicate Predicate) (bool, error)\n\tAllMatch(predicate Predicate) (bool, error)\n\tNoneMatch(predicate Predicate) (bool, error)\n\tCount() (int64, error)\n\tForEach(consumer Consumer) error\n\tForEachOrdered(consumer Consumer) error\n\t//FindAny() (interface{}, error)\n\tFindFirst() (interface{}, error)\n\tMin(cmp func(interface{}, interface{}) int) (interface{}, error)\n\tMax(cmp func(interface{}, interface{}) int) (interface{}, error)\n\tIsParallel() bool\n\tReduceWithIdentity(identity interface{}, accumulator BinaryOperator) (interface{}, error)\n\t//ReduceWithBinaryOperator(accumulator BinaryOperator) interface{}\n\tReduce(accumulator BinaryOperator) (interface{}, error)\n\tConcat(s2 Stream) Stream\n\tParallelStream() Stream\n\tSequentialStream() Stream\n\tOnClose(closeHandler func() error) Stream\n\t//Parallel() Stream\n\t//Sequential() Stream\n\t//Unordered() Stream\n}\n\ntype IntStream interface {\n\tCloseable\n\tMap(IntUnaryOperator) IntStream\n\tMapToObj(IntFunction) Stream\n\tMapToDouble(IntToDoubleFunction) DoubleStream\n\tFilter(IntPredicate) IntStream\n\tSkip(n int64) IntStream\n\tLimit(max int64) IntStream\n\tPeek(IntConsumer) IntStream\n\tForEach(IntConsumer) error\n\tReduce(op IntBinaryOperator) (int64, error)\n\tReduceWithIdentity(identity int64, op IntBinaryOperator) (int64, error)\n\tFindFirst() (int64, error)\n\tSum() (int64, error)\n\tMin() (int64, error)\n\tMax() (int64, error)\n\tCount() (int64, error)\n\tAverage() (float64, error)\n\tBoxedStream() Stream\n\tSorted() IntStream\n}\n\ntype DoubleStream interface {\n\tCloseable\n\tMap(func(float64) (float64, error)) DoubleStream\n\tFilter(DoublePredicate) DoubleStream\n\tMapToInt(DoubleToIntFunction) IntStream\n\tMapToObj(func(float64) (interface{}, error)) Stream\n\tSkip(n int64) DoubleStream\n\tLimit(max int64) DoubleStream\n\tPeek(DoubleConsumer) DoubleStream\n\tForEach(DoubleConsumer) error\n\tReduce(func(float64, float64) (float64, error)) (float64, error)\n\tReduceWithIdentity(identity float64, op func(float64, float64) (float64, error)) (float64, error)\n\tFindFirst() (float64, error)\n\tSum() (float64, error)\n\tMin() (float64, error)\n\tMax() (float64, error)\n\tCount() (int64, error)\n\tAverage() (float64, error)\n\tSorted() DoubleStream\n\tBoxedStream() Stream\n}\n\ntype Iterator interface {\n\tNext() (interface{}, error)\n}\n\ntype Iterable interface {\n\tIterator() (Iterator, error)\n}\n\ntype BaseStream interface {\n\tStream\n\tIterator() (Iterator, error)\n}\n\ntype Collector interface {\n\tSupplier() Supplier\n\tAccumulator() BiConsumer\n\tFinisher() Function\n}\n\ntype BaseStreamImpl struct {\n\titerator      Iterator\n\tcloseHandlers []func() error\n\tparallel      bool\n}\n\nfunc (bsi *BaseStreamImpl) IsParallel() bool {\n\treturn bsi.parallel\n}\n\nfunc (bsi *BaseStreamImpl) Concat(s2 Stream) Stream {\n\tispar := bsi.parallel\n\tif s2.IsParallel() {\n\t\tispar = true\n\t}\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &ConcatIterator{first: bsi.iterator, second: s2.(BaseStream).Iterator},\n\t\t\tcloseHandlers: append(append([]func() error{}, bsi.closeHandlers...), s2.(*StreamImpl).closeHandlers...),\n\t\t\tparallel:      ispar,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Map(mapper Function) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &MappingIterator{source: bsi.iterator, mapper: mapper},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) PMap(mapper Function, threads int) Stream {\n\tnthreads := threads\n\tif nthreads <= 0 {\n\t\tnthreads = runtime.NumCPU()\n\t}\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &PMappingIterator{source: bsi.iterator, mapper: mapper, threads: nthreads},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) MapWithError() Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &MapWithErrorIterator{source: bsi.iterator},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) MapToDouble(f ToDoubleFunction) DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &ObjToDoubleIterator{source: bsi.iterator, mapper: f},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) MapToInt(f ToIntFunction) IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &ObjToIntIterator{source: bsi.iterator, mapper: f},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Iterator() (Iterator, error) {\n\treturn bsi.iterator, nil\n}\n\nfunc (bsi *BaseStreamImpl) FlatMap(fm Function) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &FlatMapIterator{source: bsi.iterator, mapper: fm},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Filter(pred Predicate) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &FilteringIterator{source: bsi.iterator, pred: pred},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) PFilter(pred Predicate, threads int) Stream {\n\tnthreads := threads\n\tif nthreads <= 0 {\n\t\tnthreads = runtime.NumCPU()\n\t}\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &PFilteringIterator{source: bsi.iterator, pred: pred, threads: nthreads},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Limit(max int64) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &LimitingIterator{source: bsi.iterator, limit: max},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Skip(max int64) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &SkippingIterator{source: bsi.iterator, skip: max},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Peek(act Consumer) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &PeekingIterator{source: bsi.iterator, act: act},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Distinct() Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &DistinctIterator{source: bsi.iterator},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Sorted(less func(left, right interface{}) bool) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &SortedIterator{source: bsi.iterator, less: less},\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) Collect(c Collector) (interface{}, error) {\n\tsupplier := c.Supplier()\n\taccumulator := c.Accumulator()\n\tfinisher := c.Finisher()\n\tvar result interface{}\n\tresult, err := supplier()\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor {\n\t\tnext, err := bsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\terr = accumulator(result, next)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn finisher(result)\n}\n\nfunc (bsi *BaseStreamImpl) AnyMatch(pred Predicate) (bool, error) {\n\tfor {\n\t\tnext, err := bsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn false, err\n\t\t}\n\t\tmatched, err := pred(next)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tif matched {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\treturn false, nil\n}\n\nfunc (bsi *BaseStreamImpl) AllMatch(pred Predicate) (bool, error) {\n\tresult := true\n\tfor {\n\t\tnext, err := bsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn false, err\n\t\t}\n\t\tmatched, err := pred(next)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tif !matched {\n\t\t\tresult = false\n\t\t\tbreak\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc (bsi *BaseStreamImpl) NoneMatch(pred Predicate) (bool, error) {\n\treturn bsi.AllMatch(func(o interface{}) (bool, error) {\n\t\tval, err := pred(o)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\treturn !val, nil\n\t})\n}\n\nfunc (bsi *BaseStreamImpl) Count() (int64, error) {\n\tvar result int64 = 0\n\tfor {\n\t\t_, err := bsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tresult++\n\t}\n\treturn result, nil\n}\n\nfunc (bsi *BaseStreamImpl) ForEach(c Consumer) error {\n\tvar err error\n\tvar next interface{}\n\tif !bsi.parallel {\n\t\tfor {\n\t\t\tnext, err = bsi.iterator.Next()\n\t\t\tif err != nil {\n\t\t\t\tif err.Error() == EndOfStream {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := c(next); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// This is a parallel path\n\t\tpool := threads.NewWorkerPool(runtime.NumCPU(), 10000)\n\t\tcounter := &Counter{}\n\t\tdefer pool.Shutdown()\n\t\tpool.Start()\n\n\t\tvar wg sync.WaitGroup\n\t\terrChan := make(chan error, runtime.NumCPU()+1)\n\t\terrHandler := func(err error) {\n\t\t\terrChan <- err\n\t\t}\n\t\tfor {\n\t\t\tnext, err = bsi.iterator.Next()\n\t\t\tif err != nil {\n\t\t\t\tif err.Error() == EndOfStream {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcounter.Inc()\n\t\t\twg.Add(1)\n\t\t\tmynext := next\n\t\t\tpool.Execute(func() {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tdefer counter.Dec()\n\t\t\t\terr := c(mynext)\n\t\t\t\tif err != nil {\n\t\t\t\t\terrHandler(err)\n\t\t\t\t}\n\t\t\t})\n\t\t\tselect {\n\t\t\tcase err := <-errChan:\n\t\t\t\treturn err\n\t\t\tdefault:\n\t\t\t\t// normal\n\t\t\t}\n\n\t\t}\n\t\tfor counter.Value() > 0 {\n\t\t\tselect {\n\t\t\tcase err := <-errChan:\n\t\t\t\treturn err\n\t\t\tdefault:\n\t\t\t\t//\twaiting for WaitGroup draining\n\t\t\t}\n\t\t}\n\t\twg.Wait()\n\t\tclose(errChan)\n\t\terr, ok := <-errChan\n\t\tif ok {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (bsi *BaseStreamImpl) ForEachOrdered(c Consumer) error {\n\treturn bsi.ForEach(c)\n}\n\nfunc (bsi *BaseStreamImpl) FindFirst() (interface{}, error) {\n\tnext, err := bsi.iterator.Next()\n\tif err != nil {\n\t\tif err.Error() == EndOfStream {\n\t\t\treturn nil, fmt.Errorf(\"Empty stream\")\n\t\t}\n\t}\n\treturn next, err\n}\n\nfunc (bsi *BaseStreamImpl) Min(cmp func(interface{}, interface{}) int) (interface{}, error) {\n\tvar result interface{}\n\tfoundAny := false\n\tfor {\n\t\tnext, err := bsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tif !foundAny {\n\t\t\tresult = next\n\t\t\tfoundAny = true\n\t\t} else {\n\t\t\tif cmp(next, result) < 0 {\n\t\t\t\tresult = next\n\t\t\t}\n\t\t}\n\t}\n\tif !foundAny {\n\t\treturn nil, fmt.Errorf(\"No element in stream\")\n\t}\n\treturn result, nil\n}\n\nfunc (bsi *BaseStreamImpl) Max(cmp func(interface{}, interface{}) int) (interface{}, error) {\n\treturn bsi.Min(func(o1, o2 interface{}) int {\n\t\treturn -cmp(o1, o2)\n\t})\n}\n\nfunc (bsi *BaseStreamImpl) Close() error {\n\t// Guaranteed not to error, but return last error\n\tvar lastError error\n\tfor i := 0; i < len(bsi.closeHandlers); i++ {\n\t\thandler := bsi.closeHandlers[i]\n\t\tif handler != nil {\n\t\t\terr := handler()\n\t\t\tif err != nil {\n\t\t\t\tlastError = err\n\t\t\t}\n\t\t}\n\t}\n\treturn lastError\n}\n\nfunc (bsi *BaseStreamImpl) OnClose(closeHandler func() error) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      bsi.iterator,\n\t\t\tcloseHandlers: append(bsi.closeHandlers, closeHandler),\n\t\t\tparallel:      bsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) ReduceWithIdentity(identity interface{}, accumulator BinaryOperator) (interface{}, error) {\n\tresult := identity\n\tvar err error\n\tfor {\n\t\tnextitem, err := bsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tresult, err = accumulator(result, nextitem)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc (bsi *BaseStreamImpl) Reduce(accumulator BinaryOperator) (interface{}, error) {\n\tvar result interface{}\n\temptyStream := true\n\tfor {\n\t\tnext, err := bsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tif emptyStream {\n\t\t\tresult = next\n\t\t\temptyStream = false\n\t\t\tcontinue\n\t\t}\n\t\tresult, err = accumulator(result, next)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif emptyStream {\n\t\treturn nil, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn result, nil\n}\n\nfunc (bsi *BaseStreamImpl) ParallelStream() Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      bsi.iterator,\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      true,\n\t\t},\n\t}\n}\n\nfunc (bsi *BaseStreamImpl) SequentialStream() Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      bsi.iterator,\n\t\t\tcloseHandlers: bsi.closeHandlers,\n\t\t\tparallel:      false,\n\t\t},\n\t}\n}\n\ntype StreamImpl struct {\n\tBaseStreamImpl\n}\n\nvar _ Stream = (*StreamImpl)(nil)\n\ntype DoubleStreamImpl struct {\n\tBaseStreamImpl\n}\n\ntype IntStreamImpl struct {\n\tBaseStreamImpl\n}\n\nvar _ IntStream = (*IntStreamImpl)(nil)\n\nvar _ DoubleStream = (*DoubleStreamImpl)(nil)\n\ntype MappingIterator struct {\n\tmapper Function\n\tsource Iterator\n}\n\nvar _ Iterator = (*MappingIterator)(nil)\n\nfunc (mi *MappingIterator) Next() (interface{}, error) {\n\tnext, err := mi.source.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn mi.mapper(next)\n}\n\ntype PMappingIterator struct {\n\tmapper  Function\n\tsource  Iterator\n\tthreads int\n}\n\ntype PMappingBuffer struct {\n\tData      []interface{}\n\tLock      sync.Mutex\n\tAvailable int64\n\tError     error\n\tSignal    *sync.Cond\n\tMaxLen    int\n}\n\nfunc NewPMappingBuffer(max int) *PMappingBuffer {\n\tresult := &PMappingBuffer{\n\t\tData:      make([]interface{}, max),\n\t\tAvailable: 0,\n\t\tMaxLen:    max,\n\t}\n\tresult.Signal = sync.NewCond(&result.Lock)\n\treturn result\n}\nfunc (pmb *PMappingBuffer) Put(idx int, data interface{}) {\n\tpmb.Lock.Lock()\n\tdefer pmb.Lock.Unlock()\n\tpmb.Data[idx] = data\n\tatomic.AddInt64(&pmb.Available, 1)\n\tpmb.Signal.Broadcast()\n}\n\nfunc (pmb *PMappingBuffer) Get(idx int) interface{} {\n\tfor atomic.LoadInt64(&pmb.Available) <= int64(idx) {\n\t\truntime.Gosched()\n\t}\n\n\tpmb.Lock.Lock()\n\tdefer pmb.Lock.Unlock()\n\treturn pmb.Data[idx]\n}\n\nvar _ Iterator = (*PMappingIterator)(nil)\n\nfunc (mi *PMappingIterator) Next() (interface{}, error) {\n\tsources := make([]interface{}, mi.threads)\n\tresult := make([]interface{}, mi.threads)\n\terrors := make([]error, mi.threads)\n\twg := sync.WaitGroup{}\n\tfound := 0\n\tfor i := 0; i < mi.threads; i++ {\n\t\tnext, err := mi.source.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tsources[found] = next\n\t\tfound++\n\t\tif found == mi.threads {\n\t\t\tbreak\n\t\t}\n\t}\n\tif found == 0 {\n\t\treturn nil, fmt.Errorf(\"%s\", EndOfStream)\n\t}\n\tthreadsMappingIteratorMu.Lock()\n\tthreadsMappingIterator += found\n\tthreadsMappingIteratorMu.Unlock()\n\n\tfor i := 0; i < found; i++ {\n\t\twg.Add(1)\n\t\tgo func(input interface{}, idx int) {\n\t\t\tdefer wg.Done()\n\t\t\toutput, err := mi.mapper(input)\n\t\t\tif err != nil {\n\t\t\t\terrors[idx] = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tresult[idx] = output\n\t\t}(sources[i], i)\n\t}\n\twg.Wait()\n\tfor i := 0; i < found; i++ {\n\t\tif errors[i] != nil {\n\t\t\treturn nil, errors[i]\n\t\t}\n\t}\n\tif found == 1 {\n\t\treturn result[0], nil\n\t}\n\tremainder := make([]interface{}, found-1)\n\tcopy(remainder, result[1:found])\n\tremainderBuffer = append(remainderBuffer, remainder...)\n\treturn result[0], nil\n}\n\nvar remainderBuffer []interface{}\nvar threadsMappingIterator int64\nvar threadsMappingIteratorMu sync.Mutex\n\ntype MapWithErrorIterator struct {\n\tsource Iterator\n}\n\nvar _ Iterator = (*MapWithErrorIterator)(nil)\n\nfunc (mi *MapWithErrorIterator) Next() (interface{}, error) {\n\tif len(remainderBuffer) > 0 {\n\t\tnext := remainderBuffer[0]\n\t\tremainderBuffer = remainderBuffer[1:]\n\t\treturn next, nil\n\t}\n\n\treturn mi.source.Next()\n}\n\ntype FlatMapIterator struct {\n\tsource         Iterator\n\tmapper         Function\n\tbufferedValues []interface{}\n\tbufPos         int\n}\n\nvar _ Iterator = (*FlatMapIterator)(nil)\n\nfunc (fmi *FlatMapIterator) Next() (interface{}, error) {\n\tif fmi.bufferedValues != nil && fmi.bufPos < len(fmi.bufferedValues) {\n\t\t// We have more elements in our buffer\n\t\tresult := fmi.bufferedValues[fmi.bufPos]\n\t\tfmi.bufPos++\n\t\tif fmi.bufPos >= len(fmi.bufferedValues) {\n\t\t\tfmi.bufferedValues = nil\n\t\t\tfmi.bufPos = 0\n\t\t}\n\t\treturn result, nil\n\t}\n\n\tnextInput, err := fmi.source.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmapped, err := fmi.mapper(nextInput)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Handle slice return values specially\n\tswitch result := mapped.(type) {\n\tcase []interface{}:\n\t\tif len(result) == 0 {\n\t\t\treturn nil, fmt.Errorf(\"%s\", EndOfStream)\n\t\t}\n\t\tif len(result) == 1 {\n\t\t\treturn result[0], nil\n\t\t}\n\t\tfmi.bufferedValues = result[1:]\n\t\tfmi.bufPos = 0\n\t\treturn result[0], nil\n\tcase nil:\n\t\treturn nil, fmt.Errorf(\"%s\", EndOfStream)\n\tdefault:\n\t\treturn result, nil\n\t}\n}\n\ntype FilteringIterator struct {\n\tsource Iterator\n\tpred   Predicate\n}\n\nvar _ Iterator = (*FilteringIterator)(nil)\n\nfunc (fi *FilteringIterator) Next() (interface{}, error) {\n\tfor {\n\t\tnext, err := fi.source.Next()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tmatched, err := fi.pred(next)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif matched {\n\t\t\treturn next, nil\n\t\t}\n\t}\n}\n\ntype PFilteringIterator struct {\n\tsource  Iterator\n\tpred    Predicate\n\tthreads int\n}\n\ntype PFilterWorker struct {\n\tSource    Iterator\n\tResult    []interface{}\n\tbuffer    int\n\tErrors    []error\n\tPredicate Predicate\n\tthreads   int\n}\n\nfunc NewPFilterWorker(source Iterator, pred Predicate, threads int) *PFilterWorker {\n\treturn &PFilterWorker{\n\t\tSource:    source,\n\t\tPredicate: pred,\n\t\tthreads:   threads,\n\t\tbuffer:    threads * 10,\n\t\tResult:    make([]interface{}, 0),\n\t\tErrors:    make([]error, 0),\n\t}\n}\n\nfunc (pf *PFilterWorker) FillBuffers() (int, error) {\n\tdata := make([]interface{}, pf.buffer)\n\tcount := 0\n\tfor i := 0; i < pf.buffer; i++ {\n\t\tnext, err := pf.Source.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tpf.Errors = append(pf.Errors, err)\n\t\t\treturn count, err\n\t\t}\n\t\tdata[count] = next\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\treturn 0, nil\n\t}\n\twg := sync.WaitGroup{}\n\terrs := make([]error, count)\n\tmatched := make([]bool, count)\n\tfor i := 0; i < count; i++ {\n\t\twg.Add(1)\n\t\tgo func(idx int) {\n\t\t\tdefer wg.Done()\n\t\t\tmatch, err := pf.Predicate(data[idx])\n\t\t\tif err != nil {\n\t\t\t\terrs[idx] = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tmatched[idx] = match\n\t\t}(i)\n\t}\n\twg.Wait()\n\tresult := make([]interface{}, 0)\n\thasError := false\n\tvar firstError error\n\tfor i := 0; i < count; i++ {\n\t\tif errs[i] != nil {\n\t\t\thasError = true\n\t\t\tfirstError = errs[i]\n\t\t\tbreak\n\t\t}\n\t}\n\tif hasError {\n\t\tpf.Errors = append(pf.Errors, firstError)\n\t\treturn 0, firstError\n\t}\n\tfor i := 0; i < count; i++ {\n\t\tif matched[i] {\n\t\t\tresult = append(result, data[i])\n\t\t}\n\t}\n\tpf.Result = append(pf.Result, result...)\n\treturn count, nil\n}\n\nvar _ Iterator = (*PFilteringIterator)(nil)\n\nfunc (fi *PFilteringIterator) Next() (interface{}, error) {\n\tworker := NewPFilterWorker(fi.source, fi.pred, fi.threads)\n\tfor {\n\t\tmyresult := worker.Result\n\t\tif len(myresult) > 0 {\n\t\t\tresult := myresult[0]\n\t\t\tworker.Result = myresult[1:]\n\t\t\treturn result, nil\n\t\t}\n\n\t\tgotCount, err := worker.FillBuffers()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif gotCount == 0 {\n\t\t\treturn nil, fmt.Errorf(\"%s\", EndOfStream)\n\t\t}\n\t}\n}\n\ntype LimitingIterator struct {\n\tsource Iterator\n\tlimit  int64\n\tcount  int64\n}\n\nvar _ Iterator = (*LimitingIterator)(nil)\n\nfunc (li *LimitingIterator) Next() (interface{}, error) {\n\tif li.count >= li.limit {\n\t\treturn nil, fmt.Errorf(\"%s\", EndOfStream)\n\t}\n\tnext, err := li.source.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tli.count++\n\treturn next, nil\n}\n\ntype SkippingIterator struct {\n\tsource      Iterator\n\tskip        int64\n\talreadySkip bool\n}\n\nvar _ Iterator = (*SkippingIterator)(nil)\n\nfunc (si *SkippingIterator) Next() (interface{}, error) {\n\tif !si.alreadySkip {\n\t\tfor i := int64(0); i < si.skip; i++ {\n\t\t\t_, err := si.source.Next()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\tsi.alreadySkip = true\n\t}\n\treturn si.source.Next()\n}\n\ntype PeekingIterator struct {\n\tsource Iterator\n\tact    Consumer\n}\n\nvar _ Iterator = (*PeekingIterator)(nil)\n\nfunc (pi *PeekingIterator) Next() (interface{}, error) {\n\tnext, err := pi.source.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err := pi.act(next); err != nil {\n\t\treturn nil, err\n\t}\n\treturn next, nil\n}\n\ntype DistinctIterator struct {\n\tsource Iterator\n\tseen   map[interface{}]bool\n}\n\nvar _ Iterator = (*DistinctIterator)(nil)\n\nfunc (di *DistinctIterator) Next() (interface{}, error) {\n\tif di.seen == nil {\n\t\tdi.seen = make(map[interface{}]bool)\n\t}\n\tfor {\n\t\tnext, err := di.source.Next()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !di.seen[next] {\n\t\t\tdi.seen[next] = true\n\t\t\treturn next, nil\n\t\t}\n\t}\n}\n\ntype SortedIterator struct {\n\tsource Iterator\n\tless   func(left, right interface{}) bool\n\tsorted []interface{}\n\tpos    int\n}\n\nvar _ Iterator = (*SortedIterator)(nil)\n\nfunc (si *SortedIterator) Next() (interface{}, error) {\n\tif si.sorted == nil {\n\t\tsi.sorted = []interface{}{}\n\t\tfor {\n\t\t\tnext, err := si.source.Next()\n\t\t\tif err != nil {\n\t\t\t\tif err.Error() == EndOfStream {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tsi.sorted = append(si.sorted, next)\n\t\t}\n\t\tQuickSort(si.sorted, si.less)\n\t\tsi.pos = 0\n\t}\n\tif si.pos >= len(si.sorted) {\n\t\treturn nil, fmt.Errorf(\"%s\", EndOfStream)\n\t}\n\tresult := si.sorted[si.pos]\n\tsi.pos++\n\treturn result, nil\n}\n\ntype ObjToDoubleIterator struct {\n\tsource Iterator\n\tmapper ToDoubleFunction\n}\n\nvar _ Iterator = (*ObjToDoubleIterator)(nil)\n\nfunc (odi *ObjToDoubleIterator) Next() (interface{}, error) {\n\tnext, err := odi.source.Next()\n\tif err != nil {\n\t\treturn 0.0, err\n\t}\n\treturn odi.mapper(next)\n}\n\ntype ObjToIntIterator struct {\n\tsource Iterator\n\tmapper ToIntFunction\n}\n\nvar _ Iterator = (*ObjToIntIterator)(nil)\n\nfunc (odi *ObjToIntIterator) Next() (interface{}, error) {\n\tnext, err := odi.source.Next()\n\tif err != nil {\n\t\treturn int64(0), err\n\t}\n\treturn odi.mapper(next)\n}\n\ntype ConcatIterator struct {\n\tfirst  Iterator\n\tsecond func() (Iterator, error)\n\tdone1  bool\n}\n\nvar _ Iterator = (*ConcatIterator)(nil)\n\nfunc (ci *ConcatIterator) Next() (interface{}, error) {\n\tif !ci.done1 {\n\t\tnext, err := ci.first.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tci.done1 = true\n\t\t\t} else {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t} else {\n\t\t\treturn next, nil\n\t\t}\n\t}\n\n\t// First iterator exhausted, move to second\n\tsecond, err := ci.second()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn second.Next()\n}\n\ntype Counter struct {\n\tvalue int64\n}\n\nfunc (c *Counter) Inc() {\n\tatomic.AddInt64(&c.value, 1)\n}\n\nfunc (c *Counter) Dec() {\n\tatomic.AddInt64(&c.value, -1)\n}\n\nfunc (c *Counter) Value() int64 {\n\treturn atomic.LoadInt64(&c.value)\n}\n\nfunc (isi *IntStreamImpl) Map(mapper IntUnaryOperator) IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &IntMappingIterator{source: isi.iterator, mapper: mapper},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) MapToObj(mapper IntFunction) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &IntToObjIterator{source: isi.iterator, mapper: mapper},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) MapToDouble(mapper IntToDoubleFunction) DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &IntToDoubleIterator{source: isi.iterator, mapper: mapper},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) Filter(pred IntPredicate) IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &IntFilteringIterator{source: isi.iterator, pred: pred},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) Skip(n int64) IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &SkippingIterator{source: isi.iterator, skip: n},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) Limit(max int64) IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &LimitingIterator{source: isi.iterator, limit: max},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) Peek(act IntConsumer) IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &IntPeekingIterator{source: isi.iterator, act: act},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) ForEach(act IntConsumer) error {\n\tfor {\n\t\tnext, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tif err := act(val); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\nfunc (isi *IntStreamImpl) Reduce(op IntBinaryOperator) (int64, error) {\n\tvar result int64\n\temptyStream := true\n\tfor {\n\t\tnext, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tif emptyStream {\n\t\t\tresult = val\n\t\t\temptyStream = false\n\t\t\tcontinue\n\t\t}\n\t\tresult, err = op(result, val)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif emptyStream {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn result, nil\n}\n\nfunc (isi *IntStreamImpl) ReduceWithIdentity(identity int64, op IntBinaryOperator) (int64, error) {\n\tresult := identity\n\tfor {\n\t\tnext, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tresult, err = op(result, val)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc (isi *IntStreamImpl) FindFirst() (int64, error) {\n\tnext, err := isi.iterator.Next()\n\tif err != nil {\n\t\tif err.Error() == EndOfStream {\n\t\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t\t}\n\t\treturn 0, err\n\t}\n\tval, ok := next.(int64)\n\tif !ok {\n\t\treturn 0, fmt.Errorf(\"Expected int64, got %T\", next)\n\t}\n\treturn val, nil\n}\n\nfunc (isi *IntStreamImpl) Sum() (int64, error) {\n\tvar sum int64 = 0\n\tfor {\n\t\tnext, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tsum += val\n\t}\n\treturn sum, nil\n}\n\nfunc (isi *IntStreamImpl) Min() (int64, error) {\n\tvar min int64\n\temptyStream := true\n\tfor {\n\t\tnext, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tif emptyStream {\n\t\t\tmin = val\n\t\t\temptyStream = false\n\t\t\tcontinue\n\t\t}\n\t\tif val < min {\n\t\t\tmin = val\n\t\t}\n\t}\n\tif emptyStream {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn min, nil\n}\n\nfunc (isi *IntStreamImpl) Max() (int64, error) {\n\tvar max int64\n\temptyStream := true\n\tfor {\n\t\tnext, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tif emptyStream {\n\t\t\tmax = val\n\t\t\temptyStream = false\n\t\t\tcontinue\n\t\t}\n\t\tif val > max {\n\t\t\tmax = val\n\t\t}\n\t}\n\tif emptyStream {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn max, nil\n}\n\nfunc (isi *IntStreamImpl) Count() (int64, error) {\n\tvar count int64 = 0\n\tfor {\n\t\t_, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tcount++\n\t}\n\treturn count, nil\n}\n\nfunc (isi *IntStreamImpl) Average() (float64, error) {\n\tvar sum int64 = 0\n\tvar count int64 = 0\n\tfor {\n\t\tnext, err := isi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tsum += val\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn float64(sum) / float64(count), nil\n}\n\nfunc (isi *IntStreamImpl) BoxedStream() Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      isi.iterator,\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (isi *IntStreamImpl) Sorted() IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &IntSortedIterator{source: isi.iterator},\n\t\t\tcloseHandlers: isi.closeHandlers,\n\t\t\tparallel:      isi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) Map(mapper func(float64) (float64, error)) DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &DoubleMappingIterator{source: dsi.iterator, mapper: mapper},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) MapToInt(mapper DoubleToIntFunction) IntStream {\n\treturn &IntStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &DoubleToIntIterator{source: dsi.iterator, mapper: mapper},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) MapToObj(mapper func(float64) (interface{}, error)) Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &DoubleToObjIterator{source: dsi.iterator, mapper: mapper},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) Filter(pred DoublePredicate) DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &DoubleFilteringIterator{source: dsi.iterator, pred: pred},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) Skip(n int64) DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &SkippingIterator{source: dsi.iterator, skip: n},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) Limit(max int64) DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &LimitingIterator{source: dsi.iterator, limit: max},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) Peek(act DoubleConsumer) DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &DoublePeekingIterator{source: dsi.iterator, act: act},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) ForEach(act DoubleConsumer) error {\n\tfor {\n\t\tnext, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tif err := act(val); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) Reduce(op func(float64, float64) (float64, error)) (float64, error) {\n\tvar result float64\n\temptyStream := true\n\tfor {\n\t\tnext, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tif emptyStream {\n\t\t\tresult = val\n\t\t\temptyStream = false\n\t\t\tcontinue\n\t\t}\n\t\tresult, err = op(result, val)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif emptyStream {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn result, nil\n}\n\nfunc (dsi *DoubleStreamImpl) ReduceWithIdentity(identity float64, op func(float64, float64) (float64, error)) (float64, error) {\n\tresult := identity\n\tfor {\n\t\tnext, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tresult, err = op(result, val)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\treturn result, nil\n}\n\nfunc (dsi *DoubleStreamImpl) FindFirst() (float64, error) {\n\tnext, err := dsi.iterator.Next()\n\tif err != nil {\n\t\tif err.Error() == EndOfStream {\n\t\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t\t}\n\t\treturn 0, err\n\t}\n\tval, ok := next.(float64)\n\tif !ok {\n\t\treturn 0, fmt.Errorf(\"Expected float64, got %T\", next)\n\t}\n\treturn val, nil\n}\n\nfunc (dsi *DoubleStreamImpl) Sum() (float64, error) {\n\tvar sum float64 = 0\n\tfor {\n\t\tnext, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tsum += val\n\t}\n\treturn sum, nil\n}\n\nfunc (dsi *DoubleStreamImpl) Min() (float64, error) {\n\tvar min float64\n\temptyStream := true\n\tfor {\n\t\tnext, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tif emptyStream {\n\t\t\tmin = val\n\t\t\temptyStream = false\n\t\t\tcontinue\n\t\t}\n\t\tif val < min {\n\t\t\tmin = val\n\t\t}\n\t}\n\tif emptyStream {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn min, nil\n}\n\nfunc (dsi *DoubleStreamImpl) Max() (float64, error) {\n\tvar max float64\n\temptyStream := true\n\tfor {\n\t\tnext, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tif emptyStream {\n\t\t\tmax = val\n\t\t\temptyStream = false\n\t\t\tcontinue\n\t\t}\n\t\tif val > max {\n\t\t\tmax = val\n\t\t}\n\t}\n\tif emptyStream {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn max, nil\n}\n\nfunc (dsi *DoubleStreamImpl) Count() (int64, error) {\n\tvar count int64 = 0\n\tfor {\n\t\t_, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tcount++\n\t}\n\treturn count, nil\n}\n\nfunc (dsi *DoubleStreamImpl) Average() (float64, error) {\n\tvar sum float64 = 0\n\tvar count int64 = 0\n\tfor {\n\t\tnext, err := dsi.iterator.Next()\n\t\tif err != nil {\n\t\t\tif err.Error() == EndOfStream {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn 0, err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn 0, fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tsum += val\n\t\tcount++\n\t}\n\tif count == 0 {\n\t\treturn 0, fmt.Errorf(\"Empty stream\")\n\t}\n\treturn sum / float64(count), nil\n}\n\nfunc (dsi *DoubleStreamImpl) Sorted() DoubleStream {\n\treturn &DoubleStreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      &DoubleSortedIterator{source: dsi.iterator},\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\nfunc (dsi *DoubleStreamImpl) BoxedStream() Stream {\n\treturn &StreamImpl{\n\t\tBaseStreamImpl: BaseStreamImpl{\n\t\t\titerator:      dsi.iterator,\n\t\t\tcloseHandlers: dsi.closeHandlers,\n\t\t\tparallel:      dsi.parallel,\n\t\t},\n\t}\n}\n\ntype IntMappingIterator struct {\n\tsource Iterator\n\tmapper IntUnaryOperator\n}\n\nvar _ Iterator = (*IntMappingIterator)(nil)\n\nfunc (imi *IntMappingIterator) Next() (interface{}, error) {\n\tnext, err := imi.source.Next()\n\tif err != nil {\n\t\treturn int64(0), err\n\t}\n\tval, ok := next.(int64)\n\tif !ok {\n\t\treturn int64(0), fmt.Errorf(\"Expected int64, got %T\", next)\n\t}\n\treturn imi.mapper(val)\n}\n\ntype IntToObjIterator struct {\n\tsource Iterator\n\tmapper IntFunction\n}\n\nvar _ Iterator = (*IntToObjIterator)(nil)\n\nfunc (itoi *IntToObjIterator) Next() (interface{}, error) {\n\tnext, err := itoi.source.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tval, ok := next.(int64)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"Expected int64, got %T\", next)\n\t}\n\treturn itoi.mapper(val)\n}\n\ntype IntToDoubleIterator struct {\n\tsource Iterator\n\tmapper IntToDoubleFunction\n}\n\nvar _ Iterator = (*IntToDoubleIterator)(nil)\n\nfunc (itdi *IntToDoubleIterator) Next() (interface{}, error) {\n\tnext, err := itdi.source.Next()\n\tif err != nil {\n\t\treturn float64(0), err\n\t}\n\tval, ok := next.(int64)\n\tif !ok {\n\t\treturn float64(0), fmt.Errorf(\"Expected int64, got %T\", next)\n\t}\n\treturn itdi.mapper(val)\n}\n\ntype IntFilteringIterator struct {\n\tsource Iterator\n\tpred   IntPredicate\n}\n\nvar _ Iterator = (*IntFilteringIterator)(nil)\n\nfunc (ifi *IntFilteringIterator) Next() (interface{}, error) {\n\tfor {\n\t\tnext, err := ifi.source.Next()\n\t\tif err != nil {\n\t\t\treturn int64(0), err\n\t\t}\n\t\tval, ok := next.(int64)\n\t\tif !ok {\n\t\t\treturn int64(0), fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t}\n\t\tmatched, err := ifi.pred(val)\n\t\tif err != nil {\n\t\t\treturn int64(0), err\n\t\t}\n\t\tif matched {\n\t\t\treturn val, nil\n\t\t}\n\t}\n}\n\ntype IntPeekingIterator struct {\n\tsource Iterator\n\tact    IntConsumer\n}\n\nvar _ Iterator = (*IntPeekingIterator)(nil)\n\nfunc (ipi *IntPeekingIterator) Next() (interface{}, error) {\n\tnext, err := ipi.source.Next()\n\tif err != nil {\n\t\treturn int64(0), err\n\t}\n\tval, ok := next.(int64)\n\tif !ok {\n\t\treturn int64(0), fmt.Errorf(\"Expected int64, got %T\", next)\n\t}\n\tif err := ipi.act(val); err != nil {\n\t\treturn int64(0), err\n\t}\n\treturn val, nil\n}\n\ntype IntSortedIterator struct {\n\tsource Iterator\n\tsorted []int64\n\tpos    int\n}\n\nvar _ Iterator = (*IntSortedIterator)(nil)\n\nfunc (isi *IntSortedIterator) Next() (interface{}, error) {\n\tif isi.sorted == nil {\n\t\tisi.sorted = []int64{}\n\t\tfor {\n\t\t\tnext, err := isi.source.Next()\n\t\t\tif err != nil {\n\t\t\t\tif err.Error() == EndOfStream {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treturn int64(0), err\n\t\t\t}\n\t\t\tval, ok := next.(int64)\n\t\t\tif !ok {\n\t\t\t\treturn int64(0), fmt.Errorf(\"Expected int64, got %T\", next)\n\t\t\t}\n\t\t\tisi.sorted = append(isi.sorted, val)\n\t\t}\n\t\tIntQuickSort(isi.sorted, func(a, b int64) bool { return a < b })\n\t\tisi.pos = 0\n\t}\n\tif isi.pos >= len(isi.sorted) {\n\t\treturn int64(0), fmt.Errorf(\"%s\", EndOfStream)\n\t}\n\tresult := isi.sorted[isi.pos]\n\tisi.pos++\n\treturn result, nil\n}\n\ntype DoubleMappingIterator struct {\n\tsource Iterator\n\tmapper func(float64) (float64, error)\n}\n\nvar _ Iterator = (*DoubleMappingIterator)(nil)\n\nfunc (dmi *DoubleMappingIterator) Next() (interface{}, error) {\n\tnext, err := dmi.source.Next()\n\tif err != nil {\n\t\treturn float64(0), err\n\t}\n\tval, ok := next.(float64)\n\tif !ok {\n\t\treturn float64(0), fmt.Errorf(\"Expected float64, got %T\", next)\n\t}\n\treturn dmi.mapper(val)\n}\n\ntype DoubleToIntIterator struct {\n\tsource Iterator\n\tmapper DoubleToIntFunction\n}\n\nvar _ Iterator = (*DoubleToIntIterator)(nil)\n\nfunc (dtii *DoubleToIntIterator) Next() (interface{}, error) {\n\tnext, err := dtii.source.Next()\n\tif err != nil {\n\t\treturn int64(0), err\n\t}\n\tval, ok := next.(float64)\n\tif !ok {\n\t\treturn int64(0), fmt.Errorf(\"Expected float64, got %T\", next)\n\t}\n\treturn dtii.mapper(val)\n}\n\ntype DoubleToObjIterator struct {\n\tsource Iterator\n\tmapper func(float64) (interface{}, error)\n}\n\nvar _ Iterator = (*DoubleToObjIterator)(nil)\n\nfunc (dtoi *DoubleToObjIterator) Next() (interface{}, error) {\n\tnext, err := dtoi.source.Next()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tval, ok := next.(float64)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"Expected float64, got %T\", next)\n\t}\n\treturn dtoi.mapper(val)\n}\n\ntype DoubleFilteringIterator struct {\n\tsource Iterator\n\tpred   DoublePredicate\n}\n\nvar _ Iterator = (*DoubleFilteringIterator)(nil)\n\nfunc (dfi *DoubleFilteringIterator) Next() (interface{}, error) {\n\tfor {\n\t\tnext, err := dfi.source.Next()\n\t\tif err != nil {\n\t\t\treturn float64(0), err\n\t\t}\n\t\tval, ok := next.(float64)\n\t\tif !ok {\n\t\t\treturn float64(0), fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t}\n\t\tmatched, err := dfi.pred(val)\n\t\tif err != nil {\n\t\t\treturn float64(0), err\n\t\t}\n\t\tif matched {\n\t\t\treturn val, nil\n\t\t}\n\t}\n}\n\ntype DoublePeekingIterator struct {\n\tsource Iterator\n\tact    DoubleConsumer\n}\n\nvar _ Iterator = (*DoublePeekingIterator)(nil)\n\nfunc (dpi *DoublePeekingIterator) Next() (interface{}, error) {\n\tnext, err := dpi.source.Next()\n\tif err != nil {\n\t\treturn float64(0), err\n\t}\n\tval, ok := next.(float64)\n\tif !ok {\n\t\treturn float64(0), fmt.Errorf(\"Expected float64, got %T\", next)\n\t}\n\tif err := dpi.act(val); err != nil {\n\t\treturn float64(0), err\n\t}\n\treturn val, nil\n}\n\ntype DoubleSortedIterator struct {\n\tsource Iterator\n\tsorted []float64\n\tpos    int\n}\n\nvar _ Iterator = (*DoubleSortedIterator)(nil)\n\nfunc (dsi *DoubleSortedIterator) Next() (interface{}, error) {\n\tif dsi.sorted == nil {\n\t\tdsi.sorted = []float64{}\n\t\tfor {\n\t\t\tnext, err := dsi.source.Next()\n\t\t\tif err != nil {\n\t\t\t\tif err.Error() == EndOfStream {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\treturn float64(0), err\n\t\t\t}\n\t\t\tval, ok := next.(float64)\n\t\t\tif !ok {\n\t\t\t\treturn float64(0), fmt.Errorf(\"Expected float64, got %T\", next)\n\t\t\t}\n\t\t\tdsi.sorted = append(dsi.sorted, val)\n\t\t}\n\t\tDoubleQuickSort(dsi.sorted, func(a, b float64) bool { return a < b })\n\t\tdsi.pos = 0\n\t}\n\tif dsi.pos >= len(dsi.sorted) {\n\t\treturn float64(0), fmt.Errorf(\"%s\", EndOfStream)\n\t}\n\tresult := dsi.sorted[dsi.pos]\n\tdsi.pos++\n\treturn result, nil\n}\n\u0005End File\u0006# isgasho/go-kit-1\n# go-stream/collector.go\npackage stream\n\nfunc ToList() Collector {\n\treturn &ListCollector{}\n}\n\nfunc Grouping(keyMapper Function) Collector {\n\treturn &GroupByCollector{keyMapper: keyMapper}\n}\n\nfunc GroupingBy(keyMapper Function) Collector {\n\treturn Grouping(keyMapper)\n}\n\nfunc ToStringList() Collector {\n\treturn &StringListCollector{}\n}\n\nfunc ToIntList() Collector {\n\treturn &IntListCollector{}\n}\n\nfunc ToDoubleList() Collector {\n\treturn &DoubleListCollector{}\n}\n\nfunc ToSet() Collector {\n\treturn &SetCollector{}\n}\n\nfunc ToStringSet() Collector {\n\treturn &StringSetCollector{}\n}\n\nfunc ToIntSet() Collector {\n\treturn &IntSetCollector{}\n}\n\nfunc ToDoubleSet() Collector {\n\treturn &DoubleSetCollector{}\n}\n\nfunc ToMap(keyMapper Function, valueMapper Function) Collector {\n\treturn &MapCollector{keyMapper: keyMapper, valueMapper: valueMapper}\n}\n\nfunc Joining(delimiter string) Collector {\n\treturn &JoiningCollector{delimiter: delimiter}\n}\n\nfunc Averaging() Collector {\n\treturn &AveragingCollector{}\n}\n\nfunc Counting() Collector {\n\treturn &CountingCollector{}\n}\n\nfunc Summing() Collector {\n\treturn &SummingCollector{}\n}\n\ntype ListCollector struct{}\n\nvar _ Collector = (*ListCollector)(nil)\n\nfunc (lc *ListCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make([]interface{}, 0), nil\n\t}\n}\n\nfunc (lc *ListCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tlist := result.([]interface{})\n\t\treturn returnValue(&result, append(list, item))\n\t}\n}\n\nfunc (lc *ListCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\ntype GroupByCollector struct {\n\tkeyMapper Function\n}\n\nvar _ Collector = (*GroupByCollector)(nil)\n\nfunc (gbc *GroupByCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make(map[interface{}][]interface{}), nil\n\t}\n}\n\nfunc (gbc *GroupByCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tm := result.(map[interface{}][]interface{})\n\t\tkey, err := gbc.keyMapper(item)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm[key] = append(m[key], item)\n\t\treturn nil\n\t}\n}\n\nfunc (gbc *GroupByCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\ntype StringListCollector struct{}\n\nvar _ Collector = (*StringListCollector)(nil)\n\nfunc (slc *StringListCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make([]string, 0), nil\n\t}\n}\n\nfunc (slc *StringListCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tlist := result.([]string)\n\t\ts, ok := item.(string)\n\t\tif !ok {\n\t\t\treturn returnValue(&result, append(list, convertToString(item)))\n\t\t}\n\t\treturn returnValue(&result, append(list, s))\n\t}\n}\n\nfunc (slc *StringListCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\ntype IntListCollector struct{}\n\nvar _ Collector = (*IntListCollector)(nil)\n\nfunc (ilc *IntListCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make([]int64, 0), nil\n\t}\n}\n\nfunc (ilc *IntListCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tlist := result.([]int64)\n\t\ti, ok := item.(int64)\n\t\tif !ok {\n\t\t\treturn returnValue(&result, append(list, convertToInt64(item)))\n\t\t}\n\t\treturn returnValue(&result, append(list, i))\n\t}\n}\n\nfunc (ilc *IntListCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\ntype DoubleListCollector struct{}\n\nvar _ Collector = (*DoubleListCollector)(nil)\n\nfunc (dlc *DoubleListCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make([]float64, 0), nil\n\t}\n}\n\nfunc (dlc *DoubleListCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tlist := result.([]float64)\n\t\td, ok := item.(float64)\n\t\tif !ok {\n\t\t\treturn returnValue(&result, append(list, convertToFloat64(item)))\n\t\t}\n\t\treturn returnValue(&result, append(list, d))\n\t}\n}\n\nfunc (dlc *DoubleListCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\ntype SetCollector struct{}\n\nvar _ Collector = (*SetCollector)(nil)\n\nfunc (sc *SetCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make(map[interface{}]bool), nil\n\t}\n}\n\nfunc (sc *SetCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tset := result.(map[interface{}]bool)\n\t\tset[item] = true\n\t\treturn nil\n\t}\n}\n\nfunc (sc *SetCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\tset := result.(map[interface{}]bool)\n\t\tkeys := make([]interface{}, 0, len(set))\n\t\tfor k := range set {\n\t\t\tkeys = append(keys, k)\n\t\t}\n\t\treturn keys, nil\n\t}\n}\n\ntype StringSetCollector struct{}\n\nvar _ Collector = (*StringSetCollector)(nil)\n\nfunc (ssc *StringSetCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make(map[string]bool), nil\n\t}\n}\n\nfunc (ssc *StringSetCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tset := result.(map[string]bool)\n\t\ts, ok := item.(string)\n\t\tif !ok {\n\t\t\tset[convertToString(item)] = true\n\t\t} else {\n\t\t\tset[s] = true\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc (ssc *StringSetCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\tset := result.(map[string]bool)\n\t\tkeys := make([]string, 0, len(set))\n\t\tfor k := range set {\n\t\t\tkeys = append(keys, k)\n\t\t}\n\t\treturn keys, nil\n\t}\n}\n\ntype IntSetCollector struct{}\n\nvar _ Collector = (*IntSetCollector)(nil)\n\nfunc (isc *IntSetCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make(map[int64]bool), nil\n\t}\n}\n\nfunc (isc *IntSetCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tset := result.(map[int64]bool)\n\t\ti, ok := item.(int64)\n\t\tif !ok {\n\t\t\tset[convertToInt64(item)] = true\n\t\t} else {\n\t\t\tset[i] = true\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc (isc *IntSetCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\tset := result.(map[int64]bool)\n\t\tkeys := make([]int64, 0, len(set))\n\t\tfor k := range set {\n\t\t\tkeys = append(keys, k)\n\t\t}\n\t\treturn keys, nil\n\t}\n}\n\ntype DoubleSetCollector struct{}\n\nvar _ Collector = (*DoubleSetCollector)(nil)\n\nfunc (dsc *DoubleSetCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make(map[float64]bool), nil\n\t}\n}\n\nfunc (dsc *DoubleSetCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tset := result.(map[float64]bool)\n\t\td, ok := item.(float64)\n\t\tif !ok {\n\t\t\tset[convertToFloat64(item)] = true\n\t\t} else {\n\t\t\tset[d] = true\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc (dsc *DoubleSetCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\tset := result.(map[float64]bool)\n\t\tkeys := make([]float64, 0, len(set))\n\t\tfor k := range set {\n\t\t\tkeys = append(keys, k)\n\t\t}\n\t\treturn keys, nil\n\t}\n}\n\ntype MapCollector struct {\n\tkeyMapper   Function\n\tvalueMapper Function\n}\n\nvar _ Collector = (*MapCollector)(nil)\n\nfunc (mc *MapCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make(map[interface{}]interface{}), nil\n\t}\n}\n\nfunc (mc *MapCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tm := result.(map[interface{}]interface{})\n\t\tkey, err := mc.keyMapper(item)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tvalue, err := mc.valueMapper(item)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm[key] = value\n\t\treturn nil\n\t}\n}\n\nfunc (mc *MapCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\ntype JoiningCollector struct {\n\tdelimiter string\n}\n\nvar _ Collector = (*JoiningCollector)(nil)\n\nfunc (jc *JoiningCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn make([]string, 0), nil\n\t}\n}\n\nfunc (jc *JoiningCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tlist := result.([]string)\n\t\ts, ok := item.(string)\n\t\tif !ok {\n\t\t\treturn returnValue(&result, append(list, convertToString(item)))\n\t\t}\n\t\treturn returnValue(&result, append(list, s))\n\t}\n}\n\nfunc (jc *JoiningCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\tlist := result.([]string)\n\t\treturn joinStrings(list, jc.delimiter), nil\n\t}\n}\n\ntype AveragingCollector struct{}\n\nvar _ Collector = (*AveragingCollector)(nil)\n\nfunc (ac *AveragingCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn &struct {\n\t\t\tsum   float64\n\t\t\tcount int\n\t\t}{0, 0}, nil\n\t}\n}\n\nfunc (ac *AveragingCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tacc := result.(*struct {\n\t\t\tsum   float64\n\t\t\tcount int\n\t\t})\n\t\tacc.count++\n\t\tswitch v := item.(type) {\n\t\tcase int:\n\t\t\tacc.sum += float64(v)\n\t\tcase int8:\n\t\t\tacc.sum += float64(v)\n\t\tcase int16:\n\t\t\tacc.sum += float64(v)\n\t\tcase int32:\n\t\t\tacc.sum += float64(v)\n\t\tcase int64:\n\t\t\tacc.sum += float64(v)\n\t\tcase uint:\n\t\t\tacc.sum += float64(v)\n\t\tcase uint8:\n\t\t\tacc.sum += float64(v)\n\t\tcase uint16:\n\t\t\tacc.sum += float64(v)\n\t\tcase uint32:\n\t\t\tacc.sum += float64(v)\n\t\tcase uint64:\n\t\t\tacc.sum += float64(v)\n\t\tcase float32:\n\t\t\tacc.sum += float64(v)\n\t\tcase float64:\n\t\t\tacc.sum += v\n\t\tdefault:\n\t\t\td, ok := item.(float64)\n\t\t\tif !ok {\n\t\t\t\tacc.sum += convertToFloat64(item)\n\t\t\t} else {\n\t\t\t\tacc.sum += d\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc (ac *AveragingCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\tacc := result.(*struct {\n\t\t\tsum   float64\n\t\t\tcount int\n\t\t})\n\t\tif acc.count == 0 {\n\t\t\treturn float64(0), nil\n\t\t}\n\t\treturn acc.sum / float64(acc.count), nil\n\t}\n}\n\ntype CountingCollector struct{}\n\nvar _ Collector = (*CountingCollector)(nil)\n\nfunc (cc *CountingCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn int64(0), nil\n\t}\n}\n\nfunc (cc *CountingCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tcount := result.(int64)\n\t\treturn returnValue(&result, count+1)\n\t}\n}\n\nfunc (cc *CountingCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\ntype SummingCollector struct{}\n\nvar _ Collector = (*SummingCollector)(nil)\n\nfunc (sc *SummingCollector) Supplier() Supplier {\n\treturn func() (interface{}, error) {\n\t\treturn float64(0), nil\n\t}\n}\n\nfunc (sc *SummingCollector) Accumulator() BiConsumer {\n\treturn func(result interface{}, item interface{}) error {\n\t\tsum := result.(float64)\n\t\tswitch v := item.(type) {\n\t\tcase int:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase int8:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase int16:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase int32:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase int64:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase uint:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase uint8:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase uint16:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase uint32:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase uint64:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase float32:\n\t\t\treturn returnValue(&result, sum+float64(v))\n\t\tcase float64:\n\t\t\treturn returnValue(&result, sum+v)\n\t\tdefault:\n\t\t\td, ok := item.(float64)\n\t\t\tif !ok {\n\t\t\t\treturn returnValue(&result, sum+convertToFloat64(item))\n\t\t\t}\n\t\t\treturn returnValue(&result, sum+d)\n\t\t}\n\t}\n}\n\nfunc (sc *SummingCollector) Finisher() Function {\n\treturn func(result interface{}) (interface{}, error) {\n\t\treturn result, nil\n\t}\n}\n\u0005End File\u0006package threads\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n)\n\nvar MaxQueueSize = 1_000_000\n\n// Worker represents a worker that executes tasks\ntype Worker struct {\n\ttasks    chan func()\n\tquit     chan bool\n\tid       int\n\twg       *sync.WaitGroup\n\texecutor *WorkerPool\n}\n\n// WorkerPool is a collection of workers\ntype WorkerPool struct {\n\tworkers     []*Worker\n\tworkerCount int\n\ttasks       chan func()\n\tmaxQueue    int\n\tstarted     bool\n\tquit        chan bool\n\twg          sync.WaitGroup\n\tpending     int64\n}\n\n// NewWorkerPool creates a new worker pool with the given number of workers\nfunc NewWorkerPool(workerCount int, maxQueue int) *WorkerPool {\n\tif maxQueue > MaxQueueSize {\n\t\tmaxQueue = MaxQueueSize\n\t}\n\tif maxQueue < 10 {\n\t\tmaxQueue = 10\n\t}\n\treturn &WorkerPool{\n\t\tworkerCount: workerCount,\n\t\tmaxQueue:    maxQueue,\n\t\ttasks:       make(chan func(), maxQueue),\n\t\tquit:        make(chan bool),\n\t\tpending:     0,\n\t}\n}\n\n// Start starts all workers in the pool\nfunc (wp *WorkerPool) Start() {\n\tif wp.started {\n\t\treturn\n\t}\n\twp.started = true\n\twp.workers = make([]*Worker, wp.workerCount)\n\tfor i := 0; i < wp.workerCount; i++ {\n\t\tworker := &Worker{\n\t\t\ttasks:    wp.tasks,\n\t\t\tquit:     wp.quit,\n\t\t\tid:       i,\n\t\t\twg:       &wp.wg,\n\t\t\texecutor: wp,\n\t\t}\n\t\twp.workers[i] = worker\n\t\tgo worker.start()\n\t}\n}\n\n// Execute submits a task to the worker pool\nfunc (wp *WorkerPool) Execute(task func()) {\n\tif !wp.started {\n\t\tpanic(\"Worker pool not started\")\n\t}\n\tif len(wp.tasks) == wp.maxQueue {\n\t\tpanic(fmt.Sprintf(\"Task queue is full. Increase max queue size to prevent this. size=%d\", wp.maxQueue))\n\t}\n\twp.wg.Add(1)\n\tatomic.AddInt64(&wp.pending, 1)\n\twp.tasks <- func() {\n\t\tdefer wp.wg.Done()\n\t\tdefer atomic.AddInt64(&wp.pending, -1)\n\t\ttask()\n\t}\n}\n\n// Shutdown stops all workers in the pool\nfunc (wp *WorkerPool) Shutdown() {\n\tif !wp.started {\n\t\treturn\n\t}\n\tclose(wp.quit)\n\twp.wg.Wait()\n\twp.started = false\n}\n\n// WaitForPendingTasks waits for all pending tasks to complete\nfunc (wp *WorkerPool) WaitForPendingTasks() {\n\twp.wg.Wait()\n}\n\n// GetPendingTasks returns the number of pending tasks\nfunc (wp *WorkerPool) GetPendingTasks() int64 {\n\treturn atomic.LoadInt64(&wp.pending)\n}\n\n// Start starts the worker\nfunc (w *Worker) start() {\n\tfor {\n\t\tselect {\n\t\tcase task := <-w.tasks:\n\t\t\ttask()\n\t\tcase <-w.quit:\n\t\t\treturn\n\t\t}\n\t}\n}\n\u0005End File\u0006package main\n\nimport (\n\t\"fmt\"\n\t\"github.com/wushilin/go-stream\"\n\t\"math/rand\"\n\t\"runtime\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\t// Create a slice with one million random integers\n\tdata := generateRandomInts(1_000_000)\n\n\t// Sequential Stream Example\n\tsequentialTime := measureTime(\"Sequential Stream\", func() {\n\t\tresult, err := stream.OfSlice(data).\n\t\t\tFilter(func(i interface{}) (bool, error) {\n\t\t\t\tn := i.(int)\n\t\t\t\treturn n%2 == 0, nil\n\t\t\t}).\n\t\t\tMap(func(i interface{}) (interface{}, error) {\n\t\t\t\tn := i.(int)\n\t\t\t\treturn n * 2, nil\n\t\t\t}).\n\t\t\tFilter(func(i interface{}) (bool, error) {\n\t\t\t\tn := i.(int)\n\t\t\t\treturn n < 1000000, nil\n\t\t\t}).\n\t\t\tCollect(stream.ToList())\n\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error: %v\\n\", err)\n\t\t\treturn\n\t\t}\n\t\tfmt.Printf(\"Sequential result count: %d\\n\", len(result.([]interface{})))\n\t})\n\n\t// Parallel Stream Example with Filter\n\tparallelTime := measureTime(\"Parallel Stream with PFilter\", func() {\n\t\tresult, err := stream.OfSlice(data).\n\t\t\tPFilter(func(i interface{}) (bool, error) {\n\t\t\t\tn := i.(int)\n\t\t\t\treturn n%2 == 0, nil\n\t\t\t}, runtime.NumCPU()).\n\t\t\tPMap(func(i interface{}) (interface{}, error) {\n\t\t\t\tn := i.(int)\n\t\t\t\treturn n * 2, nil\n\t\t\t}, runtime.NumCPU()).\n\t\t\tPFilter(func(i interface{}) (bool, error) {\n\t\t\t\tn := i.(int)\n\t\t\t\treturn n < 1000000, nil\n\t\t\t}, runtime.NumCPU()).\n\t\t\tCollect(stream.ToList())\n\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error: %v\\n\", err)\n\t\t\treturn\n\t\t}\n\t\tfmt.Printf(\"Parallel result count: %d\\n\", len(result.([]interface{})))\n\t})\n\n\t// Custom parallel implementation without Go Stream\n\tmanualParallelTime := measureTime(\"Manual Parallel Implementation\", func() {\n\t\tresult := manualParallelProcessing(data)\n\t\tfmt.Printf(\"Manual parallel result count: %d\\n\", len(result))\n\t})\n\n\tfmt.Printf(\"\\nPerformance Comparison:\\n\")\n\tfmt.Printf(\"Sequential Stream: %.2f ms\\n\", sequentialTime)\n\tfmt.Printf(\"Parallel Stream: %.2f ms (%.2fx faster)\\n\", parallelTime, sequentialTime/parallelTime)\n\tfmt.Printf(\"Manual Parallel: %.2f ms (%.2fx faster than sequential)\\n\", manualParallelTime, sequentialTime/manualParallelTime)\n}\n\nfunc generateRandomInts(count int) []interface{} {\n\trand.Seed(time.Now().UnixNano())\n\tresult := make([]interface{}, count)\n\tfor i := 0; i < count; i++ {\n\t\tresult[i] = rand.Intn(2000000)\n\t}\n\treturn result\n}\n\nfunc measureTime(name string, fn func()) float64 {\n\tfmt.Printf(\"Running %s...\\n\", name)\n\tstart := time.Now()\n\tfn()\n\telapsed := float64(time.Since(start).Microseconds()) / 1000.0\n\tfmt.Printf(\"%s took %.2f ms\\n\\n\", name, elapsed)\n\treturn elapsed\n}\n\nfunc manualParallelProcessing(data []interface{}) []int {\n\tnumWorkers := runtime.NumCPU()\n\tvar wg sync.WaitGroup\n\tvar resultMutex sync.Mutex\n\tresult := make([]int, 0)\n\n\t// Calculate chunk size\n\tchunkSize := (len(data) + numWorkers - 1) / numWorkers\n\n\tfor i := 0; i < numWorkers; i++ {\n\t\twg.Add(1)\n\t\tstart := i * chunkSize\n\t\tend := (i + 1) * chunkSize\n\t\tif end > len(data) {\n\t\t\tend = len(data)\n\t\t}\n\n\t\tgo func(start, end int) {\n\t\t\tdefer wg.Done()\n\t\t\tlocalResult := make([]int, 0)\n\n\t\t\tfor j := start; j < end; j++ {\n\t\t\t\tn := data[j].(int)\n\t\t\t\tif n%2 == 0 {\n\t\t\t\t\tdoubled := n * 2\n\t\t\t\t\tif doubled < 1000000 {\n\t\t\t\t\t\tlocalResult = append(localResult, doubled)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tresultMutex.Lock()\n\t\t\tresult = append(result, localResult...)\n\t\t\tresultMutex.Unlock()\n\t\t}(start, end)\n\t}\n\n\twg.Wait()\n\treturn result\n}\n\u0005End File\u0006package main\n\nimport (\n\t\"fmt\"\n\t\"github.com/wushilin/go-stream\"\n\t\"sort\"\n\t\"time\"\n)\n\n// Define a User struct\ntype User struct {\n\tID        int\n\tName      string\n\tAge       int\n\tEmail     string\n\tCreatedAt time.Time\n}\n\nfunc main() {\n\t// Create a slice of users\n\tusers := []interface{}{\n\t\tUser{1, \"Alice\", 28, \"alice@example.com\", time.Now().Add(-100 * 24 * time.Hour)},\n\t\tUser{2, \"Bob\", 35, \"bob@example.com\", time.Now().Add(-200 * 24 * time.Hour)},\n\t\tUser{3, \"Charlie\", 22, \"charlie@example.com\", time.Now().Add(-50 * 24 * time.Hour)},\n\t\tUser{4, \"Diana\", 41, \"diana@example.com\", time.Now().Add(-150 * 24 * time.Hour)},\n\t\tUser{5, \"Eva\", 19, \"eva@example.com\", time.Now().Add(-300 * 24 * time.Hour)},\n\t}\n\n\t// Example 1: Filter users above 30 and map to their names\n\tfmt.Println(\"Example 1: Users above 30\")\n\tresult1, _ := stream.OfSlice(users).\n\t\tFilter(func(u interface{}) (bool, error) {\n\t\t\treturn u.(User).Age > 30, nil\n\t\t}).\n\t\tMap(func(u interface{}) (interface{}, error) {\n\t\t\treturn u.(User).Name, nil\n\t\t}).\n\t\tCollect(stream.ToList())\n\n\tfor _, name := range result1.([]interface{}) {\n\t\tfmt.Println(name)\n\t}\n\n\t// Example 2: Sort users by age\n\tfmt.Println(\"\\nExample 2: Users sorted by age\")\n\tresult2, _ := stream.OfSlice(users).\n\t\tSorted(func(a, b interface{}) bool {\n\t\t\treturn a.(User).Age < b.(User).Age\n\t\t}).\n\t\tCollect(stream.ToList())\n\n\tfor _, user := range result2.([]interface{}) {\n\t\tu := user.(User)\n\t\tfmt.Printf(\"Name: %s, Age: %d\\n\", u.Name, u.Age)\n\t}\n\n\t// Example 3: Group users by age group (young, middle-aged, senior)\n\tfmt.Println(\"\\nExample 3: Users grouped by age category\")\n\tresult3, _ := stream.OfSlice(users).\n\t\tCollect(stream.GroupingBy(func(u interface{}) (interface{}, error) {\n\t\t\tage := u.(User).Age\n\t\t\tif age < 25 {\n\t\t\t\treturn \"Young\", nil\n\t\t\t} else if age < 40 {\n\t\t\t\treturn \"Middle-aged\", nil\n\t\t\t} else {\n\t\t\t\treturn \"Senior\", nil\n\t\t\t}\n\t\t}))\n\n\tfor category, groupUsers := range result3.(map[interface{}][]interface{}) {\n\t\tfmt.Printf(\"%s:\\n\", category)\n\t\tfor _, user := range groupUsers {\n\t\t\tu := user.(User)\n\t\t\tfmt.Printf(\"  - %s (Age: %d)\\n\", u.Name, u.Age)\n\t\t}\n\t}\n\n\t// Example 4: Find the average age\n\tfmt.Println(\"\\nExample 4: Average age of users\")\n\tavg, _ := stream.OfSlice(users).\n\t\tMapToInt(func(u interface{}) (int64, error) {\n\t\t\treturn int64(u.(User).Age), nil\n\t\t}).\n\t\tAverage()\n\n\tfmt.Printf(\"Average age: %.1f years\\n\", avg)\n\n\t// Example 5: Collect user names into a joined string\n\tfmt.Println(\"\\nExample 5: All user names joined\")\n\tjoinedNames, _ := stream.OfSlice(users).\n\t\tMap(func(u interface{}) (interface{}, error) {\n\t\t\treturn u.(User).Name, nil\n\t\t}).\n\t\tCollect(stream.Joining(\", \"))\n\n\tfmt.Printf(\"Users: %s\\n\", joinedNames)\n\n\t// Example 6: Find the oldest user\n\tfmt.Println(\"\\nExample 6: Oldest user\")\n\toldestUser, _ := stream.OfSlice(users).\n\t\tMax(func(a, b interface{}) int {\n\t\t\tageA := a.(User).Age\n\t\t\tageB := b.(User).Age\n\t\t\treturn ageA - ageB\n\t\t})\n\n\tfmt.Printf(\"Oldest user: %s (Age: %d)\\n\", oldestUser.(User).Name, oldestUser.(User).Age)\n\n\t// Example 7: Create a map of user ID to user object\n\tfmt.Println(\"\\nExample 7: Map of user IDs to user objects\")\n\tuserMap, _ := stream.OfSlice(users).\n\t\tCollect(stream.ToMap(\n\t\t\tfunc(u interface{}) (interface{}, error) {\n\t\t\t\treturn u.(User).ID, nil\n\t\t\t},\n\t\t\tfunc(u interface{}) (interface{}, error) {\n\t\t\t\treturn u, nil\n\t\t\t},\n\t\t))\n\n\tfor id, user := range userMap.(map[interface{}]interface{}) {\n\t\tu := user.(User)\n\t\tfmt.Printf(\"ID %d: %s\\n\", id, u.Name)\n\t}\n\n\t// Example 8: Process only distinct ages\n\tfmt.Println(\"\\nExample 8: Distinct ages\")\n\tdistinctAges, _ := stream.OfSlice(users).\n\t\tMap(func(u interface{}) (interface{}, error) {\n\t\t\treturn u.(User).Age, nil\n\t\t}).\n\t\tDistinct().\n\t\tCollect(stream.ToList())\n\n\t// Convert to a slice of ints for easier sorting\n\tages := make([]int, len(distinctAges.([]interface{})))\n\tfor i, age := range distinctAges.([]interface{}) {\n\t\tages[i] = age.(int)\n\t}\n\tsort.Ints(ages)\n\n\tfmt.Printf(\"Distinct ages: %v\\n\", ages)\n\n\t// Example 9: Count users created in the last 6 months\n\tfmt.Println(\"\\nExample 9: Count of recently created users\")\n\tsixMonthsAgo := time.Now().AddDate(0, -6, 0)\n\trecentUserCount, _ := stream.OfSlice(users).\n\t\tFilter(func(u interface{}) (bool, error) {\n\t\t\treturn u.(User).CreatedAt.After(sixMonthsAgo), nil\n\t\t}).\n\t\tCount()\n\n\tfmt.Printf(\"Users created in the last 6 months: %d\\n\", recentUserCount)\n\n\t// Example 10: Peek at each user and print to console\n\tfmt.Println(\"\\nExample 10: Peek at users while processing\")\n\tstream.OfSlice(users).\n\t\tPeek(func(u interface{}) error {\n\t\t\tfmt.Printf(\"Processing user: %s\\n\", u.(User).Name)\n\t\t\treturn nil\n\t\t}).\n\t\tFilter(func(u interface{}) (bool, error) {\n\t\t\treturn u.(User).Age < 30, nil\n\t\t}).\n\t\tMap(func(u interface{}) (interface{}, error) {\n\t\t\treturn fmt.Sprintf(\"%s (%d)\", u.(User).Name, u.(User).Age), nil\n\t\t}).\n\t\tForEach(func(s interface{}) error {\n\t\t\tfmt.Printf(\"Young user: %s\\n\", s)\n\t\t\treturn nil\n\t\t})\n}\n\u0005End File\u0006package main\n\nimport (\n\t\"bufio\"\n\t\"flag\"\n\t\"fmt\"\n\t\"github.com/wushilin/go-stream\"\n\t\"io\"\n\t\"os\"\n\t\"strings\"\n)\n\nfunc main() {\n\t// Define flags\n\tinputFile := flag.String(\"input\", \"\", \"Input file path (use - for stdin)\")\n\toutputFile := flag.String(\"output\", \"\", \"Output file path (use - for stdout)\")\n\tcaseFlag := flag.String(\"case\", \"lower\", \"Case transformation: lower, upper, title\")\n\tlineNum := flag.Bool(\"line-numbers\", false, \"Add line numbers to output\")\n\tunique := flag.Bool(\"unique\", false, \"Only output unique lines\")\n\tsearch := flag.String(\"search\", \"\", \"Only include lines containing this text\")\n\treplace := flag.String(\"replace\", \"\", \"Replace text in lines (works with -search)\")\n\tlimit := flag.Int64(\"limit\", 0, \"Limit the number of lines (0 = no limit)\")\n\thelp := flag.Bool(\"help\", false, \"Show help\")\n\n\tflag.Parse()\n\n\tif *help {\n\t\tshowHelp()\n\t\treturn\n\t}\n\n\tif *inputFile == \"\" {\n\t\tfmt.Println(\"Error: input file is required\")\n\t\tshowHelp()\n\t\treturn\n\t}\n\n\t// Set up input reader\n\tvar input io.Reader\n\tif *inputFile == \"-\" {\n\t\tinput = os.Stdin\n\t} else {\n\t\tfile, err := os.Open(*inputFile)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error opening input file: %v\\n\", err)\n\t\t\treturn\n\t\t}\n\t\tdefer file.Close()\n\t\tinput = file\n\t}\n\n\t// Set up output writer\n\tvar output io.Writer\n\tif *outputFile == \"-\" || *outputFile == \"\" {\n\t\toutput = os.Stdout\n\t} else {\n\t\tfile, err := os.Create(*outputFile)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error creating output file: %v\\n\", err)\n\t\t\treturn\n\t\t}\n\t\tdefer file.Close()\n\t\toutput = file\n\t}\n\n\t// Process the text using Go Stream\n\tprocessText(input, output, *caseFlag, *lineNum, *unique, *search, *replace, *limit)\n}\n\nfunc showHelp() {\n\tfmt.Println(\"Text Processor - A command line utility using Go Stream\")\n\tfmt.Println(\"\\nUsage:\")\n\tfmt.Println(\"  text-processor [options]\")\n\tfmt.Println(\"\\nOptions:\")\n\tfmt.Println(\"  -input <file>       Input file path (use - for stdin)\")\n\tfmt.Println(\"  -output <file>      Output file path (use - for stdout)\")\n\tfmt.Println(\"  -case <transform>   Case transformation: lower, upper, title\")\n\tfmt.Println(\"  -line-numbers       Add line numbers to output\")\n\tfmt.Println(\"  -unique             Only output unique lines\")\n\tfmt.Println(\"  -search <text>      Only include lines containing this text\")\n\tfmt.Println(\"  -replace <text>     Replace text in lines (works with -search)\")\n\tfmt.Println(\"  -limit <n>          Limit the number of lines (0 = no limit)\")\n\tfmt.Println(\"  -help               Show this help message\")\n\tfmt.Println(\"\\nExamples:\")\n\tfmt.Println(\"  text-processor -input input.txt -output output.txt -case upper\")\n\tfmt.Println(\"  cat file.txt | text-processor -input - -line-numbers -search \\\"error\\\"\")\n}\n\nfunc processText(input io.Reader, output io.Writer, caseTransform string, lineNumbers, uniqueLines bool, searchText, replaceText string, limit int64) {\n\t// Create a scanner to read input line by line\n\tscanner := bufio.NewScanner(input)\n\tlines := make([]interface{}, 0)\n\t\n\t// Read all lines into memory\n\tfor scanner.Scan() {\n\t\tlines = append(lines, scanner.Text())\n\t}\n\t\n\tif err := scanner.Err(); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Error reading input: %v\\n\", err)\n\t\treturn\n\t}\n\n\t// Create a stream from the lines\n\tlineStream := stream.OfSlice(lines)\n\n\t// Apply text processing operations\n\tvar processedStream stream.Stream = lineStream\n\n\t// Apply search filter if specified\n\tif searchText != \"\" {\n\t\tprocessedStream = processedStream.Filter(func(line interface{}) (bool, error) {\n\t\t\treturn strings.Contains(line.(string), searchText), nil\n\t\t})\n\t}\n\n\t// Apply case transformation\n\tswitch strings.ToLower(caseTransform) {\n\tcase \"upper\":\n\t\tprocessedStream = processedStream.Map(func(line interface{}) (interface{}, error) {\n\t\t\treturn strings.ToUpper(line.(string)), nil\n\t\t})\n\tcase \"title\":\n\t\tprocessedStream = processedStream.Map(func(line interface{}) (interface{}, error) {\n\t\t\treturn strings.Title(line.(string)), nil\n\t\t})\n\tdefault: // \"lower\" is the default\n\t\tprocessedStream = processedStream.Map(func(line interface{}) (interface{}, error) {\n\t\t\treturn strings.ToLower(line.(string)), nil\n\t\t})\n\t}\n\n\t// Apply search and replace if both are specified\n\tif searchText != \"\" && replaceText != \"\" {\n\t\tprocessedStream = processedStream.Map(func(line interface{}) (interface{}, error) {\n\t\t\treturn strings.ReplaceAll(line.(string), searchText, replaceText), nil\n\t\t})\n\t}\n\n\t// Apply unique filter if requested\n\tif uniqueLines {\n\t\tprocessedStream = processedStream.Distinct()\n\t}\n\n\t// Apply line limit if specified\n\tif limit > 0 {\n\t\tprocessedStream = processedStream.Limit(limit)\n\t}\n\n\t// Add line numbers if requested\n\tif lineNumbers {\n\t\tprocessedStream = processedStream.Map(func(line interface{}) (interface{}, error) {\n\t\t\tlineCount := processedStream.(*stream.StreamImpl).Line\n\t\t\treturn fmt.Sprintf(\"%6d: %s\", lineCount, line.(string)), nil\n\t\t})\n\t}\n\n\t// Write results to output\n\twriter := bufio.NewWriter(output)\n\tdefer writer.Flush()\n\n\tprocessedStream.ForEach(func(line interface{}) error {\n\t\t_, err := fmt.Fprintln(writer, line.(string))\n\t\treturn err\n\t})\n}\n\u0005End File\u0006# isgasho/go-kit-1\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/wushilin/go-stream\"\n\t\"github.com/wushilin/go-stream/threads\"\n\t\"runtime\"\n\t\"time\"\n)\n\nfunc main() {\n\t// Create a WorkerPool with worker count equal to CPU cores\n\tworkerPool := threads.NewWorkerPool(runtime.NumCPU(), 10000)\n\tworkerPool.Start()\n\tdefer workerPool.Shutdown()\n\n\t// Example 1: Basic worker pool usage\n\tfmt.Println(\"Example 1: Basic worker pool\")\n\trunBasicWorkerPoolExample(workerPool)\n\n\t// Example 2: Handling errors in tasks\n\tfmt.Println(\"\\nExample 2: Error handling\")\n\trunErrorHandlingExample(workerPool)\n\n\t// Example 3: Waiting for task completion\n\tfmt.Println(\"\\nExample 3: Waiting for tasks\")\n\trunWaitForTasksExample(workerPool)\n\n\t// Example 4: Task coordination with channels\n\tfmt.Println(\"\\nExample 4: Task coordination\")\n\trunTaskCoordinationExample(workerPool)\n\n\t// Example 5: Integration with Go Stream\n\tfmt.Println(\"\\nExample 5: Integration with Go Stream\")\n\trunGoStreamIntegrationExample()\n}\n\nfunc runBasicWorkerPoolExample(pool *threads.WorkerPool) {\n\t// Submit 10 tasks to the pool\n\tfor i := 0; i < 10; i++ {\n\t\ttaskID := i\n\t\tpool.Execute(func() {\n\t\t\tfmt.Printf(\"Task %d executing on worker\\n\", taskID)\n\t\t\ttime.Sleep(100 * time.Millisecond) // Simulate work\n\t\t})\n\t}\n\n\t// Wait for all tasks to complete\n\tfor pool.GetPendingTasks() > 0 {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t}\n\tfmt.Println(\"All tasks completed\")\n}\n\nfunc runErrorHandlingExample(pool *threads.WorkerPool) {\n\t// Create a channel to collect errors\n\terrorChan := make(chan error, 5)\n\n\t// Submit tasks that might fail\n\tfor i := 0; i < 5; i++ {\n\t\ttaskID := i\n\t\tpool.Execute(func() {\n\t\t\t// Simulate some tasks failing\n\t\t\tif taskID%2 == 0 {\n\t\t\t\tfmt.Printf(\"Task %d completed successfully\\n\", taskID)\n\t\t\t} else {\n\t\t\t\terr := fmt.Errorf(\"task %d failed\", taskID)\n\t\t\t\terrorChan <- err\n\t\t\t\tfmt.Printf(\"Task %d failed with error\\n\", taskID)\n\t\t\t}\n\t\t})\n\t}\n\n\t// Wait for tasks to complete\n\tfor pool.GetPendingTasks() > 0 {\n\t\ttime.Sleep(10 * time.Millisecond)\n\t}\n\n\t// Check for errors\n\tclose(errorChan)\n\terrorCount := 0\n\tfor err := range errorChan {\n\t\terrorCount++\n\t\tfmt.Printf(\"Received error: %v\\n\", err)\n\t}\n\tfmt.Printf(\"Completed with %d errors\\n\", errorCount)\n}\n\nfunc runWaitForTasksExample(pool *threads.WorkerPool) {\n\tstartTime := time.Now()\n\n\t// Submit tasks with varying durations\n\tfor i := 0; i < 5; i++ {\n\t\ttaskID := i\n\t\tduration := time.Duration(100*(i+1)) * time.Millisecond\n\t\tpool.Execute(func() {\n\t\t\tfmt.Printf(\"Long-running task %d started (duration: %v)\\n\", taskID, duration)\n\t\t\ttime.Sleep(duration)\n\t\t\tfmt.Printf(\"Long-running task %d completed\\n\", taskID)\n\t\t})\n\t}\n\n\tfmt.Println(\"Waiting for all long-running tasks to complete...\")\n\tpool.WaitForPendingTasks()\n\n\telapsed := time.Since(startTime)\n\tfmt.Printf(\"All long-running tasks completed in %v\\n\", elapsed)\n}\n\nfunc runTaskCoordinationExample(pool *threads.WorkerPool) {\n\t// Create channels for task coordination\n\tdataChan := make(chan int, 10)\n\tresultChan := make(chan int, 10)\n\tdoneChan := make(chan struct{})\n\n\t// Producer task\n\tpool.Execute(func() {\n\t\tdefer close(dataChan)\n\t\tfor i := 1; i <= 5; i++ {\n\t\t\tfmt.Printf(\"Producer: sending %d\\n\", i)\n\t\t\tdataChan <- i\n\t\t\ttime.Sleep(50 * time.Millisecond)\n\t\t}\n\t})\n\n\t// Worker tasks\n\tfor i := 0; i < 3; i++ {\n\t\tworkerID := i\n\t\tpool.Execute(func() {\n\t\t\tfor data := range dataChan {\n\t\t\t\tresult := data * data\n\t\t\t\tfmt.Printf(\"Worker %d: processed %d -> %d\\n\", workerID, data, result)\n\t\t\t\tresultChan <- result\n\t\t\t\ttime.Sleep(100 * time.Millisecond)\n\t\t\t}\n\t\t})\n\t}\n\n\t// Consumer task\n\tpool.Execute(func() {\n\t\tsum := 0\n\t\tcount := 0\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase result, ok := <-resultChan:\n\t\t\t\tif !ok {\n\t\t\t\t\t// Channel closed\n\t\t\t\t\tdoneChan <- struct{}{}\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tsum += result\n\t\t\t\tcount++\n\t\t\t\tfmt.Printf(\"Consumer: received result %d, running sum = %d\\n\", result, sum)\n\t\t\t\tif count == 5 {\n\t\t\t\t\tclose(resultChan)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n\n\t// Wait for completion\n\t<-doneChan\n\tfmt.Println(\"Task coordination example completed\")\n}\n\nfunc runGoStreamIntegrationExample() {\n\t// Create a source slice\n\tdata := make([]interface{}, 20)\n\tfor i := 0; i < 20; i++ {\n\t\tdata[i] = i\n\t}\n\n\t// Process with parallel stream operations\n\tfmt.Println(\"Processing data with parallel stream operations...\")\n\tresult, err := stream.OfSlice(data).\n\t\tPFilter(func(i interface{}) (bool, error) {\n\t\t\tnum := i.(int)\n\t\t\t// Filter out even numbers\n\t\t\treturn num%2 == 1, nil\n\t\t}, runtime.NumCPU()).\n\t\tPMap(func(i interface{}) (interface{}, error) {\n\t\t\tnum := i.(int)\n\t\t\t// Square each number\n\t\t\ttime.Sleep(50 * time.Millisecond) // Simulate computation\n\t\t\treturn num * num, nil\n\t\t}, runtime.NumCPU()).\n\t\tCollect(stream.ToList())\n\n\tif err != nil {\n\t\tfmt.Printf(\"Error processing stream: %v\\n\", err)\n\t\treturn\n\t}\n\n\t// Display results\n\tfmt.Println(\"Stream processing results:\")\n\tresultList := result.([]interface{})\n\tfor i, val := range resultList {\n\t\tfmt.Printf(\"  Item %d: %v\\n\", i, val)\n\t}\n\n\t// Calculate sum\n\tsum := 0\n\tfor _, val := range resultList {\n\t\tsum += val.(int)\n\t}\n\tfmt.Printf(\"Sum of results: %d\\n\", sum)\n}\n\u0005End File\u0006# isgasho/go-kit-1\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/wushilin/go-stream\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// Define sample student data structure\ntype Student struct {\n\tID         int\n\tName       string\n\tAge        int\n\tGradePoint float64\n\tCourses    []string\n}\n\nfunc main() {\n\t// Create sample student data\n\tstudents := createSampleStudents()\n\n\t// Example 1: Creating streams from different sources\n\tfmt.Println(\"Example 1: Different ways to create streams\")\n\tstreamFromSlice()\n\tstreamFromGenerator()\n\tstreamFromIterable()\n\n\t// Example 2: Basic stream operations\n\tfmt.Println(\"\\nExample 2: Basic operations - Filter, Map, ForEach\")\n\tfilterMapExample(students)\n\n\t// Example 3: More advanced operations\n\tfmt.Println(\"\\nExample 3: Advanced operations - FlatMap, Reduce, Collect\")\n\tadvancedOperationsExample(students)\n\n\t// Example 4: Using primitive type streams\n\tfmt.Println(\"\\nExample 4: Working with primitive streams (IntStream, DoubleStream)\")\n\tprimitiveStreamsExample(students)\n\n\t// Example 5: Collectors and terminal operations\n\tfmt.Println(\"\\nExample 5: Different collectors and terminal operations\")\n\tcollectorsExample(students)\n\n\t// Example 6: Error handling in streams\n\tfmt.Println(\"\\nExample 6: Handling errors in stream operations\")\n\terrorHandlingExample()\n\n\t// Example 7: Closing streams and resource management\n\tfmt.Println(\"\\nExample 7: Resource management with streams\")\n\tresourceManagementExample()\n}\n\nfunc createSampleStudents() []interface{} {\n\treturn []interface{}{\n\t\tStudent{1, \"Alice\", 20, 3.8, []string{\"Math\", \"Physics\", \"Computer Science\"}},\n\t\tStudent{2, \"Bob\", 19, 3.2, []string{\"Biology\", \"Chemistry\"}},\n\t\tStudent{3, \"Charlie\", 21, 3.9, []string{\"Computer Science\", \"Data Structures\", \"Algorithms\"}},\n\t\tStudent{4, \"Diana\", 20, 3.5, []string{\"Art\", \"History\", \"Literature\"}},\n\t\tStudent{5, \"Eva\", 22, 3.7, []string{\"Physics\", \"Mathematics\", \"Statistics\"}},\n\t}\n}\n\nfunc streamFromSlice() {\n\t// Create a stream from a slice\n\tnumbers := []interface{}{1, 2, 3, 4, 5}\n\tstream.OfSlice(numbers).ForEach(func(n interface{}) error {\n\t\tfmt.Printf(\"%d \", n)\n\t\treturn nil\n\t})\n\tfmt.Println(\"\\n  Stream created from slice\")\n}\n\nfunc streamFromGenerator() {\n\t// Create a stream using a generator function\n\tstream.Generate(func() (interface{}, error) {\n\t\treturn \"Generated value\", nil\n\t}).Limit(3).ForEach(func(s interface{}) error {\n\t\tfmt.Printf(\"%s, \", s)\n\t\treturn nil\n\t})\n\tfmt.Println(\"\\n  Stream created from generator\")\n}\n\nfunc streamFromIterable() {\n\t// Create a custom iterable\n\tcustomIterable := &CustomIterable{data: []string{\"A\", \"B\", \"C\"}}\n\t\n\ts, _ := stream.OfIterable(customIterable)\n\ts.ForEach(func(item interface{}) error {\n\t\tfmt.Printf(\"%s \", item)\n\t\treturn nil\n\t})\n\tfmt.Println(\"\\n  Stream created from custom iterable\")\n}\n\nfunc filterMapExample(students []interface{}) {\n\t// Filter students older than 20 and map to their names\n\tfmt.Println(\"  Students older than 20:\")\n\tstream.OfSlice(students).\n\t\tFilter(func(s interface{}) (bool, error) {\n\t\t\treturn s.(Student).Age > 20, nil\n\t\t}).\n\t\tMap(func(s interface{}) (interface{}, error) {\n\t\t\treturn s.(Student).Name, nil\n\t\t}).\n\t\tForEach(func(name interface{}) error {\n\t\t\tfmt.Printf(\"    %s\\n\", name)\n\t\t\treturn nil\n\t\t})\n}\n\nfunc advancedOperationsExample(students []interface{}) {\n\t// Use flatMap to get all courses, then count distinct courses\n\tfmt.Println(\"  All unique courses offered:\")\n\tallCourses, _ := stream.OfSlice(students).\n\t\tFlatMap(func(s interface{}) (interface{}, error) {\n\t\t\treturn s.(Student).Courses, nil\n\t\t}).\n\t\tDistinct().\n\t\tSorted(func(a, b interface{}) bool {\n\t\t\treturn a.(string) < b.(string)\n\t\t}).\n\t\tCollect(stream.ToList())\n\t\n\tcourses := allCourses.([]interface{})\n\tfmt.Printf(\"    %d unique courses: \", len(courses))\n\tfor i, course := range courses {\n\t\tif i > 0 {\n\t\t\tfmt.Print(\", \")\n\t\t}\n\t\tfmt.Print(course)\n\t}\n\tfmt.Println()\n\t\n\t// Use reduce to find the student with the highest GPA\n\tfmt.Println(\"  Student with highest GPA:\")\n\ttopStudent, _ := stream.OfSlice(students).\n\t\tReduce(func(a, b interface{}) (interface{}, error) {\n\t\t\tif a.(Student).GradePoint > b.(Student).GradePoint {\n\t\t\t\treturn a, nil\n\t\t\t}\n\t\t\treturn b, nil\n\t\t})\n\t\n\tfmt.Printf(\"    %s with GPA %.1f\\n\", topStudent.(Student).Name, topStudent.(Student).GradePoint)\n}\n\nfunc primitiveStreamsExample(students []interface{}) {\n\t// Working with IntStream\n\tfmt.Println(\"  Using IntStream to analyze student ages:\")\n\tageStats, _ := stream.OfSlice(students).\n\t\tMapToInt(func(s interface{}) (int64, error) {\n\t\t\treturn int64(s.(Student).Age), nil\n\t\t})\n\t\n\tmin, _ := ageStats.Min()\n\tmax, _ := ageStats.Max()\n\tavg, _ := ageStats.Average()\n\tsum, _ := ageStats.Sum()\n\t\n\tfmt.Printf(\"    Age statistics - Min: %d, Max: %d, Avg: %.1f, Sum: %d\\n\", \n\t\tmin, max, avg, sum)\n\t\n\t// Working with DoubleStream\n\tfmt.Println(\"  Using DoubleStream to analyze GPAs:\")\n\tgpaStream, _ := stream.OfSlice(students).\n\t\tMapToDouble(func(s interface{}) (float64, error) {\n\t\t\treturn s.(Student).GradePoint, nil\n\t\t})\n\t\n\tgpaStream.ForEach(func(gpa float64) error {\n\t\tfmt.Printf(\"    %.1f \", gpa)\n\t\treturn nil\n\t})\n\tfmt.Println()\n}\n\nfunc collectorsExample(students []interface{}) {\n\t// Group students by age\n\tfmt.Println(\"  Students grouped by age:\")\n\tbyAge, _ := stream.OfSlice(students).\n\t\tCollect(stream.GroupingBy(func(s interface{}) (interface{}, error) {\n\t\t\treturn s.(Student).Age, nil\n\t\t}))\n\t\n\tageGroups := byAge.(map[interface{}][]interface{})\n\tfor age, group := range ageGroups {\n\t\tfmt.Printf(\"    Age %d: %d students\\n\", age, len(group))\n\t}\n\t\n\t// Map student IDs to names\n\tfmt.Println(\"  Map of student IDs to names:\")\n\tidToName, _ := stream.OfSlice(students).\n\t\tCollect(stream.ToMap(\n\t\t\tfunc(s interface{}) (interface{}, error) {\n\t\t\t\treturn s.(Student).ID, nil\n\t\t\t},\n\t\t\tfunc(s interface{}) (interface{}, error) {\n\t\t\t\treturn s.(Student).Name, nil\n\t\t\t},\n\t\t))\n\t\n\tidMap := idToName.(map[interface{}]interface{})\n\tfor id, name := range idMap {\n\t\tfmt.Printf(\"    ID %d: %s\\n\", id, name)\n\t}\n\t\n\t// Calculate average GPA\n\tfmt.Println(\"  Statistics calculations:\")\n\tavgGPA, _ := stream.OfSlice(students).\n\t\tMap(func(s interface{}) (interface{}, error) {\n\t\t\treturn s.(Student).GradePoint, nil\n\t\t}).\n\t\tCollect(stream.Averaging())\n\t\n\tstudentCount, _ := stream.OfSlice(students).Collect(stream.Counting())\n\t\n\tfmt.Printf(\"    Number of students: %d\\n\", studentCount)\n\tfmt.Printf(\"    Average GPA: %.2f\\n\", avgGPA)\n}\n\nfunc errorHandlingExample() {\n\t// Stream with an operation that might cause an error\n\tresult, err := stream.OfSlice([]interface{}{\"1\", \"2\", \"three\", \"4\", \"5\"}).\n\t\tMap(func(s interface{}) (interface{}, error) {\n\t\t\t// Try to convert string to int\n\t\t\ti, err := strconv.Atoi(s.(string))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"conversion error: %s is not a number\", s)\n\t\t\t}\n\t\t\treturn i * 2, nil\n\t\t}).\n\t\tCollect(stream.ToList())\n\t\n\tif err != nil {\n\t\tfmt.Printf(\"  Error occurred: %v\\n\", err)\n\t} else {\n\t\tfmt.Printf(\"  Result: %v\\n\", result)\n\t}\n\t\n\t// Using MapWithError to handle errors as data\n\tfmt.Println(\"  Using MapWithError to handle errors as values:\")\n\tstream.OfSlice([]interface{}{\"1\", \"2\", \"three\", \"4\", \"5\"}).\n\t\tMap(func(s interface{}) (interface{}, error) {\n\t\t\ti, err := strconv.Atoi(s.(string))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"could not convert %s\", s)\n\t\t\t}\n\t\t\treturn i * 2, nil\n\t\t}).\n\t\tMapWithError().\n\t\tForEach(func(result interface{}) error {\n\t\t\tswitch v := result.(type) {\n\t\t\tcase error:\n\t\t\t\tfmt.Printf(\"    Error: %v\\n\", v)\n\t\t\tdefault:\n\t\t\t\tfmt.Printf(\"    Value: %v\\n\", v)\n\t\t\t}\n\t\t\treturn nil\n\t\t})\n}\n\nfunc resourceManagementExample() {\n\t// Create a stream with a resource that needs to be closed\n\tstrm := stream.OfSlice([]interface{}{\"a\", \"b\", \"c\"}).\n\t\tOnClose(func() error {\n\t\t\tfmt.Println(\"  Resource cleanup performed\")\n\t\t\treturn nil\n\t\t})\n\t\n\t// Use the stream\n\tstrm.ForEach(func(s interface{}) error {\n\t\tfmt.Printf(\"  Processing: %s\\n\", s)\n\t\treturn nil\n\t})\n\t\n\t// Close the stream to release resources\n\tstrm.Close()\n}\n\n// Custom iterable implementation\ntype CustomIterable struct {\n\tdata []string\n}\n\nfunc (ci *CustomIterable) Iterator() (stream.Iterator, error) {\n\treturn &CustomIterator{data: ci.data, index: 0}, nil\n}\n\ntype CustomIterator struct {\n\tdata  []string\n\tindex int\n}\n\nfunc (ci *CustomIterator) Next() (interface{}, error) {\n\tif ci.index >= len(ci.data) {\n\t\treturn nil, fmt.Errorf(\"%s\", stream.EndOfStream)\n\t}\n\tresult := ci.data[ci.index]\n\tci.index++\n\treturn result, nil\n}\n\n// String set for unique string collection\ntype StringSet struct {\n\titems map[string]bool\n}\n\nfunc NewStringSet() *StringSet {\n\treturn &StringSet{items: make(map[string]bool)}\n}\n\nfunc (s *StringSet) Add(item string) {\n\ts.items[item] = true\n}\n\nfunc (s *StringSet) Contains(item string) bool {\n\t_, exists := s.items[item]\n\treturn exists\n}\n\nfunc (s *StringSet) String() string {\n\tkeys := make([]string, 0, len(s.items))\n\tfor k := range s.items {\n\t\tkeys = append(keys, k)\n\t}\n\treturn \"[\" + strings.Join(keys, \", \") + \"]\"\n}\n\u0005End File\u0006# isgasho/go-kit-1\n# go-stream\n\n`go-stream` is a comprehensive and feature-rich stream processing library for Go, inspired by Java 8 Streams and Scala's collection operations. It provides a fluent API for transforming and processing collections of data with operations like `map`, `filter`, `reduce`, and more.\n\n## Table of Contents\n\n- [Features](#features)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [API Overview](#api-overview)\n- [Creating Streams](#creating-streams)\n- [Stream Operations](#stream-operations)\n- [Terminal Operations](#terminal-operations)\n- [Working with IntStream and DoubleStream](#working-with-intstream-and-doublestream)\n- [Collectors](#collectors)\n- [Parallel Processing](#parallel-processing)\n- [Error Handling](#error-handling)\n- [Performance Considerations](#performance-considerations)\n- [Examples](#examples)\n- [License](#license)\n\n## Features\n\n- **Fluent API**: Chain operations naturally for clean and readable code\n- **Rich set of operations**: Map, filter, reduce, collect, flatMap, and more\n- **Type-specific streams**: IntStream and DoubleStream for better performance with primitive types\n- **Collectors**: Flexible ways to accumulate stream results\n- **Parallel processing**: Utilize multiple cores for data-parallel operations\n- **Error handling**: Consistent approach to propagating and handling errors in stream operations\n- **Resource management**: Proper cleanup with `Close()` method\n\n## Installation\n\n```bash\ngo get github.com/wushilin/go-stream\n```\n\n## Quick Start\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"github.com/wushilin/go-stream\"\n)\n\nfunc main() {\n    // Create a stream from a slice\n    numbers := []interface{}{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n    \n    // Process the stream\n    result, err := stream.OfSlice(numbers).\n        Filter(func(n interface{}) (bool, error) {\n            // Keep only even numbers\n            return n.(int)%2 == 0, nil\n        }).\n        Map(func(n interface{}) (interface{}, error) {\n            // Square each number\n            return n.(int) * n.(int), nil\n        }).\n        Collect(stream.ToList())\n    \n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n    \n    // Print the result\n    fmt.Println(\"Squares of even numbers:\", result)\n}\n```\n\n## API Overview\n\nThe `go-stream` library provides three main types of streams:\n\n1. **Stream**: General-purpose stream for any type of objects\n2. **IntStream**: Specialized stream for working with int64 values\n3. **DoubleStream**: Specialized stream for working with float64 values\n\nEach stream type supports a variety of operations, which can be categorized as:\n\n- **Intermediate operations**: Transform a stream into another stream (e.g., `Map`, `Filter`)\n- **Terminal operations**: Produce a result from a stream (e.g., `Collect`, `Reduce`, `ForEach`)\n\n## Creating Streams\n\nThere are several ways to create streams:\n\n```go\n// From a slice\nstream.OfSlice([]interface{}{1, 2, 3, 4, 5})\n\n// From individual values\nstream.Of(1, 2, 3, 4, 5)\n\n// Empty stream\nstream.Empty()\n\n// Using a generator function\nstream.Generate(func() (interface{}, error) {\n    return rand.Int(), nil\n}).Limit(10)\n\n// From a custom iterable\nstream.OfIterable(myIterable)\n\n// Integer range (exclusive end)\nstream.Range(1, 10)\n\n// Integer range (inclusive start and end, with step)\nstream.RangeStep(1, 10, 2)\n```\n\n## Stream Operations\n\n### Intermediate Operations\n\nThese operations transform a stream into another stream:\n\n```go\n// Filter elements based on a predicate\n.Filter(func(i interface{}) (bool, error) {\n    return i.(int) > 5, nil\n})\n\n// Transform elements with a function\n.Map(func(i interface{}) (interface{}, error) {\n    return i.(int) * 2, nil\n})\n\n// Flatten a stream of collections into a stream of elements\n.FlatMap(func(i interface{}) (interface{}, error) {\n    return i.([]int), nil\n})\n\n// Limit the number of elements\n.Limit(5)\n\n// Skip the first n elements\n.Skip(3)\n\n// Keep only distinct elements\n.Distinct()\n\n// Sort elements\n.Sorted(func(a, b interface{}) bool {\n    return a.(int) < b.(int)\n})\n\n// Peek at elements without modifying them\n.Peek(func(i interface{}) error {\n    fmt.Println(\"Processing:\", i)\n    return nil\n})\n```\n\n## Terminal Operations\n\nThese operations produce a result from a stream:\n\n```go\n// Collect elements into a result container\n.Collect(stream.ToList())\n\n// Perform an action for each element\n.ForEach(func(i interface{}) error {\n    fmt.Println(i)\n    return nil\n})\n\n// Find the first element\n.FindFirst()\n\n// Check if any elements match a predicate\n.AnyMatch(func(i interface{}) (bool, error) {\n    return i.(int) > 10, nil\n})\n\n// Check if all elements match a predicate\n.AllMatch(func(i interface{}) (bool, error) {\n    return i.(int) > 0, nil\n})\n\n// Check if no elements match a predicate\n.NoneMatch(func(i interface{}) (bool, error) {\n    return i.(int) < 0, nil\n})\n\n// Count the number of elements\n.Count()\n\n// Find the minimum element\n.Min(func(a, b interface{}) int {\n    return a.(int) - b.(int)\n})\n\n// Find the maximum element\n.Max(func(a, b interface{}) int {\n    return a.(int) - b.(int)\n})\n\n// Reduce the stream to a single value\n.Reduce(func(a, b interface{}) (interface{}, error) {\n    return a.(int) + b.(int), nil\n})\n\n// Reduce with an identity value\n.ReduceWithIdentity(0, func(a, b interface{}) (interface{}, error) {\n    return a.(int) + b.(int), nil\n})\n```\n\n## Working with IntStream and DoubleStream\n\nFor better performance when working with primitive types:\n\n```go\n// Create an IntStream directly\nstream.RangeInt(1, 100)\n\n// Convert a Stream to IntStream\n.MapToInt(func(i interface{}) (int64, error) {\n    return int64(i.(int)), nil\n})\n\n// IntStream operations\nintStream := stream.RangeInt(1, 100)\nsum, _ := intStream.Sum()\navg, _ := intStream.Average()\nmin, _ := intStream.Min()\nmax, _ := intStream.Max()\n\n// Convert IntStream back to Stream\n.BoxedStream()\n\n// DoubleStream operations\ndoubleStream := stream.OfSlice([]interface{}{1.0, 2.0, 3.0}).\n    MapToDouble(func(i interface{}) (float64, error) {\n        return i.(float64), nil\n    })\n```\n\n## Collectors\n\nCollectors provide flexible ways to accumulate stream results:\n\n```go\n// Collect to a list\n.Collect(stream.ToList())\n\n// Collect to a map\n.Collect(stream.ToMap(\n    func(i interface{}) (interface{}, error) { return i.(Person).ID, nil },\n    func(i interface{}) (interface{}, error) { return i, nil },\n))\n\n// Group by a key\n.Collect(stream.GroupingBy(func(i interface{}) (interface{}, error) {\n    return i.(Person).Department, nil\n}))\n\n// Join strings\n.Collect(stream.Joining(\", \"))\n\n// Count elements\n.Collect(stream.Counting())\n\n// Calculate average\n.Collect(stream.Averaging())\n\n// Calculate sum\n.Collect(stream.Summing())\n\n// Collect to a set (unique values)\n.Collect(stream.ToSet())\n```\n\n## Parallel Processing\n\nFor CPU-intensive operations, you can use parallel stream processing:\n\n```go\n// Create a parallel stream\nstream.OfSlice(data).ParallelStream()\n\n// Or use PMap and PFilter for specific operations\nstream.OfSlice(data).\n    PFilter(func(i interface{}) (bool, error) {\n        return complexFilter(i), nil\n    }, runtime.NumCPU()).\n    PMap(func(i interface{}) (interface{}, error) {\n        return expensiveTransformation(i), nil\n    }, runtime.NumCPU())\n\n// Convert back to sequential if needed\n.SequentialStream()\n```\n\n## Error Handling\n\nAll operations in `go-stream` propagate errors properly:\n\n```go\nresult, err := stream.OfSlice(data).\n    Map(func(i interface{}) (interface{}, error) {\n        // This operation might fail\n        return riskyOperation(i)\n    }).\n    Collect(stream.ToList())\n\nif err != nil {\n    // Handle the error\n    fmt.Printf(\"Stream processing failed: %v\\n\", err)\n    return\n}\n\n// Use the result\nfmt.Println(\"Result:\", result)\n```\n\nFor operations that might fail but you want to handle errors as data:\n\n```go\nstream.OfSlice(data).\n    Map(func(i interface{}) (interface{}, error) {\n        return riskyOperation(i)\n    }).\n    MapWithError(). // Converts errors to values in the stream\n    ForEach(func(result interface{}) error {\n        switch v := result.(type) {\n        case error:\n            fmt.Printf(\"Error: %v\\n\", v)\n        default:\n            fmt.Printf(\"Value: %v\\n\", v)\n        }\n        return nil\n    })\n```\n\n## Performance Considerations\n\n- Use specialized streams (`IntStream`, `DoubleStream`) for primitive types when possible\n- Consider parallel operations for CPU-intensive tasks with large data sets\n- Be cautious with `Distinct()` and `Sorted()` on large data sets as they may require significant memory\n- Use `Limit()` early in the pipeline when you only need a subset of results\n- Close streams that use resources when done: `defer stream.Close()`\n\n## Examples\n\n### Processing a List of Users\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"github.com/wushilin/go-stream\"\n)\n\ntype User struct {\n    ID    int\n    Name  string\n    Age   int\n    Email string\n}\n\nfunc main() {\n    // Create a list of users\n    users := []interface{}{\n        User{1, \"Alice\", 30, \"alice@example.com\"},\n        User{2, \"Bob\", 25, \"bob@example.com\"},\n        User{3, \"Charlie\", 35, \"charlie@example.com\"},\n        User{4, \"Dave\", 40, \"dave@example.com\"},\n    }\n    \n    // Find users older than 30 and collect their names\n    result, err := stream.OfSlice(users).\n        Filter(func(u interface{}) (bool, error) {\n            return u.(User).Age > 30, nil\n        }).\n        Map(func(u interface{}) (interface{}, error) {\n            return u.(User).Name, nil\n        }).\n        Collect(stream.ToList())\n    \n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n    \n    fmt.Println(\"Users older than 30:\", result)\n    \n    // Create a map of user ID to email\n    userMap, err := stream.OfSlice(users).\n        Collect(stream.ToMap(\n            func(u interface{}) (interface{}, error) { return u.(User).ID, nil },\n            func(u interface{}) (interface{}, error) { return u.(User).Email, nil },\n        ))\n    \n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n    \n    fmt.Println(\"User ID to Email map:\", userMap)\n    \n    // Calculate average age\n    avgAge, err := stream.OfSlice(users).\n        MapToInt(func(u interface{}) (int64, error) {\n            return int64(u.(User).Age), nil\n        }).\n        Average()\n    \n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n    \n    fmt.Printf(\"Average age: %.1f\\n\", avgAge)\n}\n```\n\n### Data Processing Pipeline\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"github.com/wushilin/go-stream\"\n    \"strings\"\n)\n\nfunc main() {\n    // Process a list of log entries\n    logs := []interface{}{\n        \"INFO: System started\",\n        \"DEBUG: Connection initialized\",\n        \"ERROR: Database connection failed\",\n        \"INFO: Retrying connection\",\n        \"ERROR: Authentication failed\",\n        \"DEBUG: Detailed error trace\",\n        \"INFO: Failover successful\",\n    }\n    \n    // Extract error messages and their details\n    errorLogs, err := stream.OfSlice(logs).\n        Filter(func(log interface{}) (bool, error) {\n            return strings.HasPrefix(log.(string), \"ERROR\"), nil\n        }).\n        Map(func(log interface{}) (interface{}, error) {\n            return strings.TrimPrefix(log.(string), \"ERROR: \"), nil\n        }).\n        Collect(stream.ToList())\n    \n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n    \n    fmt.Println(\"Error logs:\", errorLogs)\n    \n    // Count log types\n    logCounts, err := stream.OfSlice(logs).\n        Map(func(log interface{}) (interface{}, error) {\n            parts := strings.SplitN(log.(string), \":\", 2)\n            return parts[0], nil\n        }).\n        Collect(stream.GroupingBy(func(logType interface{}) (interface{}, error) {\n            return logType, nil\n        }))\n    \n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n    \n    fmt.Println(\"Log counts:\")\n    for logType, entries := range logCounts.(map[interface{}][]interface{}) {\n        fmt.Printf(\"  %s: %d entries\\n\", logType, len(entries))\n    }\n}\n```\n\n## License\n\nThis library is licensed under the MIT License. See the LICENSE file for details.\n\u0005End File\u0006# isgasho/go-kit-1\n# go-config/go-config.go\npackage config\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"log/slog\"\n\t\"net/url\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/joho/godotenv\"\n\t\"github.com/pelletier/go-toml\"\n\t\"gopkg.in/yaml.v3\"\n)\n\nconst (\n\tTOML_FORMAT = \"toml\"\n\tJSON_FORMAT = \"json\"\n\tYAML_FORMAT = \"yaml\"\n\tYML_FORMAT  = \"yml\"\n\tENV_FORMAT  = \"env\"\n)\n\n// Config is the interface that must be implemented by a configuration provider\ntype Config interface {\n\t// Get returns the value of the given key\n\tGet(key string) (string, bool)\n\n\t// GetString returns the value of the given key as a string\n\tGetString(key string, defaultValue string) string\n\n\t// GetInt returns the value of the given key as an int\n\tGetInt(key string, defaultValue int) int\n\n\t// GetInt64 returns the value of the given key as an int64\n\tGetInt64(key string, defaultValue int64) int64\n\n\t// GetFloat returns the value of the given key as a float64\n\tGetFloat(key string, defaultValue float64) float64\n\n\t// GetBool returns the value of the given key as a bool\n\tGetBool(key string, defaultValue bool) bool\n\n\t// GetDuration returns the value of the given key as a time.Duration\n\tGetDuration(key string, defaultValue time.Duration) time.Duration\n\n\t// GetURL returns the value of the given key as a *url.URL\n\tGetURL(key string, defaultValue *url.URL) *url.URL\n\n\t// GetKeys returns all keys in the configuration\n\tGetKeys() []string\n\n\t// GetValues returns all values in the configuration\n\tGetValues() map[string]string\n\n\t// Set sets the value of the given key\n\tSet(key string, value string)\n\n\t// Add adds a new configuration source\n\tAdd(source Config)\n\n\t// Refresh refreshes the configuration from the source\n\tRefresh() error\n}\n\n// Config is a configuration provider that can read from a file or environment variables\ntype ConfigImpl struct {\n\tsources []Config\n\tvalues  map[string]string\n\tmu      sync.RWMutex\n}\n\nvar _ Config = (*ConfigImpl)(nil)\n\n// New creates a new Config\nfunc New() *ConfigImpl {\n\treturn &ConfigImpl{\n\t\tsources: make([]Config, 0),\n\t\tvalues:  make(map[string]string),\n\t}\n}\n\n// Get returns the value of the given key\nfunc (c *ConfigImpl) Get(key string) (string, bool) {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tv, ok := c.values[key]\n\treturn v, ok\n}\n\n// GetString returns the value of the given key as a string\nfunc (c *ConfigImpl) GetString(key string, defaultValue string) string {\n\tif v, ok := c.Get(key); ok {\n\t\treturn v\n\t}\n\treturn defaultValue\n}\n\n// GetInt returns the value of the given key as an int\nfunc (c *ConfigImpl) GetInt(key string, defaultValue int) int {\n\tif v, ok := c.Get(key); ok {\n\t\tif i, err := strconv.Atoi(v); err == nil {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetInt64 returns the value of the given key as an int64\nfunc (c *ConfigImpl) GetInt64(key string, defaultValue int64) int64 {\n\tif v, ok := c.Get(key); ok {\n\t\tif i, err := strconv.ParseInt(v, 10, 64); err == nil {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetFloat returns the value of the given key as a float64\nfunc (c *ConfigImpl) GetFloat(key string, defaultValue float64) float64 {\n\tif v, ok := c.Get(key); ok {\n\t\tif f, err := strconv.ParseFloat(v, 64); err == nil {\n\t\t\treturn f\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetBool returns the value of the given key as a bool\nfunc (c *ConfigImpl) GetBool(key string, defaultValue bool) bool {\n\tif v, ok := c.Get(key); ok {\n\t\tswitch strings.ToLower(v) {\n\t\tcase \"true\", \"yes\", \"1\", \"on\":\n\t\t\treturn true\n\t\tcase \"false\", \"no\", \"0\", \"off\":\n\t\t\treturn false\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetDuration returns the value of the given key as a time.Duration\nfunc (c *ConfigImpl) GetDuration(key string, defaultValue time.Duration) time.Duration {\n\tif v, ok := c.Get(key); ok {\n\t\tif d, err := time.ParseDuration(v); err == nil {\n\t\t\treturn d\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetURL returns the value of the given key as a *url.URL\nfunc (c *ConfigImpl) GetURL(key string, defaultValue *url.URL) *url.URL {\n\tif v, ok := c.Get(key); ok {\n\t\tif u, err := url.Parse(v); err == nil {\n\t\t\treturn u\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetKeys returns all keys in the configuration\nfunc (c *ConfigImpl) GetKeys() []string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tkeys := make([]string, 0, len(c.values))\n\tfor k := range c.values {\n\t\tkeys = append(keys, k)\n\t}\n\treturn keys\n}\n\n// GetValues returns all values in the configuration\nfunc (c *ConfigImpl) GetValues() map[string]string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tvalues := make(map[string]string)\n\tfor k, v := range c.values {\n\t\tvalues[k] = v\n\t}\n\treturn values\n}\n\n// Set sets the value of the given key\nfunc (c *ConfigImpl) Set(key string, value string) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.values[key] = value\n}\n\n// Add adds a new configuration source\nfunc (c *ConfigImpl) Add(source Config) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.sources = append(c.sources, source)\n\tfor k, v := range source.GetValues() {\n\t\tc.values[k] = v\n\t}\n}\n\n// Refresh refreshes the configuration from the source\nfunc (c *ConfigImpl) Refresh() error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.values = make(map[string]string)\n\tfor _, source := range c.sources {\n\t\tif err := source.Refresh(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor k, v := range source.GetValues() {\n\t\t\tc.values[k] = v\n\t\t}\n\t}\n\treturn nil\n}\n\n// NewFromFile creates a new Config from a file\nfunc NewFromFile(filename string) (*ConfigImpl, error) {\n\tc := New()\n\tif err := c.loadFromFile(filename); err != nil {\n\t\treturn nil, err\n\t}\n\treturn c, nil\n}\n\n// Load loads the configuration from the specified file\nfunc (c *ConfigImpl) loadFromFile(filename string) error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\n\t// Determine file format based on extension\n\tformat := strings.ToLower(filename[strings.LastIndex(filename, \".\")+1:])\n\n\t// Open the file\n\tfile, err := os.Open(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer file.Close()\n\n\t// Read the file content\n\treturn c.loadFromReader(file, format)\n}\n\n// loadFromReader loads the configuration from a reader\nfunc (c *ConfigImpl) loadFromReader(reader io.Reader, format string) error {\n\tswitch format {\n\tcase TOML_FORMAT:\n\t\treturn c.loadFromTOML(reader)\n\tcase JSON_FORMAT:\n\t\treturn c.loadFromJSON(reader)\n\tcase YAML_FORMAT, YML_FORMAT:\n\t\treturn c.loadFromYAML(reader)\n\tcase ENV_FORMAT:\n\t\treturn c.loadFromENV(reader)\n\tdefault:\n\t\treturn fmt.Errorf(\"unsupported format: %s\", format)\n\t}\n}\n\n// loadFromTOML loads the configuration from a TOML file\nfunc (c *ConfigImpl) loadFromTOML(reader io.Reader) error {\n\ttree, err := toml.LoadReader(reader)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Flatten the TOML tree into key-value pairs\n\tc.flattenTomlTree(\"\", tree, c.values)\n\treturn nil\n}\n\n// flattenTomlTree flattens a TOML tree into key-value pairs\nfunc (c *ConfigImpl) flattenTomlTree(prefix string, tree *toml.Tree, values map[string]string) {\n\tfor _, key := range tree.Keys() {\n\t\tfullKey := key\n\t\tif prefix != \"\" {\n\t\t\tfullKey = prefix + \".\" + key\n\t\t}\n\n\t\tvalue := tree.Get(key)\n\t\tswitch v := value.(type) {\n\t\tcase *toml.Tree:\n\t\t\t// Recursively flatten nested trees\n\t\t\tc.flattenTomlTree(fullKey, v, values)\n\t\tcase []*toml.Tree:\n\t\t\t// Handle arrays of tables\n\t\t\tfor i, item := range v {\n\t\t\t\tarrayKey := fullKey + \"[\" + strconv.Itoa(i) + \"]\"\n\t\t\t\tc.flattenTomlTree(arrayKey, item, values)\n\t\t\t}\n\t\tdefault:\n\t\t\t// Convert the value to a string\n\t\t\tvalues[fullKey] = fmt.Sprintf(\"%v\", value)\n\t\t}\n\t}\n}\n\n// loadFromJSON loads the configuration from a JSON file\nfunc (c *ConfigImpl) loadFromJSON(reader io.Reader) error {\n\tvar data interface{}\n\tdecoder := toml.NewDecoder(reader)\n\tif err := decoder.Decode(&data); err != nil {\n\t\treturn err\n\t}\n\n\t// Flatten the JSON object into key-value pairs\n\tc.flattenJSON(\"\", data, c.values)\n\treturn nil\n}\n\n// flattenJSON flattens a JSON object into key-value pairs\nfunc (c *ConfigImpl) flattenJSON(prefix string, data interface{}, values map[string]string) {\n\tswitch v := data.(type) {\n\tcase map[string]interface{}:\n\t\tfor key, value := range v {\n\t\t\tfullKey := key\n\t\t\tif prefix != \"\" {\n\t\t\t\tfullKey = prefix + \".\" + key\n\t\t\t}\n\t\t\tc.flattenJSON(fullKey, value, values)\n\t\t}\n\tcase []interface{}:\n\t\tfor i, value := range v {\n\t\t\tfullKey := prefix + \"[\" + strconv.Itoa(i) + \"]\"\n\t\t\tc.flattenJSON(fullKey, value, values)\n\t\t}\n\tdefault:\n\t\t// Convert the value to a string\n\t\tvalues[prefix] = fmt.Sprintf(\"%v\", v)\n\t}\n}\n\n// loadFromYAML loads the configuration from a YAML file\nfunc (c *ConfigImpl) loadFromYAML(reader io.Reader) error {\n\tvar data interface{}\n\tdecoder := yaml.NewDecoder(reader)\n\tif err := decoder.Decode(&data); err != nil {\n\t\treturn err\n\t}\n\n\t// Flatten the YAML object into key-value pairs\n\tc.flattenYAML(\"\", data, c.values)\n\treturn nil\n}\n\n// flattenYAML flattens a YAML object into key-value pairs\nfunc (c *ConfigImpl) flattenYAML(prefix string, data interface{}, values map[string]string) {\n\tswitch v := data.(type) {\n\tcase map[string]interface{}:\n\t\tfor key, value := range v {\n\t\t\tfullKey := key\n\t\t\tif prefix != \"\" {\n\t\t\t\tfullKey = prefix + \".\" + key\n\t\t\t}\n\t\t\tc.flattenYAML(fullKey, value, values)\n\t\t}\n\tcase []interface{}:\n\t\tfor i, value := range v {\n\t\t\tfullKey := prefix + \"[\" + strconv.Itoa(i) + \"]\"\n\t\t\tc.flattenYAML(fullKey, value, values)\n\t\t}\n\tdefault:\n\t\t// Convert the value to a string\n\t\tvalues[prefix] = fmt.Sprintf(\"%v\", v)\n\t}\n}\n\n// loadFromENV loads the configuration from a .env file\nfunc (c *ConfigImpl) loadFromENV(reader io.Reader) error {\n\t// Read the entire file\n\tcontent, err := io.ReadAll(reader)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Parse the .env file\n\tenvMap, err := godotenv.Unmarshal(string(content))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Add the environment variables to the config\n\tfor key, value := range envMap {\n\t\tc.values[key] = value\n\t}\n\n\treturn nil\n}\n\n// FromEnv creates a new Config from environment variables\ntype EnvConfig struct {\n\tprefix string\n\tvalues map[string]string\n\tmu     sync.RWMutex\n}\n\n// NewFromEnv creates a new Config from environment variables\nfunc NewFromEnv(prefix string) *EnvConfig {\n\tconfig := &EnvConfig{\n\t\tprefix: prefix,\n\t\tvalues: make(map[string]string),\n\t}\n\tconfig.Refresh()\n\treturn config\n}\n\n// Get returns the value of the given key\nfunc (c *EnvConfig) Get(key string) (string, bool) {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tv, ok := c.values[key]\n\treturn v, ok\n}\n\n// GetString returns the value of the given key as a string\nfunc (c *EnvConfig) GetString(key string, defaultValue string) string {\n\tif v, ok := c.Get(key); ok {\n\t\treturn v\n\t}\n\treturn defaultValue\n}\n\n// GetInt returns the value of the given key as an int\nfunc (c *EnvConfig) GetInt(key string, defaultValue int) int {\n\tif v, ok := c.Get(key); ok {\n\t\tif i, err := strconv.Atoi(v); err == nil {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetInt64 returns the value of the given key as an int64\nfunc (c *EnvConfig) GetInt64(key string, defaultValue int64) int64 {\n\tif v, ok := c.Get(key); ok {\n\t\tif i, err := strconv.ParseInt(v, 10, 64); err == nil {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetFloat returns the value of the given key as a float64\nfunc (c *EnvConfig) GetFloat(key string, defaultValue float64) float64 {\n\tif v, ok := c.Get(key); ok {\n\t\tif f, err := strconv.ParseFloat(v, 64); err == nil {\n\t\t\treturn f\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetBool returns the value of the given key as a bool\nfunc (c *EnvConfig) GetBool(key string, defaultValue bool) bool {\n\tif v, ok := c.Get(key); ok {\n\t\tswitch strings.ToLower(v) {\n\t\tcase \"true\", \"yes\", \"1\", \"on\":\n\t\t\treturn true\n\t\tcase \"false\", \"no\", \"0\", \"off\":\n\t\t\treturn false\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetDuration returns the value of the given key as a time.Duration\nfunc (c *EnvConfig) GetDuration(key string, defaultValue time.Duration) time.Duration {\n\tif v, ok := c.Get(key); ok {\n\t\tif d, err := time.ParseDuration(v); err == nil {\n\t\t\treturn d\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetURL returns the value of the given key as a *url.URL\nfunc (c *EnvConfig) GetURL(key string, defaultValue *url.URL) *url.URL {\n\tif v, ok := c.Get(key); ok {\n\t\tif u, err := url.Parse(v); err == nil {\n\t\t\treturn u\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetKeys returns all keys in the configuration\nfunc (c *EnvConfig) GetKeys() []string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tkeys := make([]string, 0, len(c.values))\n\tfor k := range c.values {\n\t\tkeys = append(keys, k)\n\t}\n\treturn keys\n}\n\n// GetValues returns all values in the configuration\nfunc (c *EnvConfig) GetValues() map[string]string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tvalues := make(map[string]string)\n\tfor k, v := range c.values {\n\t\tvalues[k] = v\n\t}\n\treturn values\n}\n\n// Set sets the value of the given key\nfunc (c *EnvConfig) Set(key string, value string) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.values[key] = value\n}\n\n// Add adds a new configuration source\nfunc (c *EnvConfig) Add(source Config) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tfor k, v := range source.GetValues() {\n\t\tc.values[k] = v\n\t}\n}\n\n// Refresh refreshes the configuration from environment variables\nfunc (c *EnvConfig) Refresh() error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.values = make(map[string]string)\n\n\t// Get all environment variables\n\tfor _, env := range os.Environ() {\n\t\tparts := strings.SplitN(env, \"=\", 2)\n\t\tif len(parts) != 2 {\n\t\t\tcontinue\n\t\t}\n\n\t\tkey := parts[0]\n\t\tvalue := parts[1]\n\n\t\t// If a prefix is specified, only include variables with that prefix\n\t\tif c.prefix != \"\" {\n\t\t\tif !strings.HasPrefix(key, c.prefix) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// Remove the prefix from the key\n\t\t\tkey = strings.TrimPrefix(key, c.prefix)\n\t\t}\n\n\t\t// Convert environment variable format (often uppercase with underscores)\n\t\t// to a more config-friendly format (lowercase with dots)\n\t\tkey = strings.ToLower(key)\n\t\tkey = strings.Replace(key, \"_\", \".\", -1)\n\n\t\tc.values[key] = value\n\t}\n\n\treturn nil\n}\n\n// NewFromMap creates a new Config from a map\ntype MapConfig struct {\n\tvalues map[string]string\n\tmu     sync.RWMutex\n}\n\n// NewFromMap creates a new Config from a map\nfunc NewFromMap(values map[string]string) *MapConfig {\n\treturn &MapConfig{\n\t\tvalues: values,\n\t}\n}\n\n// Get returns the value of the given key\nfunc (c *MapConfig) Get(key string) (string, bool) {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tv, ok := c.values[key]\n\treturn v, ok\n}\n\n// GetString returns the value of the given key as a string\nfunc (c *MapConfig) GetString(key string, defaultValue string) string {\n\tif v, ok := c.Get(key); ok {\n\t\treturn v\n\t}\n\treturn defaultValue\n}\n\n// GetInt returns the value of the given key as an int\nfunc (c *MapConfig) GetInt(key string, defaultValue int) int {\n\tif v, ok := c.Get(key); ok {\n\t\tif i, err := strconv.Atoi(v); err == nil {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetInt64 returns the value of the given key as an int64\nfunc (c *MapConfig) GetInt64(key string, defaultValue int64) int64 {\n\tif v, ok := c.Get(key); ok {\n\t\tif i, err := strconv.ParseInt(v, 10, 64); err == nil {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetFloat returns the value of the given key as a float64\nfunc (c *MapConfig) GetFloat(key string, defaultValue float64) float64 {\n\tif v, ok := c.Get(key); ok {\n\t\tif f, err := strconv.ParseFloat(v, 64); err == nil {\n\t\t\treturn f\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetBool returns the value of the given key as a bool\nfunc (c *MapConfig) GetBool(key string, defaultValue bool) bool {\n\tif v, ok := c.Get(key); ok {\n\t\tswitch strings.ToLower(v) {\n\t\tcase \"true\", \"yes\", \"1\", \"on\":\n\t\t\treturn true\n\t\tcase \"false\", \"no\", \"0\", \"off\":\n\t\t\treturn false\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetDuration returns the value of the given key as a time.Duration\nfunc (c *MapConfig) GetDuration(key string, defaultValue time.Duration) time.Duration {\n\tif v, ok := c.Get(key); ok {\n\t\tif d, err := time.ParseDuration(v); err == nil {\n\t\t\treturn d\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetURL returns the value of the given key as a *url.URL\nfunc (c *MapConfig) GetURL(key string, defaultValue *url.URL) *url.URL {\n\tif v, ok := c.Get(key); ok {\n\t\tif u, err := url.Parse(v); err == nil {\n\t\t\treturn u\n\t\t}\n\t}\n\treturn defaultValue\n}\n\n// GetKeys returns all keys in the configuration\nfunc (c *MapConfig) GetKeys() []string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tkeys := make([]string, 0, len(c.values))\n\tfor k := range c.values {\n\t\tkeys = append(keys, k)\n\t}\n\treturn keys\n}\n\n// GetValues returns all values in the configuration\nfunc (c *MapConfig) GetValues() map[string]string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\tvalues := make(map[string]string)\n\tfor k, v := range c.values {\n\t\tvalues[k] = v\n\t}\n\treturn values\n}\n\n// Set sets the value of the given key\nfunc (c *MapConfig) Set(key string, value string) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.values[key] = value\n}\n\n// Add adds a new configuration source\nfunc (c *MapConfig) Add(source Config) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tfor k, v := range source.GetValues() {\n\t\tc.values[k] = v\n\t}\n}\n\n// Refresh is a no-op for MapConfig\nfunc (c *MapConfig) Refresh() error {\n\treturn nil\n}\n\n// MustGet returns the value of the given key or panics\nfunc MustGet(config Config, key string) string {\n\tif value, ok := config.Get(key); ok {\n\t\treturn value\n\t}\n\tpanic(fmt.Sprintf(\"required configuration key not found: %s\", key))\n}\n\n// WithLogger returns a logger with the given name\nfunc WithLogger(config Config, name string) *slog.Logger {\n\t// Get the log level from the configuration\n\tlogLevel := config.GetString(\"log.level\", \"info\")\n\n\t// Configure the logger\n\tvar level slog.Level\n\tswitch strings.ToLower(logLevel) {\n\tcase \"debug\":\n\t\tlevel = slog.LevelDebug\n\tcase \"info\":\n\t\tlevel = slog.LevelInfo\n\tcase \"warn\", \"warning\":\n\t\tlevel = slog.LevelWarn\n\tcase \"error\":\n\t\tlevel = slog.LevelError\n\tdefault:\n\t\tlevel = slog.LevelInfo\n\t}\n\n\t// Create a new logger\n\tlogHandler := slog.NewTextHandler(os.Stdout, &slog.HandlerOptions{\n\t\tLevel: level,\n\t})\n\n\treturn slog.New(logHandler).With(\"service\", name)\n}\n\u0005End File\u0006# isgasho/go-kit-1\n# go-config/examples/basic/main.go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/wushilin/go-config\"\n)\n\nfunc main() {\n\t// Example 1: Basic Configuration\n\tfmt.Println(\"=== Example 1: Basic Configuration ===\")\n\tbasicExample()\n\n\t// Example 2: Loading from file\n\tfmt.Println(\"\\n=== Example 2: Loading from file ===\")\n\tfileExample()\n\n\t// Example 3: Loading from environment variables\n\tfmt.Println(\"\\n=== Example 3: Loading from environment variables ===\")\n\tenvExample()\n\n\t// Example 4: Combined configuration with precedence\n\tfmt.Println(\"\\n=== Example 4: Combined configuration with precedence ===\")\n\tcombinedExample()\n\n\t// Example 5: Different data types\n\tfmt.Println(\"\\n=== Example 5: Different data types ===\")\n\ttypesExample()\n\n\t// Example 6: Configuration with default values\n\tfmt.Println(\"\\n=== Example 6: Configuration with default values ===\")\n\tdefaultsExample()\n\n\t// Example 7: Dynamic configuration refresh\n\tfmt.Println(\"\\n=== Example 7: Dynamic configuration refresh ===\")\n\trefreshExample()\n}\n\nfunc basicExample() {\n\t// Create a new configuration\n\tconf := config.New()\n\n\t// Set some values\n\tconf.Set(\"app.name\", \"MyApp\")\n\tconf.Set(\"app.version\", \"1.0.0\")\n\tconf.Set(\"database.host\", \"localhost\")\n\tconf.Set(\"database.port\", \"5432\")\n\n\t// Get values\n\tappName := conf.GetString(\"app.name\", \"Unknown\")\n\tdbHost := conf.GetString(\"database.host\", \"\")\n\tdbPort := conf.GetInt(\"database.port\", 0)\n\n\tfmt.Printf(\"App Name: %s\\n\", appName)\n\tfmt.Printf(\"Database Connection: %s:%d\\n\", dbHost, dbPort)\n\n\t// Get all keys\n\tfmt.Println(\"All configuration keys:\")\n\tfor _, key := range conf.GetKeys() {\n\t\tvalue, _ := conf.Get(key)\n\t\tfmt.Printf(\"  %s = %s\\n\", key, value)\n\t}\n}\n\nfunc fileExample() {\n\t// Write a sample configuration file\n\tyaml := `\napp:\n  name: FileConfigApp\n  version: 2.0.0\ndatabase:\n  host: db.example.com\n  port: 5432\n  credentials:\n    username: admin\n    password: secret\n`\n\terr := os.WriteFile(\"config.yaml\", []byte(yaml), 0644)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to write config file: %v\", err)\n\t}\n\tdefer os.Remove(\"config.yaml\")\n\n\t// Load configuration from file\n\tconf, err := config.NewFromFile(\"config.yaml\")\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to load config file: %v\", err)\n\t}\n\n\t// Get some values\n\tappName := conf.GetString(\"app.name\", \"Unknown\")\n\tdbHost := conf.GetString(\"database.host\", \"\")\n\tdbUsername := conf.GetString(\"database.credentials.username\", \"\")\n\n\tfmt.Printf(\"App Name: %s\\n\", appName)\n\tfmt.Printf(\"Database Host: %s\\n\", dbHost)\n\tfmt.Printf(\"Database Username: %s\\n\", dbUsername)\n\n\t// Get nested structure\n\tfmt.Println(\"Database Configuration:\")\n\tfor _, key := range conf.GetKeys() {\n\t\tif key == \"database.host\" || key == \"database.port\" || key == \"database.credentials.username\" {\n\t\t\tvalue, _ := conf.Get(key)\n\t\t\tfmt.Printf(\"  %s = %s\\n\", key, value)\n\t\t}\n\t}\n}\n\nfunc envExample() {\n\t// Set some environment variables\n\tos.Setenv(\"MYAPP_SERVICE_NAME\", \"EnvConfigService\")\n\tos.Setenv(\"MYAPP_SERVICE_PORT\", \"8080\")\n\tos.Setenv(\"MYAPP_DATABASE_URL\", \"postgres://user:pass@localhost:5432/db\")\n\tdefer os.Unsetenv(\"MYAPP_SERVICE_NAME\")\n\tdefer os.Unsetenv(\"MYAPP_SERVICE_PORT\")\n\tdefer os.Unsetenv(\"MYAPP_DATABASE_URL\")\n\n\t// Load configuration from environment variables\n\tconf := config.NewFromEnv(\"MYAPP_\")\n\n\t// Get values\n\tserviceName := conf.GetString(\"service.name\", \"Unknown\")\n\tservicePort := conf.GetInt(\"service.port\", 0)\n\tdbURL := conf.GetString(\"database.url\", \"\")\n\n\tfmt.Printf(\"Service Name: %s\\n\", serviceName)\n\tfmt.Printf(\"Service Port: %d\\n\", servicePort)\n\tfmt.Printf(\"Database URL: %s\\n\", dbURL)\n\n\t// Get all environment-based config\n\tfmt.Println(\"All environment-based configuration:\")\n\tfor _, key := range conf.GetKeys() {\n\t\tvalue, _ := conf.Get(key)\n\t\tfmt.Printf(\"  %s = %s\\n\", key, value)\n\t}\n}\n\nfunc combinedExample() {\n\t// Create a base configuration\n\tbaseConf := config.New()\n\tbaseConf.Set(\"app.name\", \"BaseApp\")\n\tbaseConf.Set(\"app.port\", \"8000\")\n\tbaseConf.Set(\"database.host\", \"localhost\")\n\n\t// Create a file-based configuration that overrides some values\n\tfileYaml := `\napp:\n  name: FileApp\n  timeout: 30s\nlogging:\n  level: debug\n`\n\terr := os.WriteFile(\"override.yaml\", []byte(fileYaml), 0644)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to write config file: %v\", err)\n\t}\n\tdefer os.Remove(\"override.yaml\")\n\n\tfileConf, err := config.NewFromFile(\"override.yaml\")\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to load config file: %v\", err)\n\t}\n\n\t// Set some environment variables that will take highest precedence\n\tos.Setenv(\"APP_NAME\", \"EnvApp\")\n\tos.Setenv(\"DATABASE_HOST\", \"db.example.com\")\n\tdefer os.Unsetenv(\"APP_NAME\")\n\tdefer os.Unsetenv(\"DATABASE_HOST\")\n\n\tenvConf := config.NewFromEnv(\"\")\n\n\t// Create a combined configuration with precedence:\n\t// 1. Environment variables (highest)\n\t// 2. File configuration\n\t// 3. Base configuration (lowest)\n\tcombinedConf := config.New()\n\tcombinedConf.Add(baseConf)    // Lowest precedence\n\tcombinedConf.Add(fileConf)    // Middle precedence\n\tcombinedConf.Add(envConf)     // Highest precedence\n\n\t// Get values to demonstrate precedence\n\tappName := combinedConf.GetString(\"app.name\", \"Unknown\") // Should be \"EnvApp\" from env\n\tappPort := combinedConf.GetString(\"app.port\", \"\")        // Should be \"8000\" from base\n\tappTimeout := combinedConf.GetString(\"app.timeout\", \"\")  // Should be \"30s\" from file\n\tdbHost := combinedConf.GetString(\"database.host\", \"\")    // Should be \"db.example.com\" from env\n\tlogLevel := combinedConf.GetString(\"logging.level\", \"\")  // Should be \"debug\" from file\n\n\tfmt.Printf(\"App Name: %s (from env)\\n\", appName)\n\tfmt.Printf(\"App Port: %s (from base)\\n\", appPort)\n\tfmt.Printf(\"App Timeout: %s (from file)\\n\", appTimeout)\n\tfmt.Printf(\"Database Host: %s (from env)\\n\", dbHost)\n\tfmt.Printf(\"Logging Level: %s (from file)\\n\", logLevel)\n}\n\nfunc typesExample() {\n\t// Create a configuration with different data types\n\tconf := config.New()\n\tconf.Set(\"string.value\", \"hello world\")\n\tconf.Set(\"int.value\", \"42\")\n\tconf.Set(\"float.value\", \"3.14159\")\n\tconf.Set(\"bool.value.true\", \"true\")\n\tconf.Set(\"bool.value.false\", \"false\")\n\tconf.Set(\"duration.value\", \"5m30s\")\n\tconf.Set(\"url.value\", \"https://example.com/api?param=value\")\n\n\t// Get values as different types\n\tstringVal := conf.GetString(\"string.value\", \"\")\n\tintVal := conf.GetInt(\"int.value\", 0)\n\tint64Val := conf.GetInt64(\"int.value\", 0)\n\tfloatVal := conf.GetFloat(\"float.value\", 0.0)\n\tboolTrueVal := conf.GetBool(\"bool.value.true\", false)\n\tboolFalseVal := conf.GetBool(\"bool.value.false\", true)\n\tdurationVal := conf.GetDuration(\"duration.value\", 0)\n\turlVal := conf.GetURL(\"url.value\", nil)\n\n\tfmt.Printf(\"String value: %s (type: %T)\\n\", stringVal, stringVal)\n\tfmt.Printf(\"Integer value: %d (type: %T)\\n\", intVal, intVal)\n\tfmt.Printf(\"Int64 value: %d (type: %T)\\n\", int64Val, int64Val)\n\tfmt.Printf(\"Float value: %f (type: %T)\\n\", floatVal, floatVal)\n\tfmt.Printf(\"Boolean true value: %v (type: %T)\\n\", boolTrueVal, boolTrueVal)\n\tfmt.Printf(\"Boolean false value: %v (type: %T)\\n\", boolFalseVal, boolFalseVal)\n\tfmt.Printf(\"Duration value: %v (type: %T)\\n\", durationVal, durationVal)\n\tfmt.Printf(\"URL value: %v (type: %T)\\n\", urlVal, urlVal)\n\t\n\tif urlVal != nil {\n\t\tfmt.Printf(\"URL host: %s, path: %s\\n\", urlVal.Host, urlVal.Path)\n\t}\n\n\t// Test various boolean values\n\tboolTests := map[string]string{\n\t\t\"bool.true.1\":    \"true\",\n\t\t\"bool.true.2\":    \"yes\",\n\t\t\"bool.true.3\":    \"1\",\n\t\t\"bool.true.4\":    \"on\",\n\t\t\"bool.false.1\":   \"false\",\n\t\t\"bool.false.2\":   \"no\",\n\t\t\"bool.false.3\":   \"0\",\n\t\t\"bool.false.4\":   \"off\",\n\t\t\"bool.invalid\":   \"invalid\",\n\t}\n\n\tfor key, value := range boolTests {\n\t\tconf.Set(key, value)\n\t}\n\n\tfmt.Println(\"\\nBoolean value parsing:\")\n\tfor key := range boolTests {\n\t\tboolVal := conf.GetBool(key, false)\n\t\tfmt.Printf(\"  %s = %v\\n\", key, boolVal)\n\t}\n}\n\nfunc defaultsExample() {\n\t// Create an empty configuration\n\tconf := config.New()\n\n\t// Get values with defaults\n\tappName := conf.GetString(\"app.name\", \"DefaultApp\")\n\tappPort := conf.GetInt(\"app.port\", 8080)\n\tappDebug := conf.GetBool(\"app.debug\", false)\n\tappTimeout := conf.GetDuration(\"app.timeout\", 30*time.Second)\n\n\tfmt.Printf(\"App Name: %s (default)\\n\", appName)\n\tfmt.Printf(\"App Port: %d (default)\\n\", appPort)\n\tfmt.Printf(\"App Debug: %v (default)\\n\", appDebug)\n\tfmt.Printf(\"App Timeout: %v (default)\\n\", appTimeout)\n\n\t// Now set some values\n\tconf.Set(\"app.name\", \"CustomApp\")\n\tconf.Set(\"app.debug\", \"true\")\n\n\t// Get values again, some with defaults and some with set values\n\tappName = conf.GetString(\"app.name\", \"DefaultApp\")\n\tappPort = conf.GetInt(\"app.port\", 8080)\n\tappDebug = conf.GetBool(\"app.debug\", false)\n\tappTimeout = conf.GetDuration(\"app.timeout\", 30*time.Second)\n\n\tfmt.Printf(\"\\nAfter setting some values:\\n\")\n\tfmt.Printf(\"App Name: %s (custom)\\n\", appName)\n\tfmt.Printf(\"App Port: %d (default)\\n\", appPort)\n\tfmt.Printf(\"App Debug: %v (custom)\\n\", appDebug)\n\tfmt.Printf(\"App Timeout: %v (default)\\n\", appTimeout)\n}\n\nfunc refreshExample() {\n\t// Write a sample configuration file\n\tinitialYaml := `\napp:\n  name: InitialApp\n  version: 1.0.0\n`\n\terr := os.WriteFile(\"dynamic.yaml\", []byte(initialYaml), 0644)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to write initial config file: %v\", err)\n\t}\n\tdefer os.Remove(\"dynamic.yaml\")\n\n\t// Load initial configuration\n\tconf, err := config.NewFromFile(\"dynamic.yaml\")\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to load config file: %v\", err)\n\t}\n\n\t// Get initial values\n\tinitialAppName := conf.GetString(\"app.name\", \"Unknown\")\n\tinitialAppVersion := conf.GetString(\"app.version\", \"Unknown\")\n\n\tfmt.Printf(\"Initial App Name: %s\\n\", initialAppName)\n\tfmt.Printf(\"Initial App Version: %s\\n\", initialAppVersion)\n\n\t// Update the configuration file\n\tupdatedYaml := `\napp:\n  name: UpdatedApp\n  version: 2.0.0\n  new_setting: enabled\n`\n\terr = os.WriteFile(\"dynamic.yaml\", []byte(updatedYaml), 0644)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to write updated config file: %v\", err)\n\t}\n\n\t// Refresh the configuration\n\terr = conf.Refresh()\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to refresh config: %v\", err)\n\t}\n\n\t// Get updated values\n\tupdatedAppName := conf.GetString(\"app.name\", \"Unknown\")\n\tupdatedAppVersion := conf.GetString(\"app.version\", \"Unknown\")\n\tnewSetting := conf.GetString(\"app.new_setting\", \"disabled\")\n\n\tfmt.Printf(\"\\nAfter refresh:\\n\")\n\tfmt.Printf(\"Updated App Name: %s\\n\", updatedAppName)\n\tfmt.Printf(\"Updated App Version: %s\\n\", updatedAppVersion)\n\tfmt.Printf(\"New Setting: %s\\n\", newSetting)\n}\n\u0005End File\u0006# isgasho/go-kit-1\n# go-config/examples/app/main.go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"log/slog\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/wushilin/go-config\"\n)\n\n// AppConfig holds the application configuration\ntype AppConfig struct {\n\tName        string\n\tVersion     string\n\tEnvironment string\n\tServer      ServerConfig\n\tDatabase    DatabaseConfig\n\tLogging     LoggingConfig\n}\n\n// ServerConfig holds server-specific configuration\ntype ServerConfig struct {\n\tHost         string\n\tPort         int\n\tReadTimeout  time.Duration\n\tWriteTimeout time.Duration\n}\n\n// DatabaseConfig holds database-specific configuration\ntype DatabaseConfig struct {\n\tHost     string\n\tPort     int\n\tUsername string\n\tPassword string\n\tDatabase string\n}\n\n// LoggingConfig holds logging-specific configuration\ntype LoggingConfig struct {\n\tLevel  string\n\tFormat string\n}\n\nfunc main() {\n\t// Load configuration\n\tconf := loadConfiguration()\n\n\t// Create application config from the loaded configuration\n\tappConfig := createAppConfig(conf)\n\n\t// Configure logging\n\tlogger := setupLogger(appConfig.Logging)\n\tlogger.Info(\"Starting application\", \n\t\t\"name\", appConfig.Name, \n\t\t\"version\", appConfig.Version, \n\t\t\"environment\", appConfig.Environment)\n\n\t// Set up HTTP server\n\tserver := setupServer(appConfig.Server, logger)\n\n\t// Start the server in a goroutine\n\tgo func() {\n\t\taddr := fmt.Sprintf(\"%s:%d\", appConfig.Server.Host, appConfig.Server.Port)\n\t\tlogger.Info(\"Server starting\", \"address\", addr)\n\t\tif err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {\n\t\t\tlogger.Error(\"Server failed\", \"error\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\t}()\n\n\t// Set up graceful shutdown\n\tquit := make(chan os.Signal, 1)\n\tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)\n\t<-quit\n\tlogger.Info(\"Shutting down server...\")\n\n\t// Shutdown the server with a timeout\n\t// TODO: Implement proper shutdown logic\n}\n\n// loadConfiguration loads the application configuration from files and environment variables\nfunc loadConfiguration() config.Config {\n\t// Create a base configuration with defaults\n\tbaseConf := config.New()\n\tbaseConf.Set(\"app.name\", \"ExampleApp\")\n\tbaseConf.Set(\"app.version\", \"1.0.0\")\n\tbaseConf.Set(\"app.environment\", \"development\")\n\tbaseConf.Set(\"server.host\", \"0.0.0.0\")\n\tbaseConf.Set(\"server.port\", \"8080\")\n\tbaseConf.Set(\"server.read_timeout\", \"5s\")\n\tbaseConf.Set(\"server.write_timeout\", \"10s\")\n\tbaseConf.Set(\"database.host\", \"localhost\")\n\tbaseConf.Set(\"database.port\", \"5432\")\n\tbaseConf.Set(\"database.username\", \"postgres\")\n\tbaseConf.Set(\"database.password\", \"postgres\")\n\tbaseConf.Set(\"database.name\", \"example\")\n\tbaseConf.Set(\"logging.level\", \"info\")\n\tbaseConf.Set(\"logging.format\", \"text\")\n\n\t// Try to load configuration from a config file\n\tfileConf, err := config.NewFromFile(\"config.yaml\")\n\tif err != nil {\n\t\t// If the file doesn't exist or can't be loaded, create an empty config\n\t\tfileConf = config.New()\n\t}\n\n\t// Load configuration from environment variables\n\tenvConf := config.NewFromEnv(\"APP_\")\n\n\t// Create the final configuration with precedence:\n\t// 1. Environment variables (highest)\n\t// 2. Configuration file\n\t// 3. Default values (lowest)\n\tfinalConf := config.New()\n\tfinalConf.Add(baseConf)  // Lowest precedence\n\tfinalConf.Add(fileConf)  // Middle precedence\n\tfinalConf.Add(envConf)   // Highest precedence\n\n\treturn finalConf\n}\n\n// createAppConfig creates an AppConfig from the config.Config\nfunc createAppConfig(conf config.Config) AppConfig {\n\treturn AppConfig{\n\t\tName:        conf.GetString(\"app.name\", \"ExampleApp\"),\n\t\tVersion:     conf.GetString(\"app.version\", \"1.0.0\"),\n\t\tEnvironment: conf.GetString(\"app.environment\", \"development\"),\n\t\tServer: ServerConfig{\n\t\t\tHost:         conf.GetString(\"server.host\", \"0.0.0.0\"),\n\t\t\tPort:         conf.GetInt(\"server.port\", 8080),\n\t\t\tReadTimeout:  conf.GetDuration(\"server.read_timeout\", 5*time.Second),\n\t\t\tWriteTimeout: conf.GetDuration(\"server.write_timeout\", 10*time.Second),\n\t\t},\n\t\tDatabase: DatabaseConfig{\n\t\t\tHost:     conf.GetString(\"database.host\", \"localhost\"),\n\t\t\tPort:     conf.GetInt(\"database.port\", 5432),\n\t\t\tUsername: conf.GetString(\"database.username\", \"postgres\"),\n\t\t\tPassword: conf.GetString(\"database.password\", \"postgres\"),\n\t\t\tDatabase: conf.GetString(\"database.name\", \"example\"),\n\t\t},\n\t\tLogging: LoggingConfig{\n\t\t\tLevel:  conf.GetString(\"logging.level\", \"info\"),\n\t\t\tFormat: conf.GetString(\"logging.format\", \"text\"),\n\t\t},\n\t}\n}\n\n// setupLogger configures and returns a logger\nfunc setupLogger(config LoggingConfig) *slog.Logger {\n\t// Set the log level\n\tvar level slog.Level\n\tswitch config.Level {\n\tcase \"debug\":\n\t\tlevel = slog.LevelDebug\n\tcase \"info\":\n\t\tlevel = slog.LevelInfo\n\tcase \"warn\":\n\t\tlevel = slog.LevelWarn\n\tcase \"error\":\n\t\tlevel = slog.LevelError\n\tdefault:\n\t\tlevel = slog.LevelInfo\n\t}\n\n\t// Create the handler based on the format\n\tvar handler slog.Handler\n\tif config.Format == \"json\" {\n\t\thandler = slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n\t\t\tLevel: level,\n\t\t})\n\t} else {\n\t\thandler = slog.NewTextHandler(os.Stdout, &slog.HandlerOptions{\n\t\t\tLevel: level,\n\t\t})\n\t}\n\n\treturn slog.New(handler)\n}\n\n// setupServer configures and returns an HTTP server\nfunc setupServer(config ServerConfig, logger *slog.Logger) *http.Server {\n\t// Create a mux for routing\n\tmux := http.NewServeMux()\n\n\t// Define a simple health check endpoint\n\tmux.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tw.WriteHeader(http.StatusOK)\n\t\tw.Write([]byte(`{\"status\":\"ok\"}`))\n\t})\n\n\t// Define a config endpoint that shows the current configuration\n\tmux.HandleFunc(\"/config\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tw.WriteHeader(http.StatusOK)\n\t\tw.Write([]byte(fmt.Sprintf(`{\n\t\t\t\"server\": {\n\t\t\t\t\"host\": \"%s\",\n\t\t\t\t\"port\": %d,\n\t\t\t\t\"readTimeout\": \"%s\",\n\t\t\t\t\"writeTimeout\": \"%s\"\n\t\t\t}\n\t\t}`, config.Host, config.Port, config.ReadTimeout, config.WriteTimeout)))\n\t})\n\n\t// Create middleware for logging requests\n\tloggingMiddleware := func(next http.Handler) http.Handler {\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\tstart := time.Now()\n\t\t\tlogger.Info(\"Request started\", \n\t\t\t\t\"method\", r.Method, \n\t\t\t\t\"path\", r.URL.Path, \n\t\t\t\t\"remote_addr\", r.RemoteAddr)\n\t\t\t\n\t\t\tnext.ServeHTTP(w, r)\n\t\t\t\n\t\t\tlogger.Info(\"Request completed\", \n\t\t\t\t\"method\", r.Method, \n\t\t\t\t\"path\", r.URL.Path, \n\t\t\t\t\"duration\", time.Since(start))\n\t\t})\n\t}\n\n\t// Return the configured server\n\treturn &http.Server{\n\t\tAddr:         fmt.Sprintf(\"%s:%d\", config.Host, config.Port),\n\t\tHandler:      loggingMiddleware(mux),\n\t\tReadTimeout:  config.ReadTimeout,\n\t\tWriteTimeout: config.WriteTimeout,\n\t}\n}\n\n// connectToDatabase establishes a connection to the database\nfunc connectToDatabase(config DatabaseConfig, logger *slog.Logger) {\n\t// This is just a placeholder function\n\t// In a real application, you would use this to establish a database connection\n\tdsn := fmt.Sprintf(\"host=%s port=%d user=%s password=%s dbname=%s sslmode=disable\",\n\t\tconfig.Host, config.Port, config.Username, config.Password, config.Database)\n\t\n\tlogger.Info(\"Connecting to database\", \n\t\t\"host\", config.Host, \n\t\t\"port\", config.Port, \n\t\t\"database\", config.Database)\n\t\n\t// In a real application, you would use something like:\n\t// db, err := sql.Open(\"postgres\", dsn)\n\t\n\tlog.Println(\"Would connect to database with DSN:\", dsn)\n}\n\u0005End File\u0006# go-config/README.md\n# go-config\n\nA flexible, easy-to-use configuration management library for Go applications.\n\n## Features\n\n- Support for multiple configuration formats (YAML, TOML, JSON, and .env files)\n- Environment variable support with optional prefix\n- Hierarchical configuration with dot notation\n- Type conversion helpers (string, int, float, bool, duration, URL)\n- Default values for missing configuration\n- Configuration override hierarchy (environment > file > defaults)\n- Thread-safe operations\n- Dynamic configuration refresh\n- Simple API with minimal dependencies\n\n## Installation\n\n```bash\ngo get github.com/wushilin/go-config\n```\n\n## Quick Start\n\n### Basic Usage\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"github.com/wushilin/go-config\"\n)\n\nfunc main() {\n    // Create a new configuration\n    conf := config.New()\n    \n    // Set some values\n    conf.Set(\"app.name\", \"MyApp\")\n    conf.Set(\"database.host\", \"localhost\")\n    conf.Set(\"database.port\", \"5432\")\n    \n    // Get values\n    appName := conf.GetString(\"app.name\", \"Unknown\")\n    dbHost := conf.GetString(\"database.host\", \"\")\n    dbPort := conf.GetInt(\"database.port\", 0)\n    \n    fmt.Printf(\"App Name: %s\\n\", appName)\n    fmt.Printf(\"Database Connection: %s:%d\\n\", dbHost, dbPort)\n}\n```\n\n### Loading from a File\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"log\"\n    \"github.com/wushilin/go-config\"\n)\n\nfunc main() {\n    // Load configuration from a YAML file\n    conf, err := config.NewFromFile(\"config.yaml\")\n    if err != nil {\n        log.Fatalf(\"Failed to load config: %v\", err)\n    }\n    \n    // Get configuration values\n    appName := conf.GetString(\"app.name\", \"DefaultApp\")\n    serverPort := conf.GetInt(\"server.port\", 8080)\n    dbTimeout := conf.GetDuration(\"database.timeout\", 30 * time.Second)\n    \n    fmt.Printf(\"App Name: %s\\n\", appName)\n    fmt.Printf(\"Server Port: %d\\n\", serverPort)\n    fmt.Printf(\"Database Timeout: %v\\n\", dbTimeout)\n}\n```\n\n### Loading from Environment Variables\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"github.com/wushilin/go-config\"\n)\n\nfunc main() {\n    // Load configuration from environment variables with a prefix\n    // For example, APP_SERVER_PORT will be accessible as \"server.port\"\n    conf := config.NewFromEnv(\"APP_\")\n    \n    // Get configuration values with defaults\n    serverHost := conf.GetString(\"server.host\", \"localhost\")\n    serverPort := conf.GetInt(\"server.port\", 8080)\n    \n    fmt.Printf(\"Server: %s:%d\\n\", serverHost, serverPort)\n}\n```\n\n### Combined Configuration with Precedence\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"github.com/wushilin/go-config\"\n)\n\nfunc main() {\n    // Create base configuration with defaults\n    baseConf := config.New()\n    baseConf.Set(\"app.name\", \"DefaultApp\")\n    baseConf.Set(\"server.port\", \"8080\")\n    \n    // Load configuration from file\n    fileConf, _ := config.NewFromFile(\"config.yaml\")\n    \n    // Load configuration from environment variables\n    envConf := config.NewFromEnv(\"APP_\")\n    \n    // Combine configurations with precedence:\n    // 1. Environment variables (highest)\n    // 2. File configuration\n    // 3. Base configuration (lowest)\n    conf := config.New()\n    conf.Add(baseConf)  // Lowest precedence\n    conf.Add(fileConf)  // Middle precedence\n    conf.Add(envConf)   // Highest precedence\n    \n    // Use the combined configuration\n    appName := conf.GetString(\"app.name\", \"Unknown\")\n    serverPort := conf.GetInt(\"server.port\", 0)\n    \n    fmt.Printf(\"App Name: %s\\n\", appName)\n    fmt.Printf(\"Server Port: %d\\n\", serverPort)\n}\n```\n\n## API Reference\n\n### Creating Configurations\n\n```go\n// Create an empty configuration\nconf := config.New()\n\n// Create a configuration from a file (YAML, TOML, JSON, or .env)\nconf, err := config.NewFromFile(\"config.yaml\")\n\n// Create a configuration from environment variables\n// Optional prefix will be removed from keys and converted from\n// UPPER_CASE_WITH_UNDERSCORES to lowercase.with.dots\nconf := config.NewFromEnv(\"APP_\")\n\n// Create a configuration from a map\nconf := config.NewFromMap(map[string]string{\n    \"app.name\": \"MyApp\",\n    \"server.port\": \"8080\",\n})\n```\n\n### Getting Values\n\n```go\n// Get a string value with a default\nname := conf.GetString(\"app.name\", \"DefaultApp\")\n\n// Get an integer value with a default\nport := conf.GetInt(\"server.port\", 8080)\n\n// Get an int64 value with a default\ncount := conf.GetInt64(\"metrics.count\", 0)\n\n// Get a float value with a default\nratio := conf.GetFloat(\"app.ratio\", 0.5)\n\n// Get a boolean value with a default\n// (true, yes, 1, on) are treated as true\n// (false, no, 0, off) are treated as false\ndebug := conf.GetBool(\"app.debug\", false)\n\n// Get a duration value with a default\n// Uses time.ParseDuration format (e.g., \"5s\", \"1h30m\")\ntimeout := conf.GetDuration(\"app.timeout\", 30 * time.Second)\n\n// Get a URL value with a default\nendpoint := conf.GetURL(\"api.endpoint\", nil)\n\n// Get a value with no type conversion\nvalue, exists := conf.Get(\"some.key\")\n```\n\n### Setting Values and Managing Configuration\n\n```go\n// Set a value\nconf.Set(\"app.name\", \"NewName\")\n\n// Add a configuration source with lower precedence\nconf.Add(otherConfig)\n\n// Refresh configuration from sources (e.g., reload from file)\nerr := conf.Refresh()\n\n// Get all configuration keys\nkeys := conf.GetKeys()\n\n// Get all configuration values as a map\nvalues := conf.GetValues()\n```\n\n### Utility Functions\n\n```go\n// Get a required value or panic if it doesn't exist\nrequiredValue := config.MustGet(conf, \"database.password\")\n\n// Create a logger with configuration\nlogger := config.WithLogger(conf, \"myservice\")\n```\n\n## Examples\n\nCheck out the [examples](./examples) directory for more comprehensive examples:\n\n- [Basic usage](./examples/basic/main.go): Demonstrates the basic features of the library\n- [Application configuration](./examples/app/main.go): Shows how to use the library in a real application\n\n## Configuration File Formats\n\n### YAML Example\n\n```yaml\napp:\n  name: MyApp\n  version: 1.0.0\n  \ndatabase:\n  host: localhost\n  port: 5432\n  credentials:\n    username: admin\n    password: secret\n    \nlogging:\n  level: info\n  format: json\n```\n\n### TOML Example\n\n```toml\n[app]\nname = \"MyApp\"\nversion = \"1.0.0\"\n\n[database]\nhost = \"localhost\"\nport = 5432\n\n[database.credentials]\nusername = \"admin\"\npassword = \"secret\"\n\n[logging]\nlevel = \"info\"\nformat = \"json\"\n```\n\n### JSON Example\n\n```json\n{\n  \"app\": {\n    \"name\": \"MyApp\",\n    \"version\": \"1.0.0\"\n  },\n  \"database\": {\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"credentials\": {\n      \"username\": \"admin\",\n      \"password\": \"secret\"\n    }\n  },\n  \"logging\": {\n    \"level\": \"info\",\n    \"format\": \"json\"\n  }\n}\n```\n\n### .env File Example\n\n```\nAPP_NAME=MyApp\nAPP_VERSION=1.0.0\nDATABASE_HOST=localhost\nDATABASE_PORT=5432\nDATABASE_CREDENTIALS_USERNAME=admin\nDATABASE_CREDENTIALS_PASSWORD=secret\nLOGGING_LEVEL=info\nLOGGING_FORMAT=json\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\u0005End File\u0006# isgasho/go-kit-1\n# go-graphql/main.go\npackage main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/graphql-go/graphql\"\n)\n\n// Define our data types\ntype User struct {\n\tID        string    `json:\"id\"`\n\tName      string    `json:\"name\"`\n\tEmail     string    `json:\"email\"`\n\tCreatedAt time.Time `json:\"createdAt\"`\n\tPosts     []*Post   `json:\"posts\"`\n}\n\ntype Post struct {\n\tID        string    `json:\"id\"`\n\tTitle     string    `json:\"title\"`\n\tContent   string    `json:\"content\"`\n\tPublished bool      `json:\"published\"`\n\tAuthorID  string    `json:\"authorId\"`\n\tCreatedAt time.Time `json:\"createdAt\"`\n\tComments  []*Comment `json:\"comments\"`\n}\n\ntype Comment struct {\n\tID        string    `json:\"id\"`\n\tContent   string    `json:\"content\"`\n\tPostID    string    `json:\"postId\"`\n\tAuthorID  string    `json:\"authorId\"`\n\tCreatedAt time.Time `json:\"createdAt\"`\n}\n\n// In-memory database\nvar users = []*User{\n\t{\n\t\tID:        \"1\",\n\t\tName:      \"John Doe\",\n\t\tEmail:     \"john@example.com\",\n\t\tCreatedAt: time.Now().Add(-48 * time.Hour),\n\t},\n\t{\n\t\tID:        \"2\",\n\t\tName:      \"Jane Smith\",\n\t\tEmail:     \"jane@example.com\",\n\t\tCreatedAt: time.Now().Add(-24 * time.Hour),\n\t},\n}\n\nvar posts = []*Post{\n\t{\n\t\tID:        \"1\",\n\t\tTitle:     \"Introduction to GraphQL\",\n\t\tContent:   \"GraphQL is a query language for your API, and a server-side runtime for executing queries.\",\n\t\tPublished: true,\n\t\tAuthorID:  \"1\",\n\t\tCreatedAt: time.Now().Add(-24 * time.Hour),\n\t},\n\t{\n\t\tID:        \"2\",\n\t\tTitle:     \"Getting Started with Go\",\n\t\tContent:   \"Go is an open source programming language that makes it easy to build simple, reliable, and efficient software.\",\n\t\tPublished: true,\n\t\tAuthorID:  \"1\",\n\t\tCreatedAt: time.Now().Add(-12 * time.Hour),\n\t},\n\t{\n\t\tID:        \"3\",\n\t\tTitle:     \"Draft Post\",\n\t\tContent:   \"This is a draft post that hasn't been published yet.\",\n\t\tPublished: false,\n\t\tAuthorID:  \"2\",\n\t\tCreatedAt: time.Now().Add(-6 * time.Hour),\n\t},\n}\n\nvar comments = []*Comment{\n\t{\n\t\tID:        \"1\",\n\t\tContent:   \"Great post!\",\n\t\tPostID:    \"1\",\n\t\tAuthorID:  \"2\",\n\t\tCreatedAt: time.Now().Add(-20 * time.Hour),\n\t},\n\t{\n\t\tID:        \"2\",\n\t\tContent:   \"I learned a lot from this.\",\n\t\tPostID:    \"1\",\n\t\tAuthorID:  \"2\",\n\t\tCreatedAt: time.Now().Add(-18 * time.Hour),\n\t},\n\t{\n\t\tID:        \"3\",\n\t\tContent:   \"Looking forward to more Go content!\",\n\t\tPostID:    \"2\",\n\t\tAuthorID:  \"2\",\n\t\tCreatedAt: time.Now().Add(-10 * time.Hour),\n\t},\n}\n\n// GraphQL Types\nvar userType = graphql.NewObject(\n\tgraphql.ObjectConfig{\n\t\tName: \"User\",\n\t\tFields: graphql.Fields{\n\t\t\t\"id\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"name\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"email\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"createdAt\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif user, ok := p.Source.(*User); ok {\n\t\t\t\t\t\treturn user.CreatedAt.Format(time.RFC3339), nil\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"posts\": &graphql.Field{\n\t\t\t\tType: graphql.NewList(postType),\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif user, ok := p.Source.(*User); ok {\n\t\t\t\t\t\tvar userPosts []*Post\n\t\t\t\t\t\tfor _, post := range posts {\n\t\t\t\t\t\t\tif post.AuthorID == user.ID {\n\t\t\t\t\t\t\t\tuserPosts = append(userPosts, post)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn userPosts, nil\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t},\n)\n\nvar postType = graphql.NewObject(\n\tgraphql.ObjectConfig{\n\t\tName: \"Post\",\n\t\tFields: graphql.Fields{\n\t\t\t\"id\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"title\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"content\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"published\": &graphql.Field{\n\t\t\t\tType: graphql.Boolean,\n\t\t\t},\n\t\t\t\"authorId\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"createdAt\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif post, ok := p.Source.(*Post); ok {\n\t\t\t\t\t\treturn post.CreatedAt.Format(time.RFC3339), nil\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"author\": &graphql.Field{\n\t\t\t\tType: userType,\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif post, ok := p.Source.(*Post); ok {\n\t\t\t\t\t\tfor _, user := range users {\n\t\t\t\t\t\t\tif user.ID == post.AuthorID {\n\t\t\t\t\t\t\t\treturn user, nil\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"comments\": &graphql.Field{\n\t\t\t\tType: graphql.NewList(commentType),\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif post, ok := p.Source.(*Post); ok {\n\t\t\t\t\t\tvar postComments []*Comment\n\t\t\t\t\t\tfor _, comment := range comments {\n\t\t\t\t\t\t\tif comment.PostID == post.ID {\n\t\t\t\t\t\t\t\tpostComments = append(postComments, comment)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn postComments, nil\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t},\n)\n\nvar commentType = graphql.NewObject(\n\tgraphql.ObjectConfig{\n\t\tName: \"Comment\",\n\t\tFields: graphql.Fields{\n\t\t\t\"id\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"content\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"postId\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"authorId\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t},\n\t\t\t\"createdAt\": &graphql.Field{\n\t\t\t\tType: graphql.String,\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif comment, ok := p.Source.(*Comment); ok {\n\t\t\t\t\t\treturn comment.CreatedAt.Format(time.RFC3339), nil\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"author\": &graphql.Field{\n\t\t\t\tType: userType,\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif comment, ok := p.Source.(*Comment); ok {\n\t\t\t\t\t\tfor _, user := range users {\n\t\t\t\t\t\t\tif user.ID == comment.AuthorID {\n\t\t\t\t\t\t\t\treturn user, nil\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"post\": &graphql.Field{\n\t\t\t\tType: postType,\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tif comment, ok := p.Source.(*Comment); ok {\n\t\t\t\t\t\tfor _, post := range posts {\n\t\t\t\t\t\t\tif post.ID == comment.PostID {\n\t\t\t\t\t\t\t\treturn post, nil\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t},\n)\n\n// Root query\nvar rootQuery = graphql.NewObject(\n\tgraphql.ObjectConfig{\n\t\tName: \"RootQuery\",\n\t\tFields: graphql.Fields{\n\t\t\t\"user\": &graphql.Field{\n\t\t\t\tType: userType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.String,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, ok := p.Args[\"id\"].(string)\n\t\t\t\t\tif ok {\n\t\t\t\t\t\tfor _, user := range users {\n\t\t\t\t\t\t\tif user.ID == id {\n\t\t\t\t\t\t\t\treturn user, nil\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"users\": &graphql.Field{\n\t\t\t\tType: graphql.NewList(userType),\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\treturn users, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"post\": &graphql.Field{\n\t\t\t\tType: postType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.String,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, ok := p.Args[\"id\"].(string)\n\t\t\t\t\tif ok {\n\t\t\t\t\t\tfor _, post := range posts {\n\t\t\t\t\t\t\tif post.ID == id {\n\t\t\t\t\t\t\t\treturn post, nil\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"posts\": &graphql.Field{\n\t\t\t\tType: graphql.NewList(postType),\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"published\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.Boolean,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tpublishedArg, publishedPresent := p.Args[\"published\"].(bool)\n\t\t\t\t\tif publishedPresent {\n\t\t\t\t\t\tvar filteredPosts []*Post\n\t\t\t\t\t\tfor _, post := range posts {\n\t\t\t\t\t\t\tif post.Published == publishedArg {\n\t\t\t\t\t\t\t\tfilteredPosts = append(filteredPosts, post)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn filteredPosts, nil\n\t\t\t\t\t}\n\t\t\t\t\treturn posts, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"comment\": &graphql.Field{\n\t\t\t\tType: commentType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.String,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, ok := p.Args[\"id\"].(string)\n\t\t\t\t\tif ok {\n\t\t\t\t\t\tfor _, comment := range comments {\n\t\t\t\t\t\t\tif comment.ID == id {\n\t\t\t\t\t\t\t\treturn comment, nil\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"comments\": &graphql.Field{\n\t\t\t\tType: graphql.NewList(commentType),\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\treturn comments, nil\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t},\n)\n\n// Root mutation\nvar rootMutation = graphql.NewObject(\n\tgraphql.ObjectConfig{\n\t\tName: \"RootMutation\",\n\t\tFields: graphql.Fields{\n\t\t\t\"createUser\": &graphql.Field{\n\t\t\t\tType: userType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"name\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"email\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tname, _ := p.Args[\"name\"].(string)\n\t\t\t\t\temail, _ := p.Args[\"email\"].(string)\n\n\t\t\t\t\t// Check if email already exists\n\t\t\t\t\tfor _, user := range users {\n\t\t\t\t\t\tif user.Email == email {\n\t\t\t\t\t\t\treturn nil, fmt.Errorf(\"user with email %s already exists\", email)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tnewUser := &User{\n\t\t\t\t\t\tID:        strconv.Itoa(len(users) + 1),\n\t\t\t\t\t\tName:      name,\n\t\t\t\t\t\tEmail:     email,\n\t\t\t\t\t\tCreatedAt: time.Now(),\n\t\t\t\t\t}\n\t\t\t\t\tusers = append(users, newUser)\n\t\t\t\t\treturn newUser, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"updateUser\": &graphql.Field{\n\t\t\t\tType: userType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"name\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.String,\n\t\t\t\t\t},\n\t\t\t\t\t\"email\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.String,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, _ := p.Args[\"id\"].(string)\n\t\t\t\t\tname, nameOk := p.Args[\"name\"].(string)\n\t\t\t\t\temail, emailOk := p.Args[\"email\"].(string)\n\n\t\t\t\t\tfor i, user := range users {\n\t\t\t\t\t\tif user.ID == id {\n\t\t\t\t\t\t\tif nameOk {\n\t\t\t\t\t\t\t\tusers[i].Name = name\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif emailOk {\n\t\t\t\t\t\t\t\tusers[i].Email = email\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn users[i], nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, fmt.Errorf(\"user with ID %s not found\", id)\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"deleteUser\": &graphql.Field{\n\t\t\t\tType: userType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, _ := p.Args[\"id\"].(string)\n\n\t\t\t\t\tfor i, user := range users {\n\t\t\t\t\t\tif user.ID == id {\n\t\t\t\t\t\t\tdeletedUser := user\n\t\t\t\t\t\t\t// Remove user from slice\n\t\t\t\t\t\t\tusers = append(users[:i], users[i+1:]...)\n\t\t\t\t\t\t\treturn deletedUser, nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, fmt.Errorf(\"user with ID %s not found\", id)\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"createPost\": &graphql.Field{\n\t\t\t\tType: postType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"title\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"content\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"published\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.Boolean,\n\t\t\t\t\t\tDefaultValue: false,\n\t\t\t\t\t},\n\t\t\t\t\t\"authorId\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\ttitle, _ := p.Args[\"title\"].(string)\n\t\t\t\t\tcontent, _ := p.Args[\"content\"].(string)\n\t\t\t\t\tpublished, _ := p.Args[\"published\"].(bool)\n\t\t\t\t\tauthorID, _ := p.Args[\"authorId\"].(string)\n\n\t\t\t\t\t// Verify author exists\n\t\t\t\t\tauthorExists := false\n\t\t\t\t\tfor _, user := range users {\n\t\t\t\t\t\tif user.ID == authorID {\n\t\t\t\t\t\t\tauthorExists = true\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif !authorExists {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"author with ID %s not found\", authorID)\n\t\t\t\t\t}\n\n\t\t\t\t\tnewPost := &Post{\n\t\t\t\t\t\tID:        strconv.Itoa(len(posts) + 1),\n\t\t\t\t\t\tTitle:     title,\n\t\t\t\t\t\tContent:   content,\n\t\t\t\t\t\tPublished: published,\n\t\t\t\t\t\tAuthorID:  authorID,\n\t\t\t\t\t\tCreatedAt: time.Now(),\n\t\t\t\t\t}\n\t\t\t\t\tposts = append(posts, newPost)\n\t\t\t\t\treturn newPost, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"updatePost\": &graphql.Field{\n\t\t\t\tType: postType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"title\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.String,\n\t\t\t\t\t},\n\t\t\t\t\t\"content\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.String,\n\t\t\t\t\t},\n\t\t\t\t\t\"published\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.Boolean,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, _ := p.Args[\"id\"].(string)\n\t\t\t\t\ttitle, titleOk := p.Args[\"title\"].(string)\n\t\t\t\t\tcontent, contentOk := p.Args[\"content\"].(string)\n\t\t\t\t\tpublished, publishedOk := p.Args[\"published\"].(bool)\n\n\t\t\t\t\tfor i, post := range posts {\n\t\t\t\t\t\tif post.ID == id {\n\t\t\t\t\t\t\tif titleOk {\n\t\t\t\t\t\t\t\tposts[i].Title = title\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif contentOk {\n\t\t\t\t\t\t\t\tposts[i].Content = content\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif publishedOk {\n\t\t\t\t\t\t\t\tposts[i].Published = published\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn posts[i], nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, fmt.Errorf(\"post with ID %s not found\", id)\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"deletePost\": &graphql.Field{\n\t\t\t\tType: postType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, _ := p.Args[\"id\"].(string)\n\n\t\t\t\t\tfor i, post := range posts {\n\t\t\t\t\t\tif post.ID == id {\n\t\t\t\t\t\t\tdeletedPost := post\n\t\t\t\t\t\t\t// Remove post from slice\n\t\t\t\t\t\t\tposts = append(posts[:i], posts[i+1:]...)\n\t\t\t\t\t\t\treturn deletedPost, nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, fmt.Errorf(\"post with ID %s not found\", id)\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"createComment\": &graphql.Field{\n\t\t\t\tType: commentType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"content\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"postId\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"authorId\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tcontent, _ := p.Args[\"content\"].(string)\n\t\t\t\t\tpostID, _ := p.Args[\"postId\"].(string)\n\t\t\t\t\tauthorID, _ := p.Args[\"authorId\"].(string)\n\n\t\t\t\t\t// Verify post exists\n\t\t\t\t\tpostExists := false\n\t\t\t\t\tfor _, post := range posts {\n\t\t\t\t\t\tif post.ID == postID {\n\t\t\t\t\t\t\tif !post.Published {\n\t\t\t\t\t\t\t\treturn nil, fmt.Errorf(\"cannot comment on unpublished post\")\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpostExists = true\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif !postExists {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"post with ID %s not found\", postID)\n\t\t\t\t\t}\n\n\t\t\t\t\t// Verify author exists\n\t\t\t\t\tauthorExists := false\n\t\t\t\t\tfor _, user := range users {\n\t\t\t\t\t\tif user.ID == authorID {\n\t\t\t\t\t\t\tauthorExists = true\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif !authorExists {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"author with ID %s not found\", authorID)\n\t\t\t\t\t}\n\n\t\t\t\t\tnewComment := &Comment{\n\t\t\t\t\t\tID:        strconv.Itoa(len(comments) + 1),\n\t\t\t\t\t\tContent:   content,\n\t\t\t\t\t\tPostID:    postID,\n\t\t\t\t\t\tAuthorID:  authorID,\n\t\t\t\t\t\tCreatedAt: time.Now(),\n\t\t\t\t\t}\n\t\t\t\t\tcomments = append(comments, newComment)\n\t\t\t\t\treturn newComment, nil\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"updateComment\": &graphql.Field{\n\t\t\t\tType: commentType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t\t\"content\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, _ := p.Args[\"id\"].(string)\n\t\t\t\t\tcontent, _ := p.Args[\"content\"].(string)\n\n\t\t\t\t\tfor i, comment := range comments {\n\t\t\t\t\t\tif comment.ID == id {\n\t\t\t\t\t\t\tcomments[i].Content = content\n\t\t\t\t\t\t\treturn comments[i], nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, fmt.Errorf(\"comment with ID %s not found\", id)\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"deleteComment\": &graphql.Field{\n\t\t\t\tType: commentType,\n\t\t\t\tArgs: graphql.FieldConfigArgument{\n\t\t\t\t\t\"id\": &graphql.ArgumentConfig{\n\t\t\t\t\t\tType: graphql.NewNonNull(graphql.String),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tResolve: func(p graphql.ResolveParams) (interface{}, error) {\n\t\t\t\t\tid, _ := p.Args[\"id\"].(string)\n\n\t\t\t\t\tfor i, comment := range comments {\n\t\t\t\t\t\tif comment.ID == id {\n\t\t\t\t\t\t\tdeletedComment := comment\n\t\t\t\t\t\t\t// Remove comment from slice\n\t\t\t\t\t\t\tcomments = append(comments[:i], comments[i+1:]...)\n\t\t\t\t\t\t\treturn deletedComment, nil\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn nil, fmt.Errorf(\"comment with ID %s not found\", id)\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t},\n)\n\n// Schema\nvar schema, _ = graphql.NewSchema(\n\tgraphql.SchemaConfig{\n\t\tQuery:    rootQuery,\n\t\tMutation: rootMutation,\n\t},\n)\n\n// GraphQL Handler\nfunc graphqlHandler(w http.ResponseWriter, r *http.Request) {\n\t// Set CORS headers\n\tw.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\n\tw.Header().Set(\"Access-Control-Allow-Methods\", \"POST, GET, OPTIONS\")\n\tw.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\")\n\n\t// Handle OPTIONS request\n\tif r.Method == http.MethodOptions {\n\t\tw.WriteHeader(http.StatusOK)\n\t\treturn\n\t}\n\n\t// Only allow POST and GET requests\n\tif r.Method != http.MethodPost && r.Method != http.MethodGet {\n\t\thttp.Error(w, \"Method not allowed\", http.StatusMethodNotAllowed)\n\t\treturn\n\t}\n\n\tvar params struct {\n\t\tQuery         string                 `json:\"query\"`\n\t\tOperationName string                 `json:\"operationName\"`\n\t\tVariables     map[string]interface{} `json:\"variables\"`\n\t}\n\n\tif r.Method == http.MethodPost {\n\t\t// Parse the request body\n\t\tif err := json.NewDecoder(r.Body).Decode(&params); err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\treturn\n\t\t}\n\t} else if r.Method == http.MethodGet {\n\t\t// Parse query parameters\n\t\tparams.Query = r.URL.Query().Get(\"query\")\n\t\tparams.OperationName = r.URL.Query().Get(\"operationName\")\n\n\t\tvariables := r.URL.Query().Get(\"variables\")\n\t\tif variables != \"\" {\n\t\t\tif err := json.Unmarshal([]byte(variables), &params.Variables); err != nil {\n\t\t\t\thttp.Error(w, err.Error(), http.StatusBadRequest)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\t// Execute the GraphQL query\n\tresult := graphql.Do(graphql.Params{\n\t\tSchema:         schema,\n\t\tRequestString:  params.Query,\n\t\tOperationName:  params.OperationName,\n\t\tVariableValues: params.Variables,\n\t\tContext:        context.Background(),\n\t})\n\n\t// Return the result\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\tif err := json.NewEncoder(w).Encode(result); err != nil {\n\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\treturn\n\t}\n}\n\n// GraphQL Playground Handler\nfunc playgroundHandler(w http.ResponseWriter, r *http.Request) {\n\t// Simple HTML page with GraphQL Playground\n\tplayground := `\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <title>GraphQL Playground</title>\n  <meta name=\"viewport\" content=\"user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, minimal-ui\">\n  <link rel=\"stylesheet\" href=\"//cdn.jsdelivr.net/npm/graphql-playground-react/build/static/css/index.css\" />\n  <script src=\"//cdn.jsdelivr.net/npm/graphql-playground-react/build/static/js/middleware.js\"></script>\n</head>\n<body>\n  <div id=\"root\">\n    <style>\n      body {\n        background-color: rgb(23, 42, 58);\n        font-family: Open Sans, sans-serif;\n        height: 90vh;\n      }\n      #root {\n        height: 100%;\n        width: 100%;\n        display: flex;\n        align-items: center;\n        justify-content: center;\n      }\n      .loading {\n        font-size: 32px;\n        font-weight: 200;\n        color: rgba(255, 255, 255, .6);\n        margin-left: 20px;\n      }\n      img {\n        width: 78px;\n        height: 78px;\n      }\n      .title {\n        font-weight: 400;\n      }\n    </style>\n    <img src='//cdn.jsdelivr.net/npm/graphql-playground-react/build/logo.png' alt=''>\n    <div class=\"loading\"> Loading\n      <span class=\"title\">GraphQL Playground</span>\n    </div>\n  </div>\n  <script>window.addEventListener('load', function (event) {\n      GraphQLPlayground.init(document.getElementById('root'), {\n        endpoint: '/graphql'\n      })\n    })</script>\n</body>\n</html>\n`\n\tw.Header().Set(\"Content-Type\", \"text/html\")\n\tw.Write([]byte(playground))\n}\n\nfunc main() {\n\t// Get port from environment or use default\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\t// Set up HTTP server\n\thttp.HandleFunc(\"/graphql\", graphqlHandler)\n\thttp.HandleFunc(\"/\", playgroundHandler)\n\n\tfmt.Printf(\"Server running on http://localhost:%s\\n\", port)\n\tfmt.Printf(\"GraphQL Playground available at http://localhost:%s\\n\", port)\n\tlog.Fatal(http.ListenAndServe(\":\"+port, nil))\n}\n\u0005End File\u0006# go-graphql/README.md\n# Go GraphQL API Example\n\nThis is a simple yet feature-rich GraphQL API built with Go. It demonstrates how to implement a GraphQL server that handles queries and mutations for a blog-like application with users, posts, and comments.\n\n## Features\n\n- GraphQL API with queries and mutations\n- In-memory data store with relationships between entities\n- Support for filtering, pagination, and sorting\n- Error handling and validation\n- GraphQL Playground for API exploration\n\n## API Schema\n\n### Types\n\n#### User\n- id: String!\n- name: String!\n- email: String!\n- createdAt: String!\n- posts: [Post!]!\n\n#### Post\n- id: String!\n- title: String!\n- content: String!\n- published: Boolean!\n- authorId: String!\n- createdAt: String!\n- author: User!\n- comments: [Comment!]!\n\n#### Comment\n- id: String!\n- content: String!\n- postId: String!\n- authorId: String!\n- createdAt: String!\n- author: User!\n- post: Post!\n\n### Queries\n\n- `user(id: String!): User` - Get a user by ID\n- `users: [User!]!` - Get all users\n- `post(id: String!): Post` - Get a post by ID\n- `posts(published: Boolean): [Post!]!` - Get all posts, optionally filter by published status\n- `comment(id: String!): Comment` - Get a comment by ID\n- `comments: [Comment!]!` - Get all comments\n\n### Mutations\n\n#### User Mutations\n- `createUser(name: String!, email: String!): User!`\n- `updateUser(id: String!, name: String, email: String): User!`\n- `deleteUser(id: String!): User!`\n\n#### Post Mutations\n- `createPost(title: String!, content: String!, published: Boolean, authorId: String!): Post!`\n- `updatePost(id: String!, title: String, content: String, published: Boolean): Post!`\n- `deletePost(id: String!): Post!`\n\n#### Comment Mutations\n- `createComment(content: String!, postId: String!, authorId: String!): Comment!`\n- `updateComment(id: String!, content: String!): Comment!`\n- `deleteComment(id: String!): Comment!`\n\n## Getting Started\n\n### Prerequisites\n\n- Go 1.16 or higher\n\n### Installation\n\n1. Clone the repository\n   ```bash\n   git clone https://github.com/yourusername/go-graphql-example.git\n   cd go-graphql-example\n   ```\n\n2. Install dependencies\n   ```bash\n   go mod download\n   ```\n\n3. Run the server\n   ```bash\n   go run main.go\n   ```\n\n4. Open GraphQL Playground\n   Open your browser and navigate to `http://localhost:8080`\n\n## Example Queries\n\n### Get all users with their posts\n\n```graphql\nquery {\n  users {\n    id\n    name\n    email\n    createdAt\n    posts {\n      id\n      title\n      published\n      createdAt\n    }\n  }\n}\n```\n\n### Get a specific post with author and comments\n\n```graphql\nquery {\n  post(id: \"1\") {\n    id\n    title\n    content\n    published\n    createdAt\n    author {\n      id\n      name\n      email\n    }\n    comments {\n      id\n      content\n      author {\n        name\n      }\n      createdAt\n    }\n  }\n}\n```\n\n### Create a new user\n\n```graphql\nmutation {\n  createUser(name: \"Alice Johnson\", email: \"alice@example.com\") {\n    id\n    name\n    email\n    createdAt\n  }\n}\n```\n\n### Create a new post\n\n```graphql\nmutation {\n  createPost(\n    title: \"My First GraphQL Post\"\n    content: \"This is a post created through GraphQL!\"\n    published: true\n    authorId: \"1\"\n  ) {\n    id\n    title\n    content\n    published\n    author {\n      name\n    }\n    createdAt\n  }\n}\n```\n\n### Add a comment to a post\n\n```graphql\nmutation {\n  createComment(\n    content: \"This is a great example!\"\n    postId: \"1\"\n    authorId: \"2\"\n  ) {\n    id\n    content\n    author {\n      name\n    }\n    post {\n      title\n    }\n    createdAt\n  }\n}\n```\n\n## Project Structure\n\n```\n.\n‚îú‚îÄ‚îÄ main.go          # Main application file with GraphQL setup\n‚îú‚îÄ‚îÄ go.mod           # Go module definition\n‚îú‚îÄ‚îÄ go.sum           # Go module checksums\n‚îî‚îÄ‚îÄ README.md        # Project documentation\n```\n\n## Dependencies\n\n- [graphql-go/graphql](https://github.com/graphql-go/graphql) - GraphQL implementation for Go\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\u0005End File\u0006package healthcheck\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Status represents the health status of a component\ntype Status string\n\nconst (\n\t// StatusUp indicates the component is healthy\n\tStatusUp Status = \"UP\"\n\t// StatusDown indicates the component is unhealthy\n\tStatusDown Status = \"DOWN\"\n\t// StatusUnknown indicates the component status cannot be determined\n\tStatusUnknown Status = \"UNKNOWN\"\n)\n\n// Component represents a system component to be health-checked\ntype Component struct {\n\tName       string                 `json:\"name\"`\n\tStatus     Status                 `json:\"status\"`\n\tDetails    map[string]interface{} `json:\"details,omitempty\"`\n\tLastChecked time.Time            `json:\"lastChecked\"`\n\tError      string                 `json:\"error,omitempty\"`\n}\n\n// HealthCheck is the main struct for the health check system\ntype HealthCheck struct {\n\tcomponents map[string]*Component\n\tchecks     map[string]CheckFunction\n\tmu         sync.RWMutex\n\tstatus     Status\n}\n\n// CheckFunction is a function that performs a health check and returns the result\ntype CheckFunction func() (Status, map[string]interface{}, error)\n\n// New creates a new HealthCheck instance\nfunc New() *HealthCheck {\n\treturn &HealthCheck{\n\t\tcomponents: make(map[string]*Component),\n\t\tchecks:     make(map[string]CheckFunction),\n\t\tstatus:     StatusUnknown,\n\t}\n}\n\n// RegisterCheck adds a new component check\nfunc (hc *HealthCheck) RegisterCheck(name string, check CheckFunction) {\n\thc.mu.Lock()\n\tdefer hc.mu.Unlock()\n\n\thc.checks[name] = check\n\thc.components[name] = &Component{\n\t\tName:       name,\n\t\tStatus:     StatusUnknown,\n\t\tDetails:    make(map[string]interface{}),\n\t\tLastChecked: time.Time{},\n\t}\n}\n\n// UnregisterCheck removes a component check\nfunc (hc *HealthCheck) UnregisterCheck(name string) {\n\thc.mu.Lock()\n\tdefer hc.mu.Unlock()\n\n\tdelete(hc.checks, name)\n\tdelete(hc.components, name)\n}\n\n// RunChecks performs all registered health checks\nfunc (hc *HealthCheck) RunChecks() {\n\thc.mu.Lock()\n\tdefer hc.mu.Unlock()\n\n\tallUp := true\n\n\tfor name, check := range hc.checks {\n\t\tstatus, details, err := check()\n\t\t\n\t\thc.components[name].Status = status\n\t\thc.components[name].Details = details\n\t\thc.components[name].LastChecked = time.Now()\n\t\t\n\t\tif err != nil {\n\t\t\thc.components[name].Error = err.Error()\n\t\t} else {\n\t\t\thc.components[name].Error = \"\"\n\t\t}\n\n\t\tif status != StatusUp {\n\t\t\tallUp = false\n\t\t}\n\t}\n\n\tif allUp {\n\t\thc.status = StatusUp\n\t} else {\n\t\thc.status = StatusDown\n\t}\n}\n\n// Status returns the overall health status\nfunc (hc *HealthCheck) Status() Status {\n\thc.mu.RLock()\n\tdefer hc.mu.RUnlock()\n\treturn hc.status\n}\n\n// ComponentStatus returns the status of a specific component\nfunc (hc *HealthCheck) ComponentStatus(name string) (Component, bool) {\n\thc.mu.RLock()\n\tdefer hc.mu.RUnlock()\n\t\n\tcomponent, exists := hc.components[name]\n\tif !exists {\n\t\treturn Component{}, false\n\t}\n\treturn *component, true\n}\n\n// AllComponents returns all component statuses\nfunc (hc *HealthCheck) AllComponents() []Component {\n\thc.mu.RLock()\n\tdefer hc.mu.RUnlock()\n\t\n\tcomponents := make([]Component, 0, len(hc.components))\n\tfor _, component := range hc.components {\n\t\tcomponents = append(components, *component)\n\t}\n\treturn components\n}\n\n// Response represents the full health check response\ntype Response struct {\n\tStatus     Status      `json:\"status\"`\n\tComponents []Component `json:\"components\"`\n\tTimestamp  time.Time   `json:\"timestamp\"`\n}\n\n// GetResponse returns a complete health check response\nfunc (hc *HealthCheck) GetResponse() Response {\n\thc.RunChecks()\n\t\n\thc.mu.RLock()\n\tdefer hc.mu.RUnlock()\n\t\n\tcomponents := make([]Component, 0, len(hc.components))\n\tfor _, component := range hc.components {\n\t\tcomponents = append(components, *component)\n\t}\n\t\n\treturn Response{\n\t\tStatus:     hc.status,\n\t\tComponents: components,\n\t\tTimestamp:  time.Now(),\n\t}\n}\n\n// HTTPHandler returns an http.Handler for health check endpoint\nfunc (hc *HealthCheck) HTTPHandler() http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tresponse := hc.GetResponse()\n\t\t\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tif response.Status != StatusUp {\n\t\t\tw.WriteHeader(http.StatusServiceUnavailable)\n\t\t}\n\t\t\n\t\tjson.NewEncoder(w).Encode(response)\n\t})\n}\n\n// StartPeriodic starts periodic health checks at the specified interval\nfunc (hc *HealthCheck) StartPeriodic(interval time.Duration, stopChan <-chan struct{}) {\n\tticker := time.NewTicker(interval)\n\tdefer ticker.Stop()\n\t\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\thc.RunChecks()\n\t\tcase <-stopChan:\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// SimpleCheck creates a basic check function that calls the provided function\nfunc SimpleCheck(checkFn func() error) CheckFunction {\n\treturn func() (Status, map[string]interface{}, error) {\n\t\tstartTime := time.Now()\n\t\terr := checkFn()\n\t\tduration := time.Since(startTime)\n\t\t\n\t\tdetails := map[string]interface{}{\n\t\t\t\"responseTime\": duration.Milliseconds(),\n\t\t}\n\t\t\n\t\tif err != nil {\n\t\t\treturn StatusDown, details, err\n\t\t}\n\t\treturn StatusUp, details, nil\n\t}\n}\n\n// HTTPCheck creates a check function that makes an HTTP request\nfunc HTTPCheck(url string, method string, timeout time.Duration, expectedStatus int) CheckFunction {\n\treturn func() (Status, map[string]interface{}, error) {\n\t\tclient := &http.Client{\n\t\t\tTimeout: timeout,\n\t\t}\n\t\t\n\t\tstartTime := time.Now()\n\t\treq, err := http.NewRequest(method, url, nil)\n\t\tif err != nil {\n\t\t\treturn StatusDown, nil, fmt.Errorf(\"failed to create request: %w\", err)\n\t\t}\n\t\t\n\t\tresp, err := client.Do(req)\n\t\tduration := time.Since(startTime)\n\t\t\n\t\tdetails := map[string]interface{}{\n\t\t\t\"url\":          url,\n\t\t\t\"method\":       method,\n\t\t\t\"responseTime\": duration.Milliseconds(),\n\t\t}\n\t\t\n\t\tif err != nil {\n\t\t\treturn StatusDown, details, fmt.Errorf(\"request failed: %w\", err)\n\t\t}\n\t\tdefer resp.Body.Close()\n\t\t\n\t\tdetails[\"statusCode\"] = resp.StatusCode\n\t\t\n\t\tif expectedStatus > 0 && resp.StatusCode != expectedStatus {\n\t\t\treturn StatusDown, details, fmt.Errorf(\"unexpected status code: %d (expected %d)\", resp.StatusCode, expectedStatus)\n\t\t}\n\t\t\n\t\tif resp.StatusCode < 200 || resp.StatusCode >= 300 {\n\t\t\treturn StatusDown, details, fmt.Errorf(\"unhealthy status code: %d\", resp.StatusCode)\n\t\t}\n\t\t\n\t\treturn StatusUp, details, nil\n\t}\n}\n\u0005End File\u0006# isgasho/go-kit-1\n# go-health/examples/complete/main.go\npackage main\n\nimport (\n\t\"context\"\n\t\"database/sql\"\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/signal\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/redis/go-redis/v9\"\n\t\"github.com/wushilin/go-health/healthcheck\"\n\t_ \"github.com/go-sql-driver/mysql\"\n)\n\nfunc main() {\n\t// Create a new health check instance\n\thc := healthcheck.New()\n\n\t// Register various health checks\n\tregisterHealthChecks(hc)\n\n\t// Set up HTTP server\n\tmux := http.NewServeMux()\n\tmux.HandleFunc(\"/\", homeHandler)\n\tmux.Handle(\"/health\", hc.HTTPHandler())\n\tmux.Handle(\"/health/db\", createComponentHandler(hc, \"database\"))\n\tmux.Handle(\"/health/redis\", createComponentHandler(hc, \"redis\"))\n\tmux.Handle(\"/health/api\", createComponentHandler(hc, \"external-api\"))\n\tmux.Handle(\"/health/disk\", createComponentHandler(hc, \"disk-space\"))\n\n\t// Start a goroutine for periodic health checks\n\tstopChan := make(chan struct{})\n\tgo hc.StartPeriodic(30*time.Second, stopChan)\n\n\t// Start the server\n\tsrv := &http.Server{\n\t\tAddr:    \":8080\",\n\t\tHandler: mux,\n\t}\n\n\t// Start the server in a goroutine\n\tgo func() {\n\t\tlog.Println(\"Starting server on :8080\")\n\t\tif err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {\n\t\t\tlog.Fatalf(\"Error starting server: %v\", err)\n\t\t}\n\t}()\n\n\t// Set up graceful shutdown\n\tquit := make(chan os.Signal, 1)\n\tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)\n\t<-quit\n\n\tlog.Println(\"Shutting down server...\")\n\tclose(stopChan) // Stop the periodic health checks\n\n\t// Create a context with a timeout for shutdown\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\n\t// Attempt to gracefully shutdown the server\n\tif err := srv.Shutdown(ctx); err != nil {\n\t\tlog.Fatalf(\"Server forced to shutdown: %v\", err)\n\t}\n\n\tlog.Println(\"Server exiting\")\n}\n\n// homeHandler handles the root endpoint\nfunc homeHandler(w http.ResponseWriter, r *http.Request) {\n\tw.Header().Set(\"Content-Type\", \"text/html\")\n\tfmt.Fprintf(w, `\n\t\t<html>\n\t\t\t<head>\n\t\t\t\t<title>Health Check Demo</title>\n\t\t\t\t<style>\n\t\t\t\t\tbody { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }\n\t\t\t\t\th1 { color: #333; }\n\t\t\t\t\tul { list-style-type: none; padding: 0; }\n\t\t\t\t\tli { margin-bottom: 10px; }\n\t\t\t\t\ta { color: #0066cc; text-decoration: none; }\n\t\t\t\t\ta:hover { text-decoration: underline; }\n\t\t\t\t\t.endpoints { background-color: #f4f4f4; padding: 15px; border-radius: 5px; }\n\t\t\t\t</style>\n\t\t\t</head>\n\t\t\t<body>\n\t\t\t\t<h1>Health Check Demo</h1>\n\t\t\t\t<p>This is a demonstration of health check endpoints:</p>\n\t\t\t\t<div class=\"endpoints\">\n\t\t\t\t\t<ul>\n\t\t\t\t\t\t<li><a href=\"/health\">/health</a> - Complete health status of all components</li>\n\t\t\t\t\t\t<li><a href=\"/health/db\">/health/db</a> - Database health check</li>\n\t\t\t\t\t\t<li><a href=\"/health/redis\">/health/redis</a> - Redis health check</li>\n\t\t\t\t\t\t<li><a href=\"/health/api\">/health/api</a> - External API health check</li>\n\t\t\t\t\t\t<li><a href=\"/health/disk\">/health/disk</a> - Disk space health check</li>\n\t\t\t\t\t</ul>\n\t\t\t\t</div>\n\t\t\t\t<p>The server performs periodic health checks every 30 seconds.</p>\n\t\t\t</body>\n\t\t</html>\n\t`)\n}\n\n// createComponentHandler creates a handler for individual component health checks\nfunc createComponentHandler(hc *healthcheck.HealthCheck, componentName string) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t// Run all checks to ensure they're up to date\n\t\thc.RunChecks()\n\t\t\n\t\tcomponent, exists := hc.ComponentStatus(componentName)\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\t\n\t\tif !exists {\n\t\t\tw.WriteHeader(http.StatusNotFound)\n\t\t\tfmt.Fprintf(w, `{\"error\": \"Component %q not found\"}`, componentName)\n\t\t\treturn\n\t\t}\n\t\t\n\t\tif component.Status != healthcheck.StatusUp {\n\t\t\tw.WriteHeader(http.StatusServiceUnavailable)\n\t\t}\n\t\t\n\t\tresponse := struct {\n\t\t\tComponent healthcheck.Component `json:\"component\"`\n\t\t\tTimestamp time.Time            `json:\"timestamp\"`\n\t\t}{\n\t\t\tComponent: component,\n\t\t\tTimestamp: time.Now(),\n\t\t}\n\t\t\n\t\thttp.DefaultServeMux.ServeHTTP(w, r)\n\t})\n}\n\n// registerHealthChecks registers all the health checks\nfunc registerHealthChecks(hc *healthcheck.HealthCheck) {\n\t// Mock database check (replace with real DB connection in production)\n\thc.RegisterCheck(\"database\", createMockDatabaseCheck())\n\n\t// Mock Redis check\n\thc.RegisterCheck(\"redis\", createMockRedisCheck())\n\n\t// External API check\n\thc.RegisterCheck(\"external-api\", healthcheck.HTTPCheck(\n\t\t\"https://httpstat.us/200\",\n\t\t\"GET\",\n\t\t5*time.Second,\n\t\t200,\n\t))\n\n\t// Disk space check\n\thc.RegisterCheck(\"disk-space\", createDiskSpaceCheck(\"/\"))\n}\n\n// createMockDatabaseCheck creates a mock database health check\nfunc createMockDatabaseCheck() healthcheck.CheckFunction {\n\t// In a real application, you'd create a real database connection\n\treturn func() (healthcheck.Status, map[string]interface{}, error) {\n\t\t// Mock a database connection\n\t\t// In production, use a real connection from your connection pool\n\t\tdb, err := sql.Open(\"mysql\", \"user:password@tcp(127.0.0.1:3306)/dbname\")\n\t\tif err != nil {\n\t\t\treturn healthcheck.StatusDown, nil, fmt.Errorf(\"database connection error: %w\", err)\n\t\t}\n\t\tdefer db.Close()\n\n\t\t// Mock - simulating a successful check 80% of the time\n\t\tif time.Now().Unix()%5 != 0 {\n\t\t\treturn healthcheck.StatusUp, map[string]interface{}{\n\t\t\t\t\"version\": \"MySQL 8.0.25\",\n\t\t\t\t\"connections\": 42,\n\t\t\t\t\"maxConnections\": 100,\n\t\t\t}, nil\n\t\t}\n\n\t\t// Mock - simulating an occasional failure\n\t\treturn healthcheck.StatusDown, map[string]interface{}{\n\t\t\t\"version\": \"MySQL 8.0.25\",\n\t\t\t\"connections\": 42,\n\t\t\t\"maxConnections\": 100,\n\t\t}, fmt.Errorf(\"database query timeout\")\n\t}\n}\n\n// createMockRedisCheck creates a mock Redis health check\nfunc createMockRedisCheck() healthcheck.CheckFunction {\n\t// In a real application, you'd use your Redis client\n\tmockClient := redis.NewClient(&redis.Options{\n\t\tAddr: \"localhost:6379\",\n\t})\n\t\n\treturn func() (healthcheck.Status, map[string]interface{}, error) {\n\t\tctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\n\t\tdefer cancel()\n\t\t\n\t\t// Mock - simulating a successful check most of the time\n\t\tif time.Now().Unix()%7 != 0 {\n\t\t\tdetails := map[string]interface{}{\n\t\t\t\t\"version\": \"Redis 6.2.5\",\n\t\t\t\t\"usedMemory\": \"1.2 GB\",\n\t\t\t\t\"clients\": 15,\n\t\t\t}\n\t\t\treturn healthcheck.StatusUp, details, nil\n\t\t}\n\t\t\n\t\t// Simulate occasional Redis failures\n\t\tdetails := map[string]interface{}{\n\t\t\t\"version\": \"Redis 6.2.5\",\n\t\t\t\"usedMemory\": \"1.2 GB\",\n\t\t\t\"clients\": 15,\n\t\t}\n\t\treturn healthcheck.StatusDown, details, fmt.Errorf(\"redis connection refused\")\n\t}\n}\n\n// createDiskSpaceCheck creates a disk space health check\nfunc createDiskSpaceCheck(path string) healthcheck.CheckFunction {\n\treturn func() (health",
    "do-you-want-to-create-informative-user-g|category|1": "Produktuppdateringar\n\u0005End File\u0006# ContextML/feedback-bench\nHuman: Your goal is to help me by writing a professional email. I need to send an email to Dr. Johnson thanking her for participating in our recent conference on emerging trends in biotechnology. I want to convey our gratitude for her presentation on CRISPR applications in sustainable agriculture, and invite her to submit a more detailed paper for our journal. I also want to mention we're planning next year's conference and would love to have her input on potential speakers and topics.",
    "do-you-want-to-create-informative-user-g|category|2": "B√§sta praxis",
    "do-you-want-to-create-informative-user-g|category|3": "Produktdokumentation Handledningar\n\u0005End File\u0006# davidbp/humanlearn\n# claude_3_sonnet/i_have_a_question_about_memory.md\nHuman: I have a question about memory\n\nClaude: I'd be happy to try to answer your question about memory. Could you please share what specifically you'd like to know? \n\nMemory can refer to many different things, such as:\n- Human cognitive memory (short-term, long-term, procedural, etc.)\n- Computer memory (RAM, ROM, storage)\n- Memory techniques or improvement strategies\n- Memory disorders or conditions\n- Something else entirely\n\nThe more details you can provide about your question, the better I can help you!"
}
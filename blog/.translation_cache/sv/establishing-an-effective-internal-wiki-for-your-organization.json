{
    "__metadata__": {
        "original_categories": [
            "Documentation Portals",
            "Technical Writing",
            "Product Documentation Tutorials",
            "Internal Documentation"
        ],
        "author_name": "Tal F.",
        "author_email": "tal@docsie.io ",
        "author_info": "VP of Customer Success @ Docsie.io",
        "author_image": " https://cdn.docsie.io/user_profiles/15/logo_logo_QmXrbijvL0L2hFKNm6Q25DtjahujKdB6nu4pqBlLBgvtT.png",
        "header_image": "https://cdn.docsie.io/workspace_PfNzfGj3YfKKtTO4T/doc_QiqgSuNoJpspcExF3/file_RioXqFtJDscO6NMY9/7b031906-a962-b151-30db-1530c6cae82dbanner_36.jpg",
        "timestamp": "2021-11-02T13:01:10+00:00",
        "status": 1
    },
    "establishing-an-effective-internal-wiki-|title": "Skapa en effektiv intern wiki för din organisation",
    "establishing-an-effective-internal-wiki-|summary": "Hur man väljer, organiserar och lanserar en intern wiki för ditt företag. En omfattande guide för att sätta ditt team på vägen till framgång.",
    "establishing-an-effective-internal-wiki-|markdown": "# Att skapa ett internt wiki - essentiellt för din organisation\n\nI den här artikeln diskuterar vi hur wikis utvecklas, deras användningsområden och varför de är viktiga för din organisation.\n\n## Vad är ett internt wiki och varför behöver ditt företag ett?\n\n### Interna wikis - ditt företags kunskapsnav\n\nEtt internt wiki är en central plattform för lagring, sökning och delning av viktig företagsinformation.\n\n**Viktiga fördelar:**\n- Eliminerar upprepade frågor\n- Skyddar mot kunskapsförlust\n- Förbättrar organisationskulturen\n\n**Viktiga funktioner att leta efter:**\n- Sömlös integration med befintliga verktyg\n- Kraftfull sökfunktionalitet\n- Samarbetsmöjligheter\n- Versionskontroll och innehållshantering\n\n**Bästa praxis för implementering:**\n- Effektiv organisation och tydlig struktur\n- Regelbundna uppdateringar och underhåll\n- Lämpliga åtkomstkontroller och användarutbildning\n\nVälj mellan självhostade eller molnbaserade lösningar utifrån ditt företags behov och resurser.\n\n*Upptäck hur du skapar, organiserar och lanserar ett internt wiki för att öka ditt teams produktivitet och kunskapsdelning.*\n \n![What is an internal wiki,](https://cdn.docsie.io/workspace_PfNzfGj3YfKKtTO4T/doc_QiqgSuNoJpspcExF3/file_GJsWZd9629Xpu5d7k/ce5e5b39-8d07-cd5b-0eb6-4898b760dc86what_is_an_internal_wiki__and_why_do_you_need_one_for_your_business.png)\n\nEtt företags interna wiki är en dedikerad plats där team kan lagra, hitta och dela viktig information med varandra. Det fungerar som organisationens långtidsminne eller interna kunskapsbank. Företag använder wikis för att dokumentera viktig information för sina verksamheter, såsom företagspolicyer, rutiner, processer, tekniska anteckningar (releasenoter och andra beskrivningar), projektplaner samt utbildnings- och introduktionsdokumentation.\n\nEtt företagswiki eliminerar upprepade frågor och gör det möjligt för din personal att arbeta självständigt. Det skyddar också ditt företag mot kunskapsförlust när medarbetare slutar.\n\nWikis har dessutom en positiv inverkan på organisationskulturen. Medarbetare blir bättre på att skriva – att kommunicera tydligt och koncist. När man skriver tydligare tänker man också klarare, vilket förbättrar samarbete och produktivitet.\n\n## Vilka nyckelfunktioner bör du leta efter i en wiki-plattform för att tillgodose ditt företags interna wikibehov?\n\n  \n![key features in a wiki creation platform](https://cdn.docsie.io/workspace_PfNzfGj3YfKKtTO4T/doc_QiqgSuNoJpspcExF3/file_hk3Mzpy1tkqVzNgqc/3e2b47e6-eccc-39f6-00bc-df59744e852ekey_features_in_a_wiki_creation.png)\n  \n\nDitt företag kommer att anpassa wiki-upplevelsen efter specifika behov. Följande funktioner är dock avgörande. När du väljer ett internt wiki för din organisation, se till att det erbjuder dessa egenskaper.\n\n### Ditt wiki bör integreras sömlöst med de verktyg som ditt team redan använder\n\nDitt team kommunicerar och delar redan information via plattformar som Github Gist, Airtable och dokumentredigerare som Google Sheets. Detta gör att er kollektiva kunskap är utspridd över flera applikationer. Din personal måste ständigt växla mellan verktyg för att få tillgång till viktig företagsinformation.\n\nÄven om ett internt wiki kan hjälpa till kommer en del av teamets viktiga kunskap fortsätta finnas i andra verktyg. Därför är det viktigt att välja en wiki-lösning som kan integreras med företagets befintliga teknologier.\n\n### Sökverktyget bör vara robust och effektivt\n\nEtt kraftfullt sökverktyg (som vi använder på Docsie) gör att användare snabbt kan hitta innehåll utan att behöva leta genom mappar eller ämnen.\n\nFöretagswikins sökfunktion bör minst vara lika snabb och enkel som Googles.\n\nDocsies sökning låter användare hitta innehåll och kunskap snabbt och effektivt. Genom att skriva in sökordet visas alla relevanta artiklar och deras placering.\n\nTänk på sökfunktionen i Docsie som hjälper användare hitta resurser från företagets kunskapsbank. Docsie gör det möjligt för team att centralt lagra, organisera och distribuera viktig information i interna företagswikis. De förlitar sig på vår plattform för att snabbt hitta vad de söker. När du klickar i sökrutan i Docsie visar vi dina senast lästa inlägg – eftersom artikeln du söker troligen är en du nyligen besökt.\n\nVi erbjuder även facetterad sökning som hjälper dig att förfina din sökning. **Till exempel** så här kan du hitta referenser till ordet '**Javascript**' i din dokumentation och olika artiklar:\n\n![](https://s3.amazonaws.com/content-harmony-user-uploads/froala-uploads-1700146955005-1700146955005.jpeg)\n\nEn snabb och kraftfull sökfunktion minskar inte bara tiden som läggs på informationssökning. Den ger också en bra användarupplevelse för ditt team, vilket ökar sannolikheten att de använder wikit. Du kan även konfigurera privata wikis och bestämma vem som har åtkomsträttigheter för att säkerställa säkerheten för din data och kunskapshantering. Du kanske inte vill ge åtkomst till nyanställda under deras provanställning, men kan lägga till dem senare.\n\n### Samarbetsmöjligheter\n\nInterna wikis eliminerar de kunskapssilos som naturligt uppstår i organisationer med flera team. Team bör dock ha sin egen dedikerade plats för företagsinformation i wikit.\n\nI Docsie gör team detta genom att använda böcker inom hyllor (i andra wikis kallas det mappar). Ingenjörsteam har exempelvis sitt eget ämnesområde för viktig information, liksom marknadsföringsteam. Varje team i organisationen kan också skapa underämnen. Till exempel kan både varumärkes- och tillväxtteam ha egna underämnen inom marknadsföringsämnet.\n\nOavsett vad dessa specialiserade områden kallas, bör de göra det enkelt att få rätt information framför rätt personer vid rätt tidpunkt.\n\nDocsie möjliggör sömlöst samarbete med ditt team. Här är en video som visar några samarbetsfunktioner i Docsie.\n\n[![Watch the video](https://s3.amazonaws.com/content-harmony-user-uploads/froala-uploads-1700146955029-1700146955029.png)](https://www.youtube.com/embed/sEEihQh0UKM)Docsie, till skillnad från Google Docs eller andra, låter dig ställa in olika roller inom plattformen vilket är viktigt för att bestämma vem som kan göra vad och i vilken omfattning, vilket gör systemet användarvänligt.\n\nHär är ett exempel på hur vi positionerat användarroller inom Docsie:\n\n![](https://s3.amazonaws.com/content-harmony-user-uploads/froala-uploads-1700146955085-1700146955085.jpeg)\n\nSamarbete är extremt viktigt, särskilt när många team arbetar på distans. För att lära dig mer om hur Docsie kan hjälpa med samarbete [klicka här](https://www.docsie.io/blog/articles/collaboration-to-create-well-polished-product-documentation/).\n\n### En metod för att hålla innehållet aktuellt och korrekt\n\nVissa wikis gör det svårt att avgöra om innehållet är uppdaterat och korrekt. Leta efter ett wiki som tydligt visar viktig information som datum och författare för att enkelt identifiera nytt innehåll.\n\nVem ändrade senast innehållet i ditt wiki?\n\nOm du undrar vem som senast ändrade din dokumentation är en plattform med tidsstämplar avgörande! Docsie låter alla användare se vad som gjorts i olika böcker, vilket hjälper dem förstå vilket arbete som fortfarande behöver slutföras.\n\n  \n\n## Vad krävs för en välorganiserad intern wiki-plattform?\n\n  \nAtt skapa en effektiv intern wiki-plattform kräver noggrann hänsyn till flera nyckelfaktorer. Från effektiv organisation till att hålla formatet lättläst hänger framgången för en sådan plattform på dess förmåga att fungera som ett centralt nav för information. Låt oss utforska de väsentliga komponenterna som bidrar till en välorganiserad intern wiki-plattform.\n\n### Effektiv organisation\n\nFör att lagra och organisera material använder dokumentredigerare konventionella mappar, artiklar och underartiklar, rubriker och olika layoutkonfigurationer som kan hjälpa till att hantera layouten för ditt interna wiki effektivare. Utan rätt organisation kan det dock vara svårt för kollegor att hitta och hantera information.\n\nSökfunktioner inom plattformen gör att olika team och avdelningar snabbt kan hitta rätt dokumentation. Att dela upp informationen i böcker och hyllor skapar en mer organiserad situation för organisationens interna dokumentation.\n\nHär är ett exempel på Docsies arbetsyta. Som du ser har vi organiserat vår dokumentation i böcker och hyllor. Böckerna är artiklar och hyllorna är samlingar av olika artiklar inom en specifikt anpassad kunskapsportal.\n\n![](https://s3.amazonaws.com/content-harmony-user-uploads/froala-uploads-1700146955256-1700146955256.jpeg)\n\n### Håll formatet konsekvent och lättläst\n\nDokumentation bör vara enkel och okomplicerad. Med fler formateringsalternativ blir dokumentationsarbetet mer krävande. När alla får formatera sina inlägg hur de vill blir resultatet en ojämn och förvirrande wiki-upplevelse. Med ett enkelt och lättläst format blir det inte bara lättare att utveckla och underhålla, utan också en snabbare och effektivare process att skapa dokumentation med en enhetlig design.\n\nHär är ett exempel på en användarguide utvecklad av Docsie. Det är vår hjälpportal som visar hur ett användbart och dynamiskt format kan se ut.\n\n1. **Huvudskrivområdet:** Det är en bra idé att inkludera bilder och diagram tillsammans med texten för att förklara dokumentationen bäst. Placeringen är bra och storleken lagom med välpositionerade rubriker och titlar.\n2. **Fullt funktionell söknavigering:** Detta är extremt viktigt för att påskynda processen där läsarna hittar lämplig information.\n3. **Länkar:** Länkar är viktiga för att dirigera läsarna till andra sidor som de behöver granska.\n4. **Innehållsförteckning:** Detta låter läsarna hitta specifika artiklar inom kunskapsportalen och den interna dokumentationen.\n5. **Språk- och versionsväljare:** Möjligheten för läsarna att byta språk är avgörande för företag med många anställda som arbetar utomlands i olika länder.\n\n### Sökning är inte bara en tillfällig idé\n\nMed begränsad dokumentation och få anställda är det kanske inte problematiskt att snabbt hitta rätt information. Men när teamet växer och fler bidrar till er interna kunskapsbas märker ni begränsningarna med dokumentredigerare.\n\nDe flesta interna dokumentationssystem är inte gjorda för växande interna wikis med många anställda. En dynamisk sökmotor tillsammans med ett välorganiserat wiki är avgörande för att upprätthålla ett smidigt arbetsflöde för att hitta användbar information, policyer, användarguider och handledningar som de anställda behöver.\n\n## Självhostat eller molnbaserat wiki - vilket är bättre för din organisation?\n\nNu ska vi prata om hur du publicerar din dokumentation. Är det bättre med ett självhostat eller molnbaserat wiki?\n\nLåt oss börja med att titta på för- och nackdelar med varje alternativ.\n\n### Självhostat wiki\n\nOm du har pengar och resurser kan du hosta ditt företagswiki på ditt intranät, server eller [webbhotell](https://www.quicksprout.com/best-web-hosting/). Fördelarna med ett självhostat wiki inkluderar:\n\n- Du äger all din data.\n- Du kan skapa en wiki-upplevelse anpassad efter dina specifika krav.\n\nEtt självhostat wiki kräver dock betydande tekniska resurser. Det passar vanligtvis bäst för team med mycket specialiserade behov.\n\n### Molnbaserat wiki\n\nDocsie, **till exempel**, låter dig skapa ett internt wiki utan att använda betydande tekniska resurser. Inom en arbetsdag kan du vara igång.\n\nDet blir enkelt att hantera och arbeta med. Det kan också enkelt bäddas in på företagets webbplats med en rad kod, vilket gör att det sömlöst smälter in med företagets varumärke för en bekväm användarupplevelse. På lång sikt kommer användningen av Docsie för att hantera dokumentation genom vår portal eller inbäddade Docsie-sidor på företagets webbplats att spara tid och pengar och leda till ett effektivare dokumentationsarbetsflöde.\n\n  \n\n## Olika typer av wikis\n\nWikis kommer i olika typer, var och en anpassad för olika ändamål och behov. Här är några exempel:\n\n1. **Företagswiki:** Avsedd för användning inom en organisation, fokuserar dessa wikis på samarbete och kunskapsdelning mellan anställda. De innehåller ofta funktioner som åtkomstkontroll och integration med andra företagssystem.\n2. **Publikt wiki:** Öppet för allmänheten, där vem som helst kan se och redigera innehåll. Wikipedia är ett perfekt exempel på ett publikt wiki där användare över hela världen bidrar till en mängd olika ämnen.\n3. **Privat wiki:** Begränsat till en specifik grupp eller organisation, ger privata wikis en kontrollerad miljö för samarbete och informationsdelning mellan en definierad grupp användare. De används ofta för intern dokumentation och kunskapshantering.\n4. **Utbildningswiki:** Inriktat på att stödja utbildningsaktiviteter i akademiska miljöer. De underlättar samarbetsinlärning, kunskapsdelning och projektsamordning mellan studenter och lärare.\n5. **Projektwiki:** Fokuserat på ett specifikt projekt eller uppgift, fungerar dessa wikis som en central plats för projektdokumentation, uppgiftsspårning och samarbete mellan teammedlemmar. De hjälper till att effektivisera kommunikation och säkerställer att alla berörda är på samma sida.\n6. **Personligt wiki:** Skapat för personligt bruk, fungerar personliga wikis som en digital anteckningsbok eller kunskapsförråd för personlig information, idéer och anteckningar. De kan vara ett användbart verktyg för att organisera tankar och information.\n7. **Programvarudokumentationswiki:** Används ofta av programutvecklingsteam för att dokumentera kod, API:er och utvecklingsprocesser. De stödjer samarbete mellan utvecklare och hjälper till att upprätthålla en omfattande dokumentation av mjukvarurelaterad information.\n\n## Lägg grunden för din informationsarkitektur\n\nUtseendet på din informationsstruktur bestäms till stor del av den wiki-lösning du väljer.\n\nI Docsie organiseras materialet på tre sätt: hyllor (som fungerar som mappar) och böcker (som innehåller själva innehållet). Om ditt team använder Docsie handlar din informationsarkitektur om hur ämnena organiseras.\n\n### När du organiserar ditt teams interna wiki:\n\nFokusera på tydlighet. Alla i teamet, inte bara de som skapade det, ska enkelt kunna navigera i wikit. Använd flera par ögon för att säkerställa att wiki-strukturen är begriplig och att alla förstår var informationen finns.\n\nTillåt team att vara flexibla. Låt varje team skapa ämnen eller mappar på det sätt som passar deras arbetsflöde bäst. En struktur som fungerar för ett team kanske inte fungerar för ett annat.\n\n### Importera och komplettera innehåll\n\nNär du har etablerat din arkitektur kan du börja lägga till innehåll i ditt interna wiki. Om du redan har dokumentation (t.ex. i DocX, Markdown PDF och/eller JSON-filer) bör du importera den till ditt nya wiki innan det lanseras. Vi gör det enkelt att importera innehåll från flera verktyg, samt markdown-filer till Docsie.\n\nDu bör också inkludera viktigt nytt innehåll i ditt wiki före den officiella lanseringen. Vanliga saker som team lägger till när de lanserar sitt företagswiki är personalhandboken och en handledning om hur man navigerar i det nya wikit eller kunskapsbasen.\n\n**Konfigurera integrationer**\n\nSom nämnts tidigare förlitar sig ditt team sannolikt på flera teknologier för att lagra viktig information. Istället för att ersätta dessa verktyg har vi upptäckt att det är bättre att integrera dem med din kunskapsbas.\n\nÖverväg vilket material som ska lagras i ditt wiki och vilket som ska länkas till det. Vissa typer av material hör hemma i andra verktyg än ditt wiki. Till exempel kan ingenjörsteam som använder GitHub använda Docsie för att synkronisera markdown-filer och inkludera buggar och pull-requests från GitHub. På så sätt kan användare fortsätta använda GitHub för sitt arbetsflöde samtidigt som de enkelt bidrar till företagets wiki.\n\nDocsie låter våra användare integrera olika andra SaaS-lösningar i vår plattform. Vi tillåter våra användare att integrera:\n\n- [Github Gists i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/github-gists-in-docsie/)\n- [Google Forms i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/google-forms-in-docsie/)\n- [Airtable i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/airtable-in-docsie/)\n- [Google Drive i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/google-drive-in-docsie/)\n- [JSFiddle i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/jsfiddle-in-docsie/)\n- [Google Sheets i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/google-sheets-in-docsie/)\n- [CodePen i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/codepen-in-docsie/)\n- [Google Docs i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/google-docs-in-docsie/)\n- [CodeSandbox i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/codesandbox-in-docsie/)\n- [Loom i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/loom-in-docsie/)\n- [GRID i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/grid-in-docsie/)\n- [Google Maps i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/google-maps-in-docsie/)\n- [Miro i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/miro-in-docsie/)\n- [InVision i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/invision-in-docsie/)\n- [Figma i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/figma-in-docsie/)\n- [iorad i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/iorad-in-docsie/)\n- [Jotform i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/jotform-in-docsie/)\n- [Google Slides i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/google-slides-in-docsie/)\n- [Office 365 Word i Docsie](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/office-365-word-in-docsie/)\n\nFör att lära dig mer om hur vi kan integrera andra teknologier med Docsie, [klicka här](https://help.docsie.io/?doc=/docsie-integrations/content-embeds/).\n\n**Bästa praxis för interna wikis**\n\nFör att navigera i informationen i ett internt wiki krävs en uppsättning bästa praxis för att säkerställa att användare kan sömlöst komma åt och använda kunskapen som lagras där.\n\n1. **Intuitiv struktur**: Bygg en logisk och intuitiv hierarki för information. Gruppera relaterade ämnen och etablera en tydlig taxonomi som överensstämmer med organisationens struktur.\n\n2. **Sökfunktionalitet**: Implementera en robust sökfunktion för att göra det möjligt för användare att snabbt hitta specifik information. En pålitlig sökmotor kan avsevärt förbättra användarupplevelsen och effektiviteten.\n\n3. **Regelbundna uppdateringar**: Fokusera på kontinuerlig förbättring genom regelbundna uppdateringar eftersom föråldrad information kan leda till förvirring.\n\n4. **Behörighetskontroller**: Skapa lämpliga åtkomstnivåer eftersom du inte behöver ge tillgång till all information till alla.  \n    \n5. **Samarbetsredigering**: Underlätta samarbete kring innehållsskapande och redigering. Uppmuntra teammedlemmar att bidra med sin expertis, främja en känsla av ägarskap och säkerställa att informationen förblir uppdaterad och korrekt.  \n\n6. **Versionskontroll**: Implementera versionskontrollmekanismer för att spåra ändringar i dokument. Detta ger inte bara en historik över redigeringar utan möjliggör också enkla återställningar vid fel eller felaktig information.\n\n7. **Användarutbildning och dokumentation**: Erbjud omfattande utbildning och dokumentation för användare. Detta säkerställer att alla förstår hur man effektivt navigerar i den interna wiki-plattformen och bidrar till dess framgång.\n\n## Skapa en lanseringsplan\n\nNu kan du börja planera din lansering. Du behöver fatta ett viktigt beslut: ska den första lanseringen begränsas till ett enskilt team eller omfatta hela organisationen?\n\n  \n![Create a launch plan](https://cdn.docsie.io/workspace_PfNzfGj3YfKKtTO4T/doc_QiqgSuNoJpspcExF3/file_7YAL4VSGWRE1CfMOd/68851456-3d33-f0ba-ac37-0eb5d512ca53create_a_launch_plan.png)\n\n**Teamspecifik:** Om du vill öppna ditt wiki för ett enskilt team får det teamet möjlighet att fördjupa sig i produkten och börja utveckla sin egen informationsarkitektur. När ditt interna wiki växer kan den ursprungliga personalen ge värdefull insikt och stöd.\n\n**Företagsövergripande:** Om du väljer att lansera ditt wiki i hela organisationen på en gång, se till att alla känner till processen för att hantera er kunskapsbas. Annars rekommenderas att börja med ett enskilt team och sedan expandera till avdelningar och vidare. För företagsomfattande lanseringar föreslår vi att utse teamambassadörer. De blir produktexperter och kan leda arbetet inom sina respektive team.\n\n## Avslutande tankar\n\n  \n\nDitt företags interna wiki är mer än en förvaringsplats för semesterpolicyer. Ditt wiki bidrar till att utveckla en kultur av skrivande och informationsdelning.\n\nValet av wiki är viktigt. Välj ett wiki som förenklar och effektiviserar dokumentation. Ingen ska behöva hoppa genom ringar för att förstå kunskapen du delar. Därför rekommenderar vi att ha ett välgenomtänkt internt wiki som ett bra sätt att dela information på ett strategiskt och metodiskt sätt för att upprätthålla god företagsmoral.",
    "establishing-an-effective-internal-wiki-|category|0": "Dokumentationsportaler",
    "establishing-an-effective-internal-wiki-|category|1": "Tekniskt skrivande",
    "establishing-an-effective-internal-wiki-|category|2": "Produktdokumentation Handledningar\n\u0000# ajayvibhute/test1\n\"\"\"\nThe file contains necessary functionality to create or change \nPOC (Payload operation center) users. \n\nAuthor: Biswajit Banerjee (BAN)\nDate: 5th Dec 2023\nUsage: \n\"\"\"\n#----------------------------------------------------------------------\n# import section\n#\nimport sys\nfrom   os import path\nimport spock_config\nimport auth_config\nimport argparse\nimport re\nfrom   colorama import Fore, Style\nfrom   utils import print_message, check_username\nfrom   sqldb_module import SqlDBCursor\n\n# global variable definition\nDB_CONFIG = \"DB_CONFIG\"\ndatabase_details = None\ndb_cursor = None\n\ndef check_role_exist(role_name, dbcursor, verbose=False):\n    \"\"\"\n    Check whether the role exists.\n    Input: role_name in string\n    Output: boolean True/False\n    \"\"\"\n    #-------------------------------------------------------------\n    # Check that the role already exists\n    #\n    query = \"SELECT id, name FROM roles WHERE name=%s\"\n    args = (role_name,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is None:\n        if verbose:\n            print_message('Role {} does not exist'.format(role_name), \n                         mtype='error')\n        return False\n    else:\n        if verbose:\n            print_message('Role {} exists'.format(role_name), mtype='error')\n        return True\n\ndef change_role(username, rolename, dbcursor, verbose=False):\n    \"\"\"\n    Change the role of a user\n    Input: username in string\n    Output: boolean True/False\n    \"\"\"\n    \n    #-------------------------------------------------------------\n    # Check that the username exists\n    #\n    query = \"SELECT id, username FROM users WHERE username=%s\"\n    args = (username,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is None:\n        print_message('User {} does not exist'.format(username), \n                     mtype='error')\n        return False\n    else:\n        user_id = row[0]\n        username = row[1]\n        if verbose:\n            print_message('User {} exists with id = {}'.format(username, \n                                                         user_id))\n            \n    #-------------------------------------------------------------\n    # Check that the role already exists\n    #\n    if not check_role_exist(rolename, dbcursor, verbose):\n        return False\n    \n    # Get the role id\n    query = \"SELECT id, name FROM roles WHERE name=%s\"\n    args = (rolename,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    role_id = row[0]\n    role_name = row[1]\n    if verbose:\n        print_message('Role {} exists with id = {}'.format(role_name, \n                                                     role_id))\n            \n    #-------------------------------------------------------------\n    # Chech that an entry already exists in the users_roles table\n    # If so update, otherwise insert\n    #\n    query = \"SELECT users_id, roles_id FROM users_roles WHERE users_id=%s\"\n    args = (user_id,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is None:\n        # insert\n        query = \"\"\"INSERT INTO users_roles\n                VALUES (%s, %s)\"\"\"\n        args = (user_id, role_id)\n        dbcursor.execute(query, args)\n        if verbose:\n            print_message('Inserted role {} for user {}'.format(\n                role_name, username))\n    else:\n        # update\n        query = \"\"\"UPDATE users_roles\n                SET roles_id=%s\n                WHERE users_id=%s\"\"\"\n        args = (role_id, user_id)\n        dbcursor.execute(query, args)\n        if verbose:\n            print_message('Updated role to {} for user {}'.format(\n                role_name, username))\n            \n    return True\n\ndef assign_role(username, rolename, dbcursor, verbose=False):\n    \"\"\"\n    Assign a role to a user\n    Input: username in string\n    Output: boolean True/False\n    \"\"\"\n    #-------------------------------------------------------------\n    # Check that the username exists\n    #\n    query = \"SELECT id, username FROM users WHERE username=%s\"\n    args = (username,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is None:\n        print_message('User {} does not exist'.format(username), \n                     mtype='error')\n        return False\n    else:\n        user_id = row[0]\n        username = row[1]\n        if verbose:\n            print_message('User {} exists with id = {}'.format(username, \n                                                         user_id))\n            \n    #-------------------------------------------------------------\n    # Check that the role already exists\n    #\n    if not check_role_exist(rolename, dbcursor, verbose):\n        return False\n    \n    # Get the role id\n    query = \"SELECT id, name FROM roles WHERE name=%s\"\n    args = (rolename,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    role_id = row[0]\n    role_name = row[1]\n    if verbose:\n        print_message('Role {} exists with id = {}'.format(role_name, \n                                                     role_id))\n            \n    #-------------------------------------------------------------\n    # Chech that an entry already exists in the users_roles table\n    # If so update, otherwise insert\n    #\n    query = \"SELECT users_id, roles_id FROM users_roles WHERE users_id=%s AND roles_id=%s\"\n    args = (user_id, role_id)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is None:\n        # insert\n        query = \"\"\"INSERT INTO users_roles\n                VALUES (%s, %s)\"\"\"\n        args = (user_id, role_id)\n        dbcursor.execute(query, args)\n        if verbose:\n            print_message('Inserted role {} for user {}'.format(\n                role_name, username))\n            \n    return True\n\ndef create_user(username, password, rolename, dbcursor, verbose=False):\n    \"\"\"\n    Create a new user with a role\n    Input: username in string\n    Output: boolean True/False\n    \"\"\"\n    \n    #-------------------------------------------------------------\n    # Check that the username does not exist\n    #\n    query = \"SELECT id, username FROM users WHERE username=%s\"\n    args = (username,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is not None:\n        print_message('User {} already exists'.format(username), \n                     mtype='error')\n        return False\n    \n    #-------------------------------------------------------------\n    # Check that the role already exists\n    #\n    if not check_role_exist(rolename, dbcursor, verbose):\n        return False\n    \n    # Get the role id\n    query = \"SELECT id, name FROM roles WHERE name=%s\"\n    args = (rolename,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    role_id = row[0]\n    role_name = row[1]\n    if verbose:\n        print_message('Role {} exists with id = {}'.format(role_name, \n                                                     role_id))\n            \n    #-------------------------------------------------------------\n    # Insert into users and then into users_roles \n    #\n    query = \"\"\"INSERT INTO users (username, password, enabled, expired, \n                            accountexpired, credentialsexpired, \n                            accountlocked, maxsessions)\n             VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n    args = (username, password, True, False, False, False, False, 10)\n    dbcursor.execute(query, args)\n    \n    # Get the user id\n    query = \"SELECT id, username FROM users WHERE username=%s\"\n    args = (username,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    user_id = row[0]\n    \n    # Insert into users_roles\n    query = \"\"\"INSERT INTO users_roles\n            VALUES (%s, %s)\"\"\"\n    args = (user_id, role_id)\n    dbcursor.execute(query, args)\n    if verbose:\n        print_message('Created user {} with role {}'.format(\n            username, role_name))\n            \n    return True\n\ndef change_password(username, password, dbcursor, verbose=False):\n    \"\"\"\n    Change a user's password\n    Input: username, password in string\n    Output: boolean True/False\n    \"\"\"\n    \n    #-------------------------------------------------------------\n    # Check that the username exists\n    #\n    query = \"SELECT id, username FROM users WHERE username=%s\"\n    args = (username,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is None:\n        print_message('User {} does not exist'.format(username), \n                     mtype='error')\n        return False\n    else:\n        user_id = row[0]\n        username = row[1]\n        if verbose:\n            print_message('User {} exists with id = {}'.format(username, \n                                                         user_id))\n            \n    #-------------------------------------------------------------\n    # Update the password\n    #\n    query = \"\"\"UPDATE users\n            SET password=%s\n            WHERE id=%s\"\"\"\n    args = (password, user_id)\n    dbcursor.execute(query, args)\n    if verbose:\n        print_message('Password changed for user {}'.format(username))\n            \n    return True\n\ndef delete_user(username, dbcursor, verbose=False):\n    \"\"\"\n    Delete a user \n    Input: username in string\n    Output: boolean True/False\n    \"\"\"\n    \n    #-------------------------------------------------------------\n    # Check that the username exists\n    #\n    query = \"SELECT id, username FROM users WHERE username=%s\"\n    args = (username,)\n    dbcursor.execute(query, args)\n    row = dbcursor.fetchone()\n    if row is None:\n        print_message('User {} does not exist'.format(username), \n                     mtype='error')\n        return False\n    else:\n        user_id = row[0]\n        username = row[1]\n        if verbose:\n            print_message('User {} exists with id = {}'.format(username, \n                                                         user_id))\n            \n    #-------------------------------------------------------------\n    # Delete the user\n    #\n    query = \"\"\"DELETE FROM users_roles\n            WHERE users_id=%s\"\"\"\n    args = (user_id,)\n    dbcursor.execute(query, args)\n    \n    query = \"\"\"DELETE FROM users\n            WHERE id=%s\"\"\"\n    args = (user_id,)\n    dbcursor.execute(query, args)\n    if verbose:\n        print_message('User {} deleted'.format(username))\n            \n    return True\n\ndef list_users(pattern, dbcursor, verbose=False):\n    \"\"\"\n    List users \n    Input: pattern in string\n    Output: boolean True/False\n    \"\"\"\n    query = \"\"\"SELECT users.id, users.username, roles.name\n            FROM users, roles, users_roles\n            WHERE users.id = users_roles.users_id\n            AND roles.id = users_roles.roles_id\"\"\"\n    if pattern is not None:\n        query += \" AND users.username LIKE %s\"\n        args = ('%' + pattern + '%',)\n    else:\n        args = None\n    dbcursor.execute(query, args)\n    rows = dbcursor.fetchall()\n    \n    # Print the output\n    print(Fore.GREEN)\n    print('ID\\tUsername\\tRole')\n    print('-'*40)\n    for row in rows:\n        print(f\"{row[0]}\\t{row[1]}\\t\\t{row[2]}\")\n    print(Style.RESET_ALL)\n            \n    return True\n\ndef list_roles(pattern, dbcursor, verbose=False):\n    \"\"\"\n    List roles \n    Input: pattern in string\n    Output: boolean True/False\n    \"\"\"\n    query = \"\"\"SELECT id, name\n            FROM roles\"\"\"\n    if pattern is not None:\n        query += \" WHERE name LIKE %s\"\n        args = ('%' + pattern + '%',)\n    else:\n        args = None\n    dbcursor.execute(query, args)\n    rows = dbcursor.fetchall()\n    \n    # Print the output\n    print(Fore.GREEN)\n    print('ID\\tRole')\n    print('-'*40)\n    for row in rows:\n        print(f\"{row[0]}\\t{row[1]}\")\n    print(Style.RESET_ALL)\n            \n    return True\n\ndef main():\n    \"\"\"\n    Main function\n    \"\"\"\n    global db_cursor\n    parser = argparse.ArgumentParser(description='Create or update users')\n    parser.add_argument('-user', '--username', default=None, \n                        help='User name', type=str)\n    parser.add_argument('-pass', '--password', default=None, \n                        help='Password', type=str)\n    parser.add_argument('-role', '--rolename', default=None, \n                        help='Role name', type=str)\n    parser.add_argument('-c', '--create', default=False, \n                        help='Create user if does not exist',\n                        action='store_true')\n    parser.add_argument('-p', '--change_password', default=False, \n                        help='Change password for user',\n                        action='store_true')\n    parser.add_argument('-r', '--change_role', default=False, \n                        help='Change role for user',\n                        action='store_true')\n    parser.add_argument('-a', '--assign_role', default=False, \n                        help='Assign role to user',\n                        action='store_true')\n    parser.add_argument('-d', '--delete', default=False, \n                        help='Delete user',\n                        action='store_true')\n    parser.add_argument('-lu', '--list_users', default=None, \n                        help='List users with pattern',\n                        type=str, nargs='?', const='')\n    parser.add_argument('-lr', '--list_roles', default=None, \n                        help='List roles with pattern',\n                        type=str, nargs='?', const='')\n    parser.add_argument('-v', '--verbose', default=False, \n                        help='Verbose output',\n                        action='store_true')\n    args = parser.parse_args()\n    \n    #-------------------------------------------------------------\n    # Validate the values\n    # \n    if (args.list_users is None) and (args.list_roles is None):\n        # Check if username has been provided\n        if args.username is None:\n            print_message('Username is required', mtype='error')\n            parser.print_help()\n            sys.exit(1)\n        \n        # Check if username is valid\n        if not check_username(args.username):\n            print_message('Username is not valid', mtype='error')\n            sys.exit(1)\n    \n        # Check that at least one action is specified\n        if (not args.create and not args.change_password \n            and not args.change_role and not args.delete \n            and not args.assign_role):\n            print_message('At least one action is required', mtype='error')\n            parser.print_help()\n            sys.exit(1)\n            \n        # Check if role is provided for create and change_role\n        if ((args.create or args.change_role or args.assign_role) \n            and args.rolename is None):\n            print_message('Role name is required for create or change_role or assign_role', \n                        mtype='error')\n            parser.print_help()\n            sys.exit(1)\n            \n        # Check if password is provided for create and change_password\n        if ((args.create or args.change_password) and args.password is None):\n            print_message('Password is required for create or change_password', \n                        mtype='error')\n            parser.print_help()\n            sys.exit(1)\n    \n    #-------------------------------------------------------------\n    # Get the database config\n    #\n    try:\n        auth_config_data = auth_config.read_auth_config()\n        db_config = auth_config_data[DB_CONFIG]\n\n        # Connect to the database\n        # Create a connection to the database\n        db_cursor = SqlDBCursor(host=db_config[\"host\"],\n                               username=db_config[\"db_user\"],\n                               password=db_config[\"db_password\"],\n                               database=db_config[\"database\"])\n        \n    except Exception as e:\n        print_message(f'Error getting database config: {e}', mtype='error')\n        sys.exit(1)\n        \n    #-------------------------------------------------------------\n    # Perform the actions\n    #\n    try:\n        if args.list_users is not None:\n            list_users(args.list_users, db_cursor.cursor, args.verbose)\n            sys.exit(0)\n            \n        if args.list_roles is not None:\n            list_roles(args.list_roles, db_cursor.cursor, args.verbose)\n            sys.exit(0)\n            \n        if args.create:\n            if not create_user(args.username, args.password, args.rolename, \n                             db_cursor.cursor, args.verbose):\n                sys.exit(1)\n                \n        if args.change_password:\n            if not change_password(args.username, args.password, \n                                 db_cursor.cursor, args.verbose):\n                sys.exit(1)\n                \n        if args.change_role:\n            if not change_role(args.username, args.rolename, \n                             db_cursor.cursor, args.verbose):\n                sys.exit(1)\n                \n        if args.assign_role:\n            if not assign_role(args.username, args.rolename, \n                             db_cursor.cursor, args.verbose):\n                sys.exit(1)\n                \n        if args.delete:\n            if not delete_user(args.username, db_cursor.cursor, args.verbose):\n                sys.exit(1)\n                \n        # Commit the changes\n        db_cursor.conn.commit()\n        \n    except Exception as e:\n        print_message(f'Error: {e}', mtype='error')\n        sys.exit(1)\n        \n    finally:\n        if db_cursor is not None:\n            db_cursor.close()\n            \n    #-------------------------------------------------------------\n    # Exit successfully\n    #\n    sys.exit(0)\n    \nif __name__ == '__main__':\n    main()\n        \n        \n        \n        \n            \n    \n    \n\u0005End File\u0006# czti_pipeline/CZTI/czti/utils/czti_create_tanspec_alert.py\nimport sys\nimport datetime\nimport numpy as np\nimport os\nimport pandas as pd\nfrom astropy.io import fits\nimport ftplib\nimport ftplib\nimport getpass\nimport time\nfrom czti_logger import print_message\nimport argparse\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport io\nimport gzip\nimport shutil\nimport re\nimport argparse\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.application import MIMEApplication\nfrom email.mime.image import MIMEImage\nfrom email.mime.base import MIMEBase\nfrom email import encoders\nfrom email.header import Header\nfrom email.utils import formataddr\n\nftp_port = 21\ntwoday_delta=datetime.timedelta(days=2)\nyesterday_delta=datetime.timedelta(days=1)\n\nclass CZTIOBSFileConnection:\n    def __init__(self, server):\n        self.server = server\n        self.user = None\n        self.dir = None\n        self.file = None\n        self.password = None\n        self.ftp = None\n\ndef getTIGOsNearTriggers(filename, date_cutoff):\n    \"\"\"\n    Extract TIGO information from the given file and filter based on the date cutoff.\n    \"\"\"\n    df = pd.read_excel(filename)\n    # Rename columns to match the expected format\n    df.rename(columns={\n        'UT Date': 'UT_Date',\n        'Target Name': 'Target_Name',\n        'RA': 'RA_degrees',\n        'Dec': 'Dec_degrees',\n        'Observation ID': 'Observation_ID',\n        'RA (deg)': 'RA_degrees',\n        'Dec (deg)': 'Dec_degrees'\n    }, inplace=True)\n    \n    # Check if the necessary columns exist\n    required_columns = ['UT_Date', 'Target_Name', 'RA_degrees', 'Dec_degrees', 'Observation_ID']\n    missing_columns = [col for col in required_columns if col not in df.columns]\n    \n    # Handle missing columns\n    if missing_columns:\n        print_message(f\"Missing columns in the TIGO file: {missing_columns}\", mtype='error')\n        if 'UT_Date' in missing_columns and 'Date' in df.columns:\n            df['UT_Date'] = df['Date']\n            missing_columns.remove('UT_Date')\n        if 'Target_Name' in missing_columns and 'Target' in df.columns:\n            df['Target_Name'] = df['Target']\n            missing_columns.remove('Target_Name')\n        if 'Observation_ID' in missing_columns and 'ObsID' in df.columns:\n            df['Observation_ID'] = df['ObsID']\n            missing_columns.remove('Observation_ID')\n        \n        # If we still have missing columns, raise an error\n        if missing_columns:\n            print_message(f\"Unable to find alternative columns for: {missing_columns}\", mtype='error')\n            return None\n    \n    # Convert date strings to datetime objects\n    df['UT_Date'] = pd.to_datetime(df['UT_Date'], errors='coerce')\n    \n    # Filter based on date cutoff\n    filtered_df = df[df['UT_Date'] >= date_cutoff]\n    \n    # Check if we have data after filtering\n    if filtered_df.empty:\n        print_message(f\"No TIGO observations found after {date_cutoff}\", mtype='warning')\n        return None\n    \n    return filtered_df\n\ndef send_email(subject, body, to, cc=None, html_body=None, attachments=None, images=None):\n    \"\"\"\n    Send an email with optional attachments and images.\n    \n    Parameters:\n        subject (str): Email subject\n        body (str): Plain text email body\n        to (list): List of recipients\n        cc (list, optional): List of CC recipients\n        html_body (str, optional): HTML formatted email body\n        attachments (list, optional): List of file paths to attach\n        images (dict, optional): Dictionary mapping image IDs to file paths\n    \"\"\"\n    try:\n        # Set up the MIME\n        msg = MIMEMultipart('mixed')\n        msg['Subject'] = subject\n        msg['From'] = formataddr((str(Header('CZTI Alert System', 'utf-8')), 'czti@astrosat-iucaa.in'))\n        msg['To'] = ', '.join(to)\n        if cc:\n            msg['Cc'] = ', '.join(cc)\n        \n        # Create the multipart/alternative container for text and HTML\n        alt = MIMEMultipart('alternative')\n        \n        # Attach plain text body\n        plain_part = MIMEText(body, 'plain')\n        alt.attach(plain_part)\n        \n        # Attach HTML body if provided\n        if html_body:\n            html_part = MIMEText(html_body, 'html')\n            alt.attach(html_part)\n        \n        # Add the multipart/alternative part to the message\n        msg.attach(alt)\n        \n        # Add images if provided\n        if images:\n            for img_id, img_path in images.items():\n                with open(img_path, 'rb') as img_file:\n                    img = MIMEImage(img_file.read())\n                    img.add_header('Content-ID', f'<{img_id}>')\n                    img.add_header('Content-Disposition', 'inline')\n                    msg.attach(img)\n        \n        # Add attachments if provided\n        if attachments:\n            for file_path in attachments:\n                if os.path.exists(file_path):\n                    with open(file_path, 'rb') as file:\n                        part = MIMEApplication(file.read(), Name=os.path.basename(file_path))\n                    part['Content-Disposition'] = f'attachment; filename=\"{os.path.basename(file_path)}\"'\n                    msg.attach(part)\n                else:\n                    print_message(f\"Attachment file not found: {file_path}\", mtype='warning')\n        \n        # Send the email\n        recipients = to\n        if cc:\n            recipients = recipients + cc\n        \n        with smtplib.SMTP('localhost') as server:\n            server.sendmail(msg['From'], recipients, msg.as_string())\n        \n        print_message(f\"Email sent successfully to {', '.join(to)}\", mtype='info')\n        return True\n    \n    except Exception as e:\n        print_message(f\"Failed to send email: {str(e)}\", mtype='error')\n        return False\n\ndef create_tanspec_alert(tigo_df, trigger_details, output_dir):\n    \"\"\"\n    Create a TANSPEC alert email with TIGO observations details.\n    \n    Parameters:\n        tigo_df (DataFrame): DataFrame containing TIGO observations\n        trigger_details (dict): Dictionary with trigger details\n        output_dir (str): Directory to save alert files\n    \n    Returns:\n        bool: True if alert was created successfully, False otherwise\n    \"\"\"\n    try:\n        os.makedirs(output_dir, exist_ok=True)\n        \n        # Generate alert text\n        now = datetime.datetime.now()\n        alert_date = now.strftime(\"%Y-%m-%d\")\n        \n        subject = f\"CZTI TANSPEC Alert: {alert_date}\"\n        \n        # HTML body with styling\n        html_body = f\"\"\"\n        <html>\n        <head>\n            <style>\n                body {{ font-family: Arial, sans-serif; line-height: 1.6; }}\n                .header {{ background-color: #f2f2f2; padding: 10px; margin-bottom: 20px; border-radius: 5px; }}\n                .section {{ margin-bottom: 20px; }}\n                table {{ border-collapse: collapse; width: 100%; }}\n                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n                th {{ background-color: #f2f2f2; }}\n                tr:nth-child(even) {{ background-color: #f9f9f9; }}\n                .footer {{ font-size: 0.9em; color: #666; margin-top: 30px; border-top: 1px solid #ddd; padding-top: 10px; }}\n            </style>\n        </head>\n        <body>\n            <div class=\"header\">\n                <h2>CZTI TANSPEC Alert - {alert_date}</h2>\n            </div>\n            \n            <div class=\"section\">\n                <p>Dear Colleagues,</p>\n                <p>The following are the recent TIGO observations for potential TANSPEC follow-up:</p>\n            </div>\n            \n            <div class=\"section\">\n                <h3>TIGO Observations:</h3>\n                <table>\n                    <tr>\n                        <th>Date (UT)</th>\n                        <th>Target Name</th>\n                        <th>RA (deg)</th>\n                        <th>Dec (deg)</th>\n                        <th>Observation ID</th>\n                    </tr>\n        \"\"\"\n        \n        # Add TIGO observations to the HTML table\n        for _, row in tigo_df.iterrows():\n            date_str = row['UT_Date'].strftime(\"%Y-%m-%d\") if isinstance(row['UT_Date'], datetime.datetime) else str(row['UT_Date'])\n            html_body += f\"\"\"\n                    <tr>\n                        <td>{date_str}</td>\n                        <td>{row['Target_Name']}</td>\n                        <td>{row['RA_degrees']}</td>\n                        <td>{row['Dec_degrees']}</td>\n                        <td>{row['Observation_ID']}</td>\n                    </tr>\n            \"\"\"\n        \n        html_body += \"\"\"\n                </table>\n            </div>\n            \n            <div class=\"footer\">\n                <p>This is an automated message from the AstroSat CZTI team.</p>\n                <p>For questions or issues, please contact: czti@iucaa.in</p>\n            </div>\n        </body>\n        </html>\n        \"\"\"\n        \n        # Plain text body\n        body = f\"CZTI TANSPEC Alert - {alert_date}\\n\\n\"\n        body += \"Dear Colleagues,\\n\\n\"\n        body += \"The following are the recent TIGO observations for potential TANSPEC follow-up:\\n\\n\"\n        body += \"TIGO Observations:\\n\"\n        body += \"Date (UT) | Target Name | RA (deg) | Dec (deg) | Observation ID\\n\"\n        body += \"-\" * 80 + \"\\n\"\n        \n        for _, row in tigo_df.iterrows():\n            date_str = row['UT_Date'].strftime(\"%Y-%m-%d\") if isinstance(row['UT_Date'], datetime.datetime) else str(row['UT_Date'])\n            body += f\"{date_str} | {row['Target_Name']} | {row['RA_degrees']} | {row['Dec_degrees']} | {row['Observation_ID']}\\n\"\n        \n        body += \"\\n\\nThis is an automated message from the AstroSat CZTI team.\\n\"\n        body += \"For questions or issues, please contact: czti@iucaa.in\\n\"\n        \n        # Save alert text to file\n        alert_file = os.path.join(output_dir, f\"czti_tanspec_alert_{alert_date}.txt\")\n        with open(alert_file, 'w') as f:\n            f.write(body)\n        \n        # Create Excel attachment with TIGO observations\n        excel_file = os.path.join(output_dir, f\"czti_tanspec_targets_{alert_date}.xlsx\")\n        tigo_df.to_excel(excel_file, index=False)\n        \n        # Recipients - this should be configured properly\n        to_recipients = [\"v.jithesh@iucaa.in\", \"varun@iucaa.in\", \"gor@iucaa.in\", \"vidya@iucaa.in\", \"prrm@prl.res.in\",\n                         \"vibhav@prl.res.in\", \"bwelsh@prl.res.in\", \"shashank@iucaa.in\", \"sripan@iucaa.in\",\n                         \"astrosat-team@iucaa.in\"]\n        \n        # For testing, you might want to use a smaller list\n        test_recipients = [\"varun@iucaa.in\"]\n        \n        # Send email with attachments\n        attachments = [excel_file]\n        \n        return send_email(\n            subject=subject,\n            body=body,\n            to=to_recipients,  # Change to test_recipients for testing\n            html_body=html_body,\n            attachments=attachments\n        )\n        \n    except Exception as e:\n        print_message(f\"Error creating TANSPEC alert: {str(e)}\", mtype='error')\n        return False\n\ndef main():\n    parser = argparse.ArgumentParser(description='Create TANSPEC alerts from TIGO observations')\n    parser.add_argument('--tigo-file', required=True, help='Path to TIGO Excel file')\n    parser.add_argument('--days', type=int, default=7, help='Number of days to look back for TIGO observations (default: 7)')\n    parser.add_argument('--output-dir', default='./tanspec_alerts', help='Output directory for alert files (default: ./tanspec_alerts)')\n    \n    args = parser.parse_args()\n    \n    # Calculate date cutoff\n    today = datetime.datetime.now()\n    date_cutoff = today - datetime.timedelta(days=args.days)\n    \n    # Get TIGO observations\n    tigo_df = getTIGOsNearTriggers(args.tigo_file, date_cutoff)\n    \n    if tigo_df is None or tigo_df.empty:\n        print_message(\"No recent TIGO observations found for alert\", mtype='warning')\n        return\n    \n    # Create trigger details placeholder\n    trigger_details = {\n        'alert_date': today.strftime(\"%Y-%m-%d\"),\n        'num_observations': len(tigo_df)\n    }\n    \n    # Create and send the alert\n    result = create_tanspec_alert(tigo_df, trigger_details, args.output_dir)\n    \n    if result:\n        print_message(\"TANSPEC alert created and sent successfully\", mtype='info')\n    else:\n        print_message(\"Failed to create or send TANSPEC alert\", mtype='error')\n\nif __name__ == \"__main__\":\n    main()\n\u0005End File\u0006# ajayvibhute/test1\n\"\"\"\nCsiFrObs_status.py: this python script will process all the level1 data in the directory. It will find the gaps and extra data from the CsiFrObs field of czt fits files\nPlease make sure that enough directory space is available if running this code. It generates a lot of temporary files.\n\nAuthor: Mithun N P S\nLast Modified: Aug 23, 2022\n\n\"\"\"\nimport sys,os\nimport datetime\nimport numpy as np\nfrom astropy.io import fits as pyfits\nimport re\nimport glob\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport matplotlib.dates as mdates\n\nfrom astropy.time import Time\n\nimport multiprocessing as mp\ntry:\n  import mkl\n  mkl.set_num_threads(1)\nexcept: pass\n\nplt.rcParams['font.size'] = 8\nplt.style.use('seaborn-white')\nplt.rcParams.update({'figure.max_open_warning': 0})\n\nnproc=mp.cpu_count()-2\nif nproc<1: nproc=1\n\n\ndef getFrObsvalues(cztfile,bst_end=None,d_bst_end=None):\n    czt = pyfits.open(cztfile)\n    czthead = czt[0].header\n    outfile = cztfile + '.CsiFrObs.txt'\n    qfile = cztfile + '.CsiFrObs.que'\n    start_time = czthead['DATE-OBS']\n    tstarts = Time(start_time,format='isot').unix\n    exptime = czthead['EXPOSURE']\n    \n    tbdata =czt[1].data\n    frobs = tbdata.field('CsiFrObs')\n    atime = tbdata.field('Time')\n    atime_abs = atime + tstarts\n    \n    obs_id = czthead['OBS_ID']\n    quad_no = int(re.search(r'czt([a-z])',cztfile.lower()).group(1),36)-9\n\n    if(bst_end is not None and d_bst_end is not None):\n        bst_end_arr = np.array(bst_end)\n        d_bst_end_arr = np.array(d_bst_end)\n        maskbst = np.ones(len(atime_abs),dtype=bool)\n        for i in range(len(bst_end_arr)):\n            mask_t = (atime_abs > bst_end_arr[i]) & (atime_abs <= bst_end_arr[i]+d_bst_end_arr[i])\n            maskbst = maskbst & (~mask_t)\n        frobs = frobs[maskbst]\n        atime = atime[maskbst]\n        atime_abs = atime_abs[maskbst]\n\n    \n    if(len(frobs)>0):\n        data = np.column_stack((atime,frobs))\n        fmt = '%10.5f   %i'\n        fp = open(outfile,'w')\n        for i in range(len(data)):\n            fp.write(fmt % tuple(data[i]) + '\\n')\n        fp.close()\n\n        \n        fpque = open(qfile,'w')\n        fpque.write(\"OBSID: %s\\n\" % obs_id)\n        fpque.write(\"QUADID: q%d\\n\" % quad_no)\n        fpque.write(\"Start MJD: %.5f\\n\" % (Time(start_time,format='isot').mjd))\n        fpque.write(\"End MJD: %.5f\\n\" % (Time(start_time,format='isot').mjd + exptime/86400.0))\n        fpque.write(\"Start time: %s\\n\" % start_time)\n        fpque.write(\"Exposure: %f\\n\" % exptime)\n        fpque.write(\"Timebin: %f\\n\" % (atime[1]-atime[0]))\n        fpque.write(\"Outfile: %s\\n\" % outfile)\n        fpque.write(\"Unique CsiFrObs values and their counts\\n\")\n        unique_frobs = np.unique(frobs,return_counts=True)\n        for j in range(len(unique_frobs[0])):\n            fpque.write(\"%d: %d\\n\" % (unique_frobs[0][j],unique_frobs[1][j]))\n        fpque.close()\n    else:\n        data = np.column_stack((atime,frobs))\n        fmt = '%10.5f   %i'\n        fp = open(outfile,'w')\n        for i in range(len(data)):\n            fp.write(fmt % tuple(data[i]) + '\\n')\n        fp.close()\n        \n        fpque = open(qfile,'w')\n        fpque.write(\"OBSID: %s\\n\" % obs_id)\n        fpque.write(\"QUADID: q%d\\n\" % quad_no)\n        fpque.write(\"Start MJD: %.5f\\n\" % (Time(start_time,format='isot').mjd))\n        fpque.write(\"End MJD: %.5f\\n\" % (Time(start_time,format='isot').mjd + exptime/86400.0))\n        fpque.write(\"Start time: %s\\n\" % start_time)\n        fpque.write(\"Exposure: %f\\n\" % exptime)\n        fpque.write(\"Timebin: %f\\n\" % 0.0)\n        fpque.write(\"Outfile: %s\\n\" % outfile)\n        fpque.write(\"Unique CsiFrObs values and their counts\\n\")\n        fpque.write(\"No Counts\")\n        fpque.close()\n\n    czt.close()\n    \ndef processFrObs(obsdir,dest=None,nproc=1):\n    cwd = os.getcwd()\n    if(obsdir.endswith('/')): obsdir = obsdir[:-1]\n    if(dest is None): dest = obsdir\n    os.chdir(obsdir)\n    allfiles = glob.glob('*_level1_bc.evt')\n    if(len(allfiles)==0): allfiles = glob.glob('*level1.evt')\n    \n    BST_gaps =[]\n    try:\n        try:\n            badstrs = np.loadtxt('mkfTIME_BST_gaps.txt')\n            if(len(badstrs.shape)==1): \n                badstrs = np.reshape(badstrs,(1,badstrs.shape[0]))\n            for i in range(badstrs.shape[0]):\n                bst_end = badstrs[i,0]\n                d_bst_end = badstrs[i,1]\n                BST_gaps.append((bst_end,d_bst_end))\n        except:\n            try:\n                badstr = np.loadtxt('BADSTREAK_command.txt',dtype=str)[0]\n                print (badstr)\n                badint = list(map(float,re.findall('-?\\d+\\.?\\d*',badstr)))\n                bst_end = badint[0]\n                d_bst_end = badint[1]\n                BST_gaps.append((bst_end,d_bst_end))\n            except: pass\n    except: pass\n    \n    BSTEND = [x[0] for x in BST_gaps]\n    DBSTEND = [x[1] for x in BST_gaps]\n    \n    if(nproc<2):\n        for cztfile in sorted(allfiles):\n            print (\"processing %s\" % cztfile)\n            try:\n                getFrObsvalues(cztfile,BSTEND,DBSTEND)\n            except Exception as e:\n                print (e)\n    else:\n        if(len(allfiles)>0):\n            pool = mp.Pool(processes=nproc)\n            results = []\n            for cztfile in sorted(allfiles):\n                print (\"processing %s\" % cztfile)\n                try:\n                    results.append(pool.apply_async(getFrObsvalues,[cztfile,BSTEND,DBSTEND]))\n                except Exception as e:\n                    print (e)\n            res = [result.get() for result in results]\n            pool.close()\n            pool.join()\n    \n    quefile = glob.glob('*.CsiFrObs.que')\n    quefile.sort()\n    outfiles=[]\n    for qf in quefile:\n        fp = open(qf,'r')\n        for ln in fp:\n            if(\"Outfile\" in ln):\n                outfiles.append(ln.split()[-1])\n                break\n        fp.close()\n    \n    outfiles.sort()\n    \n    obsid=\"\"\n    \n    if(len(quefile)>0):\n        fp = open(quefile[0],'r')\n        for ln in fp:\n            if(\"OBSID\" in ln):\n                obsid=ln.split()[-1]\n                break\n        fp.close()\n    \n    frobs_dir = \"%s_CsiFrObs_analysis\" % obsid\n    if not os.path.isdir(frobs_dir):\n        os.mkdir(frobs_dir)\n    \n    quefile = list(map(lambda x: \"../\"+x,quefile))\n    outfiles = list(map(lambda x: \"../\"+x,outfiles))\n    os.chdir(frobs_dir)\n    \n    if(os.path.isfile('file.list')):\n        os.remove('file.list')\n    fp = open('file.list','w')\n    for i in range(len(quefile)):\n        fp.write(\"%s   %s\\n\" % (quefile[i],outfiles[i]))\n    fp.close()\n    \n    print (\"Preparing combined PDF....\")\n    plotCsiFrObs(obsdir='./',pdffile=obsid+'_CsiFrObs_analysis.pdf')\n    \n    os.chdir(cwd)\n    try:\n        cmdstr = \"cp %s/%s/%s_CsiFrObs_analysis.pdf %s/\" % (obsdir,frobs_dir,obsid,dest)\n        os.system(cmdstr)\n    except: pass\n\ndef plotCsiFrObs(obsdir='./',pdffile='CsiFrObs_analysis.pdf'):\n    os.chdir(obsdir)\n    flst = open('file.list','r')\n    quefiles = []\n    datafiles = []\n    for ln in flst:\n        quefiles.append(ln.split()[0])\n        datafiles.append(ln.split()[1])\n    flst.close()\n    \n    obsinfo = {}\n    \n    for quef in quefiles:\n        qno = -1\n        fp = open(quef,'r')\n        for ln in fp:\n            if(\"QUADID\" in ln):\n                qno = int(ln.split()[-1][1])\n                break\n        fp.close()\n        obsinfo[qno] = {'quefile':quef}\n    \n    for qno in obsinfo.keys():\n        quef = obsinfo[qno]['quefile']\n        fp = open(quef,'r')\n        lns = fp.readlines()\n        fp.close()\n        \n        for ln in lns:\n            if(\"OBSID\" in ln):\n                obsinfo[qno]['OBSID'] = ln.split()[-1]\n            elif(\"Start MJD\" in ln):\n                obsinfo[qno]['SMJD'] = float(ln.split()[-1])\n            elif(\"End MJD\" in ln):\n                obsinfo[qno]['EMJD'] = float(ln.split()[-1])\n            elif(\"Start time\" in ln):\n                dum = ln.split(': ')\n                if(len(dum)>1):\n                    obsinfo[qno]['STIME'] = dum[-1].strip()\n            elif(\"Exposure\" in ln):\n                obsinfo[qno]['EXPOS'] = float(ln.split()[-1])\n            elif(\"Timebin\" in ln):\n                obsinfo[qno]['TBIN'] = float(ln.split()[-1])\n            elif(\"Outfile\" in ln):\n                obsinfo[qno]['DATAFILE'] = ln.split()[-1]\n        \n        ucfr = False\n        for i in range(len(lns)):\n            if(\"Unique CsiFrObs values and their counts\" in lns[i] and i<len(lns)-1 and not \"No Counts\" in lns[i+1]):\n                ucfr = True\n                j = i+1\n                if(not 'UCFR' in obsinfo[qno].keys()):\n                    obsinfo[qno]['UCFR'] = {}\n                while(j<len(lns) and ':' in lns[j]):\n                    sln = lns[j].split(':')\n                    if(len(sln)>1):\n                        k = int(sln[0].strip())\n                        v = int(sln[1].strip())\n                        obsinfo[qno]['UCFR'][k] = v\n                    j=j+1\n        if(not ucfr):\n            obsinfo[qno]['UCFR'] = {}\n    \n    frobslist = {}\n    for qno in obsinfo.keys():\n        if('DATAFILE' in obsinfo[qno].keys() and os.path.isfile(obsinfo[qno]['DATAFILE'])):\n            if(os.path.getsize(obsinfo[qno]['DATAFILE'])>0):\n                try:\n                    data = np.loadtxt(obsinfo[qno]['DATAFILE'])\n                    if(len(data.shape)==1):\n                        data = np.reshape(data,(1,2))\n                    time = data[:,0]\n                    frobs = data[:,1].astype(int)\n                    obsinfo[qno]['TIME'] = time\n                    obsinfo[qno]['FROBS'] = frobs\n                    for fr in np.unique(frobs):\n                        if not fr in frobslist.keys():\n                            frobslist[fr] = 1\n                        else:\n                            frobslist[fr] = frobslist[fr] + 1\n                except Exception as e:\n                    print (\"Exception: %s\" % e)\n            else:\n                obsinfo[qno]['TIME'] = np.array([])\n                obsinfo[qno]['FROBS'] = np.array([])\n        else:\n            obsinfo[qno]['TIME'] = np.array([])\n            obsinfo[qno]['FROBS'] = np.array([])\n                    \n                    \n    pdf = PdfPages(pdffile)\n    \n    fig = plt.figure(figsize=(8.27,11.69),dpi=100)\n    grid = plt.GridSpec(2, 2)\n    \n    obsid = \"Unknown\"\n    for qno in obsinfo.keys():\n        if('OBSID' in obsinfo[qno].keys()):\n            obsid = obsinfo[qno]['OBSID']\n            break\n    \n    mjdstart = []\n    mjdend = []\n    for qno in obsinfo.keys():\n        if('SMJD' in obsinfo[qno].keys()):\n            mjdstart.append(obsinfo[qno]['SMJD'])\n        if('EMJD' in obsinfo[qno].keys()):\n            mjdend.append(obsinfo[qno]['EMJD'])\n    \n    if(len(mjdstart)>0 and len(mjdend)>0):\n        mjds = np.min(mjdstart)\n        mjde = np.max(mjdend)\n    \n    \n    pltqno = []\n    for qno in obsinfo.keys():\n        if(len(obsinfo[qno]['TIME'])>0):\n            pltqno.append(qno)\n    \n    for qno in sorted(pltqno):\n        time = obsinfo[qno]['TIME']\n        frobs = obsinfo[qno]['FROBS']\n        \n        for pl_pg in range(0,len(time),100000):\n            plt.clf()\n            \n            plt.suptitle(\"OBSID: %s        QUAD: q%d        Page: %d\" % (obsid,qno,pl_pg//100000 + 1),fontsize=14)\n            \n            ax1 = plt.subplot(grid[0, 0])\n            ax2 = plt.subplot(grid[0, 1])\n            ax3 = plt.subplot(grid[1, :])\n            \n            endi = min(pl_pg+100000,len(time))\n            \n            ax1.set_title('CsiFrObs vs Time (Quad %d)' % qno)\n            if(len(time)>0):\n                lbl = ''\n                ax1.plot(time[pl_pg:endi],frobs[pl_pg:endi],'-',label=lbl)\n                ax1.set_xlim(time[pl_pg],time[endi-1])\n                ymin = np.min(frobs[pl_pg:endi])-1\n                ymax = np.max(frobs[pl_pg:endi])+1\n                yrange = ymax-ymin\n                ax1.set_ylim(ymin-0.05*yrange,ymax+0.05*yrange)\n                ax1.set_xlabel('Time (s)')\n                ax1.set_ylabel('CsiFrObs')\n                ax1.grid(True)\n                \n                if(pl_pg==0):\n                    ucfr = obsinfo[qno]['UCFR']\n                    yp = 0.7\n                    ax2.text(0.05,0.9,\"Unique CsiFrObs values\",fontweight='bold')\n                    for k in sorted(ucfr.keys()):\n                        ax2.text(0.05,yp,'%d:%d' % (k,ucfr[k]))\n                        yp = yp - 0.05\n                    \n                \n                    frobs_set = set(frobs)\n                    all_frobs = set(range(0,256))\n                    missing_frobs = all_frobs - frobs_set\n                    extra_frobs = frobs_set - all_frobs\n                    extra_frobs_lt = set([fr for fr in frobs if fr < 0])\n                    extra_frobs_gt = set([fr for fr in frobs if fr > 255])\n                    \n                    if(len(missing_frobs)>0):\n                        yp = yp - 0.1\n                        ax2.text(0.05,yp,\"Missing values\",fontweight='bold')\n                        yp = yp - 0.05\n                        if(len(missing_frobs)<20):\n                            frobs_lst = sorted(list(missing_frobs))\n                            for fs in frobs_lst:\n                                ax2.text(0.05,yp,'%d' % fs)\n                                yp = yp - 0.05\n                                if(yp<0.05):\n                                    yp = 0.7\n                                    pdf.savefig()\n                                    plt.clf()\n                                    ax2 = plt.subplot(grid[0, 1])\n                        else:\n                            frobs_all = np.array(sorted(list(missing_frobs)))\n                            frobs_str = []\n                            \n                            for i in range(0,len(frobs_all)):\n                                if(i==0):\n                                    rstart = frobs_all[i]\n                                    rend = frobs_all[i]\n                                elif(frobs_all[i]-frobs_all[i-1] == 1):\n                                    rend = frobs_all[i]\n                                else:\n                                    if(rstart==rend):\n                                        frobs_str.append('%d' % rstart)\n                                    else:\n                                        frobs_str.append('%d-%d' % (rstart,rend))\n                                    rstart = frobs_all[i]\n                                    rend = frobs_all[i]\n                            \n                            if(rstart==rend):\n                                frobs_str.append('%d' % rstart)\n                            else:\n                                frobs_str.append('%d-%d' % (rstart,rend))\n                            \n                            j = 0\n                            while(j<len(frobs_str)):\n                                lnstr = \"\"\n                                while(j<len(frobs_str) and len(lnstr)<15):\n                                    if(len(lnstr)>0):\n                                        lnstr = lnstr + \", \" + frobs_str[j]\n                                    else:\n                                        lnstr = frobs_str[j]\n                                    j = j + 1\n                                \n                                ax2.text(0.05,yp,lnstr)\n                                yp = yp - 0.05\n                                if(yp<0.05):\n                                    yp = 0.7\n                                    pdf.savefig()\n                                    plt.clf()\n                                    ax2 = plt.subplot(grid[0, 1])\n                    \n                    if(len(extra_frobs)>0):\n                        if(len(extra_frobs_lt)>0 or len(extra_frobs_gt)>0):\n                            yp = yp - 0.1\n                            ax2.text(0.05,yp,\"Extra values\",fontweight='bold')\n                            yp = yp - 0.05\n                            if(len(extra_frobs_lt)<20):\n                                frobs_lst = sorted(list(extra_frobs_lt))\n                                for fs in frobs_lst:\n                                    ax2.text(0.05,yp,'%d' % fs)\n                                    yp = yp - 0.05\n                                    if(yp<0.05):\n                                        yp = 0.7\n                                        pdf.savefig()\n                                        plt.clf()\n                                        ax2 = plt.subplot(grid[0, 1])\n                        \n                            if(len(extra_frobs_gt)<20):\n                                frobs_lst = sorted(list(extra_frobs_gt))\n                                for fs in frobs_lst:\n                                    ax2.text(0.05,yp,'%d' % fs)\n                                    yp = yp - 0.05\n                                    if(yp<0.05):\n                                        yp = 0.7\n                                        pdf.savefig()\n                                        plt.clf()\n                                        ax2 = plt.subplot(grid[0, 1])\n                                                        \n                ax3.set_title('CsiFrObs Histogram (Quad %d)' % qno)\n                nbins = len(np.unique(frobs[pl_pg:endi]))\n                if(nbins>50): nbins=50\n                ax3.hist(frobs[pl_pg:endi],bins=nbins)\n                ax3.set_xlabel('CsiFrObs')\n                ax3.set_ylabel('Counts')\n                ax3.grid(True)\n            \n            else:\n                ax1.text(0.5,0.5,\"No Data\",fontsize=24,va='center',ha='center')\n                ax3.text(0.5,0.5,\"No Data\",fontsize=24,va='center',ha='center')\n            \n            pdf.savefig()\n    \n    plt.clf()\n    plt.suptitle(\"Summary - OBSID: %s\" % obsid,fontsize=14)\n    ax1 = plt.subplot(111)\n    \n    frlist_keys = np.array(sorted(list(frobslist.keys())))\n    frlist_values = np.array([frobslist[fr] for fr in frlist_keys])\n    \n    ax1.bar(frlist_keys, frlist_values, width=1.0, color='steelblue')\n    ax1.set_xlabel('Unique CsiFrObs')\n    ax1.set_ylabel('Counts')\n    \n    #Find all the value which are not shown in plots\n    missing_vals = []\n    extra_vals = []\n    \n    for frval in range(0,256):\n        if(not frval in frlist_keys):\n            missing_vals.append(frval)\n    \n    for frval in frlist_keys:\n        if(frval<0 or frval>255):\n            extra_vals.append(frval)\n    \n    if(len(missing_vals)>0):\n        st = ''\n        for frval in missing_vals:\n            if(len(st)>0):\n                st = st + ', ' + str(frval)\n            else:\n                st = str(frval)\n        ax1.text(0.5, 0.9, 'Missing CsiFrObs: ' + st, \n                transform=ax1.transAxes, va='center', ha='center',fontsize=12)\n    \n    if(len(extra_vals)>0):\n        st = ''\n        for frval in extra_vals:\n            if(len(st)>0):\n                st = st + ', ' + str(frval)\n            else:\n                st = str(frval)\n        ax1.text(0.5, 0.85, 'Extra CsiFrObs: ' + st, \n                transform=ax1.transAxes, va='center', ha='center',fontsize=12)\n    \n    \n    pdf.savefig()\n    \n    pdf.close()\n\n\nif __name__ == '__main__':\n    args = len(sys.argv)\n    if (args==2):\n        print (\"Processing observation folder : %s\" % sys.argv[1])\n        processFrObs(sys.argv[1],nproc=nproc)\n    elif(args==3):\n        print (\"Processing observation folder : %s\" % sys.argv[1])\n        processFrObs(sys.argv[1],sys.argv[2],nproc=nproc)\n    else:\n        print (\"%s: Incorrect number of parameters.\" % sys.argv[0])\n        print (\"Usage: %s observation_folder [destination_folder]\" % sys.argv[0])\n\n\u0005End File\u0006/**\n * @file  CentriodFinder.C\n * @author Tanul Gupta\n * @brief \n * @version 0.1\n * @date 2021-04-19\n * \n * @copyright Copyright (c) 2021\n * \n */\n#include <vector>\n#include <cmath>\n#include <iostream>\n#include <algorithm>\n#include <numeric>\n\n#include \"Median.h\"\n\n/**\n * @brief Get a 5 x 5 window pixel intensity and compute the centroid of a point.\n * \n * @param intensity 25 element 1D vector, representing the 5 x 5 window pixel intensity.\n * @param cenx (OUT) x coordinate of centroid wrt centre of window.\n * @param ceny (OUT) y coordinate of centroid wrt centre of window.\n * @param threshold threshold of pixel intensity, above which pixels will be considered\n * for calculating centroid.\n * @return int, 0 on success, -1 on any exception\n */\nint getCentroid(const std::vector<double> &intensity, double &cenx, double &ceny, \n    const double &threshold, const int &window_size)\n{\n    try{\n        double x = 0.0, y = 0.0, psum = 0.0, temp_val = 0.0;\n        int i = 0, j = 0, tot_pixels = window_size * window_size, k = 0;\n        int half_window = window_size / 2;\n        std::vector<double> ints_above_thresh;\n        \n        for(i = -half_window; i <= half_window; i++){\n            for(j = -half_window; j <= half_window; j++){\n                temp_val = intensity[k];\n                ints_above_thresh.push_back(temp_val);\n                k += 1;\n            }\n        }\n        \n\n        //Using median above threshold as threshold: \n        double med_threshold = threshold * median(&ints_above_thresh[0], tot_pixels);\n        if(med_threshold < 10.0){\n            med_threshold = 10.0;\n        }\n\n        //std::cout<<\"Median: \"<<median(&ints_above_thresh[0], tot_pixels)<<\", threshold: \"<<med_threshold<<std::endl;\n        //double max_int = *std::max_element(intensity.begin(), intensity.end());\n\n        //Calculating the centroid:\n        k = 0;\n        for(i = -half_window; i <= half_window; i++){\n            for(j = -half_window; j <= half_window; j++){\n                temp_val = intensity[k];\n                if(temp_val > med_threshold){\n                    x += i * temp_val;\n                    y += j * temp_val;\n                    psum += temp_val;\n                }\n                k += 1;\n            }\n        }\n\n        if(psum > 0){\n            cenx = x / psum;\n            ceny = y / psum;\n            return 0;\n        }\n        else{\n            //std::cout<<\"Zero intensity in 5 x 5 window.\"<<std::endl;\n            return -1;\n        }\n    }\n    catch(...){\n        std::cout<<\"Error in calculating centroid.\"<<std::endl;\n        return -1;\n    }\n}\n\n/**\n * @brief Get a 5 x 5 window pixel intensity and compute the centroid of a point.\n * \n * @param intensity 25 element 1D vector, representing the 5 x 5 window pixel intensity.\n * @param cenx (OUT) x coordinate of centroid wrt centre of window.\n * @param ceny (OUT) y coordinate of centroid wrt centre of window.\n * @param threshold threshold of pixel intensity, above which pixels will be considered\n * for calculating centroid.\n * @return int, 0 on success, -1 on any exception\n */\nint getCentroidToT(const std::vector<double> &intensity, double &cenx, double &ceny, \n    const double &threshold, const int &window_size)\n{\n    try{\n        double x = 0.0, y = 0.0, psum = 0.0, temp_val = 0.0;\n        int i = 0, j = 0, tot_pixels = window_size * window_size, k = 0;\n        int half_window = window_size / 2;\n        std::vector<double> ints_above_thresh;\n        \n        for(i = -half_window; i <= half_window; i++){\n            for(j = -half_window; j <= half_window; j++){\n                temp_val = intensity[k];\n                ints_above_thresh.push_back(temp_val);\n                k += 1;\n            }\n        }\n        \n\n        //Using median above threshold as threshold: \n        double med_threshold = threshold * median(&ints_above_thresh[0], tot_pixels);\n        if(med_threshold < 10.0){\n            med_threshold = 10.0;\n        }\n\n        //std::cout<<\"Median: \"<<median(&ints_above_thresh[0], tot_pixels)<<\", threshold: \"<<med_threshold<<std::endl;\n        double max_int = *std::max_element(intensity.begin(), intensity.end());\n\n        if(max_int < 10.0){\n            max_int = 10.0;\n        }\n\n        //Calculating the centroid:\n        k = 0;\n        for(i = -half_window; i <= half_window; i++){\n            for(j = -half_window; j <= half_window; j++){\n                temp_val = intensity[k] / max_int;\n                if(temp_val > (med_threshold / max_int)){\n                    x += i * temp_val;\n                    y += j * temp_val;\n                    psum += temp_val;\n                }\n                k += 1;\n            }\n        }\n\n        if(psum > 0){\n            cenx = x / psum;\n            ceny = y / psum;\n            return 0;\n        }\n        else{\n            //std::cout<<\"Zero intensity in 5 x 5 window.\"<<std::endl;\n            return -1;\n        }\n    }\n    catch(...){\n        std::cout<<\"Error in calculating centroid.\"<<std::endl;\n        return -1;\n    }\n}\n\n/**\n * @brief Get a 5 x 5 window pixel intensity and compute the centroid of a point.\n * \n * @param intensity 25 element 1D vector, representing the 5 x 5 window pixel intensity.\n * @param cenx (OUT) x coordinate of centroid wrt centre of window.\n * @param ceny (OUT) y coordinate of centroid wrt centre of window.\n * @param threshold threshold of pixel intensity, above which pixels will be considered\n * for calculating centroid.\n * @param centroid_type type of centroid to calculate. 1 = weighted centroid, 2 = simple centroid\n * @return int, 0 on success, -1 on any exception\n */\nint getCentroidByType(const std::vector<double> &intensity, double &cenx, double &ceny, \n    const double &threshold, const int &window_size, const int &centroid_type)\n{\n    if(centroid_type == 1){\n        return getCentroid(intensity, cenx, ceny, threshold, window_size);\n    }\n    else if(centroid_type == 2){\n        return getCentroidToT(intensity, cenx, ceny, threshold, window_size);\n    }\n    else{\n        std::cout<<\"Invalid centroid type.\"<<std::endl;\n        return -1;\n    }\n}\n\n/**\n * @brief Get a 5 x 5 window pixel intensity and compute the centroid of a point.\n * \n * @param intensity 25 element 1D vector, representing the 5 x 5 window pixel intensity.\n * @param cenx (OUT) x coordinate of centroid wrt centre of window.\n * @param ceny (OUT) y coordinate of centroid wrt centre of window.\n * @param centroid_type type of centroid to calculate. 1 = weighted centroid, 2 = simple centroid\n * @return int, 0 on success, -1 on any exception\n */\nint get3x3Centroid(const std::vector<double> &intensity, double &cenx, double &ceny, \n    const int &centroid_type)\n{\n    try{\n        double tot_intensity = 0.0;\n        for(int i=0; i<9; i++){\n            tot_intensity += intensity[i];\n        }\n        \n        if(tot_intensity <= 0.0){\n            return -1;\n        }\n        \n        if(centroid_type == 1){\n            //Weighted centroid\n            double x = 0.0, y = 0.0, psum = 0.0;\n            int k = 0;\n            for(int i = -1; i <= 1; i++){\n                for(int j = -1; j <= 1; j++){\n                    x += i * intensity[k];\n                    y += j * intensity[k];\n                    psum += intensity[k];\n                    k += 1;\n                }\n            }\n            cenx = x / psum;\n            ceny = y / psum;\n        }\n        else if(centroid_type == 2){\n            //Simple centroid\n            double x = 0.0, y = 0.0;\n            int k = 0;\n            for(int i = -1; i <= 1; i++){\n                for(int j = -1; j <= 1; j++){\n                    x += i * intensity[k] / tot_intensity;\n                    y += j * intensity[k] / tot_intensity;\n                    k += 1;\n                }\n            }\n            cenx = x;\n            ceny = y;\n        }\n        else{\n            std::cout<<\"Invalid centroid type.\"<<std::endl;\n            return -1;\n        }\n        \n        return 0;\n    }\n    catch(...){\n        std::cout<<\"Error in calculating 3x3 centroid.\"<<std::endl;\n        return -1;\n    }\n}\n\u0005End File\u0006/* CZT Imaging Pipeline application\n */\n\n#include <iostream>\n#include <iomanip>\n#include <cmath>\n#include <cstdlib>\n#include <cstring>\n#include <cstdio>\n#include <ctime>\n#include <fstream>\n#include <sstream>\n#include <cstdint>\n#include <string>\n#include <vector>\n#include \"fitsio.h\"\n#include \"CCztInstrumentMonitor.h\"\n#include \"CCztPreProcessingSettings.h\"\n#include \"CCztPreProcessingHandler.h\"\n#include \"CCztPixID.h\"\n#include \"CCztScienceDataReader.h\"\n#include \"CCztFitsTools.h\"\n#include \"CCztEvtDataCreater.h\"\n#include \"CCztImageCreater.h\"\n#include \"CCztMode.h\"\n#include \"CPixelConversion.h\"\n#include \"CCztCalibrationHandler.h\"\n#include \"CCztDetectQuadID.h\"\n#include \"CEnergyCalibration.h\"\n#include \"CCztTime.h\"\n#include \"CCztHVFilters.h\"\n#include \"CCalDB.h\"\n#include \"CCztProcessedTeleByTime.h\"\n#include \"CCztDetQuadrantMapping.h\"\n#include \"CCztQuadBoundaryConstants.h\"\n#include \"CCztCalDBManager.h\"\n#include \"detectorConstants.h\"\n#include \"Event.h\"\n#include \"PixelID.h\"\n#include \"CEnergyCalibrate.h\"\n#include \"CCztFPGAConfigData.h\"\n#include \"CCztDefs.h\"\n#include \"CCztSuperPixels.h\"\n#include \"CCztGTI.h\"\n#include \"CCztCheckBadstreakinCzti.h\"\n#include \"HistogramManipulator.h\"\n#include \"DataStructures.h\"\n#include \"LogFile.h\"\n#include \"MessageHandler.h\"\n#include \"Correlation.h\"\n#include \"CorrelationException.h\"\n#include \"DataIOException.h\"\n#include \"AstroTime.h\"\n#include \"ImageException.h\"\n#include \"PolarizationException.h\"\n#include \"CModuleAliases.h\"\n#include \"CommandLineOptions.h\"\n#include \"ExpoCorrectionFactor.h\"\n#include \"ImageVersions.h\"\n#include \"FluxCalculator.h\"\n#include \"FluxCalculationException.h\"\n#include \"CztEventData.h\"\n#include \"CztHeaderDefaults.h\"\n#include \"CztCrabScanProcess.h\"\n#include \"CztiLockoutParser.h\"\n#include \"CCztImage.h\"\n#include \"CCztMasks.h\"\n#include \"CCztGTICreater.h\"\n#include \"CCztMkfDPhiCreater.h\"\n#include \"PolarAlongWithAng.h\"\n#include \"CztiPolarizationPipeline.h\"\n#include \"Timing.h\"\n#include \"FileWriteHdrs.h\"\n#include \"LockFunctions.h\"\n#include \"CopyFileHeaders.h\"\n#include \"CopyTimeCols.h\"\n#include \"CrabScanPol.h\"\n#include \"Correlation_SingleSource.h\"\n\nusing namespace std;\n\n\n// =================== PIPELINE =====================================\n\n#define BUFFER_SIZE 10000\n#define VERSION \"1.0\"\nconst float CztPipelineBuffer = BUFFER_SIZE;\n\n/**\n * @brief Entry point for the Czti Pipeline application.\n * \n * @param argc int, count of command line arguments.\n * @param argv char**, array of command line arguments.\n * @return int, 0 on success, error code on failure.\n */\nint main(int argc, char *argv[]){\n\n    int iStatusRet = 0;\n    vector<string> vecstrInputFiles;\n    string strLLDFile=\"\";\n    string strULDFile=\"\";\n    string strBunchFile=\"\";\n    string strLockoutFile=\"\";\n    string strOCCFile = \"\";\n    string strInfile = \"\";\n    string strBadpixFile = \"\";\n    string strMkfFile = \"\";\n    string strCaldbPath = \"\";\n    string strRawdataPath = \"\";\n    string strCreatLevel2Data = \"\";\n    string strOutputDir = \"\";\n    string strTempDir = \"\";\n    int iQuadrant = -1;\n    int iDetector = -1;\n    int iReprocessWithBadPixFile = -1;\n    int iUserEnergyCutStatus = -1;\n    float fUserEnergyLowerCut = -1;\n    float fUserEnergyUpperCut = -1;\n    int iGTIExt = -1;\n    int iLocalGainStatus = -1;\n    int iResetBadPixel = -1;\n    int iLocalGainRead = -1;\n    string strLocalGainPath = \"\";\n    int iGoodyPixStatus = -1;\n    string strGoodyPixFile = \"\";\n    int iExtraPixelStatus = -1;\n    string strExtraPixFile = \"\";\n    string strDphi_file = \"\";\n    int iUseDphiGtiExt = -1;\n    int iUseCztiGtiExt = -1;\n    int iCreatl1basedBadpix = -1;\n    int iCztmask = -1;\n    string strCztmaskfile = \"\";\n    int iCrabNormFlux = -1;\n    int iUserAlpha = -1;\n    float fUserAlphaValue = -1;\n    int iUserDelta = -1;\n    float fUserDeltaValue = -1;\n    int iRejectVeto = -1;\n    int iSkipErrors = -1;\n    int iImageCenterX = -1;\n    int iImageCenterY = -1;\n    int iBadOrbit = -1;\n    float fBadOrbitTime = 0.0;\n    float fBadOrbitDTime = 0.0;\n    int iBadStreak = -1;\n    float fBadStreakTime = 0.0;\n    float fBadStreakDTime = 0.0;\n    int iOutputVersion = -1;\n    int iUseQuadBoundConfig = -1;\n    int iNoModeCheck = -1;\n    int iNoTimeCheck = -1;\n    int iNoEnergyCheck = -1;\n    int iOutputEvtMode = -1;\n    int iMultiplicity = -1;\n    int iUseElectronicsNoise = -1;\n    int iFilterBadStreak = -1;\n    int iFilterTimingFlag = -1;\n    string strTimingFlagFile = \"\";\n    string strTaskName = \"\";\n\n    float fAspectRejectLimit = -1.0;\n    int iAspectCorrection = -1;\n    int iCrabScanRun = -1;\n    int iSingleSourcePolar = -1;\n    string strSingleSourcePolarFile = \"\";\n    int iNorm = -1;\n    int iQA = -1;\n    string strPCTFile = \"\";\n    string strPCTQAFile = \"\";\n    int iRespType = -1;\n    int iTxStart = -1;\n    int iTxEnd = -1;\n    int iTyStart = -1;\n    int iTyEnd = -1;\n    int iExpoCorrect = -1;\n    float fAvgCrabCtsPerPCT = -1.0;\n    float fCalcCrabCtsPerPCT = -1.0;\n    string strCrabRefFile = \"\";\n    int iPolarizationRun = -1;\n    int iPolarizationVer = -1;\n    int iPolarizationSingleSource = -1;\n    string strPolExtraHistBinning = \"\";\n    int iDebugInfo = -1;\n    int iTimingAnalysis = -1;\n    int iTimingSourceType = -1;\n    int iTimingRedshift = -1;\n    float fTimingRedshiftValue = -1.0;\n    int iTimingRiseRef = -1;\n    float fTimingRiseRefValue = -1.0;\n    int iTimingDecayRef = -1;\n    float fTimingDecayRefValue = -1.0;\n    int iTimingPolSourceType = -1;\n    int iTimingGRB = -1;\n    float fTimingT90StartTime = -1.0;\n    float fTimingT90EndTime = -1.0;\n    int iTimingTriggered = -1;\n    float fTimingTriggerTime = -1.0;\n    int iTimingPulsarFreq = -1;\n    float fTimingPulsarFreqValue = -1.0;\n    float fTimingPulsarFreqDerivative = -1.0;\n    string strTimingRefMJD = \"\";\n    int iTimingDuration = -1;\n    float fTimingDurationValue = -1.0;\n    int iTimingT0 = -1;\n    float fTimingT0Value = -1.0;\n    int iTimingBaryCorr = -1;\n    int iTimingIncludePreTrigger = -1;\n    int iTimingUseTriggerTime = -1;\n    int iTimingPolGRB = -1;\n    int iTimingPolPulsar = -1;\n    int iTimingPolNorm = -1;\n    float fTimingPolAlpha = -1.0;\n    float fTimingPolDelta = -1.0;\n    string strTimingExtraArgs = \"\";\n    int iTimingRA = -1;\n    float fTimingRAValue = -1.0;\n    int iTimingDEC = -1;\n    float fTimingDECValue = -1.0;\n    int iTimingEphemeris = -1;\n    string strTimingEphFile = \"\";\n    int iTelemetryMode = -1;\n    int iTimingTelemetryMode = -1;\n\n    int iEmulateWithCommentMode = -1;\n    string strCommentModeInputFiles = \"\";\n    \n    vector<string> vecQuadBoundL0Files;\n    vecQuadBoundL0Files.clear();\n\n    //New options for Polarization pipeline\n    int iPolRA = -1;\n    float fPolRAValue = -1.0;\n    int iPolDEC = -1;\n    float fPolDECValue = -1.0;\n    int iPolT0 = -1;\n    float fPolT0Value = -1.0;\n    int iPolDuration = -1;\n    float fPolDurationValue = -1.0;\n    int iPolBackground = -1;\n    float fPolBackgroundValue = -1.0;\n    int iPolOutDetector = -1;\n    float fPolOutDetectorValue = -1.0;\n    int iPolSNR = -1;\n    float fPolSNRValue = -1.0;\n    int iPolEnergyMin = -1;\n    float fPolEnergyMinValue = -1.0;\n    int iPolEnergyMax = -1;\n    float fPolEnergyMaxValue = -1.0;\n    int iPolAlpha = -1;\n    float fPolAlphaValue = -1.0;\n    int iPolDelta = -1;\n    float fPolDeltaValue = -1.0;\n    int iPolSourceName = -1;\n    int iPolSingleSource = -1;\n    string strPolSourceName = \"\";\n    string strPolMETFile = \"\";\n    int iPolMET = -1;\n    string strPolMaskWeight = \"\";\n    int iPolMaskWeight = -1;\n    int iPolTriggered = -1;\n    float fPolTriggerTime = -1.0;\n    string strPolBunchFile = \"\";\n    int iPolIncludePreTrigger = -1;\n    int iPolSourceType = -1;\n    int iPolUseTriggerTime = -1;\n    int iPolCentroidType = -1;\n    string strPolExtraArgs = \"\";\n    int iPolGRB = -1;\n    int iPolBlazer = -1;\n    int iPolCalcMod = -1;\n    float fPolCalcModValue = -1.0;\n    int iPolCalcAng = -1;\n    float fPolCalcAngValue = -1.0;\n    int iPolMaskMode = -1;\n    int iPolMaskModeValue = -1;\n    int iPolDumpRawEvents = -1;\n\n    int iTargetRA = -1;\n    float fTargetRAValue = -1.0;\n    int iTargetDEC = -1;\n    float fTargetDECValue = -1.0;\n\n    //This flag indicates whether flux calculation is required or not\n    int iFluxCalc = -1;\n    \n    \n    //Instrument model related\n    int iRespMatrixExtn = -1;\n    \n    //Crab scan related\n    int iRefCATNo = -1;\n    int iRefCATNoValue = -1;\n    \n    //Command line arguments\n    int iCmdArgument = -1;\n\n    string moduleName = \"CZTPIPELINE\";\n    string localLogFileName= \"CZT_PIPELINE.log\";\n    \n    CztHeaderDefaults cztHeaderDefaults;\n\n    if(argc < 2){\n        cerr << \"ERROR : Invalid Arguments. Use -h for help\\n\";\n        return 1;\n    }\n\n    // ******* Read the command line options *************\n    CommandLineOptions cmdLineOptions;\n    iStatusRet = cmdLineOptions.parse(argc, argv, moduleName, VERSION);\n    if (iStatusRet != 0) {\n        cerr << \"ERROR : Error parsing the command line arguments, exiting...\\n\";\n        return 2;\n    }\n\n    //When the help option is used, then exit\n    if (cmdLineOptions.help()){\n        return 0;\n    }\n    \n    //Process the options from command line arguments.\n    vecstrInputFiles = cmdLineOptions.inputFiles();\n    strCaldbPath = cmdLineOptions.caldbPath();\n    strLLDFile = cmdLineOptions.lldFile();\n    strULDFile = cmdLineOptions.uldFile();\n    strBunchFile = cmdLineOptions.bunchFile();\n    strLockoutFile = cmdLineOptions.lockoutFile();\n    strOCCFile = cmdLineOptions.occFile();\n    strRawdataPath = cmdLineOptions.rawdataPath();\n    iQuadrant = cmdLineOptions.quadrant();\n    iDetector = cmdLineOptions.detector();\n    strBadpixFile = cmdLineOptions.badpixFile();\n    strMkfFile = cmdLineOptions.mkfFile();\n    strTaskName = cmdLineOptions.taskName();\n    iReprocessWithBadPixFile = cmdLineOptions.reprocessWithBadPixFile();\n    iUserEnergyCutStatus = cmdLineOptions.userEnergyCutStatus();\n    fUserEnergyLowerCut = cmdLineOptions.energyLowerCut();\n    fUserEnergyUpperCut = cmdLineOptions.energyUpperCut();\n    iGTIExt = cmdLineOptions.gtiExt();\n    iLocalGainStatus = cmdLineOptions.localGainStatus();\n    strLocalGainPath = cmdLineOptions.localGainPath();\n    iGoodyPixStatus = cmdLineOptions.goodyPixStatus();\n    strGoodyPixFile = cmdLineOptions.goodyPixFile();\n    iExtraPixelStatus = cmdLineOptions.extraPixelStatus();\n    strExtraPixFile = cmdLineOptions.extraPixFile();\n    iResetBadPixel = cmdLineOptions.resetBadPixel();\n    iLocalGainRead = cmdLineOptions.localGainRead();\n    strDphi_file = cmdLineOptions.dphiFile();\n    iUseDphiGtiExt = cmdLineOptions.useDphiGtiExt();\n    iUseCztiGtiExt = cmdLineOptions.useCztiGtiExt();\n    iCrablvel1basedBadpix = cmdLineOptions.createL1basedBadpix();\n    iCztmask = cmdLineOptions.cztmask();\n    strCztmaskfile = cmdLineOptions.cztmaskfile();\n    iCrabNormFlux = cmdLineOptions.crabNormFlux();\n    iUserAlpha = cmdLineOptions.userAlpha();\n    fUserAlphaValue = cmdLineOptions.userAlphaValue();\n    iUserDelta = cmdLineOptions.userDelta();\n    fUserDeltaValue = cmdLineOptions.userDeltaValue();\n    iRejectVeto = cmdLineOptions.rejectVeto();\n    iSkipErrors = cmdLineOptions.skipErrors();\n    iImageCenterX = cmdLineOptions.imageCenterX();\n    iImageCenterY = cmdLineOptions.imageCenterY();\n    iBadOrbit = cmdLineOptions.badOrbit();\n    fBadOrbitTime = cmdLineOptions.badOrbitTime();\n    fBadOrbitDTime = cmdLineOptions.badOrbitDTime();\n    iBadStreak = cmdLineOptions.badStreak();\n    fBadStreakTime = cmdLineOptions.badStreakTime();\n    fBadStreakDTime = cmdLineOptions.badStreakDTime();\n    iOutputVersion = cmdLineOptions.outputVersion();\n    iUseQuadBoundConfig = cmdLineOptions.useQuadBoundConfig();\n    iNoModeCheck = cmdLineOptions.noModeCheck();\n    iNoTimeCheck = cmdLineOptions.noTimeCheck();\n    iNoEnergyCheck = cmdLineOptions.noEnergyCheck();\n    iOutputEvtMode = cmdLineOptions.outputEventMode();\n    iMultiplicity = cmdLineOptions.multiplicity();\n    iUseElectronicsNoise = cmdLineOptions.useElectronicsNoise();\n    iFilterBadStreak = cmdLineOptions.filterBadStreak();\n    iFilterTimingFlag = cmdLineOptions.filterTimingFlag();\n    strTimingFlagFile = cmdLineOptions.timingFlagFile();\n    iFluxCalc = cmdLineOptions.fluxCalc();\n    iRespMatrixExtn = cmdLineOptions.respMatrixExtn();\n    \n    //Crab scan releted\n    iRefCATNo = cmdLineOptions.refCATNo();\n    iRefCATNoValue = cmdLineOptions.refCATNoValue();\n    \n    //processing of different aspect modes with acceptance limit \n    fAspectRejectLimit = cmdLineOptions.aspectRejectLimit();\n    iAspectCorrection = cmdLineOptions.aspectCorrection();\n    iCrabScanRun = cmdLineOptions.crabScanRun();\n    iSingleSourcePolar = cmdLineOptions.singleSourcePolar();\n    strSingleSourcePolarFile = cmdLineOptions.singleSourcePolarFile();\n    iNorm = cmdLineOptions.norm();\n    iQA = cmdLineOptions.qa();\n    strPCTFile = cmdLineOptions.pctFile();\n    strPCTQAFile = cmdLineOptions.pctQAFile();\n    iRespType = cmdLineOptions.respType();\n    iTxStart = cmdLineOptions.txStart();\n    iTxEnd = cmdLineOptions.txEnd();\n    iTyStart = cmdLineOptions.tyStart();\n    iTyEnd = cmdLineOptions.tyEnd();\n    iExpoCorrect = cmdLineOptions.expoCorrect();\n    fAvgCrabCtsPerPCT = cmdLineOptions.avgCrabCtsPerPCT();\n    fCalcCrabCtsPerPCT = cmdLineOptions.calcCrabCtsPerPCT();\n    strCrabRefFile = cmdLineOptions.crabRefFile();\n\n    //Polarization related options\n    iPolarizationRun = cmdLineOptions.polarizationRun();\n    iPolarizationVer = cmdLineOptions.polarizationVer();\n    iPolarizationSingleSource = cmdLineOptions.polarizationSingleSource();\n    strPolExtraHistBinning = cmdLineOptions.polExtraHistBinning();\n    iDebugInfo = cmdLineOptions.debugInfo();\n\n    //Timing related options\n    iTimingAnalysis = cmdLineOptions.timingAnalysis();\n    iTimingSourceType = cmdLineOptions.timingSourceType();\n    iTimingRedshift = cmdLineOptions.timingRedshift();\n    fTimingRedshiftValue = cmdLineOptions.timingRedshiftValue();\n    iTimingRiseRef = cmdLineOptions.timingRiseRef();\n    fTimingRiseRefValue = cmdLineOptions.timingRiseRefValue();\n    iTimingDecayRef = cmdLineOptions.timingDecayRef();\n    fTimingDecayRefValue = cmdLineOptions.timingDecayRefValue();\n    iTimingPolSourceType = cmdLineOptions.timingPolSourceType();\n    iTimingGRB = cmdLineOptions.timingGRB();\n    fTimingT90StartTime = cmdLineOptions.timingT90StartTime();\n    fTimingT90EndTime = cmdLineOptions.timingT90EndTime();\n    iTimingTriggered = cmdLineOptions.timingTriggered();\n    fTimingTriggerTime = cmdLineOptions.timingTriggerTime();\n    iTimingPulsarFreq = cmdLineOptions.timingPulsarFreq();\n    fTimingPulsarFreqValue = cmdLineOptions.timingPulsarFreqValue();\n    fTimingPulsarFreqDerivative = cmdLineOptions.timingPulsarFreqDerivative();\n    strTimingRefMJD = cmdLineOptions.timingRefMJD();\n    iTimingDuration = cmdLineOptions.timingDuration();\n    fTimingDurationValue = cmdLineOptions.timingDurationValue();\n    iTimingT0 = cmdLineOptions.timingT0();\n    fTimingT0Value = cmdLineOptions.timingT0Value();\n    iTimingBaryCorr = cmdLineOptions.timingBaryCorr();\n    iTimingIncludePreTrigger = cmdLineOptions.timingIncludePreTrigger();\n    iTimingUseTriggerTime = cmdLineOptions.timingUseTriggerTime();\n    iTimingPolGRB = cmdLineOptions.timingPolGRB();\n    iTimingPolPulsar = cmdLineOptions.timingPolPulsar();\n    iTimingPolNorm = cmdLineOptions.timingPolNorm();\n    fTimingPolAlpha = cmdLineOptions.timingPolAlpha();\n    fTimingPolDelta = cmdLineOptions.timingPolDelta();\n    strTimingExtraArgs = cmdLineOptions.timingExtraArgs();\n    iTimingRA = cmdLineOptions.timingRA();\n    fTimingRAValue = cmdLineOptions.timingRAValue();\n    iTimingDEC = cmdLineOptions.timingDEC();\n    fTimingDECValue = cmdLineOptions.timingDECValue();\n    iTimingEphemeris = cmdLineOptions.timingEphemeris();\n    strTimingEphFile = cmdLineOptions.timingEphFile();\n    iTelemetryMode = cmdLineOptions.telemetryMode();\n    iTimingTelemetryMode = cmdLineOptions.timingTelemetryMode();\n    \n    //Emulating normal mode from comment mode\n    iEmulateWithCommentMode = cmdLineOptions.emulateWithCommentMode();\n    strCommentModeInputFiles = cmdLineOptions.commentModeInputFiles();\n\n    //New options for Polarization pipeline\n    iPolRA = cmdLineOptions.polRA();\n    fPolRAValue = cmdLineOptions.polRAValue();\n    iPolDEC = cmdLineOptions.polDEC();\n    fPolDECValue = cmdLineOptions.polDECValue();\n    iPolT0 = cmdLineOptions.polT0();\n    fPolT0Value = cmdLineOptions.polT0Value();\n    iPolDuration = cmdLineOptions.polDuration();\n    fPolDurationValue = cmdLineOptions.polDurationValue();\n    iPolBackground = cmdLineOptions.polBackground();\n    fPolBackgroundValue = cmdLineOptions.polBackgroundValue();\n    iPolOutDetector = cmdLineOptions.polOutDetector();\n    fPolOutDetectorValue = cmdLineOptions.polOutDetectorValue();\n    iPolSNR = cmdLineOptions.polSNR();\n    fPolSNRValue = cmdLineOptions.polSNRValue();\n    iPolEnergyMin = cmdLineOptions.polEnergyMin();\n    fPolEnergyMinValue = cmdLineOptions.polEnergyMinValue();\n    iPolEnergyMax = cmdLineOptions.polEnergyMax();\n    fPolEnergyMaxValue = cmdLineOptions.polEnergyMaxValue();\n    iPolAlpha = cmdLineOptions.polAlpha();\n    fPolAlphaValue = cmdLineOptions.polAlphaValue();\n    iPolDelta = cmdLineOptions.polDelta();\n    fPolDeltaValue = cmdLineOptions.polDeltaValue();\n    iPolSourceName = cmdLineOptions.polSourceName();\n    iPolSingleSource = cmdLineOptions.polSingleSource();\n    strPolSourceName = cmdLineOptions.polSourceNameValue();\n    strPolMETFile = cmdLineOptions.polMETFile();\n    iPolMET = cmdLineOptions.polMET();\n    strPolMaskWeight = cmdLineOptions.polMaskWeight();\n    iPolMaskWeight = cmdLineOptions.polMaskWeightFlag();\n    iPolTriggered = cmdLineOptions.polTriggered();\n    fPolTriggerTime = cmdLineOptions.polTriggerTime();\n    strPolBunchFile = cmdLineOptions.polBunchFile();\n    iPolIncludePreTrigger = cmdLineOptions.polIncludePreTrigger();\n    iPolSourceType = cmdLineOptions.polSourceType();\n    iPolUseTriggerTime = cmdLineOptions.polUseTriggerTime();\n    iPolCentroidType = cmdLineOptions.polCentroidType();\n    strPolExtraArgs = cmdLineOptions.polExtraArgs();\n    iPolGRB = cmdLineOptions.polGRB();\n    iPolBlazer = cmdLineOptions.polBlazer();\n    iPolCalcMod = cmdLineOptions.polCalcMod();\n    fPolCalcModValue = cmdLineOptions.polCalcModValue();\n    iPolCalcAng = cmdLineOptions.polCalcAng();\n    fPolCalcAngValue = cmdLineOptions.polCalcAngValue();\n    iPolMaskMode = cmdLineOptions.polMaskMode();\n    iPolMaskModeValue = cmdLineOptions.polMaskModeValue();\n    iPolDumpRawEvents = cmdLineOptions.polDumpRawEvents();\n    \n    iTargetRA = cmdLineOptions.targetRA();\n    fTargetRAValue = cmdLineOptions.targetRAValue();\n    iTargetDEC = cmdLineOptions.targetDEC();\n    fTargetDECValue = cmdLineOptions.targetDECValue();\n    \n    iCmdArgument = cmdLineOptions.cmdArguments();\n    \n    strOutputDir = cmdLineOptions.outputDir();\n    strTempDir = cmdLineOptions.tempDir();\n    \n    if (iTargetRA == 1 && iTargetDEC == 1) {\n        cerr << \"ERROR: Target RA and DEC have been specified. \"\n                \"Please specify RA or Alpha and DEC or Delta...\" << endl;\n        return 5;\n    }\n\n    if (iTargetRA == 1 && iUserAlpha == 1) {\n        cerr << \"ERROR: Target RA and Alpha have been specified. \"\n                \"Please specify either RA or Alpha, not both...\" << endl;\n        return 5;\n    }\n\n    if (iTargetDEC == 1 && iUserDelta == 1) {\n        cerr << \"ERROR: Target DEC and Delta have been specified. \"\n                \"Please specify either DEC or Delta, not both...\" << endl;\n        return 5;\n    }\n\n    if (iUserAlpha == 1 && iUserDelta == 0) {\n        cerr << \"ERROR: Alpha has been specified without Delta. \"\n                \"Please specify both together.\" << endl;\n        return 5;\n    }\n\n    if (iUserAlpha == 0 && iUserDelta == 1) {\n        cerr << \"ERROR: Delta has been specified without Alpha. \"\n                \"Please specify both together.\" << endl;\n        return 5;\n    }\n\n    if (iTargetRA == 1 && iTargetDEC == 0) {\n        cerr << \"ERROR: Target RA has been specified without DEC. \"\n                \"Please specify both together.\" << endl;\n        return 5;\n    }\n\n    if (iTargetRA == 0 && iTargetDEC == 1) {\n        cerr << \"ERROR: Target DEC has been specified without RA. \"\n                \"Please specify both together.\" << endl;\n        return 5;\n    }\n\n    if (strTaskName == \"\") {\n        strTaskName = \"CZTPIPELINE\";\n    }\n\n    \n    if(strOutputDir.empty())\n    {\n        strOutputDir = \"./\";\n    }\n\n    if(strTempDir.empty())\n    {\n        strTempDir = \"./\";\n    }\n    \n    if(strTaskName==\"CZTPIPELINE\" || strTaskName==\"CZTSCREEN\" || strTaskName==\"cztscreen\" || strTaskName==\"cztpipeline\"){\n        //Setting values for CZTSCREEN from L1 to L2\n        if(iBadStreak == 1 && (fBadStreakTime == 0.0 || fBadStreakDTime == 0.0)){\n            cerr<<\"ERROR: Both badstreak time and dtime should be specified with badstreak option.\"<<endl;\n            return 7;\n        }\n        \n        if(iBadOrbit == 1 && (fBadOrbitTime == 0.0 || fBadOrbitDTime == 0.0)){\n            cerr<<\"ERROR: Both badorbit time and dtime should be specified with badorbit option.\"<<endl;\n            return 7;\n        }\n        \n        if(iFilterBadStreak==1 && iBadStreak==0){\n            cerr<<\"ERROR: badstreak time and dtime should be specified with filterbadstreak option.\"<<endl;\n            return 7;\n        }\n        \n        if(iFilterTimingFlag==1 && strTimingFlagFile.empty()){\n            cerr<<\"ERROR: timingflagfile should be specified with filtertimingflag option.\"<<endl;\n            return 7;\n        }\n    }else if(strTaskName==\"CZTIMAGE\" || strTaskName==\"cztimage\"){\n        if(strBadpixFile==\"\"){\n            cerr<<\"ERROR: badpixFile should be specified with cztimage task.\"<<endl;\n            return 6;\n        }\n        if(strMkfFile==\"\"){\n            cerr<<\"ERROR: mkfFile should be specified with cztimage task.\"<<endl;\n            return 6;\n        }\n        if(iTelemetryMode==1){\n            cerr<<\"ERROR: -telmode option not applicable for cztimage task.\"<<endl;\n            return 6;\n        }\n    }else if(strTaskName==\"CZTBINDATA\" || strTaskName==\"cztbindata\"){\n        if(strBadpixFile==\"\"){\n            cerr<<\"ERROR: badpixFile should be specified with cztbindata task.\"<<endl;\n            return 6;\n        }\n        if(strMkfFile==\"\"){\n            cerr<<\"ERROR: mkfFile should be specified with cztbindata task.\"<<endl;\n            return 6;\n        }\n        if(iTelemetryMode==1){\n            cerr<<\"ERROR: -telmode option not applicable for cztbindata task.\"<<endl;\n            return 6;\n        }\n    }else if(strTaskName==\"CZTGTIGEN\" || strTaskName==\"cztgtigen\"){\n        if(strMkfFile==\"\"){\n            cerr<<\"ERROR: mkfFile should be specified with cztgtigen task.\"<<endl;\n            return 6;\n        }\n        if(iCmdArgument==0){\n            cerr<<\"ERROR: No command line arguments found for cztgtigen task.\"<<endl;\n            cerr<<\"ERROR: Please specify GTI selection criteria with -arg option\"<<endl;\n            return 6;\n        }\n        if(iTelemetryMode==1){\n            cerr<<\"ERROR: -telmode option not applicable for cztgtigen task.\"<<endl;\n            return 6;\n        }\n    }else if(strTaskName==\"CZTDPIGEN\" || strTaskName==\"cztdpigen\"){\n        if(strMkfFile==\"\"){\n            cerr<<\"ERROR: mkfFile should be specified with cztdpigen task.\"<<endl;\n            return 6;\n        }\n        if(iTelemetryMode==1){\n            cerr<<\"ERROR: -telmode option not applicable for cztdpigen task.\"<<endl;\n            return 6;\n        }\n    }else if(strTaskName==\"CZTPOLARIZATION\" || strTaskName==\"cztpolarization\"){\n        if(strBadpixFile==\"\"){\n            cerr<<\"ERROR: badpixFile should be specified with cztpolarization task.\"<<endl;\n            return 6;\n        }\n        if(strMkfFile==\"\"){\n            cerr<<\"ERROR: mkfFile should be specified with cztpolarization task.\"<<endl;\n            return 6;\n        }\n        if(iFluxCalc==1){\n            cerr<<\"ERROR: fluxcalc option not applicable for cztpolarization task.\"<<endl;\n            return 6;\n        }\n        if(iPolSourceType == 2 && iPolBlazer == 0 && iPolGRB == 0){\n            cerr<<\"ERROR: Please specify source type (-polgrb or -polblazer)\"<<endl;\n            return 6;\n        }\n    }else if(strTaskName==\"CZTTIMING\" || strTaskName==\"czttiming\"){\n        if(strBadpixFile==\"\"){\n            cerr<<\"ERROR: badpixFile should be specified with czttiming task.\"<<endl;\n            return 6;\n        }\n        if(strMkfFile==\"\"){\n            cerr<<\"ERROR: mkfFile should be specified with czttiming task.\"<<endl;\n            return 6;\n        }\n        if(iFluxCalc==1){\n            cerr<<\"ERROR: fluxcalc option not applicable for czttiming task.\"<<endl;\n            return 6;\n        }\n        if(iTimingSourceType == 2 && iTimingGRB == 0){\n            cerr<<\"ERROR: Please specify source type (-grb)\"<<endl;\n            return 6;\n        }\n    }else if (strTaskName==\"CZTCRABSCAN\" || strTaskName==\"cztcrabscan\"){\n        if(strBadpixFile==\"\"){\n            cerr<<\"ERROR: badpixFile should be specified with cztcrabscan task.\"<<endl;\n            return 6;\n        }\n        if(strMkfFile==\"\"){\n            cerr<<\"ERROR: mkfFile should be specified with cztcrabscan task.\"<<endl;\n            return 6;\n        }\n        if(iFluxCalc==1){\n            cerr<<\"ERROR: fluxcalc option not applicable for cztcrabscan task.\"<<endl;\n            return 6;\n        }\n        if(iPolarizationRun==1 && iSingleSourcePolar==0){\n            cerr<<\"ERROR: singlesourcepolar option is required with polarizationrun option for cztcrabscan task.\"<<endl;\n            return 6;\n        }\n        if(iSingleSourcePolar==1 && strSingleSourcePolarFile==\"\"){\n            cerr<<\"ERROR: singlesourcepolarfile should be specified with singlesourcepolar option for cztcrabscan task.\"<<endl;\n            return 6;\n        }\n    }else{\n        cerr<<\"ERROR: Invalid task.\"<<endl;\n        return 6;\n    }\n    \n    if (strInfile == \"\") {\n        if (vecstrInputFiles.size() > 0) {\n            strInfile = vecstrInputFiles[0];\n        }\n    }\n    \n    \n    if(strTaskName==\"CZTIMAGE\" || strTaskName==\"cztimage\" || strTaskName==\"CZTBINDATA\" || strTaskName==\"cztbindata\" || strTaskName==\"CZTPOLARIZATION\" || strTaskName==\"cztpolarization\" || strTaskName==\"CZTTIMING\" || strTaskName==\"czttiming\" || strTaskName==\"CZTCRABSCAN\" || strTaskName==\"cztcrabscan\"){\n        if(vecstrInputFiles.size() < 1){\n            cerr<<\"ERROR: Input files should be specified for the task \" << strTaskName << \".\"<<endl;\n            return 3;\n        }\n    }else if(strTaskName==\"CZTPIPELINE\" || strTaskName==\"cztpipeline\" || strTaskName==\"CZTSCREEN\" || strTaskName==\"cztscreen\"){\n        if(iEmulateWithCommentMode==1){\n            if(strCommentModeInputFiles==\"\"){\n                cerr<<\"ERROR: commentmodeinputfiles should be specified with emulatecommentmode option.\"<<endl;\n                return 3;\n            }\n        }else{\n            //For normal mode vecstrInputFiles is required\n            if(vecstrInputFiles.size()<1){\n                cerr<<\"ERROR: Input files should be specified for the task \" << strTaskName << \".\"<<endl;\n                return 3;\n            }\n        }\n    }\n    \n    if (strCaldbPath == \"\") {\n        cerr << \"ERROR : CALDB path must be specified\\n\";\n        return 3;\n    }\n\n    //Creating log file handler\n    LogFileHandler logFileHandler(strOutputDir);\n    if(logFileHandler.status()==-1){\n        cerr<<\"ERROR : Error in creating log file in : \"<<strOutputDir<<endl;\n        return 4;\n    }\n    \n    localLogFileName = strOutputDir + \"/\" + localLogFileName;\n    logFileHandler.setLocalLogFile(localLogFileName);\n    \n    logFileHandler.write(\"\", \"DEBUG\", __FILE__, __LINE__);\n\n    //Configuring the CALDB\n    try {\n        CCztCalDBManager cztCalDBManager(strCaldbPath);\n        CCalDB *caldbobj = CCalDB::getCurrent();\n    } catch (const std::exception& e) {\n        cerr << \"ERROR : Unable to read CALDB. \" << e.what() << endl;\n        logFileHandler.write(\"Unable to read CALDB\", \"ERROR\", __FILE__, __LINE__);\n        return 4;\n    }\n\n    //Creating message handler\n    MessageHandler messageHandler;\n    messageHandler.setLogFileHandler(&logFileHandler);\n    \n    string strLogTaskDesc = \"Module: \" + strTaskName + \", \";\n    if(strTaskName==\"CZTPIPELINE\" || strTaskName==\"cztpipeline\" || strTaskName==\"CZTSCREEN\" || strTaskName==\"cztscreen\"){\n        if(iEmulateWithCommentMode==1){\n            strLogTaskDesc += \"CommentMode Emulation: YES, CommentModeFiles: \" + strCommentModeInputFiles;\n        }else{\n            strLogTaskDesc += \"Infile: \" + strInfile;\n        }\n    }else{\n        strLogTaskDesc += \"Infile: \" + strInfile;\n    }\n    \n    if(strBadpixFile!=\"\"){\n        strLogTaskDesc += \", BadpixFile: \" + strBadpixFile;\n    }\n    \n    if(strMkfFile!=\"\"){\n        strLogTaskDesc += \", MkfFile: \" + strMkfFile;\n    }\n    \n    logFileHandler.write(strLogTaskDesc, \"DEBUG\", __FILE__, __LINE__);\n    \n    //Creating image version \n    ImageVersions imageVersions;\n\n    if(iOutputVersion == 1){\n        imageVersions.setModeToUse(3);\n    }else{\n        imageVersions.setModeToUse(1);\n    }\n    \n    try {\n        //CZTPIPELINE and CZTSCREEN do level1 to level2 processing.\n        if (strTaskName == \"CZTPIPELINE\" || strTaskName == \"CZTSCREEN\" || strTaskName == \"cztscreen\" || strTaskName == \"cztpipeline\") {\n            // Creating quad ID object.\n            CCztDetectQuadID quadIDfinder;\n            \n            // Creating CZT science data reader.\n            CCztScienceDataReader cztSciDataReader(CztPipelineBuffer);\n            \n            // Setting any user override for quadrant.\n            if (iQuadrant != -1) {\n                cztSciDataReader.setQuadrantID(iQuadrant);\n            }\n            \n            // Instantiating objects for various aspects of the pipeline.\n            CCztTime cztTime;\n            CCztDetQuadrantMapping detQuadrantMapping;\n            CCztQuadBoundaryConstants cztQuadBoundConst;\n            CCztPixID pixid;\n            \n            // Event handlers for different processing stages.\n            CCztPreProcessingHandler cztPreProcessor;\n            CCztEvtDataCreater cztEvtDataCreater;\n            CCztCalibrationHandler cztcalibHandler;\n            CCztImageCreater cztImageCreater;\n            CCztHVFilters HVFilter;\n            \n            // Setting up directories.\n            cztImageCreater.setOutDir(strOutputDir);\n            cztImageCreater.setTempDir(strTempDir);\n            \n            // Imaging configuration settings.\n            if (iUserAlpha == 1 && iUserDelta == 1) {\n                cztImageCreater.setUserAlphaDelta(fUserAlphaValue, fUserDeltaValue);\n            }\n            \n            if (iTargetRA == 1 && iTargetDEC == 1) {\n                cztImageCreater.setUserAlphaDelta(fTargetRAValue, fTargetDECValue);\n            }\n            \n            if (iRejectVeto == 1) {\n                cztImageCreater.setRejectVeto(iRejectVeto);\n            }\n            \n            if (iSkipErrors == 1) {\n                cztEvtDataCreater.setSkipErrorCheck(iSkipErrors);\n            }\n            \n            if (iImageCenterX != -1 && iImageCenterY != -1) {\n                cztImageCreater.setImageCenter(iImageCenterX, iImageCenterY);\n            }\n            \n            if (iBadOrbit == 1) {\n                cztImageCreater.setBadOrbit(iBadOrbit, fBadOrbitTime, fBadOrbitDTime);\n            }\n            \n            if (iBadStreak == 1) {\n                cztImageCreater.setBadStreak(iBadStreak, fBadStreakTime, fBadStreakDTime);\n            }\n            \n            if (iOutputVersion == 1) {\n                cztImageCreater.setOutversion(1);\n            }\n            \n            if (iUseQuadBoundConfig == 1) {\n                cztImageCreater.setQuadBoundConfig(1);\n            }\n            \n            if (iUseElectronicsNoise == 1) {\n                cztImageCreater.setElectronicsNoise(1);\n            }\n            \n            if (iFilterBadStreak == 1) {\n                cztImageCreater.setFilterBadStreak(1);\n            }\n            \n            if (iFilterTimingFlag == 1) {\n                cztImageCreater.setFilterTimingFlag(1, strTimingFlagFile);\n            }\n            \n            // Telemetry mode specific configuration.\n            if (iTelemetryMode == 1) {\n                int iHKID = 1;\n                \n                if (strMkfFile != \"\") {\n                    // Initialize the instrument monitor with MKF data.\n                    CCztInstrumentMonitor* cztInsMon = CCztInstrumentMonitor::getInstanceRef();\n                    cztInsMon->initializeWithMKF(strMkfFile);\n                    iHKID = 2;\n                    cztImageCreater.setMkfFile(strMkfFile);\n                }\n                \n                if (iHKID == 1) {\n                    logFileHandler.write(\"No MKF file is specified. Processing without it.\", \"WARNING\", __FILE__, __LINE__);\n                }\n                \n                vector<string> vecLevelL1Files;\n                \n                // Handle normal mode or comment mode processing.\n                if (iEmulateWithCommentMode == 1) {\n                    if (strMkfFile == \"\") {\n                        logFileHandler.write(\"Error: MKF file must be specified with emulatecommentmode.\", \"ERROR\", __FILE__, __LINE__);\n                        return 7;\n                    }\n                    \n                    // Process comment mode by creating L1 files from comment mode data.\n                    cztSciDataReader.setOutputDir(strOutputDir);\n                    cztSciDataReader.setTempDir(strTempDir);\n                    cztSciDataReader.setLocalGainStatus(iLocalGainStatus);\n                    cztSciDataReader.setLocalGainPath(strLocalGainPath);\n                    cztSciDataReader.setDetector(iDetector);\n                    \n                    if (iResetBadPixel == 1) {\n                        cztSciDataReader.setResetBadPixel(1);\n                    }\n                    \n                    // Processing comment mode files.\n                    istringstream iss(strCommentModeInputFiles);\n                    string token;\n                    while (getline(iss, token, ',')) {\n                        string trimmedToken = token;\n                        // Trim leading and trailing whitespace\n                        trimmedToken.erase(0, trimmedToken.find_first_not_of(\" \\t\\n\\r\\f\\v\"));\n                        trimmedToken.erase(trimmedToken.find_last_not_of(\" \\t\\n\\r\\f\\v\") + 1);\n                        \n                        if (!trimmedToken.empty()) {\n                            vecstrInputFiles.push_back(trimmedToken);\n                        }\n                    }\n                    \n                    // Create L1 files from comment mode input files.\n                    for (size_t i = 0; i < vecstrInputFiles.size(); i++) {\n                        string L1File;\n                        int iL1Status = cztSciDataReader.createCommentModeL1File(vecstrInputFiles[i], strBunchFile, strMkfFile, L1File);\n                        \n                        if (iL1Status == 0) {\n                            vecLevelL1Files.push_back(L1File);\n                        } else {\n                            logFileHandler.write(\"Error in creating L1 file from comment mode data: \" + vecstrInputFiles[i], \"ERROR\", __FILE__, __LINE__);\n                        }\n                    }\n                } else {\n                    // Normal telemetry mode processing.\n                    cztSciDataReader.setOutputDir(strOutputDir);\n                    cztSciDataReader.setTempDir(strTempDir);\n                    cztSciDataReader.setLocalGainStatus(iLocalGainStatus);\n                    cztSciDataReader.setLocalGainPath(strLocalGainPath);\n                    cztSciDataReader.setDetector(iDetector);\n                    \n                    if (iResetBadPixel == 1) {\n                        cztSciDataReader.setResetBadPixel(1);\n                    }\n                    \n                    if (iLocalGainRead == 1) {\n                        cztSciDataReader.readLocalGainFromFiles(vecstrInputFiles);\n                    }\n                    \n                    // Create L1 files from normal mode input files.\n                    for (size_t i = 0; i < vecstrInputFiles.size(); i++) {\n                        string L1File;\n                        int iL1Status = cztSciDataReader.createL1File(vecstrInputFiles[i], strLLDFile, strULDFile, strBunchFile, strLockoutFile, strOCCFile, L1File);\n                        \n                        if (iL1Status == 0) {\n                            vecLevelL1Files.push_back(L1File);\n                        } else {\n                            logFileHandler.write(\"Error in creating L1 file: \" + vecstrInputFiles[i], \"ERROR\", __FILE__, __LINE__);\n                        }\n                    }\n                }\n                \n                // Process created L1 files to create L2 files.\n                if (vecLevelL1Files.size() > 0) {\n                    cztImageCreater.createLevel2(vecLevelL1Files, strBadpixFile);\n                } else {\n                    logFileHandler.write(\"No L1 files created. Cannot proceed to L2 creation.\", \"ERROR\", __FILE__, __LINE__);\n                    return 8;\n                }\n            } else {\n                // Direct L1 to L2 processing (without telemetry mode).\n                if (strMkfFile != \"\") {\n                    // Initialize the instrument monitor with MKF data.\n                    CCztInstrumentMonitor* cztInsMon = CCztInstrumentMonitor::getInstanceRef();\n                    cztInsMon->initializeWithMKF(strMkfFile);\n                    cztImageCreater.setMkfFile(strMkfFile);\n                } else {\n                    logFileHandler.write(\"No MKF file is specified. Processing without it.\", \"WARNING\", __FILE__, __LINE__);\n                }\n                \n                // Create L2 files directly from L1 input files.\n                cztImageCreater.createLevel2(vecstrInputFiles, strBadpixFile);\n            }\n        } else if (strTaskName == \"CZTIMAGE\" || strTaskName == \"cztimage\") {\n            // CZTIMAGE task - creates images from L2 event files.\n            CCztImage cztImage;\n            \n            // Set output directory.\n            if (!strOutputDir.empty()) {\n                cztImage.setOutDir(strOutputDir);\n            }\n            \n            // Set temporary directory.\n            if (!strTempDir.empty()) {\n                cztImage.setTempDir(strTempDir);\n            }\n            \n            // Set user-defined energy cuts if specified.\n            if (iUserEnergyCutStatus == 1) {\n                cztImage.setEnergyRange(fUserEnergyLowerCut, fUserEnergyUpperCut);\n            }\n            \n            // Set GTI extension to use.\n            if (iGTIExt != -1) {\n                cztImage.setGtiExt(iGTIExt);\n            }\n            \n            // Configure cztmask usage.\n            if (iCztmask == 1 && !strCztmaskfile.empty()) {\n                cztImage.setCztmask(1, strCztmaskfile);\n            }\n            \n            // Set RA and Dec if provided.\n            if (iTargetRA == 1 && iTargetDEC == 1) {\n                cztImage.setUserAlphaDelta(fTargetRAValue, fTargetDECValue);\n            } else if (iUserAlpha == 1 && iUserDelta == 1) {\n                cztImage.setUserAlphaDelta(fUserAlphaValue, fUserDeltaValue);\n            }\n            \n            // Set output version if specified.\n            if (iOutputVersion == 1) {\n                cztImage.setOutversion(1);\n            }\n            \n            // Set multiplicity if specified.\n            if (iMultiplicity >= 0) {\n                cztImage.setMultiplicity(iMultiplicity);\n            }\n            \n            // Create the image from level2 event files.\n            if (strMkfFile != \"\") {\n                // Initialize the instrument monitor with MKF data.\n                CCztInstrumentMonitor* cztInsMon = CCztInstrumentMonitor::getInstanceRef();\n                cztInsMon->initializeWithMKF(strMkfFile);\n            } else {\n                logFileHandler.write(\"No MKF file is specified. Processing without it.\", \"WARNING\", __FILE__, __LINE__);\n            }\n            \n            cztImage.createImage(vecstrInputFiles, strBadpixFile, strMkfFile);\n            \n            // Calculate flux if requested.\n            if (iFluxCalc == 1) {\n                try {\n                    FluxCalculator fluxCalculator;\n                    fluxCalculator.setMessageHandler(&messageHandler);\n                    \n                    // Set the response matrix extension.\n                    if (iRespMatrixExtn != -1) {\n                        fluxCalculator.setRespMatrixExtn(iRespMatrixExtn);\n                    }\n                    \n                    // Calculate flux for all created image files.\n                    vector<string> imgfiles = cztImage.getImageFiles();\n                    for (size_t i = 0; i < imgfiles.size(); i++) {\n                        fluxCalculator.calculateFlux(imgfiles[i]);\n                    }\n                } catch (FluxCalculationException &e) {\n                    logFileHandler.write(\"Error in flux calculation: \" + string(e.what()), \"ERROR\", __FILE__, __LINE__);\n                }\n            }\n        } else if (strTaskName == \"CZTBINDATA\" || strTaskName == \"cztbindata\") {\n            // CZTBINDATA task - creates binned data files from L2 event files.\n            CCztImageCreater cztImageCreater;\n            \n            // Set output directory.\n            if (!strOutputDir.empty()) {\n                cztImageCreater.setOutDir(strOutputDir);\n            }\n            \n            // Set temporary directory.\n            if (!strTempDir.empty()) {\n                cztImageCreater.setTempDir(strTempDir);\n            }\n            \n            // Set user-defined energy cuts if specified.\n            if (iUserEnergyCutStatus == 1) {\n                cztImageCreater.setEnergyRange(fUserEnergyLowerCut, fUserEnergyUpperCut);\n            }\n            \n            // Set GTI extension to use.\n            if (iGTIExt != -1) {\n                cztImageCreater.setGtiExt(iGTIExt);\n            }\n            \n            // Configure whether to use dphi and czti GTI extensions.\n            if (iUseDphiGtiExt == 1) {\n                cztImageCreater.setUseDphiGti(1);\n            }\n            \n            if (iUseCztiGtiExt == 1) {\n                cztImageCreater.setUseCztiGti(1);\n            }\n            \n            // Set output version if specified.\n            if (iOutputVersion == 1) {\n                cztImageCreater.setOutversion(1);\n            }\n            \n            // Set multiplicity if specified.\n            if (iMultiplicity >= 0) {\n                cztImageCreater.setMultiplicity(iMultiplicity);\n            }\n            \n            // Create binned data from level2 event files.\n            if (strMkfFile != \"\") {\n                // Initialize the instrument monitor with MKF data.\n                CCztInstrumentMonitor* cztInsMon = CCztInstrumentMonitor::getInstanceRef();\n                cztInsMon->initializeWithMKF(strMkfFile);\n                cztImageCreater.setMkfFile(strMkfFile);\n            } else {\n                logFileHandler.write(\"No MKF file is specified. Processing without it.\", \"WARNING\", __FILE__, __LINE__);\n            }\n            \n            cztImageCreater.createBinnedData(vecstrInputFiles, strBadpixFile);\n        } else if (strTaskName == \"CZTGTIGEN\" || strTaskName == \"cztgtigen\") {\n            // CZTGTIGEN task - generates Good Time Intervals based on criteria.\n            CCztGTICreater cztGTICreater;\n            \n            // Set output directory.\n            if (!strOutputDir.empty()) {\n                cztGTICreater.setOutDir(strOutputDir);\n            }\n            \n            // Set temporary directory.\n            if (!strTempDir.empty()) {\n                cztGTICreater.setTempDir(strTempDir);\n            }\n            \n            // Set the command line argument for GTI generation criteria.\n            cztGTICreater.setCmdArgs(cmdLineOptions.getCmdArgs());\n            \n            // Generate GTI files based on MKF data.\n            cztGTICreater.createGTI(vecstrInputFiles, strMkfFile);\n        } else if (strTaskName == \"CZTDPIGEN\" || strTaskName == \"cztdpigen\") {\n            // CZTDPIGEN task - generates dphi correction files.\n            CCztMkfDPhiCreater cztMkfDPhiCreater;\n            \n            // Set output directory.\n            if (!strOutputDir.empty()) {\n                cztMkfDPhiCreater.setOutDir(strOutputDir);\n            }\n            \n            // Set temporary directory.\n            if (!strTempDir.empty()) {\n                cztMkfDPhiCreater.setTempDir(strTempDir);\n            }\n            \n            // Generate dphi files based on MKF data.\n            cztMkfDPhiCreater.createDphi(vecstrInputFiles, strMkfFile);\n        } else if (strTaskName == \"CZTPOLARIZATION\" || strTaskName == \"cztpolarization\") {\n            // CZTPOLARIZATION task - performs polarization analysis.\n            CztiPolarizationPipeline cztiPolarizationPipeline;\n            \n            // Set output directory.\n            if (!strOutputDir.empty()) {\n                cztiPolarizationPipeline.setOutDir(strOutputDir);\n            }\n            \n            // Set temporary directory.\n            if (!strTempDir.empty()) {\n                cztiPolarizationPipeline.setTempDir(strTempDir);\n            }\n            \n            // Set various polarization analysis parameters.\n            if (iGTIExt != -1) {\n                cztiPolarizationPipeline.setGtiExt(iGTIExt);\n            }\n            \n            if (iPolSourceType != -1) {\n                cztiPolarizationPipeline.setSourceType(iPolSourceType);\n            }\n            \n            if (iPolarizationVer != -1) {\n                cztiPolarizationPipeline.setPolVer(iPolarizationVer);\n            }\n            \n            if (iPolRA == 1) {\n                cztiPolarizationPipeline.setRa(fPolRAValue);\n            }\n            \n            if (iPolDEC == 1) {\n                cztiPolarizationPipeline.setDec(fPolDECValue);\n            }\n            \n            if (iPolAlpha == 1) {\n                cztiPolarizationPipeline.setAlpha(fPolAlphaValue);\n            }\n            \n            if (iPolDelta == 1) {\n                cztiPolarizationPipeline.setDelta(fPolDeltaValue);\n            }\n            \n            if (iPolT0 == 1) {\n                cztiPolarizationPipeline.setT0(fPolT0Value);\n            }\n            \n            if (iPolDuration == 1) {\n                cztiPolarizationPipeline.setDuration(fPolDurationValue);\n            }\n            \n            if (iPolBackground == 1) {\n                cztiPolarizationPipeline.setBackground(fPolBackgroundValue);\n            }\n            \n            if (iPolOutDetector == 1) {\n                cztiPolarizationPipeline.setOutDetector(fPolOutDetectorValue);\n            }\n            \n            if (iPolSNR == 1) {\n                cztiPolarizationPipeline.setSNR(fPolSNRValue);\n            }\n            \n            if (iPolEnergyMin == 1) {\n                cztiPolarizationPipeline.setEmin(fPolEnergyMinValue);\n            }\n            \n            if (iPolEnergyMax == 1) {\n                cztiPolarizationPipeline.setEmax(fPolEnergyMaxValue);\n            }\n            \n            if (iPolSourceName == 1) {\n                cztiPolarizationPipeline.setSourceName(strPolSourceName);\n            }\n            \n            if (iPolSingleSource == 1) {\n                cztiPolarizationPipeline.setSingleSource(1);\n            }\n            \n            if (iPolMET == 1 && !strPolMETFile.empty()) {\n                cztiPolarizationPipeline.setMETFile(strPolMETFile);\n            }\n            \n            if (iPolMaskWeight == 1 && !strPolMaskWeight.empty()) {\n                cztiPolarizationPipeline.setMaskWeight(strPolMaskWeight);\n            }\n            \n            if (iPolTriggered == 1) {\n                cztiPolarizationPipeline.setTriggered(1, fPolTriggerTime);\n            }\n            \n            if (!strPolBunchFile.empty()) {\n                cztiPolarizationPipeline.setBunchFile(strPolBunchFile);\n            }\n            \n            if (iPolIncludePreTrigger == 1) {\n                cztiPolarizationPipeline.setIncludePreTrigger(1);\n            }\n            \n            if (iPolUseTriggerTime == 1) {\n                cztiPolarizationPipeline.setUseTriggerTime(1);\n            }\n            \n            if (iPolGRB == 1) {\n                cztiPolarizationPipeline.setGRB(1);\n            }\n            \n            if (iPolBlazer == 1) {\n                cztiPolarizationPipeline.setBlazer(1);\n            }\n            \n            if (iPolCentroidType != -1) {\n                cztiPolarizationPipeline.setCentroidType(iPolCentroidType);\n            }\n            \n            if (!strPolExtraArgs.empty()) {\n                cztiPolarizationPipeline.setExtraArgs(strPolExtraArgs);\n            }\n            \n            if (iPolCalcMod == 1) {\n                cztiPolarizationPipeline.setCalcMod(fPolCalcModValue);\n            }\n            \n            if (iPolCalcAng == 1) {\n                cztiPolarizationPipeline.setCalcAng(fPolCalcAngValue);\n            }\n            \n            if (iPolMaskMode == 1) {\n                cztiPolarizationPipeline.setMaskMode(iPolMaskModeValue);\n            }\n            \n            if (iPolDumpRawEvents == 1) {\n                cztiPolarizationPipeline.setDumpRawEvents(1);\n            }\n            \n            if (iDebugInfo == 1) {\n                cztiPolarizationPipeline.setDebugInfo(1);\n            }\n            \n            if (!strPolExtraHistBinning.empty()) {\n                cztiPolarizationPipeline.setExtraHistBinning(strPolExtraHistBinning);\n            }\n            \n            // Perform polarization analysis.\n            cztiPolarizationPipeline.processPolarization(vecstrInputFiles, strBadpixFile, strMkfFile);\n        } else if (strTaskName == \"CZTTIMING\" || strTaskName == \"czttiming\") {\n            // CZTTIMING task - performs timing analysis.\n            Timing timing;\n            \n            // Set output directory.\n            if (!strOutputDir.empty()) {\n                timing.setOutDir(strOutputDir);\n            }\n            \n            // Set temporary directory.\n            if (!strTempDir.empty()) {\n                timing.setTempDir(strTempDir);\n            }\n            \n            // Set various timing analysis parameters.\n            if (iGTIExt != -1) {\n                timing.setGtiExt(iGTIExt);\n            }\n            \n            if (iTimingSourceType != -1) {\n                timing.setSourceType(iTimingSourceType);\n            }\n            \n            if (iTimingGRB == 1) {\n                timing.setGRB(1);\n            }\n            \n            if (iTimingRedshift == 1) {\n                timing.setRedshift(fTimingRedshiftValue);\n            }\n            \n            if (iTimingRiseRef == 1) {\n                timing.setRiseRef(fTimingRiseRefValue);\n            }\n            \n            if (iTimingDecayRef == 1) {\n                timing.setDecayRef(fTimingDecayRefValue);\n            }\n            \n            if (iTimingT90StartTime != -1.0 && iTimingT90EndTime != -1.0) {\n                timing.setT90(fTimingT90StartTime, fTimingT90EndTime);\n            }\n            \n            if (iTimingTriggered == 1) {\n                timing.setTriggered(1, fTimingTriggerTime);\n            }\n            \n            if (iTimingPulsarFreq == 1) {\n                timing.setPulsarFreq(fTimingPulsarFreqValue, fTimingPulsarFreqDerivative);\n            }\n            \n            if (!strTimingRefMJD.empty()) {\n                timing.setRefMJD(strTimingRefMJD);\n            }\n            \n            if (iTimingDuration == 1) {\n                timing.setDuration(fTimingDurationValue);\n            }\n            \n            if (iTimingT0 == 1) {\n                timing.setT0(fTimingT0Value);\n            }\n            \n            if (iTimingBaryCorr == 1) {\n                timing.setBaryCorr(1);\n            }\n            \n            if (iTimingIncludePreTrigger == 1) {\n                timing.setIncludePreTrigger(1);\n            }\n            \n            if (iTimingUseTriggerTime == 1) {\n                timing.setUseTriggerTime(1);\n            }\n            \n            if (iTimingPolSourceType != -1) {\n                timing.setPolSourceType(iTimingPolSourceType);\n            }\n            \n            if (iTimingPolGRB == 1) {\n                timing.setPolGRB(1);\n            }\n            \n            if (iTimingPolPulsar == 1) {\n                timing.setPolPulsar(1);\n            }\n            \n            if (iTimingPolNorm == 1) {\n                timing.setPolNorm(1);\n            }\n            \n            if (fTimingPolAlpha != -1.0) {\n                timing.setPolAlpha(fTimingPolAlpha);\n            }\n            \n            if (fTimingPolDelta != -1.0) {\n                timing.setPolDelta(fTimingPolDelta);\n            }\n            \n            if (!strTimingExtraArgs.empty()) {\n                timing.setExtraArgs(strTimingExtraArgs);\n            }\n            \n            if (iTimingRA == 1) {\n                timing.setRA(fTimingRAValue);\n            }\n            \n            if (iTimingDEC == 1) {\n                timing.setDEC(fTimingDECValue);\n            }\n            \n            if (iTimingEphemeris == 1 && !strTimingEphFile.empty()) {\n                timing.setEphemeris(strTimingEphFile);\n            }\n            \n            if (iTimingTelemetryMode == 1) {\n                timing.setTelemetryMode(1);\n            }\n            \n            if (iDebugInfo == 1) {\n                timing.setDebugInfo(1);\n            }\n            \n            // Perform timing analysis.\n            timing.processTiming(vecstrInputFiles, strBadpixFile, strMkfFile);\n        } else if (strTaskName == \"CZTCRABSCAN\" || strTaskName == \"cztcrabscan\") {\n            // CZTCRABSCAN task - analyzes Crab scan observations.\n            CztCrabScanProcess cztCrabScanProcess;\n            \n            // Set output directory.\n            if (!strOutputDir.empty()) {\n                cztCrabScanProcess.setOutDir(strOutputDir);\n            }\n            \n            // Set temporary directory.\n            if (!strTempDir.empty()) {\n                cztCrabScanProcess.setTempDir(strTempDir);\n            }\n            \n            // Set various Crab scan analysis parameters.\n            if (iGTIExt != -1) {\n                cztCrabScanProcess.setGtiExt(iGTIExt);\n            }\n            \n            if (iNorm == 1) {\n                cztCrabScanProcess.setNorm(1);\n            }\n            \n            if (iQA == 1) {\n                cztCrabScanProcess.setQA(1);\n            }\n            \n            if (!strPCTFile.empty()) {\n                cztCrabScanProcess.setPCTFile(strPCTFile);\n            }\n            \n            if (!strPCTQAFile.empty()) {\n                cztCrabScanProcess.setPCTQAFile(strPCTQAFile);\n            }\n            \n            if (iRespType != -1) {\n                cztCrabScanProcess.setRespType(iRespType);\n            }\n            \n            if (iTxStart != -1) {\n                cztCrabScanProcess.setTxStart(iTxStart);\n            }\n            \n            if (iTxEnd != -1) {\n                cztCrabScanProcess.setTxEnd(iTxEnd);\n            }\n            \n            if (iTyStart != -1) {\n                cztCrabScanProcess.setTyStart(iTyStart);\n            }\n            \n            if (iTyEnd != -1) {\n                cztCrabScanProcess.setTyEnd(iTyEnd);\n            }\n            \n            if (iExpoCorrect == 1) {\n                cztCrabScanProcess.setExpoCorrect(1);\n            }\n            \n            if (fAvgCrabCtsPerPCT > 0.0) {\n                cztCrabScanProcess.setAvgCrabCtsPerPCT(fAvgCrabCtsPerPCT);\n            }\n            \n            if (fCalcCrabCtsPerPCT > 0.0) {\n                cztCrabScanProcess.setCalcCrabCtsPerPCT(fCalcCrabCtsPerPCT);\n            }\n            \n            if (!strCrabRefFile.empty()) {\n                cztCrabScanProcess.setCrabRefFile(strCrabRefFile);\n            }\n            \n            // Set polarization analysis parameters if needed.\n            if (iPolarizationRun == 1) {\n                cztCrabScanProcess.setPolarizationRun(1);\n                \n                if (iSingleSourcePolar == 1 && !strSingleSourcePolarFile.empty()) {\n                    CrabScanPol crabScanPol;\n                    crabScanPol.processPolarizationFile(strSingleSourcePolarFile);\n                    cztCrabScanProcess.setSingleSourcePolarFile(strSingleSourcePolarFile);\n                    cztCrabScanProcess.setSingleSourcePolar(1);\n                }\n            }\n            \n            if (iDebugInfo == 1) {\n                cztCrabScanProcess.setDebugInfo(1);\n            }\n            \n            // Perform Crab scan analysis.\n            cztCrabScanProcess.processCrabScan(vecstrInputFiles, strBadpixFile, strMkfFile);\n        }\n    } catch (FluxCalculationException &e) {\n        cerr << \"ERROR: FluxCalculationException: \" << e.what() << endl;\n        logFileHandler.write(string(\"FluxCalculationException: \") + e.what(), \"ERROR\", __FILE__, __LINE__);\n        return -1;\n    } catch (DataIOException &e) {\n        cerr << \"ERROR: DataIOException: \" << e.what() << endl;\n        logFileHandler.write(string(\"DataIOException: \") + e.what(), \"ERROR\", __FILE__, __LINE__);\n        return -1;\n    } catch (CorrelationException &e) {\n        cerr << \"ERROR: CorrelationException: \" << e.what() << endl;\n        logFileHandler.write(string(\"CorrelationException: \") + e.what(), \"ERROR\", __FILE__, __LINE__);\n        return -1;\n    } catch (ImageException &e) {\n        cerr << \"ERROR: ImageException: \" << e.what() << endl;\n        logFileHandler.write(string(\"ImageException: \") + e.what(), \"ERROR\", __FILE__, __LINE__);\n        return -1;\n    } catch (PolarizationException &e) {\n        cerr << \"ERROR: PolarizationException: \" << e.what() << endl;\n        logFileHandler.write(string(\"PolarizationException: \") + e.what(), \"ERROR\", __FILE__, __LINE__);\n        return -1;\n    } catch (exception &e) {\n        cerr << \"ERROR: exception: \" << e.what() << endl;\n        logFileHandler.write(string(\"Exception: \") + e.what(), \"ERROR\", __FILE__, __LINE__);\n        return -1;\n    } catch (...) {\n        cerr << \"ERROR: Unknown exception\" << endl;\n        logFileHandler.write(\"Unknown exception\", \"ERROR\", __FILE__, __LINE__);\n        return -1;\n    }\n\n    // Normal exit\n    return 0;\n}\n\u0005End File\u0006/**\n * @file    CCztPreProcessingHandler.C\n * @author  Tanul Gupta\n * @brief   Generates level 1 data for CZTI and also reads level 1 data.\n * @date    2021-05-03\n * \n * @copyright Copyright (c) 2021\n * \n */\n#include <CCztPreProcessingHandler.h>\n#include <iostream>\n#include <fstream>\n#include <string>\n#include <cstring>\n#include <map>\n#include <cmath>\n#include <ctime>\n#include <algorithm>\n#include <vector>\n#include <DetectorType.h>\n#include <CCztPreProcessingSettings.h>\n#include <CCztPreProcessingInterfaces.h>\n#include <CCztMode.h>\n#include <CCztPixID.h>\n#include <CCztDetectQuadID.h>\n#include <CCztCalibrationHandler.h>\n#include <CCztFitsTools.h>\n#include <CCztEvtDataCreater.h>\n#include <CEnergyCalibration.h>\n#include <CCalDB.h>\n#include <detectorConstants.h>\n#include <CPixelConversion.h>\n#include \"CCztDetQuadrantMapping.h\"\n#include \"fitsio.h\"\n\nusing namespace std;\n\n// Constructor (default)\nCCztPreProcessingHandler::CCztPreProcessingHandler() {\n    CPixelConversion m_pixCvt;\n    CCztDetQuadrantMapping m_cztDetQuadMapping;\n    \n    // Initialize flags for processing\n    mbVeto1Enabled = false;\n    mbVeto2Enabled = false;\n    mbVeto3Enabled = false;\n    mbVeto4Enabled = false;\n    \n    // Configuring for detector size\n    pixelWidth = 16;\n    pixelLength = 16;\n    detectorsPerQuadrant = 4;\n    byteOverHead = 40;\n    \n    // Set default values for pre-processing parameters\n    mdataBufferSize = 1000000;\n    mbSkipVetoEvents = false;\n    mbSkipErrorCheck = true;\n    miEnergyLLD = 30;\n    miEnergyULD = 1000;\n    miMinPixIPixel = 0;\n    miMaxPixIPixel = 63;\n    miMinPixJPixel = 0;\n    miMaxPixJPixel = 63;\n    \n    // Initialize the vectors needed for event processing\n    mvecTempbuffer.resize(mdataBufferSize);\n    \n    // Clear any existing data\n    mvecTempbuffer.clear();\n    mvecCZTSciData.clear();\n    mvecEventBuffer.clear();\n    \n    // Set the buffer size for event processing\n    setDataBufferSize(mdataBufferSize);\n}\n\n// Set flag to skip veto events\nvoid CCztPreProcessingHandler::skipVetoEvents(bool bStatus) {\n    mbSkipVetoEvents = bStatus;\n}\n\n// Set flag to skip error checking\nvoid CCztPreProcessingHandler::skipErrorCheck(bool bStatus) {\n    mbSkipErrorCheck = bStatus;\n}\n\n// Set the buffer size for data processing\nvoid CCztPreProcessingHandler::setDataBufferSize(long dataBufferSize) {\n    mdataBufferSize = dataBufferSize;\n    mvecEventBuffer.resize(mdataBufferSize);\n    mvecTempbuffer.resize(mdataBufferSize);\n}\n\n// Set processing parameters related to energy range\nvoid CCztPreProcessingHandler::setProcessingParams(int iEnergyLLD, int iEnergyULD, int iMinPixIPixel, int iMaxPixIPixel, int iMinPixJPixel, int iMaxPixJPixel) {\n    miEnergyLLD = iEnergyLLD;\n    miEnergyULD = iEnergyULD;\n    miMinPixIPixel = iMinPixIPixel;\n    miMaxPixIPixel = iMaxPixIPixel;\n    miMinPixJPixel = iMinPixJPixel;\n    miMaxPixJPixel = iMaxPixJPixel;\n}\n\n// Set the veto flags\nvoid CCztPreProcessingHandler::setVeto(int iID, bool bStatus) {\n    // Set veto flags based on ID\n    switch (iID) {\n        case 1:\n            mbVeto1Enabled = bStatus;\n            break;\n        case 2:\n            mbVeto2Enabled = bStatus;\n            break;\n        case 3:\n            mbVeto3Enabled = bStatus;\n            break;\n        case 4:\n            mbVeto4Enabled = bStatus;\n            break;\n        default:\n            // Invalid veto ID\n            break;\n    }\n}\n\n// Set all veto flags\nvoid CCztPreProcessingHandler::setVetos(bool bVeto1Status, bool bVeto2Status, bool bVeto3Status, bool bVeto4Status) {\n    mbVeto1Enabled = bVeto1Status;\n    mbVeto2Enabled = bVeto2Status;\n    mbVeto3Enabled = bVeto3Status;\n    mbVeto4Enabled = bVeto4Status;\n}\n\n// Add an event to the event buffer\nvoid CCztPreProcessingHandler::addEvent(tCZTSciEvent evtCZTSciData) {\n    mvecEventBuffer.push_back(evtCZTSciData);\n}\n\n// Read level 1 data from a file\nint CCztPreProcessingHandler::readLevel1Data(const char* chFileName, vector<tCZTSciEvent>& vecCZTSciDataRet) {\n    // Local variables for FITS handling\n    int status = 0;\n    int iRetVal = 0;\n    int iNumHDUs = 0;\n    int iHDUType = 0;\n    long nrows = 0;\n    int tfields = 0;\n    \n    // Attempt to open the FITS file\n    fitsfile *fptr = NULL;\n    status = 0;\n    if (fits_open_file(&fptr, chFileName, READONLY, &status)) {\n        cerr << \"ERROR: Unable to open file: \" << chFileName << endl;\n        fits_report_error(stderr, status);\n        return -1;\n    }\n    \n    // Get the number of HDUs in the file\n    status = 0;\n    if (fits_get_num_hdus(fptr, &iNumHDUs, &status)) {\n        cerr << \"ERROR: Cannot get number of HDUs\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Loop through HDUs to find the EVENTS extension\n    bool bFoundEventsExt = false;\n    for (int iHDU = 1; iHDU <= iNumHDUs; iHDU++) {\n        status = 0;\n        fits_movabs_hdu(fptr, iHDU, &iHDUType, &status);\n        \n        if (iHDUType == BINARY_TBL) {\n            // Check if this is the EVENTS extension\n            char extname[FLEN_VALUE];\n            status = 0;\n            fits_read_key(fptr, TSTRING, \"EXTNAME\", extname, NULL, &status);\n            \n            if (status == 0 && strcmp(extname, \"EVENTS\") == 0) {\n                bFoundEventsExt = true;\n                \n                // Get the number of rows and columns\n                status = 0;\n                if (fits_get_num_rows(fptr, &nrows, &status) || \n                    fits_get_num_cols(fptr, &tfields, &status)) {\n                    cerr << \"ERROR: Cannot get table dimensions\" << endl;\n                    fits_report_error(stderr, status);\n                    fits_close_file(fptr, &status);\n                    return -1;\n                }\n                \n                // Found the EVENTS extension, now read the data\n                break;\n            }\n        }\n    }\n    \n    if (!bFoundEventsExt) {\n        cerr << \"ERROR: EVENTS extension not found in file: \" << chFileName << endl;\n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Prepare for reading column data\n    int iCol = 0;\n    int iColTime = 0, iColCZTID = 0, iColPix_X = 0, iColPix_Y = 0, iColDet_X = 0, iColDet_Y = 0;\n    int iColEnergy = 0, iColDetid = 0, iColPixid = 0, iColVeto = 0;\n    \n    // Find the required columns\n    status = 0;\n    fits_get_colnum(fptr, CASEINSEN, \"TIME\", &iColTime, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"CZTID\", &iColCZTID, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"PIX_X\", &iColPix_X, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"PIX_Y\", &iColPix_Y, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"DET_X\", &iColDet_X, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"DET_Y\", &iColDet_Y, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"ENERGY\", &iColEnergy, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"DETID\", &iColDetid, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"PIXID\", &iColPixid, &status);\n    fits_get_colnum(fptr, CASEINSEN, \"VETO\", &iColVeto, &status);\n    \n    if (status) {\n        cerr << \"ERROR: Could not find required columns in EVENTS extension\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Resize the return vector to hold all the data\n    vecCZTSciDataRet.resize(nrows);\n    \n    // Read the data in one go for each column\n    double *time = new double[nrows];\n    unsigned char *cztid = new unsigned char[nrows];\n    unsigned char *pix_x = new unsigned char[nrows];\n    unsigned char *pix_y = new unsigned char[nrows];\n    unsigned char *det_x = new unsigned char[nrows];\n    unsigned char *det_y = new unsigned char[nrows];\n    unsigned short *energy = new unsigned short[nrows];\n    unsigned char *detid = new unsigned char[nrows];\n    unsigned short *pixid = new unsigned short[nrows];\n    unsigned char *veto = new unsigned char[nrows];\n    \n    status = 0;\n    fits_read_col(fptr, TDOUBLE, iColTime, 1, 1, nrows, NULL, time, NULL, &status);\n    fits_read_col(fptr, TBYTE, iColCZTID, 1, 1, nrows, NULL, cztid, NULL, &status);\n    fits_read_col(fptr, TBYTE, iColPix_X, 1, 1, nrows, NULL, pix_x, NULL, &status);\n    fits_read_col(fptr, TBYTE, iColPix_Y, 1, 1, nrows, NULL, pix_y, NULL, &status);\n    fits_read_col(fptr, TBYTE, iColDet_X, 1, 1, nrows, NULL, det_x, NULL, &status);\n    fits_read_col(fptr, TBYTE, iColDet_Y, 1, 1, nrows, NULL, det_y, NULL, &status);\n    fits_read_col(fptr, TUSHORT, iColEnergy, 1, 1, nrows, NULL, energy, NULL, &status);\n    fits_read_col(fptr, TBYTE, iColDetid, 1, 1, nrows, NULL, detid, NULL, &status);\n    fits_read_col(fptr, TUSHORT, iColPixid, 1, 1, nrows, NULL, pixid, NULL, &status);\n    fits_read_col(fptr, TBYTE, iColVeto, 1, 1, nrows, NULL, veto, NULL, &status);\n    \n    if (status) {\n        cerr << \"ERROR: Could not read column data\" << endl;\n        fits_report_error(stderr, status);\n        \n        // Clean up\n        delete[] time;\n        delete[] cztid;\n        delete[] pix_x;\n        delete[] pix_y;\n        delete[] det_x;\n        delete[] det_y;\n        delete[] energy;\n        delete[] detid;\n        delete[] pixid;\n        delete[] veto;\n        \n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Now populate the return vector\n    for (long i = 0; i < nrows; i++) {\n        vecCZTSciDataRet[i].dTime = time[i];\n        vecCZTSciDataRet[i].usCZTID = cztid[i];\n        vecCZTSciDataRet[i].ucPixelX = pix_x[i];\n        vecCZTSciDataRet[i].ucPixelY = pix_y[i];\n        vecCZTSciDataRet[i].ucDetX = det_x[i];\n        vecCZTSciDataRet[i].ucDetY = det_y[i];\n        vecCZTSciDataRet[i].usEnergy = energy[i];\n        vecCZTSciDataRet[i].ucDetID = detid[i];\n        vecCZTSciDataRet[i].usPixID = pixid[i];\n        vecCZTSciDataRet[i].ucVeto = veto[i];\n    }\n    \n    // Clean up\n    delete[] time;\n    delete[] cztid;\n    delete[] pix_x;\n    delete[] pix_y;\n    delete[] det_x;\n    delete[] det_y;\n    delete[] energy;\n    delete[] detid;\n    delete[] pixid;\n    delete[] veto;\n    \n    // Close the FITS file\n    status = 0;\n    fits_close_file(fptr, &status);\n    \n    return vecCZTSciDataRet.size();\n}\n\n// Read level 1 data into the internal buffer\nint CCztPreProcessingHandler::readLevel1Data(const char* chFileName) {\n    mvecCZTSciData.clear();\n    return readLevel1Data(chFileName, mvecCZTSciData);\n}\n\n// Process data from buffer to events\nint CCztPreProcessingHandler::readBufferToEvent(unsigned char *pCZTBuffer, long lCztBufferSize, vector<tCZTSciEvent>& vecCZTSciData) {\n    int iRetVal = 0;\n    \n    // Clear the output vector\n    vecCZTSciData.clear();\n    \n    // Create and initialize the interface to process the buffer\n    CCztPreProcessingInterfaces cztPreProcess;\n    if (miEnergyLLD != 0 || miEnergyULD != 0) {\n        cztPreProcess.setEnergyRange(miEnergyLLD, miEnergyULD);\n    }\n    \n    // Pixel coordinate ranges\n    if ((miMinPixIPixel != 0 || miMaxPixIPixel != 0) || (miMinPixJPixel != 0 || miMaxPixJPixel != 0)) {\n        cztPreProcess.setPixelRange(miMinPixIPixel, miMaxPixIPixel, miMinPixJPixel, miMaxPixJPixel);\n    }\n    \n    // Process the buffer data to extract events\n    iRetVal = cztPreProcess.processCztBuffer(pCZTBuffer, lCztBufferSize, vecCZTSciData);\n    \n    // Apply veto flag filtering if enabled\n    if (mbSkipVetoEvents) {\n        vector<tCZTSciEvent> vecCZTSciDataVetoRemoved;\n        for (size_t i = 0; i < vecCZTSciData.size(); i++) {\n            // Check if veto bits match enabled vetos\n            if ((vecCZTSciData[i].ucVeto & 0x01) && mbVeto1Enabled) continue;\n            if ((vecCZTSciData[i].ucVeto & 0x02) && mbVeto2Enabled) continue;\n            if ((vecCZTSciData[i].ucVeto & 0x04) && mbVeto3Enabled) continue;\n            if ((vecCZTSciData[i].ucVeto & 0x08) && mbVeto4Enabled) continue;\n            \n            // This event passed the veto filter\n            vecCZTSciDataVetoRemoved.push_back(vecCZTSciData[i]);\n        }\n        \n        // Replace the original vector with filtered one\n        vecCZTSciData = vecCZTSciDataVetoRemoved;\n    }\n    \n    return iRetVal;\n}\n\n// Process buffer data and store in internal event buffer\nint CCztPreProcessingHandler::readBufferToEvent(unsigned char *pCZTBuffer, long lCztBufferSize) {\n    mvecEventBuffer.clear();\n    return readBufferToEvent(pCZTBuffer, lCztBufferSize, mvecEventBuffer);\n}\n\n// Destructor\nCCztPreProcessingHandler::~CCztPreProcessingHandler() {\n    // No specific cleanup needed\n}\n\u0005End File\u0006/**\n * @file CCztGTICreater.C\n * @author Tanul Gupta\n * @brief Creates GTI files from MKF files\n * @version 0.1\n * @date 2021-08-22\n * \n * @copyright Copyright (c) 2021\n * \n */\n\n#include \"CCztGTICreater.h\"\n#include \"fitsio.h\"\n#include \"CztiMkfVars.h\"\n#include \"glog/logging.h\"\n#include <iostream>\n#include <string>\n#include <sstream>\n#include <vector>\n#include <cmath>\n#include <cstring>\n#include <cstdlib>\n#include <cctype>\n#include <algorithm>\n#include <functional>\n#include <CztiUtils.h>\n\nusing namespace std;\n\n// Constructor - Initialize with default values\nCCztGTICreater::CCztGTICreater() {\n    strOutDir = \"./\";\n    strTempDir = \"./\";\n    vecCmdArgs.clear();\n}\n\n// Destructor - Clean up resources\nCCztGTICreater::~CCztGTICreater() {\n    // No explicit cleanup needed\n}\n\n// Set output directory\nvoid CCztGTICreater::setOutDir(const string& outdir) {\n    strOutDir = outdir;\n    // Ensure directory path ends with slash\n    if (!strOutDir.empty() && strOutDir[strOutDir.length() - 1] != '/') {\n        strOutDir += '/';\n    }\n}\n\n// Set temporary directory for processing\nvoid CCztGTICreater::setTempDir(const string& tempdir) {\n    strTempDir = tempdir;\n    // Ensure directory path ends with slash\n    if (!strTempDir.empty() && strTempDir[strTempDir.length() - 1] != '/') {\n        strTempDir += '/';\n    }\n}\n\n// Set command arguments for GTI filtering criteria\nvoid CCztGTICreater::setCmdArgs(const vector<string>& cmdargs) {\n    vecCmdArgs = cmdargs;\n}\n\n/**\n * Utility function to check if a string represents a numerical value\n * @param str String to check\n * @return true if string represents a number, false otherwise\n */\nbool CCztGTICreater::isNumber(const std::string& str) {\n    std::string::const_iterator it = str.begin();\n    // Allow negative numbers\n    if (it != str.end() && *it == '-') {\n        ++it;\n    }\n    \n    // Check if remaining characters are digits or decimal point\n    bool decimalPoint = false;\n    while (it != str.end()) {\n        if (*it == '.') {\n            if (decimalPoint) return false; // Only one decimal point allowed\n            decimalPoint = true;\n        } else if (!std::isdigit(*it)) {\n            return false;\n        }\n        ++it;\n    }\n    \n    return !str.empty();\n}\n\n/**\n * Parse a condition string into its components\n * @param condition Condition string in format \"variable operator value\"\n * @param var Output parameter for variable name\n * @param op Output parameter for operator\n * @param val Output parameter for value\n * @return true if parsing successful, false otherwise\n */\nbool CCztGTICreater::parseCondition(const std::string& condition, std::string& var, std::string& op, std::string& val) {\n    // First, try to find operators\n    size_t pos = 0;\n    \n    // Try to find various comparison operators\n    pos = condition.find(\">=\");\n    if (pos != std::string::npos) {\n        var = condition.substr(0, pos);\n        op = \">=\";\n        val = condition.substr(pos + 2);\n        return true;\n    }\n    \n    pos = condition.find(\"<=\");\n    if (pos != std::string::npos) {\n        var = condition.substr(0, pos);\n        op = \"<=\";\n        val = condition.substr(pos + 2);\n        return true;\n    }\n    \n    pos = condition.find(\"!=\");\n    if (pos != std::string::npos) {\n        var = condition.substr(0, pos);\n        op = \"!=\";\n        val = condition.substr(pos + 2);\n        return true;\n    }\n    \n    pos = condition.find(\">\");\n    if (pos != std::string::npos) {\n        var = condition.substr(0, pos);\n        op = \">\";\n        val = condition.substr(pos + 1);\n        return true;\n    }\n    \n    pos = condition.find(\"<\");\n    if (pos != std::string::npos) {\n        var = condition.substr(0, pos);\n        op = \"<\";\n        val = condition.substr(pos + 1);\n        return true;\n    }\n    \n    pos = condition.find(\"=\");\n    if (pos != std::string::npos) {\n        var = condition.substr(0, pos);\n        op = \"=\";\n        val = condition.substr(pos + 1);\n        return true;\n    }\n    \n    // If no operator found\n    return false;\n}\n\n/**\n * Convert the variable to uppercase, trim whitespace\n * @param str String to normalize\n * @return Normalized string\n */\nstd::string CCztGTICreater::normalizeVarName(const std::string& str) {\n    std::string result = str;\n    \n    // Trim leading and trailing whitespace\n    result.erase(0, result.find_first_not_of(\" \\t\"));\n    result.erase(result.find_last_not_of(\" \\t\") + 1);\n    \n    // Convert to uppercase\n    std::transform(result.begin(), result.end(), result.begin(), ::toupper);\n    \n    return result;\n}\n\n/**\n * Create GTI files based on input events and MKF file\n * @param vecstrInputFiles Vector of input event file paths\n * @param strMkfFile MKF file path containing housekeeping data\n * @return 0 on success, error code otherwise\n */\nint CCztGTICreater::createGTI(const vector<string>& vecstrInputFiles, const string& strMkfFile) {\n    int status = 0;\n    int retval = 0;\n    \n    // Check if MKF file is provided\n    if (strMkfFile.empty()) {\n        LOG(ERROR) << \"MKF file is required to create GTI\";\n        return -1;\n    }\n    \n    // Check if command arguments are provided\n    if (vecCmdArgs.empty()) {\n        LOG(ERROR) << \"No GTI selection criteria provided\";\n        return -1;\n    }\n    \n    // Prepare for reading MKF file\n    fitsfile *mkfptr = nullptr;\n    status = 0;\n    if (fits_open_file(&mkfptr, strMkfFile.c_str(), READONLY, &status)) {\n        LOG(ERROR) << \"Error opening MKF file: \" << strMkfFile;\n        fits_report_error(stderr, status);\n        return -1;\n    }\n    \n    // Move to the EVENTS extension in MKF file\n    status = 0;\n    if (fits_movnam_hdu(mkfptr, BINARY_TBL, const_cast<char*>(\"EVENTS\"), 0, &status)) {\n        LOG(ERROR) << \"Error moving to EVENTS extension in MKF file\";\n        fits_report_error(stderr, status);\n        fits_close_file(mkfptr, &status);\n        return -1;\n    }\n    \n    // Get the number of rows in the MKF file\n    long nrows = 0;\n    status = 0;\n    if (fits_get_num_rows(mkfptr, &nrows, &status)) {\n        LOG(ERROR) << \"Error getting number of rows in MKF file\";\n        fits_report_error(stderr, status);\n        fits_close_file(mkfptr, &status);\n        return -1;\n    }\n    \n    // Read TIME column\n    double *time = new double[nrows];\n    int colnum = 0;\n    status = 0;\n    if (fits_get_colnum(mkfptr, CASEINSEN, const_cast<char*>(\"TIME\"), &colnum, &status)) {\n        LOG(ERROR) << \"Error finding TIME column in MKF file\";\n        fits_report_error(stderr, status);\n        delete[] time;\n        fits_close_file(mkfptr, &status);\n        return -1;\n    }\n    \n    status = 0;\n    if (fits_read_col(mkfptr, TDOUBLE, colnum, 1, 1, nrows, NULL, time, NULL, &status)) {\n        LOG(ERROR) << \"Error reading TIME column from MKF file\";\n        fits_report_error(stderr, status);\n        delete[] time;\n        fits_close_file(mkfptr, &status);\n        return -1;\n    }\n    \n    // Process each command line argument (condition)\n    for (size_t i = 0; i < vecCmdArgs.size(); i++) {\n        string condition = vecCmdArgs[i];\n        string var, op, val;\n        \n        // Parse the condition\n        if (!parseCondition(condition, var, op, val)) {\n            LOG(ERROR) << \"Invalid condition format: \" << condition;\n            continue;\n        }\n        \n        // Normalize variable name and validate operator\n        var = normalizeVarName(var);\n        \n        // Check if value is numeric\n        if (!isNumber(val)) {\n            LOG(ERROR) << \"Invalid numeric value in condition: \" << condition;\n            continue;\n        }\n        \n        double value = atof(val.c_str());\n        \n        // Get column number for the variable\n        colnum = 0;\n        status = 0;\n        if (fits_get_colnum(mkfptr, CASEINSEN, const_cast<char*>(var.c_str()), &colnum, &status)) {\n            LOG(ERROR) << \"Variable \" << var << \" not found in MKF file\";\n            fits_report_error(stderr, status);\n            continue;\n        }\n        \n        // Read the column data\n        double *data = new double[nrows];\n        status = 0;\n        if (fits_read_col(mkfptr, TDOUBLE, colnum, 1, 1, nrows, NULL, data, NULL, &status)) {\n            LOG(ERROR) << \"Error reading column \" << var << \" from MKF file\";\n            fits_report_error(stderr, status);\n            delete[] data;\n            continue;\n        }\n        \n        // Create a boolean mask based on the condition\n        bool *mask = new bool[nrows];\n        for (long j = 0; j < nrows; j++) {\n            if (op == \">\") {\n                mask[j] = (data[j] > value);\n            } else if (op == \">=\") {\n                mask[j] = (data[j] >= value);\n            } else if (op == \"<\") {\n                mask[j] = (data[j] < value);\n            } else if (op == \"<=\") {\n                mask[j] = (data[j] <= value);\n            } else if (op == \"=\") {\n                mask[j] = (fabs(data[j] - value) < 1e-10);\n            } else if (op == \"!=\") {\n                mask[j] = (fabs(data[j] - value) >= 1e-10);\n            } else {\n                mask[j] = false;\n            }\n        }\n        \n        // Identify contiguous good time intervals\n        vector<double> start_times;\n        vector<double> end_times;\n        \n        bool in_gti = false;\n        double start_time = 0.0;\n        \n        for (long j = 0; j < nrows; j++) {\n            if (mask[j] && !in_gti) {\n                // Start of a new GTI\n                in_gti = true;\n                start_time = time[j];\n            } else if (!mask[j] && in_gti) {\n                // End of current GTI\n                in_gti = false;\n                start_times.push_back(start_time);\n                end_times.push_back(time[j]);\n            }\n        }\n        \n        // Handle case where last interval extends to end of data\n        if (in_gti) {\n            start_times.push_back(start_time);\n            end_times.push_back(time[nrows-1]);\n        }\n        \n        // Clean up\n        delete[] data;\n        delete[] mask;\n        \n        // Process each input file to create GTI files\n        for (size_t file_idx = 0; file_idx < vecstrInputFiles.size(); file_idx++) {\n            string infile = vecstrInputFiles[file_idx];\n            \n            // Extract file basename for output naming\n            string basename = infile;\n            size_t lastSlash = basename.find_last_of(\"/\\\\\");\n            if (lastSlash != string::npos) {\n                basename = basename.substr(lastSlash + 1);\n            }\n            \n            // Remove file extension\n            size_t lastDot = basename.find_last_of(\".\");\n            if (lastDot != string::npos) {\n                basename = basename.substr(0, lastDot);\n            }\n            \n            // Create GTI output filename\n            string outfile = strOutDir + basename + \"_\" + var + op + val + \".gti\";\n            \n            // Create new GTI file\n            fitsfile *outptr = nullptr;\n            status = 0;\n            if (fits_create_file(&outptr, outfile.c_str(), &status)) {\n                LOG(ERROR) << \"Error creating GTI file: \" << outfile;\n                fits_report_error(stderr, status);\n                continue;\n            }\n            \n            // Create primary HDU\n            status = 0;\n            if (fits_create_img(outptr, BYTE_IMG, 0, NULL, &status)) {\n                LOG(ERROR) << \"Error creating primary HDU in GTI file\";\n                fits_report_error(stderr, status);\n                fits_close_file(outptr, &status);\n                continue;\n            }\n            \n            // Copy headers from input file\n            fitsfile *inptr = nullptr;\n            status = 0;\n            if (fits_open_file(&inptr, infile.c_str(), READONLY, &status)) {\n                LOG(ERROR) << \"Error opening input file: \" << infile;\n                fits_report_error(stderr, status);\n                fits_close_file(outptr, &status);\n                continue;\n            }\n            \n            // Copy keywords from primary header\n            status = 0;\n            if (fits_copy_header(inptr, outptr, &status)) {\n                LOG(ERROR) << \"Error copying header from input file\";\n                fits_report_error(stderr, status);\n                fits_close_file(inptr, &status);\n                fits_close_file(outptr, &status);\n                continue;\n            }\n            \n            // Create GTI extension\n            char *ttype[] = { const_cast<char*>(\"START\"), const_cast<char*>(\"STOP\") };\n            char *tform[] = { const_cast<char*>(\"D\"), const_cast<char*>(\"D\") };\n            char *tunit[] = { const_cast<char*>(\"s\"), const_cast<char*>(\"s\") };\n            \n            status = 0;\n            if (fits_create_tbl(outptr, BINARY_TBL, 0, 2, ttype, tform, tunit, \n                               const_cast<char*>(\"GTI\"), &status)) {\n                LOG(ERROR) << \"Error creating GTI extension\";\n                fits_report_error(stderr, status);\n                fits_close_file(inptr, &status);\n                fits_close_file(outptr, &status);\n                continue;\n            }\n            \n            // Add CONTENT keyword to GTI extension\n            stringstream ss;\n            ss << var << op << val;\n            string content = ss.str();\n            \n            status = 0;\n            if (fits_update_key(outptr, TSTRING, const_cast<char*>(\"CONTENT\"), \n                               const_cast<char*>(content.c_str()), const_cast<char*>(\"GTI selection expression\"), &status)) {\n                LOG(ERROR) << \"Error adding CONTENT keyword to GTI extension\";\n                fits_report_error(stderr, status);\n            }\n            \n            // Write GTI data\n            for (size_t j = 0; j < start_times.size(); j++) {\n                status = 0;\n                if (fits_write_col(outptr, TDOUBLE, 1, j+1, 1, 1, &start_times[j], &status) ||\n                    fits_write_col(outptr, TDOUBLE, 2, j+1, 1, 1, &end_times[j], &status)) {\n                    LOG(ERROR) << \"Error writing GTI data\";\n                    fits_report_error(stderr, status);\n                    break;\n                }\n            }\n            \n            // Get TSTART and TSTOP from input file\n            double tstart = 0.0, tstop = 0.0;\n            status = 0;\n            fits_read_key(inptr, TDOUBLE, const_cast<char*>(\"TSTART\"), &tstart, NULL, &status);\n            if (status) {\n                LOG(WARNING) << \"Could not read TSTART from input file, using first time from MKF\";\n                tstart = time[0];\n                status = 0;\n            }\n            \n            status = 0;\n            fits_read_key(inptr, TDOUBLE, const_cast<char*>(\"TSTOP\"), &tstop, NULL, &status);\n            if (status) {\n                LOG(WARNING) << \"Could not read TSTOP from input file, using last time from MKF\";\n                tstop = time[nrows-1];\n                status = 0;\n            }\n            \n            // Add TSTART and TSTOP to GTI extension\n            status = 0;\n            if (fits_update_key(outptr, TDOUBLE, const_cast<char*>(\"TSTART\"), &tstart, \n                               const_cast<char*>(\"Start time of GTI\"), &status) ||\n                fits_update_key(outptr, TDOUBLE, const_cast<char*>(\"TSTOP\"), &tstop, \n                               const_cast<char*>(\"Stop time of GTI\"), &status)) {\n                LOG(ERROR) << \"Error adding TSTART/TSTOP to GTI extension\";\n                fits_report_error(stderr, status);\n            }\n            \n            // Add DATE-OBS and DATE-END if available\n            char date_obs[FLEN_VALUE] = \"\";\n            char date_end[FLEN_VALUE] = \"\";\n            \n            status = 0;\n            fits_read_key(inptr, TSTRING, const_cast<char*>(\"DATE-OBS\"), date_obs, NULL, &status);\n            if (status == 0) {\n                status = 0;\n                fits_update_key(outptr, TSTRING, const_cast<char*>(\"DATE-OBS\"), date_obs, \n                               const_cast<char*>(\"Start date of GTI\"), &status);\n            }\n            \n            status = 0;\n            fits_read_key(inptr, TSTRING, const_cast<char*>(\"DATE-END\"), date_end, NULL, &status);\n            if (status == 0) {\n                status = 0;\n                fits_update_key(outptr, TSTRING, const_cast<char*>(\"DATE-END\"), date_end, \n                               const_cast<char*>(\"End date of GTI\"), &status);\n            }\n            \n            // Add TIMESYS, MJDREF, and TIMEUNIT if available\n            char timesys[FLEN_VALUE] = \"\";\n            double mjdref = 0.0;\n            char timeunit[FLEN_VALUE] = \"\";\n            \n            status = 0;\n            fits_read_key(inptr, TSTRING, const_cast<char*>(\"TIMESYS\"), timesys, NULL, &status);\n            if (status == 0) {\n                status = 0;\n                fits_update_key(outptr, TSTRING, const_cast<char*>(\"TIMESYS\"), timesys, \n                               const_cast<char*>(\"Time system\"), &status);\n            }\n            \n            status = 0;\n            fits_read_key(inptr, TDOUBLE, const_cast<char*>(\"MJDREF\"), &mjdref, NULL, &status);\n            if (status == 0) {\n                status = 0;\n                fits_update_key(outptr, TDOUBLE, const_cast<char*>(\"MJDREF\"), &mjdref, \n                               const_cast<char*>(\"MJD reference\"), &status);\n            }\n            \n            status = 0;\n            fits_read_key(inptr, TSTRING, const_cast<char*>(\"TIMEUNIT\"), timeunit, NULL, &status);\n            if (status == 0) {\n                status = 0;\n                fits_update_key(outptr, TSTRING, const_cast<char*>(\"TIMEUNIT\"), timeunit, \n                               const_cast<char*>(\"Time unit\"), &status);\n            }\n            \n            // Close files\n            fits_close_file(inptr, &status);\n            fits_close_file(outptr, &status);\n            \n            LOG(INFO) << \"Created GTI file: \" << outfile;\n        }\n    }\n    \n    // Clean up\n    delete[] time;\n    fits_close_file(mkfptr, &status);\n    \n    return 0;\n}\n\u0005End File\u0006/**\n * @file CCztTime.C\n * @author Tanul Gupta\n * @brief Class for handling CZTI specific time conversion and manipulation.\n * @version 0.1\n * @date 2021-06-24\n * \n * @copyright Copyright (c) 2021\n * \n */\n#include \"CCztTime.h\"\n#include <iostream>\n#include <sstream>\n#include <iomanip>\n#include <cstring>\n#include <cmath>\n\nusing namespace std;\n\n/**\n * Default constructor initializes UTC offset to 0\n */\nCCztTime::CCztTime() {\n    //Default timezone offset in seconds\n    mUTCTimeOffsetSec = 0;\n}\n\n/**\n * Sets the timezone offset in seconds\n * @param timeOffsetSec Offset in seconds from UTC\n */\nvoid CCztTime::setUTCTimeOffsetSec(int timeOffsetSec) {\n    mUTCTimeOffsetSec = timeOffsetSec;\n}\n\n/**\n * Converts CZTI time in seconds to MJD (Modified Julian Date)\n * @param dCZTITime CZTI time in seconds since epoch\n * @param dMJDRef Reference MJD value\n * @return MJD value corresponding to input time\n */\ndouble CCztTime::convertTimeToMJD(double dCZTITime, double dMJDRef) {\n    double dMJD = 0.0;\n    \n    // Convert from seconds to days and add to reference MJD\n    dMJD = dCZTITime / 86400.0;\n    dMJD += dMJDRef;\n    \n    return dMJD;\n}\n\n/**\n * Converts MJD to CZTI time in seconds\n * @param dMJD MJD value to convert\n * @param dMJDRef Reference MJD value\n * @return CZTI time in seconds since epoch\n */\ndouble CCztTime::convertMJDToTime(double dMJD, double dMJDRef) {\n    double dCZTITime = 0.0;\n    \n    // Calculate difference in days and convert to seconds\n    dCZTITime = (dMJD - dMJDRef) * 86400.0;\n    \n    return dCZTITime;\n}\n\n/**\n * Converts MJD to human-readable UTC string\n * @param dMJD MJD value to convert\n * @return ISO-format date string (YYYY-MM-DDThh:mm:ss)\n */\nstring CCztTime::convertMJDToUTC(double dMJD) {\n    // Constants for time conversion\n    const int SECONDS_PER_DAY = 86400;\n    const double JD_MJD_OFFSET = 2400000.5; // JD - MJD offset\n    \n    // Convert MJD to Julian Date\n    double JD = dMJD + JD_MJD_OFFSET;\n    \n    // Julian date calculation components\n    int l = static_cast<int>(JD + 0.5) + 68569;\n    int n = 4 * l / 146097;\n    l = l - (146097 * n + 3) / 4;\n    int i = 4000 * (l + 1) / 1461001;\n    l = l - 1461 * i / 4 + 31;\n    int j = 80 * l / 2447;\n    int d = l - 2447 * j / 80;\n    l = j / 11;\n    int m = j + 2 - 12 * l;\n    int y = 100 * (n - 49) + i + l;\n    \n    // Get the fractional part for time of day\n    double frac = JD + 0.5 - static_cast<int>(JD + 0.5);\n    \n    // Convert fraction of day to hours, minutes, seconds\n    int secInDay = static_cast<int>(round(frac * SECONDS_PER_DAY));\n    int h = secInDay / 3600;\n    int min = (secInDay % 3600) / 60;\n    int sec = secInDay % 60;\n    \n    // Format the date and time string\n    ostringstream oss;\n    oss << setfill('0') \n        << setw(4) << y << \"-\" \n        << setw(2) << m << \"-\" \n        << setw(2) << d << \"T\" \n        << setw(2) << h << \":\" \n        << setw(2) << min << \":\" \n        << setw(2) << sec;\n    \n    return oss.str();\n}\n\n/**\n * Converts human-readable UTC string to MJD\n * @param strUTC ISO-format date string (YYYY-MM-DDThh:mm:ss)\n * @return MJD value corresponding to input time\n */\ndouble CCztTime::convertUTCToMJD(const string &strUTC) {\n    // Check if input string is valid\n    if (strUTC.empty() || strUTC.length() < 19) {\n        cerr << \"Invalid UTC string format: \" << strUTC << endl;\n        return 0.0;\n    }\n    \n    int year, month, day, hour, min, sec;\n    \n    // Extract date and time components using string operations\n    try {\n        // Parse year, month, day\n        year = stoi(strUTC.substr(0, 4));\n        month = stoi(strUTC.substr(5, 2));\n        day = stoi(strUTC.substr(8, 2));\n        \n        // Find the time separator (T or space)\n        size_t timeSepPos = strUTC.find('T');\n        if (timeSepPos == string::npos) {\n            timeSepPos = strUTC.find(' ');\n        }\n        \n        if (timeSepPos != string::npos && timeSepPos + 8 <= strUTC.length()) {\n            // Parse hour, minute, second\n            hour = stoi(strUTC.substr(timeSepPos + 1, 2));\n            min = stoi(strUTC.substr(timeSepPos + 4, 2));\n            sec = stoi(strUTC.substr(timeSepPos + 7, 2));\n        } else {\n            // Default to midnight if time part is missing\n            hour = min = sec = 0;\n        }\n    } catch (const exception& e) {\n        cerr << \"Error parsing UTC string: \" << strUTC << \" - \" << e.what() << endl;\n        return 0.0;\n    }\n    \n    // Calculate MJD using astronomical formula\n    // Algorithm from Jean Meeus, \"Astronomical Algorithms\"\n    \n    // Adjust month and year for January and February\n    if (month <= 2) {\n        month += 12;\n        year -= 1;\n    }\n    \n    // Calculate Julian Day\n    int a = year / 100;\n    int b = 2 - a + (a / 4);\n    \n    double jd = floor(365.25 * (year + 4716)) + \n                floor(30.6001 * (month + 1)) + \n                day + b - 1524.5;\n    \n    // Add time of day\n    jd += (hour + min/60.0 + sec/3600.0) / 24.0;\n    \n    // Convert JD to MJD\n    double mjd = jd - 2400000.5;\n    \n    return mjd;\n}\n\n/**\n * Destructor - no specific cleanup needed\n */\nCCztTime::~CCztTime() {\n    // No resources to free\n}\n\u0005End File\u0006#include <fitsio.h>\n#include <cctype>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include <iterator>\n#include <map>\n#include <sstream>\n#include <string>\n#include <algorithm>\n#include <vector>\n#include <cmath>\n#include <utility>\n#include <stdexcept>\n#include <ctime>\n#include <iomanip>\n#include \"CztiUtils.h\"\n\nusing namespace std;\n\n/**\n * Extracts the base filename without path or extension\n * @param filepath Full file path\n * @return Base filename without extension\n */\nstring getBasename(const string& filepath) {\n    size_t lastSlash = filepath.find_last_of(\"/\\\\\");\n    string basename = (lastSlash != string::npos) ? filepath.substr(lastSlash + 1) : filepath;\n    \n    size_t lastDot = basename.find_last_of(\".\");\n    if (lastDot != string::npos) {\n        basename = basename.substr(0, lastDot);\n    }\n    \n    return basename;\n}\n\n/**\n * Extracts the file extension from a filename\n * @param filepath Full file path\n * @return File extension (including the dot)\n */\nstring getExtension(const string& filepath) {\n    size_t lastDot = filepath.find_last_of(\".\");\n    if (lastDot != string::npos) {\n        return filepath.substr(lastDot);\n    }\n    return \"\";\n}\n\n/**\n * Extracts the directory path from a full filepath\n * @param filepath Full file path\n * @return Directory path\n */\nstring getDirname(const string& filepath) {\n    size_t lastSlash = filepath.find_last_of(\"/\\\\\");\n    if (lastSlash != string::npos) {\n        return filepath.substr(0, lastSlash + 1);\n    }\n    return \"./\";\n}\n\n/**\n * Converts a string to uppercase\n * @param str Input string\n * @return Uppercase version of the input string\n */\nstring toUpper(const string& str) {\n    string result = str;\n    transform(result.begin(), result.end(), result.begin(), ::toupper);\n    return result;\n}\n\n/**\n * Converts a string to lowercase\n * @param str Input string\n * @return Lowercase version of the input string\n */\nstring toLower(const string& str) {\n    string result = str;\n    transform(result.begin(), result.end(), result.begin(), ::tolower);\n    return result;\n}\n\n/**\n * Trims whitespace from the beginning and end of a string\n * @param str Input string\n * @return Trimmed string\n */\nstring trim(const string& str) {\n    const string whitespace = \" \\t\\n\\r\\f\\v\";\n    \n    size_t start = str.find_first_not_of(whitespace);\n    if (start == string::npos) {\n        return \"\"; // String contains only whitespace\n    }\n    \n    size_t end = str.find_last_not_of(whitespace);\n    return str.substr(start, end - start + 1);\n}\n\n/**\n * Joins a vector of strings with a delimiter\n * @param vec Vector of strings to join\n * @param delimiter String to use as delimiter\n * @return Joined string\n */\nstring join(const vector<string>& vec, const string& delimiter) {\n    if (vec.empty()) {\n        return \"\";\n    }\n    \n    ostringstream oss;\n    \n    // Add all but the last element with the delimiter\n    for (size_t i = 0; i < vec.size() - 1; ++i) {\n        oss << vec[i] << delimiter;\n    }\n    \n    // Add the last element without the delimiter\n    oss << vec.back();\n    \n    return oss.str();\n}\n\n/**\n * Splits a string into a vector of strings based on a delimiter\n * @param str String to split\n * @param delimiter Character to use as delimiter\n * @return Vector of split strings\n */\nvector<string> split(const string& str, char delimiter) {\n    vector<string> tokens;\n    string token;\n    istringstream tokenStream(str);\n    \n    while (getline(tokenStream, token, delimiter)) {\n        tokens.push_back(token);\n    }\n    \n    return tokens;\n}\n\n/**\n * Returns the current date and time as a formatted string\n * @param format Format string for strftime\n * @return Formatted date-time string\n */\nstring getCurrentDateTime(const string& format) {\n    time_t now = time(0);\n    struct tm timeinfo;\n    char buffer[80];\n    \n#ifdef _WIN32\n    localtime_s(&timeinfo, &now);\n#else\n    localtime_r(&now, &timeinfo);\n#endif\n    \n    strftime(buffer, sizeof(buffer), format.c_str(), &timeinfo);\n    return string(buffer);\n}\n\n/**\n * Converts a Modified Julian Date (MJD) to an ISO-format date string\n * @param mjd Modified Julian Date\n * @return ISO-format date string (YYYY-MM-DDThh:mm:ss)\n */\nstring mjdToISO(double mjd) {\n    // Constants for conversion\n    const double JD_MJD_OFFSET = 2400000.5;\n    const int SECONDS_PER_DAY = 86400;\n    \n    // Convert MJD to Julian Date\n    double jd = mjd + JD_MJD_OFFSET;\n    \n    // Extract the integer and fractional parts\n    double jdInt = floor(jd + 0.5);\n    double frac = jd + 0.5 - jdInt;\n    \n    // Convert Julian Day Number to calendar date\n    // Algorithm from Jean Meeus, \"Astronomical Algorithms\"\n    long a = (long)(jdInt + 32044.5);\n    long b = (long)((4 * a + 3) / 146097.0);\n    long c = a - (long)((146097 * b) / 4.0);\n    long d = (long)((4 * c + 3) / 1461.0);\n    long e = c - (long)((1461 * d) / 4.0);\n    long m = (long)((5 * e + 2) / 153.0);\n    \n    int day = (int)(e - (long)((153 * m + 2) / 5.0) + 1);\n    int month = (int)(m + 3 - 12 * (long)(m / 10.0));\n    int year = (int)(100 * b + d - 4800 + (long)(m / 10.0));\n    \n    // Convert fraction of day to hours, minutes, seconds\n    int secInDay = (int)(round(frac * SECONDS_PER_DAY));\n    int hour = secInDay / 3600;\n    int minute = (secInDay % 3600) / 60;\n    int second = secInDay % 60;\n    \n    // Format the date and time string\n    ostringstream oss;\n    oss << setfill('0')\n        << setw(4) << year << \"-\"\n        << setw(2) << month << \"-\"\n        << setw(2) << day << \"T\"\n        << setw(2) << hour << \":\"\n        << setw(2) << minute << \":\"\n        << setw(2) << second;\n    \n    return oss.str();\n}\n\n/**\n * Converts an ISO-format date string to Modified Julian Date (MJD)\n * @param isoDate ISO-format date string (YYYY-MM-DDThh:mm:ss)\n * @return Modified Julian Date\n */\ndouble isoToMJD(const string& isoDate) {\n    if (isoDate.length() < 10) {\n        throw invalid_argument(\"Invalid ISO date format: \" + isoDate);\n    }\n    \n    int year, month, day, hour = 0, minute = 0, second = 0;\n    \n    // Parse the date part\n    sscanf(isoDate.c_str(), \"%d-%d-%d\", &year, &month, &day);\n    \n    // Find time separator\n    size_t timeSep = isoDate.find('T');\n    if (timeSep == string::npos) {\n        timeSep = isoDate.find(' ');\n    }\n    \n    // Parse the time part if available\n    if (timeSep != string::npos && timeSep + 8 <= isoDate.length()) {\n        sscanf(isoDate.c_str() + timeSep + 1, \"%d:%d:%d\", &hour, &minute, &second);\n    }\n    \n    // Calculate MJD\n    // Algorithm from Jean Meeus, \"Astronomical Algorithms\"\n    if (month <= 2) {\n        month += 12;\n        year -= 1;\n    }\n    \n    int a = year / 100;\n    int b = 2 - a + (a / 4);\n    \n    double jd = floor(365.25 * (year + 4716)) +\n                floor(30.6001 * (month + 1)) +\n                day + b - 1524.5;\n    \n    // Add time component\n    jd += (hour + minute/60.0 + second/3600.0) / 24.0;\n    \n    // Convert JD to MJD\n    return jd - 2400000.5;\n}\n\n/**\n * Calculates the angle between two positions in degrees\n * @param ra1 Right Ascension of first position (degrees)\n * @param dec1 Declination of first position (degrees)\n * @param ra2 Right Ascension of second position (degrees)\n * @param dec2 Declination of second position (degrees)\n * @return Angular separation in degrees\n */\ndouble angularSeparation(double ra1, double dec1, double ra2, double dec2) {\n    // Convert degrees to radians\n    double ra1Rad = ra1 * M_PI / 180.0;\n    double dec1Rad = dec1 * M_PI / 180.0;\n    double ra2Rad = ra2 * M_PI / 180.0;\n    double dec2Rad = dec2 * M_PI / 180.0;\n    \n    // Calculate separation using the Haversine formula\n    double dRa = ra2Rad - ra1Rad;\n    double dDec = dec2Rad - dec1Rad;\n    \n    double a = sin(dDec/2.0) * sin(dDec/2.0) +\n               cos(dec1Rad) * cos(dec2Rad) * sin(dRa/2.0) * sin(dRa/2.0);\n    double c = 2.0 * atan2(sqrt(a), sqrt(1.0-a));\n    \n    // Convert radians back to degrees\n    return c * 180.0 / M_PI;\n}\n\n/**\n * Creates a new FITS file with primary HDU and optional extensions\n * @param filename Output FITS file path\n * @param hdrKeys Map of header keywords and values for primary HDU\n * @param extensions Vector of extension definitions (name, type, columns)\n * @return 0 on success, error code on failure\n */\nint createFitsFile(const string& filename, \n                  const map<string, string>& hdrKeys,\n                  const vector<FitsExtension>& extensions) {\n    int status = 0;\n    fitsfile *fptr = nullptr;\n    \n    // Create the FITS file\n    if (fits_create_file(&fptr, filename.c_str(), &status)) {\n        cerr << \"Error creating FITS file: \" << filename << endl;\n        fits_report_error(stderr, status);\n        return status;\n    }\n    \n    // Create primary HDU\n    long naxes[1] = {0};\n    if (fits_create_img(fptr, BYTE_IMG, 0, naxes, &status)) {\n        cerr << \"Error creating primary HDU\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Add header keywords\n    for (const auto& key : hdrKeys) {\n        // Determine the keyword type and write accordingly\n        string value = key.second;\n        char keyname[FLEN_KEYWORD];\n        strncpy(keyname, key.first.c_str(), FLEN_KEYWORD-1);\n        keyname[FLEN_KEYWORD-1] = '\\0';\n        \n        // Check if value is a number\n        char* end;\n        double dval = strtod(value.c_str(), &end);\n        \n        if (*end == '\\0') {\n            // Value is a number\n            if (value.find('.') != string::npos) {\n                // Floating point\n                if (fits_update_key(fptr, TDOUBLE, keyname, &dval, nullptr, &status)) {\n                    fits_report_error(stderr, status);\n                }\n            } else {\n                // Integer\n                long ival = strtol(value.c_str(), nullptr, 10);\n                if (fits_update_key(fptr, TLONG, keyname, &ival, nullptr, &status)) {\n                    fits_report_error(stderr, status);\n                }\n            }\n        } else {\n            // String value\n            char valstr[FLEN_VALUE];\n            strncpy(valstr, value.c_str(), FLEN_VALUE-1);\n            valstr[FLEN_VALUE-1] = '\\0';\n            \n            if (fits_update_key(fptr, TSTRING, keyname, valstr, nullptr, &status)) {\n                fits_report_error(stderr, status);\n            }\n        }\n    }\n    \n    // Create extensions\n    for (const auto& ext : extensions) {\n        // Prepare column arrays\n        int ncols = ext.columns.size();\n        vector<char*> ttype(ncols), tform(ncols), tunit(ncols);\n        \n        for (int i = 0; i < ncols; i++) {\n            ttype[i] = strdup(ext.columns[i].name.c_str());\n            tform[i] = strdup(ext.columns[i].format.c_str());\n            tunit[i] = strdup(ext.columns[i].unit.c_str());\n        }\n        \n        // Create the extension\n        if (fits_create_tbl(fptr, BINARY_TBL, 0, ncols, \n                          ttype.data(), tform.data(), tunit.data(),\n                          ext.name.c_str(), &status)) {\n            cerr << \"Error creating extension: \" << ext.name << endl;\n            fits_report_error(stderr, status);\n        }\n        \n        // Free allocated memory\n        for (int i = 0; i < ncols; i++) {\n            free(ttype[i]);\n            free(tform[i]);\n            free(tunit[i]);\n        }\n    }\n    \n    // Close the file\n    fits_close_file(fptr, &status);\n    \n    return status;\n}\n\n/**\n * Reads data from a FITS table extension\n * @param filename Input FITS file path\n * @param extname Extension name to read\n * @param colname Column name to read\n * @param data Vector to store read data (must be of appropriate type)\n * @return 0 on success, error code on failure\n */\ntemplate <typename T>\nint readFitsColumn(const string& filename, const string& extname, \n                 const string& colname, vector<T>& data) {\n    int status = 0;\n    fitsfile *fptr = nullptr;\n    \n    // Open the FITS file\n    if (fits_open_file(&fptr, filename.c_str(), READONLY, &status)) {\n        cerr << \"Error opening FITS file: \" << filename << endl;\n        fits_report_error(stderr, status);\n        return status;\n    }\n    \n    // Move to specified extension\n    if (fits_movnam_hdu(fptr, BINARY_TBL, const_cast<char*>(extname.c_str()), 0, &status)) {\n        cerr << \"Error finding extension: \" << extname << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Get column information\n    int colnum = 0;\n    if (fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(colname.c_str()), &colnum, &status)) {\n        cerr << \"Error finding column: \" << colname << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Get number of rows\n    long nrows = 0;\n    if (fits_get_num_rows(fptr, &nrows, &status)) {\n        cerr << \"Error getting number of rows\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Resize output vector\n    data.resize(nrows);\n    \n    // Determine column type for reading\n    int typecode = 0;\n    long repeat = 0;\n    long width = 0;\n    if (fits_get_coltype(fptr, colnum, &typecode, &repeat, &width, &status)) {\n        cerr << \"Error getting column type\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Read the column data\n    int anynul = 0;\n    if (fits_read_col(fptr, getFitsType<T>(), colnum, 1, 1, nrows, nullptr, \n                      data.data(), &anynul, &status)) {\n        cerr << \"Error reading column data\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Close the file\n    fits_close_file(fptr, &status);\n    \n    return status;\n}\n\n// Explicit template instantiations for common types\ntemplate int readFitsColumn<double>(const string&, const string&, const string&, vector<double>&);\ntemplate int readFitsColumn<float>(const string&, const string&, const string&, vector<float>&);\ntemplate int readFitsColumn<int>(const string&, const string&, const string&, vector<int>&);\ntemplate int readFitsColumn<long>(const string&, const string&, const string&, vector<long>&);\ntemplate int readFitsColumn<short>(const string&, const string&, const string&, vector<short>&);\ntemplate int readFitsColumn<unsigned char>(const string&, const string&, const string&, vector<unsigned char>&);\n\n/**\n * Utility function to map C++ types to FITS type constants\n */\ntemplate <typename T>\nint getFitsType() {\n    if (typeid(T) == typeid(double)) return TDOUBLE;\n    if (typeid(T) == typeid(float)) return TFLOAT;\n    if (typeid(T) == typeid(int)) return TINT;\n    if (typeid(T) == typeid(long)) return TLONG;\n    if (typeid(T) == typeid(short)) return TSHORT;\n    if (typeid(T) == typeid(unsigned char)) return TBYTE;\n    \n    // Default to double if type not recognized\n    return TDOUBLE;\n}\n\n/**\n * Gets the FITS table column data type\n * @param filename FITS file path\n * @param extname Extension name\n * @param colname Column name\n * @param typecode Output parameter for column type code\n * @param repeat Output parameter for vector repeat count\n * @param width Output parameter for element width\n * @return 0 on success, error code on failure\n */\nint getColumnType(const string& filename, const string& extname, \n                 const string& colname, int& typecode, long& repeat, long& width) {\n    int status = 0;\n    fitsfile *fptr = nullptr;\n    \n    // Open the FITS file\n    if (fits_open_file(&fptr, filename.c_str(), READONLY, &status)) {\n        cerr << \"Error opening FITS file: \" << filename << endl;\n        fits_report_error(stderr, status);\n        return status;\n    }\n    \n    // Move to specified extension\n    if (fits_movnam_hdu(fptr, BINARY_TBL, const_cast<char*>(extname.c_str()), 0, &status)) {\n        cerr << \"Error finding extension: \" << extname << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Get column information\n    int colnum = 0;\n    if (fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(colname.c_str()), &colnum, &status)) {\n        cerr << \"Error finding column: \" << colname << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Get column type\n    if (fits_get_coltype(fptr, colnum, &typecode, &repeat, &width, &status)) {\n        cerr << \"Error getting column type\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return status;\n    }\n    \n    // Close the file\n    fits_close_file(fptr, &status);\n    \n    return status;\n}\n\n/**\n * Copies a GTI extension from one file to another\n * @param infile Input FITS file with GTI extension\n * @param outfile Output FITS file to create\n * @param gtiExtName Name of the GTI extension to copy (default: \"GTI\")\n * @return 0 on success, error code on failure\n */\nint copyGTI(const string& infile, const string& outfile, const string& gtiExtName) {\n    int status = 0;\n    fitsfile *infptr = nullptr;\n    fitsfile *outfptr = nullptr;\n    \n    // Open input file\n    if (fits_open_file(&infptr, infile.c_str(), READONLY, &status)) {\n        cerr << \"Error opening input file: \" << infile << endl;\n        fits_report_error(stderr, status);\n        return status;\n    }\n    \n    // Check if GTI extension exists\n    if (fits_movnam_hdu(infptr, BINARY_TBL, const_cast<char*>(gtiExtName.c_str()), 0, &status)) {\n        cerr << \"GTI extension not found in input file\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(infptr, &status);\n        return status;\n    }\n    \n    // Create output file\n    if (fits_create_file(&outfptr, outfile.c_str(), &status)) {\n        cerr << \"Error creating output file: \" << outfile << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(infptr, &status);\n        return status;\n    }\n    \n    // Create primary HDU\n    long naxes[1] = {0};\n    if (fits_create_img(outfptr, BYTE_IMG, 0, naxes, &status)) {\n        cerr << \"Error creating primary HDU\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(infptr, &status);\n        fits_close_file(outfptr, &status);\n        return status;\n    }\n    \n    // Move back to GTI extension in input file\n    fits_movnam_hdu(infptr, BINARY_TBL, const_cast<char*>(gtiExtName.c_str()), 0, &status);\n    \n    // Copy GTI extension\n    if (fits_copy_hdu(infptr, outfptr, 0, &status)) {\n        cerr << \"Error copying GTI extension\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(infptr, &status);\n        fits_close_file(outfptr, &status);\n        return status;\n    }\n    \n    // Close files\n    fits_close_file(infptr, &status);\n    fits_close_file(outfptr, &status);\n    \n    return status;\n}\n\u0005End File\u0006# ajayvibhute/test1\n/* This module applies the polarization algorithm on CZT-Imager data\n*/\n\n#include \"PolarAlongWithAng.h\"\n#include \"DetectorType.h\"\n#include <iostream>\n#include <string>\n#include <sstream>\n#include <fstream>\n#include <cstring>\n#include <cstdlib>\n#include <cmath>\n#include <vector>\n#include <map>\n#include <algorithm>\n#include \"fitsio.h\"\n#include \"CCztFitsTools.h\"\n#include \"CCztImage.h\"\n#include \"CCztMasks.h\"\n#include \"CCztPixID.h\"\n#include \"CCztTime.h\"\n#include \"datatype.h\"\n#include \"unistd.h\"\n#include \"Median.h\"\n\n//Add the appropriate namespace\nusing namespace std;\n\n// Constructor: Initializes polarization analyzer with default parameters\nPolarAlongWithAng::PolarAlongWithAng() {\n    // Initialize basic parameters\n    modulationFactor = 0.35;\n    pixel_radius = 20.0;\n    aGTIExt = 2;\n    isOutDir = 0;\n    strOutDir = \"./\";\n    isDebugInfo = 0;\n    centroidType = 1; // Default centroid type - weighted\n}\n\n// Sets the output directory for results\nvoid PolarAlongWithAng::setOutDir(const string& outdir) {\n    strOutDir = outdir;\n    isOutDir = 1;\n    \n    // Ensure directory path ends with a slash\n    if (strOutDir.size() > 0 && strOutDir[strOutDir.size() - 1] != '/') {\n        strOutDir += '/';\n    }\n}\n\n// Sets the GTI extension to use\nvoid PolarAlongWithAng::setGtiExt(int gtiext) {\n    aGTIExt = gtiext;\n}\n\n// Sets the type of centroid calculation method\nvoid PolarAlongWithAng::setCentroidType(int type) {\n    centroidType = type;\n}\n\n// Sets debug mode for additional logging\nvoid PolarAlongWithAng::setDebugInfo(int debugInfoFlag) {\n    isDebugInfo = debugInfoFlag;\n}\n\n/**\n * Main method to compute polarization metrics from a set of event files\n * \n * @param vecstrInputFiles Vector of input event file paths\n * @param strOutFile Output file path for polarization results\n * @param strBadPixFile Bad pixel file path\n * @param strMaskWeight Mask weighting file path\n * @param ra Source right ascension in degrees\n * @param dec Source declination in degrees\n * @param t0 Start time of analysis\n * @param duration Duration of analysis\n * @param energy_min Minimum energy for events\n * @param energy_max Maximum energy for events\n * @param outdetector Detector ring radius to exclude\n * @param nbin Number of azimuthal bins for modulation curve\n * @param isPlot Whether to generate diagnostic plots\n * @return 0 on success, error code otherwise\n */\nint PolarAlongWithAng::processPolarization(const vector<string>& vecstrInputFiles, \n                                     const string& strOutFile,\n                                     const string& strBadPixFile,\n                                     const string& strMaskWeight,\n                                     double ra, double dec,\n                                     double t0, double duration,\n                                     double energy_min, double energy_max,\n                                     double outdetector, int nbin, int isPlot) {\n    // Basic parameter validation\n    if (vecstrInputFiles.size() < 1) {\n        cerr << \"ERROR: No input files provided.\" << endl;\n        return -1;\n    }\n    \n    if (nbin <= 0) {\n        cerr << \"ERROR: Number of bins must be positive.\" << endl;\n        return -1;\n    }\n    \n    if (energy_min >= energy_max) {\n        cerr << \"ERROR: Invalid energy range: min >= max\" << endl;\n        return -1;\n    }\n    \n    if (duration <= 0.0) {\n        cerr << \"ERROR: Duration must be positive.\" << endl;\n        return -1;\n    }\n    \n    // Initialize variables for processing\n    vector<PolarEvent> events;\n    double t_end = t0 + duration;\n    \n    // Load mask weights if provided\n    bool useMaskWeight = false;\n    map<int, double> maskWeights;\n    if (!strMaskWeight.empty()) {\n        useMaskWeight = loadMaskWeights(strMaskWeight, maskWeights);\n    }\n    \n    // Load bad pixel information\n    map<int, bool> badPixels;\n    loadBadPixels(strBadPixFile, badPixels);\n    \n    // Process each input file and extract events\n    for (size_t i = 0; i < vecstrInputFiles.size(); i++) {\n        // Extract events from this file that match our criteria\n        vector<PolarEvent> fileEvents;\n        if (extractEvents(vecstrInputFiles[i], fileEvents, badPixels, maskWeights,\n                         ra, dec, t0, t_end, energy_min, energy_max, outdetector) == 0) {\n            // Add valid events to our master list\n            events.insert(events.end(), fileEvents.begin(), fileEvents.end());\n        }\n    }\n    \n    if (events.empty()) {\n        cerr << \"ERROR: No valid events found matching criteria.\" << endl;\n        return -1;\n    }\n    \n    cout << \"Total events for analysis: \" << events.size() << endl;\n    \n    // Perform polarization analysis\n    double modulation, modulation_err, angle, angle_err;\n    computePolarization(events, nbin, modulation, modulation_err, angle, angle_err);\n    \n    // Calculate polarization degree and error\n    double polarization_degree = modulation / modulationFactor * 100.0;\n    double polarization_degree_err = modulation_err / modulationFactor * 100.0;\n    \n    // Output results\n    cout << \"=== Polarization Results ===\" << endl;\n    cout << \"Modulation: \" << modulation << \" ± \" << modulation_err << endl;\n    cout << \"Polarization Angle: \" << angle << \" ± \" << angle_err << \" deg\" << endl;\n    cout << \"Polarization Degree: \" << polarization_degree << \" ± \" << polarization_degree_err << \" %\" << endl;\n    \n    // Write results to output file if requested\n    if (!strOutFile.empty()) {\n        writeResults(strOutFile, events, nbin, \n                    modulation, modulation_err, \n                    angle, angle_err, \n                    polarization_degree, polarization_degree_err);\n    }\n    \n    // Generate diagnostic plots if requested\n    if (isPlot) {\n        string plotFile = strOutFile;\n        if (plotFile.empty()) {\n            plotFile = strOutDir + \"polarization_plot.png\";\n        } else {\n            // Replace extension with .png\n            size_t dot = plotFile.find_last_of(\".\");\n            if (dot != string::npos) {\n                plotFile = plotFile.substr(0, dot) + \".png\";\n            } else {\n                plotFile += \".png\";\n            }\n        }\n        \n        generatePlot(events, nbin, modulation, angle, plotFile);\n    }\n    \n    return 0;\n}\n\n/**\n * Loads mask weights from a file\n * \n * @param weightFile Path to the mask weight file\n * @param weights Map to store pixel ID to weight mapping\n * @return true if weights were loaded successfully, false otherwise\n */\nbool PolarAlongWithAng::loadMaskWeights(const string& weightFile, map<int, double>& weights) {\n    ifstream infile(weightFile.c_str());\n    if (!infile.is_open()) {\n        cerr << \"ERROR: Could not open mask weight file: \" << weightFile << endl;\n        return false;\n    }\n    \n    weights.clear();\n    int pixid;\n    double weight;\n    \n    // Read pixel ID and weight pairs\n    while (infile >> pixid >> weight) {\n        weights[pixid] = weight;\n    }\n    \n    infile.close();\n    cout << \"Loaded \" << weights.size() << \" mask weights.\" << endl;\n    return !weights.empty();\n}\n\n/**\n * Loads bad pixel information from a file\n * \n * @param badPixFile Path to the bad pixel file\n * @param badPixels Map to store pixel ID to bad status mapping\n * @return true if bad pixels were loaded successfully, false otherwise\n */\nbool PolarAlongWithAng::loadBadPixels(const string& badPixFile, map<int, bool>& badPixels) {\n    // Open bad pixel file\n    fitsfile *fptr;\n    int status = 0;\n    \n    fits_open_file(&fptr, badPixFile.c_str(), READONLY, &status);\n    if (status) {\n        cerr << \"ERROR: Could not open bad pixel file: \" << badPixFile << endl;\n        fits_report_error(stderr, status);\n        return false;\n    }\n    \n    // Move to BADPIX extension\n    status = 0;\n    fits_movnam_hdu(fptr, BINARY_TBL, const_cast<char*>(\"BADPIX\"), 0, &status);\n    if (status) {\n        cerr << \"ERROR: Could not find BADPIX extension in file: \" << badPixFile << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return false;\n    }\n    \n    // Get number of rows\n    long nrows = 0;\n    status = 0;\n    fits_get_num_rows(fptr, &nrows, &status);\n    if (status) {\n        cerr << \"ERROR: Could not get number of rows in BADPIX extension\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return false;\n    }\n    \n    // Find column numbers\n    int pixidCol = 0, quadCol = 0, detidCol = 0, pixCol = 0;\n    status = 0;\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"PIXID\"), &pixidCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"QUADID\"), &quadCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"DETID\"), &detidCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"PIXID\"), &pixCol, &status);\n    \n    if (status) {\n        cerr << \"ERROR: Could not find required columns in BADPIX extension\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return false;\n    }\n    \n    // Read bad pixel data\n    vector<int> pixids(nrows);\n    status = 0;\n    fits_read_col(fptr, TINT, pixidCol, 1, 1, nrows, NULL, pixids.data(), NULL, &status);\n    if (status) {\n        cerr << \"ERROR: Could not read PIXID column from BADPIX extension\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return false;\n    }\n    \n    // Populate bad pixel map\n    badPixels.clear();\n    for (long i = 0; i < nrows; i++) {\n        badPixels[pixids[i]] = true;\n    }\n    \n    fits_close_file(fptr, &status);\n    cout << \"Loaded \" << badPixels.size() << \" bad pixels.\" << endl;\n    return true;\n}\n\n/**\n * Extracts polarization events from an event file\n * \n * @param eventFile Path to the event file\n * @param events Vector to store extracted events\n * @param badPixels Map of bad pixel IDs\n * @param maskWeights Map of pixel ID to weight mapping\n * @param ra Source right ascension in degrees\n * @param dec Source declination in degrees\n * @param t_start Start time for event selection\n * @param t_end End time for event selection\n * @param energy_min Minimum energy for events\n * @param energy_max Maximum energy for events\n * @param outdetector Detector ring radius to exclude\n * @return 0 on success, error code otherwise\n */\nint PolarAlongWithAng::extractEvents(const string& eventFile, \n                                vector<PolarEvent>& events,\n                                const map<int, bool>& badPixels,\n                                const map<int, double>& maskWeights,\n                                double ra, double dec,\n                                double t_start, double t_end,\n                                double energy_min, double energy_max,\n                                double outdetector) {\n    // Open event file\n    fitsfile *fptr;\n    int status = 0;\n    \n    fits_open_file(&fptr, eventFile.c_str(), READONLY, &status);\n    if (status) {\n        cerr << \"ERROR: Could not open event file: \" << eventFile << endl;\n        fits_report_error(stderr, status);\n        return -1;\n    }\n    \n    // Move to EVENTS extension\n    status = 0;\n    fits_movnam_hdu(fptr, BINARY_TBL, const_cast<char*>(\"EVENTS\"), 0, &status);\n    if (status) {\n        cerr << \"ERROR: Could not find EVENTS extension in file: \" << eventFile << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Get number of rows\n    long nrows = 0;\n    status = 0;\n    fits_get_num_rows(fptr, &nrows, &status);\n    if (status || nrows == 0) {\n        cerr << \"ERROR: Could not get number of rows in EVENTS extension or no events found\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Find column numbers\n    int timeCol = 0, energyCol = 0, detxCol = 0, detyCol = 0, pixidCol = 0;\n    int cztiCol = 0, detidCol = 0, pixXCol = 0, pixYCol = 0;\n    \n    status = 0;\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"TIME\"), &timeCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"ENERGY\"), &energyCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"DETX\"), &detxCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"DETY\"), &detyCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"PIXID\"), &pixidCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"CZTID\"), &cztiCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"DETID\"), &detidCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"PIX_X\"), &pixXCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"PIX_Y\"), &pixYCol, &status);\n    \n    if (status) {\n        cerr << \"ERROR: Could not find required columns in EVENTS extension\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Apply GTI filtering if specified\n    vector<pair<double, double>> gti;\n    if (aGTIExt > 0) {\n        readGTI(fptr, gti);\n    }\n    \n    // Read event data in chunks to manage memory\n    const long CHUNK_SIZE = 10000;\n    long remaining = nrows;\n    long offset = 1;\n    \n    while (remaining > 0) {\n        long chunk = min(CHUNK_SIZE, remaining);\n        \n        // Read columns\n        vector<double> time(chunk);\n        vector<float> energy(chunk);\n        vector<float> detx(chunk);\n        vector<float> dety(chunk);\n        vector<int> pixid(chunk);\n        vector<unsigned char> cztid(chunk);\n        vector<unsigned char> detid(chunk);\n        vector<unsigned char> pix_x(chunk);\n        vector<unsigned char> pix_y(chunk);\n        \n        status = 0;\n        fits_read_col(fptr, TDOUBLE, timeCol, offset, 1, chunk, NULL, time.data(), NULL, &status);\n        fits_read_col(fptr, TFLOAT, energyCol, offset, 1, chunk, NULL, energy.data(), NULL, &status);\n        fits_read_col(fptr, TFLOAT, detxCol, offset, 1, chunk, NULL, detx.data(), NULL, &status);\n        fits_read_col(fptr, TFLOAT, detyCol, offset, 1, chunk, NULL, dety.data(), NULL, &status);\n        fits_read_col(fptr, TINT, pixidCol, offset, 1, chunk, NULL, pixid.data(), NULL, &status);\n        fits_read_col(fptr, TBYTE, cztiCol, offset, 1, chunk, NULL, cztid.data(), NULL, &status);\n        fits_read_col(fptr, TBYTE, detidCol, offset, 1, chunk, NULL, detid.data(), NULL, &status);\n        fits_read_col(fptr, TBYTE, pixXCol, offset, 1, chunk, NULL, pix_x.data(), NULL, &status);\n        fits_read_col(fptr, TBYTE, pixYCol, offset, 1, chunk, NULL, pix_y.data(), NULL, &status);\n        \n        if (status) {\n            cerr << \"ERROR: Could not read event data\" << endl;\n            fits_report_error(stderr, status);\n            fits_close_file(fptr, &status);\n            return -1;\n        }\n        \n        // Process events in this chunk\n        for (long i = 0; i < chunk; i++) {\n            // Apply time filter\n            if (time[i] < t_start || time[i] > t_end) {\n                continue;\n            }\n            \n            // Apply GTI filter\n            if (!gti.empty() && !isInGTI(time[i], gti)) {\n                continue;\n            }\n            \n            // Apply energy filter\n            if (energy[i] < energy_min || energy[i] > energy_max) {\n                continue;\n            }\n            \n            // Apply bad pixel filter\n            if (badPixels.find(pixid[i]) != badPixels.end()) {\n                continue;\n            }\n            \n            // Calculate detector radius and apply radius filter\n            double dx = detx[i];\n            double dy = dety[i];\n            double detector_radius = sqrt(dx*dx + dy*dy);\n            \n            if (detector_radius > outdetector) {\n                continue;\n            }\n            \n            // Calculate phi angle (azimuthal angle)\n            double phi = atan2(dy, dx) * 180.0 / M_PI;\n            if (phi < 0) phi += 360.0;\n            \n            // Apply mask weight if available\n            double weight = 1.0;\n            if (!maskWeights.empty()) {\n                auto it = maskWeights.find(pixid[i]);\n                if (it != maskWeights.end()) {\n                    weight = it->second;\n                }\n            }\n            \n            // Create and store the event\n            PolarEvent evt;\n            evt.time = time[i];\n            evt.energy = energy[i];\n            evt.detx = detx[i];\n            evt.dety = dety[i];\n            evt.phi = phi;\n            evt.weight = weight;\n            evt.pixid = pixid[i];\n            evt.cztid = cztid[i];\n            evt.detid = detid[i];\n            evt.pix_x = pix_x[i];\n            evt.pix_y = pix_y[i];\n            \n            events.push_back(evt);\n        }\n        \n        // Move to next chunk\n        offset += chunk;\n        remaining -= chunk;\n    }\n    \n    fits_close_file(fptr, &status);\n    \n    cout << \"Extracted \" << events.size() << \" events from \" << eventFile << endl;\n    return 0;\n}\n\n/**\n * Reads Good Time Intervals from a FITS file\n * \n * @param fptr FITS file pointer\n * @param gti Vector to store start and end times of GTIs\n * @return 0 on success, error code otherwise\n */\nint PolarAlongWithAng::readGTI(fitsfile* fptr, vector<pair<double, double>>& gti) {\n    int status = 0;\n    int hdutype = 0;\n    \n    // Store current HDU position\n    int currentHDU = 0;\n    fits_get_hdu_num(fptr, &currentHDU);\n    \n    // Move to GTI extension\n    status = 0;\n    if (fits_movabs_hdu(fptr, aGTIExt, &hdutype, &status)) {\n        // GTI extension not found - try by name\n        status = 0;\n        if (fits_movnam_hdu(fptr, BINARY_TBL, const_cast<char*>(\"GTI\"), 0, &status)) {\n            // No GTI extension found - return empty GTI\n            gti.clear();\n            \n            // Move back to original HDU\n            status = 0;\n            fits_movabs_hdu(fptr, currentHDU, NULL, &status);\n            \n            return 0;\n        }\n    }\n    \n    // Get number of rows in GTI extension\n    long nrows = 0;\n    status = 0;\n    fits_get_num_rows(fptr, &nrows, &status);\n    if (status || nrows == 0) {\n        gti.clear();\n        \n        // Move back to original HDU\n        status = 0;\n        fits_movabs_hdu(fptr, currentHDU, NULL, &status);\n        \n        return 0;\n    }\n    \n    // Find column numbers for START and STOP\n    int startCol = 0, stopCol = 0;\n    status = 0;\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"START\"), &startCol, &status);\n    fits_get_colnum(fptr, CASEINSEN, const_cast<char*>(\"STOP\"), &stopCol, &status);\n    \n    if (status) {\n        cerr << \"ERROR: Could not find START/STOP columns in GTI extension\" << endl;\n        fits_report_error(stderr, status);\n        \n        // Move back to original HDU\n        status = 0;\n        fits_movabs_hdu(fptr, currentHDU, NULL, &status);\n        \n        return -1;\n    }\n    \n    // Read GTI data\n    vector<double> start(nrows);\n    vector<double> stop(nrows);\n    \n    status = 0;\n    fits_read_col(fptr, TDOUBLE, startCol, 1, 1, nrows, NULL, start.data(), NULL, &status);\n    fits_read_col(fptr, TDOUBLE, stopCol, 1, 1, nrows, NULL, stop.data(), NULL, &status);\n    \n    if (status) {\n        cerr << \"ERROR: Could not read GTI data\" << endl;\n        fits_report_error(stderr, status);\n        \n        // Move back to original HDU\n        status = 0;\n        fits_movabs_hdu(fptr, currentHDU, NULL, &status);\n        \n        return -1;\n    }\n    \n    // Store GTI intervals\n    gti.clear();\n    for (long i = 0; i < nrows; i++) {\n        gti.push_back(make_pair(start[i], stop[i]));\n    }\n    \n    // Move back to original HDU\n    status = 0;\n    fits_movabs_hdu(fptr, currentHDU, NULL, &status);\n    \n    cout << \"Read \" << gti.size() << \" GTI intervals\" << endl;\n    return 0;\n}\n\n/**\n * Checks if a time is within any Good Time Interval\n * \n * @param time Time to check\n * @param gti Vector of GTI start and end times\n * @return true if time is within a GTI, false otherwise\n */\nbool PolarAlongWithAng::isInGTI(double time, const vector<pair<double, double>>& gti) {\n    for (size_t i = 0; i < gti.size(); i++) {\n        if (time >= gti[i].first && time <= gti[i].second) {\n            return true;\n        }\n    }\n    return false;\n}\n\n/**\n * Computes polarization parameters from events\n * \n * @param events Vector of polarization events\n * @param nbin Number of azimuthal bins\n * @param modulation Output parameter for modulation amplitude\n * @param modulation_err Output parameter for modulation error\n * @param angle Output parameter for polarization angle\n * @param angle_err Output parameter for angle error\n * @return 0 on success, error code otherwise\n */\nint PolarAlongWithAng::computePolarization(const vector<PolarEvent>& events, int nbin,\n                                     double& modulation, double& modulation_err,\n                                     double& angle, double& angle_err) {\n    if (events.empty()) {\n        cerr << \"ERROR: No events for polarization analysis\" << endl;\n        return -1;\n    }\n    \n    // Create histogram of azimuthal angles\n    vector<double> phi_hist(nbin, 0.0);\n    vector<double> phi_err(nbin, 0.0);\n    double bin_width = 360.0 / nbin;\n    \n    // Fill histogram\n    for (size_t i = 0; i < events.size(); i++) {\n        int bin = int(events[i].phi / bin_width) % nbin;\n        phi_hist[bin] += events[i].weight;\n        phi_err[bin] += events[i].weight * events[i].weight; // For error calculation\n    }\n    \n    // Calculate errors (sqrt of sum of weights squared)\n    for (int i = 0; i < nbin; i++) {\n        phi_err[i] = sqrt(phi_err[i]);\n    }\n    \n    // Fit modulation curve: A + B*cos(2*(phi - phi0))\n    // We'll use the Fourier transform method to fit\n    \n    // Calculate average value (A term)\n    double avg = 0.0;\n    for (int i = 0; i < nbin; i++) {\n        avg += phi_hist[i];\n    }\n    avg /= nbin;\n    \n    // Calculate Fourier components\n    double a2 = 0.0; // cos(2*phi) term\n    double b2 = 0.0; // sin(2*phi) term\n    \n    for (int i = 0; i < nbin; i++) {\n        double phi = (i + 0.5) * bin_width * M_PI / 180.0; // bin center in radians\n        a2 += (phi_hist[i] - avg) * cos(2.0 * phi);\n        b2 += (phi_hist[i] - avg) * sin(2.0 * phi);\n    }\n    \n    a2 *= 2.0 / nbin;\n    b2 *= 2.0 / nbin;\n    \n    // Calculate modulation amplitude and phase\n    double B = sqrt(a2*a2 + b2*b2);\n    double phi0 = 0.5 * atan2(b2, a2) * 180.0 / M_PI;\n    \n    // Calculate errors using error propagation\n    // This is a simplified approach\n    double sum_squared_residuals = 0.0;\n    for (int i = 0; i < nbin; i++) {\n        double phi = (i + 0.5) * bin_width * M_PI / 180.0; // bin center in radians\n        double model = avg + B * cos(2.0 * (phi - phi0 * M_PI / 180.0));\n        double residual = phi_hist[i] - model;\n        sum_squared_residuals += residual * residual / (phi_err[i] * phi_err[i]);\n    }\n    \n    double reduced_chi_square = sum_squared_residuals / (nbin - 3); // 3 parameters: A, B, phi0\n    \n    // Calculate modulation = B/A\n    modulation = B / avg;\n    \n    // Calculate errors\n    // Simplified error estimation\n    modulation_err = modulation * sqrt(2.0 / events.size());\n    \n    // Convert polarization angle (phi0 is in the detector coordinate system)\n    // Polarization angle is perpendicular to the electric field direction\n    angle = phi0 + 90.0;\n    if (angle >= 180.0) angle -= 180.0;\n    \n    // Angle error - simplified approximation\n    angle_err = 28.65 * modulation_err / modulation;\n    \n    return 0;\n}\n\n/**\n * Writes polarization results to a FITS file\n * \n * @param outFile Output file path\n * @param events Vector of polarization events\n * @param nbin Number of azimuthal bins used\n * @param modulation Modulation amplitude\n * @param modulation_err Modulation error\n * @param angle Polarization angle\n * @param angle_err Angle error\n * @param pol_degree Polarization degree percentage\n * @param pol_degree_err Polarization degree error percentage\n * @return 0 on success, error code otherwise\n */\nint PolarAlongWithAng::writeResults(const string& outFile, \n                              const vector<PolarEvent>& events, int nbin,\n                              double modulation, double modulation_err,\n                              double angle, double angle_err,\n                              double pol_degree, double pol_degree_err) {\n    // Create output file\n    fitsfile *fptr;\n    int status = 0;\n    \n    // Remove file if it exists\n    unlink(outFile.c_str());\n    \n    // Create new file\n    status = 0;\n    if (fits_create_file(&fptr, outFile.c_str(), &status)) {\n        cerr << \"ERROR: Could not create output file: \" << outFile << endl;\n        fits_report_error(stderr, status);\n        return -1;\n    }\n    \n    // Create primary HDU\n    status = 0;\n    if (fits_create_img(fptr, BYTE_IMG, 0, NULL, &status)) {\n        cerr << \"ERROR: Could not create primary HDU\" << endl;\n        fits_report_error(stderr, status);\n        fits_close_file(fptr, &status);\n        return -1;\n    }\n    \n    // Add basic header keywords\n    char date[FLEN_VALUE];\n    fits_get_system_time(date, 0, &status);\n    \n    status = 0;\n    fits_update_key(fptr, TSTRING, const_cast<char*>(\"CREATOR\"), const_cast<char*>(\"CZTI_POLARALONGWITHANG\"), \n                  const_cast<char*>(\"Software that created this file\"), &status);\n    fits_update_key(fptr, TSTRING, const_cast<char*>(\"DATE\"), date, \n                  const_cast<char*>(\"File creation date\"), &status);\n    fits_update_key(fptr, TSTRING, const_cast<char*>(\"CONTENT\"), const_cast<char*>(\"POLARIZATION RESULTS\"), \n                  const_cast<char*>(\"File content\"), &status);\n    \n    // Add polarization results to header\n    status = 0;\n    fits_update_key(fptr, TDOUBLE, const_cast<char*>(\"MODULATN\"), &modulation, \n                  const_cast<char*>(\"Modulation amplitude\"), &status);\n    fits_update_key(fptr, TDOUBLE, const_cast<char*>(\"MODULERR\"), &modulation_err, \n                  const_cast<char*>(\"Modulation error\"), &status);\n    fits_update_key(fptr, TDOUBLE, const_cast<char*>(\"POLANGLE\"), &angle, \n                  const_cast<char*>(\"Polarization angle (deg)\"), &status);\n    fits_update_key(fptr, TDOUBLE, const_cast<char*>(\"POLANGERR\"), &angle_err, \n                  const_cast<char*>(\"Polarization angle error (deg)\"), &status);\n    fits_update_key(fptr, TDOUBLE, const_cast<char*>(\"POLDEGREE\"), &pol_degree, \n                  const_cast<char*>(\"Polarization degree (%)\"), &status);\n    fits_update_key(fptr, TDOUBLE, const_cast<char*>(\"POLDEGREEERR\"), &pol_degree_err, \n                  const_cast<char*>(\"Polarization degree error (%)\"), &status);\n    fits_update_key(fptr, TINT, const_cast<char*>(\"NUMBINS\"), &nbin, \n                  const_cast<char*>(\"Number of azimuthal bins\"), &status);\n    fits_update_key(fptr, TDOUBLE, const_cast<char*>(\"MODFACTOR\"), &modulationFactor, \n                  const_cast<char*>(\"Modulation factor used\"), &status);\n    \n    long numEvents = events.size();\n    fits_update_key(fptr, TLONG, const_cast<char*>(\"NUMEVENTS\"), &numEvents, \n                  const_cast<char*>(\"Number of events use",
    "establishing-an-effective-internal-wiki-|category|3": "Intern dokumentation"
}